["```py\n    import tensorflow as tf\n    ```", "```py\n    W = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[1, 6]) \n    W\n    ```", "```py\n    <tf.Tensor: shape=(1, 6), dtype=float32, numpy=array([[1., 2., 3., 4., 5., 6.]], dtype=float32)>\n    ```", "```py\n    X = tf.constant([7.0, 8.0, 9.0, 10.0, 11.0, 12.0], \\\n                    shape=[6, 1]) \n    X\n    ```", "```py\n    <tf.Tensor: shape=(6, 1), dtype=float32, numpy= \n    array([[ 7.],\n           [ 8.],\n           [ 9.],\n           [10.],\n           [11.],\n           [12.]], dtype=float32)>\n    ```", "```py\n    b = tf.constant(-88.0)\n    b\n    ```", "```py\n    <tf.Tensor: shape=(), dtype=float32, numpy=-88.0>\n    ```", "```py\n    mult = tf.matmul(W, X)\n    mult\n    ```", "```py\n    <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[217.]], dtype=float32)>\n    ```", "```py\n    Z = mult + b\n    Z\n    ```", "```py\n    <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[129.]], dtype=float32)>\n    ```", "```py\n    a = tf.math.sigmoid(Z)\n    a\n    ```", "```py\n    <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[1.]], dtype=float32)>\n    ```", "```py\nZ = W * X + b = x1*w1 + x2*w2 + x3*w3 + x4*w4 + b\n```", "```py\ny = f(Z) = f(x1*w1 + x2*w2 + x3*w3 + x4*w4 + b)\n```", "```py\ny = f(x1*w1 + x2*w2 + x3*w3 + x4*w4)\n```", "```py\ny = f(x1*w1 + x2*w2 + x3*w3 + x4*w4 + b)\ny = f(x  w + b)\n```", "```py\nfrom tensorflow.keras import layers\nlayer1 = layers.Dense(units=128, input_shape=[200])\n```", "```py\nfrom tensorflow.keras import layers\ninput_layer = layers.Flatten(input_shape=(28, 28))\nlayer1 = layers.Dense(units=128)\n```", "```py\nfrom tensorflow.keras import layers\nlayer1 = layers.Dense(units=128, input_shape=[200], \\\n                      activation='relu')\n```", "```py\n    import numpy as np\n    ```", "```py\n    def sigmoid(x): \n        return 1 / (1 + np.exp(-x))\n    ```", "```py\n    sigmoid(-1)\n    ```", "```py\n    0.2689414213699951\n    ```", "```py\n    import matplotlib.pyplot as plt\n    ```", "```py\n    x = np.arange(-10, 10, 0.1)\n    x\n    ```", "```py\n    array([-1.00000000e+01, -9.90000000e+00, -9.80000000e+00,\n           -9.70000000e+00, -9.60000000e+00, -9.50000000e+00,\n           -9.40000000e+00, -9.30000000e+00, -9.20000000e+00,\n           -9.10000000e+00, -9.00000000e+00, -8.90000000e+00,\n           -8.80000000e+00, -8.70000000e+00, -8.60000000e+00,\n           -8.50000000e+00, -8.40000000e+00, -8.30000000e+00,\n           -8.20000000e+00, -8.10000000e+00, -8.00000000e+00,\n           -7.90000000e+00, -7.80000000e+00, -7.70000000e+00,\n           -7.60000000e+00, -7.50000000e+00, -7.40000000e+00,\n           -7.30000000e+00, -7.20000000e+00, -7.10000000e+00,\n           -7.00000000e+00, -6.90000000e+00,\n    ```", "```py\n    plt.plot(x, sigmoid(x))\n    plt.show()\n    ```", "```py\n    def tanh(x): \n        return 2 / (1 + np.exp(-2*x)) - 1\n    ```", "```py\n    plt.plot(x, tanh(x))\n    plt.show()\n    ```", "```py\n    def relu(x):\n        return np.maximum(0, x)\n    ```", "```py\n    plt.plot(x, relu(x))\n    plt.show()\n    ```", "```py\n    def softmax(list): \n        return np.exp(list) / np.sum(np.exp(list))\n    ```", "```py\n    result = softmax( [0, 1, 168, 8, 2]) \n    result\n    ```", "```py\n    array([1.09276566e-73, 2.97044505e-73, 1.00000000e+00, \n           3.25748853e-70, 8.07450679e-73])\n    ```", "```py\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nmodel = tf.keras.Sequential()\ninput_layer = layers.Flatten(input_shape=(28,28))\nlayer1 = layers.Dense(128, activation='relu')\nmodel.add(input_layer)\nmodel.add(layer1)\n```", "```py\nimport tensorflow as tf\noptimizer = tf.keras.optimizers.Adam(0.001)\nmodel.compile(loss='sparse_categorical_crossentropy', \\\n              optimizer=optimizer, metrics=['accuracy'])\n```", "```py\nmodel.fit(features_train, label_train, epochs=5)\n```", "```py\nmodel.evaluate(features_test, label_test)\n```", "```py\n    from numpy import loadtxt\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop'\\\n               '/master/Datasets/german_scaled.csv'\n    ```", "```py\n    data = loadtxt(file_url, delimiter=',')\n    data\n    ```", "```py\n    array([[0\\.        , 0.33333333, 0.02941176, ..., 0\\.      , 1\\.      ,\n            1\\.        ],\n           [1\\.        , 0\\.        , 0.64705882, ..., 0\\.      , 0\\.      ,\n            1\\.        ],\n           [0\\.        , 1\\.        , 0.11764706, ..., 1\\.      , 0\\.      ,\n            1\\.        ],\n           ...,\n           [0\\.        , 1\\.        , 0.11764706, ..., 0\\.      , 0\\.      ,\n            1\\.        ],\n           [1\\.        , 0.33333333, 0.60294118, ..., 0\\.      , 1\\.      ,\n            1\\.        ],\n           [0\\.        , 0\\.        , 0.60294118, ..., 0\\.      , 0\\.      ,\n            1\\.        ]])\n    ```", "```py\n    label = data[:, 0]\n    ```", "```py\n    features = data[:, 1:]\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    features_train, features_test, \\\n    label_train, label_test = train_test_split(features, \\\n                                               label, \\\n                                               test_size=0.2, \\\n                                               random_state=7)\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(1)\n    tf.random.set_seed(1)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    layer1 = layers.Dense(16, activation='relu', \\\n                          input_shape=[19])\n    ```", "```py\n    final_layer = layers.Dense(1, activation='sigmoid')\n    ```", "```py\n    model.add(layer1)\n    model.add(final_layer)\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='binary_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(features_train, label_train, epochs=10)\n    ```", "```py\n    import pandas as pd\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop'\\\n               '/master/Datasets/boston_house_price.csv'\n    ```", "```py\n    df = pd.read_csv(file_url)\n    ```", "```py\n    df.head()\n    ```", "```py\n    label = df.pop('MEDV')\n    ```", "```py\n    from sklearn.preprocessing import scale\n    ```", "```py\n    scaled_features = scale(df)\n    scaled_features\n    ```", "```py\n    array([[-0.41978194,  0.28482986, -1.2879095 , ..., -0.66660821,\n            -1.45900038, -1.0755623 ],\n           [-0.41733926, -0.48772236, -0.59338101, ..., -0.98732948,\n            -0.30309415, -0.49243937],\n           [-0.41734159, -0.48772236, -0.59338101, ..., -0.98732948,\n            -0.30309415, -1.2087274 ],\n           ...,\n           [-0.41344658, -0.48772236,  0.11573841, ..., -0.80321172,\n             1.17646583, -0.98304761],\n           [-0.40776407, -0.48772236,  0.11573841, ..., -0.80321172,\n             1.17646583, -0.86530163],\n           [-0.41500016, -0.48772236,  0.11573841, ..., -0.80321172,\n    ```", "```py\n    from sklearn.model_selection import train_test_split\n    ```", "```py\n    features_train, features_test, \\\n    label_train, label_test = train_test_split(scaled_features, \\\n                                               label, \\\n                                               test_size=0.1, \\\n                                               random_state=8)\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    regularizer = tf.keras.regularizers.l1_l2(l1=0.1, l2=0.01)\n    ```", "```py\n    layer1 = layers.Dense(10, activation='relu', \\\n             input_shape=[12], kernel_regularizer=regularizer)\n    ```", "```py\n    final_layer = layers.Dense(1)\n    ```", "```py\n    model.add(layer1)\n    model.add(layers.Dropout(0.25))\n    model.add(final_layer)\n    ```", "```py\n    optimizer = tf.keras.optimizers.SGD(0.001)\n    ```", "```py\n    model.compile(loss='mse', optimizer=optimizer, \\\n                  metrics=['mse'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\n                                                patience=2)\n    ```", "```py\n    model.fit(features_train, label_train, \\\n              epochs=50, validation_split = 0.2, \\\n              callbacks=[callback], verbose=2)\n    ```", "```py\nfrom tensorflow.keras import layers\nlayers.Conv2D(32, kernel_size=(3, 3), strides=(1,1), \\\n              padding=\"valid\", activation=\"relu\")\n```", "```py\nfeatures_train.reshape(60000, 28, 28, 1)\n```", "```py\nfrom tensorflow.keras import layers\nlayers.MaxPool2D(pool_size=(2, 2), strides=2)\n```", "```py\n10000/10000 [==============================] - 1s 108us/sample - loss: 0.2746 - accuracy: 0.8976\n[0.27461639745235444, 0.8976]\n```", "```py\nfrom tensorflow.keras import layers\nlayers.SimpleRNN(4, activation='tanh')\n```", "```py\nfrom tensorflow.keras import layers\nlayers.GRU(4, activation='tanh', \\\n           recurrent_activation='sigmoid')\n```", "```py\nfrom tensorflow.keras import layers\nlayers.LSTM(4, activation='tanh', \\\n            recurrent_activation='sigmoid')\n```", "```py\n1000/1000 [==============================] - 0s 279us/sample - loss: 0.0016 - mse: 0.0016\n[0.00158528157370165, 0.0015852816]\n```"]