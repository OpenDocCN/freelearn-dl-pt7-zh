<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Ensemble Methods for Regression and Classification</h1>
                </header>
            
            <article>
                
<p>Advanced analytical tools are widely used by business enterprises in order to solve problems using data. The goal of analytical tools is to analyze data and extract relevant information that can be used to solve problems or increase performance of some aspect of the business. It also involves various machine learning algorithms with which we can create predictive models for better results.</p>
<p>In this chapter, we are going to explore a simple idea that can drastically improve the performance of basic predictive models.</p>
<p>We are going to cover the following topics in this chapter:</p>
<ul>
<li>Ensemble methods and their working</li>
<li>Ensemble methods for regression</li>
<li>Ensemble methods for classification</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ensemble methods and their working</h1>
                </header>
            
            <article>
                
<p>Ensemble methods are based on a very simple idea: instead of using a single model to make a prediction, we use many models and then use some method to <strong>aggregate</strong> the predictions. Having different models is like having different points of view, and it has been demonstrated that by aggregating models that offer a different point of view; predictions can be more accurate. These methods further improve generalization over a single model because they reduce the risk of selecting a poorly performing classifier:</p>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign"><img src="assets/7ea084f3-b32d-4323-b493-cce263e07286.png" style="width:43.42em;height:42.58em;"/></div>
<p>In the preceding diagram, we can see that each object belongs to one of three classes: triangles, circles, and squares. In this simplified example, we have two features to separate or classify the objects into the different classes. As you can see here, we can use three different classifiers and all the three classifiers represent different approaches and have different kinds of decision boundaries.</p>
<p>Ensemble learning combines all those individual predictions into a single one. The predictions made from combining the three boundaries usually have better properties than the ones produced by the individual models. This is the simple idea behind ensemble methods, also called <strong>ensemble learning</strong>.</p>
<p>The most commonly used ensemble methods are as follows:</p>
<ul>
<li>Bootstrap sampling</li>
<li>Bagging</li>
<li>Random forests</li>
<li>Boosting</li>
</ul>
<p>Before giving a high-level explanation of these methods, we need to discuss a very important statistical technique known as <strong>bootstrap sampling</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bootstrap sampling</h1>
                </header>
            
            <article>
                
<p>Many ensemble learning methods use a statistical technique called bootstrap sampling. A bootstrap sample of a dataset is another dataset that's obtained by randomly sampling the observations from the original dataset <em>with replacement</em>.</p>
<p>This technique is heavily used in statistics, for example; it is used for estimating standard errors on sample statistics like mean or standard deviation of values.</p>
<p>Let's understand this technique more by taking a look at the following diagram:</p>
<div class="packt_figure packt_figref CDPAlignCenter CDPAlign"><img src="assets/2fedfc25-71ae-4f2f-a64c-488eb2c170a9.png" style="width:29.83em;height:10.67em;"/></div>
<p>Let's assume that we have a population of 1 to 10, which can be considered original population data. To get a bootstrap sample, we need to draw 10 samples from the original data with replacement. Imagine you have the 10 numbers written in 10 cards in a hat; for the first element of your sample, you take one card at random from the hat and write it down, then put the card back in the hat and this process goes on until you get 10 elements. This is your bootstrap sample. As you can see in the preceding example, <strong>9</strong> is repeated thrice in the bootstrap sample.</p>
<p class="mce-root">This resampling of numbers with replacement improves the accuracy of the true population data. It also helps in understanding various discrepancies and features involved in the resampling process, thereby increasing accuracy of the same.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bagging</h1>
                </header>
            
            <article>
                
<p>Bagging, also known as bootstrap aggregation, is a general purpose procedure for reducing variance in the machine learning model. It is based on the bootstrap sampling technique and is generally used with regression or classification trees, but in principle this bagging technique can be used with any model.</p>
<p>The following steps are involved in the bagging process:</p>
<ol>
<li>We choose the number of estimators or individual models to use. Let's consider this as parameter B.</li>
<li>We take sample datasets from B with replacement using the bootstrap sampling from the training set.</li>
<li>For every one of these training datasets, we fit the machine learning model in each of the bootstrap samples. This way, we get individual predictors for the B parameter.</li>
<li>We get the ensemble prediction by aggregating all of the individual predictions.</li>
</ol>
<p>In the regression problem, the most common way to get the ensemble prediction would be to find the average of all of the individual predictions.</p>
<p>In the classification problem, the most common way to get the aggregated predictions is by doing a majority vote. The majority vote can be explained by an example. Let's say that we have 100 individual predictors and 80 of them vote for one particular category. Then, we choose that category as our aggregated prediction. This is what a majority vote means.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forests</h1>
                </header>
            
            <article>
                
<p>This ensemble method is specifically created for regression or classification trees. It is very similar to bagging since, here, each individual tree is trained on a bootstrap sample of the training dataset. The difference with bagging is that it makes the model very powerful, and on splitting a node from the tree, the split that is picked is the best among a random subset of the features. So, every individual predictor considers a random subset of the features. This has the effect of making each individual predictor slightly worse and more biased but, due to the correlation of the individual predictors, the overall ensemble is generally better than the individual predictors.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Boosting</h1>
                </header>
            
            <article>
                
<p>Boosting is another approach to ensemble learning. There are many methods for boosting, but one of the most successful and popular methods that people use for ensemble learning has been the <strong>AdaBoost</strong> algorithm. It is also called <strong>adaptive boosting</strong>. The core idea behind this algorithm is that, instead of fitting many individual predictors individually, we fit a sequence of weak learners. The next algorithm depends on the result of the previous one. In the AdaBoost algorithm, every iteration reweights all of these samples. The training data here reweights based on the result of the previous individual learners or individual models.</p>
<p>For example, in classification, the basic idea is that the examples that are misclassified gain weight and the examples that are classified correctly lose weight. So, the next learner in the sequence or the next model in the sequence focuses more on misclassified examples.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Ensemble methods for regression</h1>
                </header>
            
            <article>
                
<p>Regarding regression, we will train these different models and later compare their results. In order to test all of these models, we will need a sample dataset. We are going to use this in order to implement these methods on the given dataset and see how this helps us with the performance of our models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The diamond dataset</h1>
                </header>
            
            <article>
                
<p>Let's make actual predictions about diamond prices by using different ensemble learning models. We will use a diamonds dataset(which can be found here: <a href="https://www.kaggle.com/shivam2503/diamonds">https://www.kaggle.com/shivam2503/diamonds</a>). This dataset has the prices, among other features, of almost 54,000 diamonds. The following are the features that we have in this dataset:</p>
<ul>
<li><strong>Feature information</strong>: A dataframe with 53,940 rows and 10 variables</li>
<li><strong>Price</strong>:<span> Price in US dollars</span></li>
</ul>
<p>The following are the nine predictive features:</p>
<ul>
<li><kbd>carat</kbd>: This feature represents weight of the diamond (0.2-5.01)</li>
<li><kbd>cut</kbd>: <span>This feature represents q</span>uality of the cut (<kbd>Fair</kbd>, <kbd>Good</kbd>, <kbd>Very Good</kbd>, <kbd>Premium</kbd>, and <kbd>Ideal</kbd>)</li>
<li><kbd>color</kbd>: <span>This feature represents d</span>iamond color, from <kbd>J</kbd> (worst) to <kbd>D</kbd> (best)</li>
<li><kbd>clarity</kbd>: <span>This feature represents a</span> measurement of how clear the diamond is (<kbd>I1</kbd> (worst), <kbd>SI2</kbd>, <kbd>SI1</kbd>, <kbd>VS2</kbd>, <kbd>VS1</kbd>, <kbd>VVS2</kbd>, <kbd>VVS1</kbd>, <kbd>IF</kbd> (best))</li>
<li><kbd>x</kbd>: <span>This feature represents l</span>ength of diamond in mm (0-10.74)</li>
<li><kbd>y</kbd>: <span>This feature represents w</span>idth of diamond in mm (0-58.9)</li>
<li><kbd>z</kbd>: <span>This feature represents d</span>epth of diamond in mm (0-31.8)</li>
<li><kbd>depth</kbd>: <span>This feature represents </span>z/mean(x, y) = 2 * z/(x + y) (43-79)</li>
<li><kbd>table</kbd>: <span>This feature represents w</span>idth of the top of the diamond relative to the widest point (43-95)</li>
</ul>
<p>The <kbd>x</kbd>, <kbd>y</kbd>, and <kbd>z</kbd> variables denote the size of the diamonds.</p>
<p>The libraries that we will use are <kbd>numpy</kbd>, <kbd>matplotlib</kbd>, and <kbd>pandas</kbd>. For importing these libraries, the following lines of code can be used:</p>
<pre>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>%matplotlib inline</pre>
<p class="mce-root"/>
<p>The following screenshot shows the lines of code that we use to call the raw dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/744cd5bf-030d-4c57-9858-8f8ea652dee5.png" style="width:39.00em;height:27.83em;"/></p>
<p>The preceding dataset has some numerical features and some categorical features. Here, 53,940 is the exact number of samples that we have in this dataset. Now, for encoding the information in these categorical features, we use the one-hot encoding technique to transform these categorical features into dummy features. The reason behind this is because <kbd>scikit-learn</kbd> only works with numbers.</p>
<p>The following screenshot shows the lines of code used for the transformation of the categorical features to numbers:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3b9400c6-af95-46f0-9950-b791d06199ca.png"/></p>
<p>Here, we can see how we can do this with the <kbd>get_dummies</kbd> function from <kbd>pandas</kbd>. The final dataset looks similar to the one in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7bb25e6e-cf8d-4f81-bca4-b6424662d894.png"/></p>
<p class="mce-root"/>
<p>Here, for each of the categories in the categorical variable, we have dummy features. The value here is <kbd>1</kbd> when the category is present and <kbd>0</kbd> when the category is not present in the particular diamond.</p>
<p>Now, for rescaling the data, we will use the <kbd>RobustScaler</kbd> method to transform all the features to a similar scale. </p>
<p>The following screenshot shows the lines of code used for importing the <kbd>train_test_split</kbd> function and the <kbd>RobustScaler</kbd> method:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f0f42b97-e3c0-415a-b423-f8cf1299ecf6.png"/></p>
<p><span><span>Here,</span></span> we extract the features in the <kbd>X</kbd> matrix, mention the target, and then use the <kbd>train_test_split</kbd> function from <kbd>scikit-learn</kbd> to partition the data into two sets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training different regression models</h1>
                </header>
            
            <article>
                
<p>The following screenshot shows the dataframe that we will use to record the metrics and the performance metrics that we will use for these models. Since this is a regression task, we will use the mean squared error. Here, in the columns, we have the four models that we will use. We will be using the <kbd>KNN</kbd>, <kbd>Bagging</kbd>, <kbd>RandomForest</kbd>, and <kbd>Boosting</kbd> variables:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7372d44f-c895-45b9-8bce-e90ee96cd9a7.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">KNN model</h1>
                </header>
            
            <article>
                
<p><span>The <strong>K-Nearest Neighbours</strong> (<strong>KNN</strong>) model </span>is not an ensemble learning model, but it performs the best among the simple models:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/49b9ce91-a006-4b09-b2e9-021e1ca3a76e.png"/></p>
<p>In the preceding model, we can see the process used while making a KNN. We will use 20 neighbors. We are using the <kbd>euclidean</kbd> metric to measure the distances between the points, and then we will train the model. Here, the performance metric is saved since the value is just <kbd>1</kbd>, which is the mean squared error.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bagging model</h1>
                </header>
            
            <article>
                
<p>Bagging is an ensemble learning model. Any estimator can be used with the bagging method. So, let's take a case where we use KNN, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6e77b966-f186-47b0-a62d-df853ab1477c.png"/></p>
<p>Using the <kbd>n_estimators</kbd> parameter, we can produce an ensemble of 15 individual estimators. As a result, this will produce 15 bootstrap samples of the training dataset, and then, in each of these samples, it will fit one of these KNN regressors with 20 neighbors. In the end, we will get the individual predictions by using the bagging method. The method that this algorithm uses for giving individual predictions is a majority vote.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forests model</h1>
                </header>
            
            <article>
                
<p>Random forests is another ensemble learning model. Here, we get all the ensemble learning objects from the <kbd>ensemble</kbd> submodule in <kbd>scikit-learn</kbd>. For example, here, we use the <kbd>RandomForestRegressor</kbd> method. The following screenshot, shows the algorithm used for this model:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e9a128fc-153c-45ba-baeb-6497cbb42d7b.png"/></p>
<p>So, in a case where we produce a forest of 50 individual predictors, this algorithm will produce 50 individual trees. Each tree will have <kbd>max_depth</kbd> of <kbd>16</kbd>, which will then produce the individual predictions again by majority vote.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Boosting model</h1>
                </header>
            
            <article>
                
<p>Boosting is also an ensemble learning model. Here, we are using the <kbd>AdaBoostRegressor</kbd> model, and we will again produce <kbd>50</kbd> estimators. The following screenshot shows the algorithm used for this model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a8b9a936-0158-41a2-a251-428a10e3d4e2.png"/></p>
<p>The following screenshot shows the <kbd>train_mse</kbd> and <kbd>test_mse</kbd> results that we get after training all these models:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c9526e11-4aca-41c5-b379-5886696eb13a.png" style="width:37.17em;height:10.58em;"/></p>
<p>The following screenshot shows the algorithm and gives the comparison of all of these models on the basis of the values of the test mean squared error. The result is shown with the help of a horizontal bar graph:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/12d93d64-a55f-4309-b819-93c9523166cf.png"/></p>
<p>Now, when we compare the result of all of these models, we can see that the random forest model is the most successful. The bagging and KNN models come second and third, respectively. This is why we use the KNN model with the bagging model.</p>
<p>The following screenshot shows the algorithm used to produce a graphical representation between the predicted prices and the observed prices while testing the dataset, and also shows the performance of the random forest model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/89828296-8384-4cf6-98be-298ad1722860.png"/></p>
<p>On using this model again with a <kbd>predict</kbd> API or with a <kbd>predict</kbd> method, we can get individual predictions.</p>
<p>For example, let's predict the values for the first ten predictions that we get from the testing dataset. The following algorithm shows the prediction that is made by this random forest model, which in turns shows us the real price and the predicted price of the diamonds that we have from the testing dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fe7c964b-d9ad-4610-8191-f77921c308d7.png" style="width:39.50em;height:21.67em;"/></p>
<p>From this screenshot, we can see that the values for <kbd>Real price</kbd> and <kbd>Predicted price</kbd> are very close, both for the expensive and inexpensive diamonds.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using ensemble methods for classification</h1>
                </header>
            
            <article>
                
<p>We are now familiar with the basic concept of ensemble learning and ensemble methods. Now, we will actually put these methods into use in building models using various machine learning algorithms and compare the results generated by them. To actually test all of these methods, we will need a sample dataset in order to implement these methods on the given dataset and see how this helps us with the performance of our models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Predicting a credit card dataset </h1>
                </header>
            
            <article>
                
<p>Let's take an example of a credit card dataset. This dataset comes from a financial institution in Taiwan and can be found here: <a href="https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset">https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset</a>. Take a look at the following screenshot, which shows you the dataset's information and its features:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4843c2d6-cf4e-4e11-8f8f-8f0707ac43b8.png"/></p>
<p>Here, we have the following detailed information about each customer:</p>
<ul>
<li>It contains the limit balance, that is, the credit limit provided to the customer that is using the credit card</li>
<li>Then, we have a few features regarding personal information about each customer, such as gender, education, marital status, and age </li>
<li>We also have a history of past payments</li>
<li>We also have the bill statement's amount</li>
<li>We have the history of the bill's amount and previous payment amounts from the previous month up to six months prior, which was done by the customer</li>
</ul>
<p>With this information, we are going to predict next month's payment status of the customer. We will first do a little transformation on these features to make them easier to interpret.</p>
<p>In this case, the positive class will be the default, so the number 1 represents the customers that fall under the default status category and the number 0 represents the customers who have paid their credit card dues.</p>
<p>Now, before we start, we need to import the required libraries by running a few commands, as shown in the following code snippet:</p>
<pre>import numpy as np<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>%matplotlib inline</pre>
<p>The following screenshot shows the line of code that was used to prepare the credit card dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fe6dbac4-e195-481e-8831-add56f69a0de.png"/></p>
<p>Let's produce the dummy feature for education in <kbd>grad _school</kbd>, <kbd>university</kbd>, and <kbd>high_school</kbd>. Instead of using the word sex, use the <kbd>male</kbd> dummy feature, and instead of using marriage, let's use the <kbd>married</kbd> feature. This feature is given value of 1 when the person is married, and 0 otherwise. For the <kbd>pay_1</kbd> feature, we will do a little simplification process. If we see a positive number here, it means that the customer was late in his/her payments for <kbd>i</kbd> months. This means that this customer with an <kbd>ID</kbd> of 1 delayed the payment for the first two months. We can see that, 3 months ago, he/she was not delayed on his/her payments. This is what the dataset looks like:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f4ab3d2e-f4b8-4deb-a55d-80d918758c2d.png"/></p>
<p>Before fitting our models, the last thing we will do is rescale all the features because, as we can see here, we have features that are in very different scales. For example, <kbd>limit_bal</kbd> is in a very different scale than <kbd>age</kbd>.</p>
<p>This is why we will be using the <kbd>RobustScaler</kbd> method from <kbd>scikit-learn</kbd>—to try and transform all the features to a similar scale:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a7a7c24d-f772-4668-8a3c-cfd8d7bb559c.png"/></p>
<p>As we can see in the preceding screenshot in the last line of code, we are partitioning our dataset into a training set and a testing set and below that, the <kbd>CMatrix</kbd> function is used to print the confusion matrix for each model. This function is explained in the following code snippet:</p>
<pre>def CMatrix(CM, labels=['pay', 'default']):<br/>    df = pd.DataFrame(data=CM, index=labels, columns=labels)<br/>    df.index.name='TRUE'<br/>    df.columns.name='PREDICTION'<br/>    df.loc['Total'] = df.sum()<br/>    df['Total'] = df.sum(axis=1)<br/>    return df</pre>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training different regression models</h1>
                </header>
            
            <article>
                
<p>The following screenshot shows a dataframe where we are going to save performance. We are going to run four models, namely logistic regression, bagging, random forest, and boosting:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c745a454-b945-46c8-9d98-ab5ee3142f24.png"/></p>
<p>We are going to use the following evaluation metrics in this case:</p>
<ul>
<li><kbd>accuracy</kbd>: This metric measures how often the model predicts defaulters and non-defaulters correctly</li>
<li><kbd>precision</kbd>: This <span>metric </span>will be when the model predicts the default and how often the model is correct</li>
<li><kbd>recall</kbd>: This <span>metric </span>will be the proportion of actual defaulters that the model will correctly predict</li>
</ul>
<p>The most important of these is the <kbd>recall</kbd> metric. The reason behind this is that we want to maximize the proportion of actual defaulters that the model identifies, and so the model with the best recall is selected.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Logistic regression model</h1>
                </header>
            
            <article>
                
<p>As in <kbd>scikit-learn</kbd>, we just import the object and then instantiate the estimator, and then pass training set <kbd>X</kbd> and training set <kbd>Y</kbd> to the <kbd>fit()</kbd> method. First, we will predict the test dataset and then produce the accuracy, precision, and recall scores. The following screenshot shows the code and the confusion matrix as the output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/6d069752-6b15-482d-9354-c6589c2ca984.png"/></p>
<p>Later, we will save these into our <kbd>pandas</kbd> dataframe that we just created.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Bagging model</h1>
                </header>
            
            <article>
                
<p>Training the bagging model using methods from the ensemble learning techniques involves importing the bagging classifier with the logistic regression methods. For this, we will fit 10 of these logistic regression models and then we will combine the 10 individual predictions into a single prediction using bagging. After that, we will save this into our metrics dataframe.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following screenshot shows the code and the confusion matrix as the output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/84e409fc-7e30-4321-8f88-57c0926c643c.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Random forest model</h1>
                </header>
            
            <article>
                
<p>To perform classification with the random forest model, we have to import the <kbd>RandomForestClassifier</kbd> method. For example, let's take 35 individual trees with a <kbd>max_depth</kbd> of <kbd>20</kbd> for each tree. The <kbd>max_features</kbd> parameter tells <kbd>scikit-learn</kbd> that, when deciding upon the best split among possible features, we should use the square root of the total number of features that we have. These are all hyperparameters that we can tune.</p>
<p>The following screenshot shows the code and the confusion matrix as the output:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/667a44c8-3ce3-4e59-964b-1263b7b0b470.png"/></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Boosting model</h1>
                </header>
            
            <article>
                
<p>In classification with the boosting model, we'll use the <kbd>AdaBoostClassifier</kbd> object. Here, we'll also use <kbd>50</kbd> estimators to combine the individual predictions. The learning rate that we will use here is <kbd>0.1</kbd>, which is another hyperparameter for this model.</p>
<p>The following screenshot shows the code and the confusion matrix:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4b51908b-ba6c-4b3a-adc8-0a8728badee8.png"/></p>
<p>Now, we will compare the four models as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/f880f3a8-3521-4ee4-a837-7277b036abb9.png" style="width:33.58em;height:12.25em;"/></p>
<p>The preceding screenshot shows the similar accuracies for the four models, but the most important metric for this particular application is the <kbd>recall</kbd> metric.</p>
<p>The following screenshot shows that the model with the best recall and accuracy is the random forest model:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7505e831-8e35-4fb1-b5a2-ba85059cb6e7.png"/></p>
<p>The preceding screenshot proves that the random forest model is better than the other models overall.</p>
<p>To see the relationship between <kbd>precision</kbd>, <kbd>recall</kbd>, and <kbd>threshold</kbd>, we can use the <kbd>precision_recall_curve</kbd> function from <kbd>scikit-learn</kbd>. Here, pass the predictions and the real observed values, and the result we get consists of the objects that will allow us to produce the<span><span> <span>code for the </span><kbd>precision_recall_curve</kbd><span> function.</span></span></span></p>
<p>The following screenshot shows the code for the <kbd>precision_recall_curve</kbd> function from <kbd>scikit-learn</kbd>:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e302b9c0-37ad-41fb-ba88-8fd8b9ebd89e.png"/></p>
<p>The following screenshot will now visualize the relationship between precision and recall when using the random forest model and the logistic regression model:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/480e2a82-f60d-4756-8889-a7dacaf3e7f7.png"/></p>
<p>The preceding screenshot shows that the random forest model is better because it is above the logistic regression curve. So, for a precision of <kbd>0.30</kbd>, we get more recall with the random forest model than the logistic regression model.</p>
<p>To see the performance of the <kbd>RandomForestClassifier</kbd> method, we change the classification threshold. For example, we set a classification threshold of <kbd>0.12</kbd>, so we will get a precision of <kbd>30</kbd> and a recall of <kbd>84</kbd>. This model will correctly predict <span class="packt_screen">84% </span>of the possible defaulters, which <span>will be very useful </span>for a financial institution. This shows that the boosting model is better than the logistic regression model for this.</p>
<p>The following screenshot shows the code and the confusion matrix:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/251c8b59-4160-4ffe-821f-185c7b13f6ae.png"/></p>
<p class="mce-root"/>
<p>Feature importance is something very important that we get while using a random forest model. The <kbd>scikit-learn</kbd> library calculates this metric of feature importance for each of the features that we use in our model. The internal calculation allows us to get a metric for the importance of each feature in the predictions.</p>
<p>The following screenshot shows the visualization of these features, hence highlighting the importance of using a <kbd>RandomForestClassifier</kbd> method:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/731b8ad3-d783-4308-a3a7-a442087ee7ee.png"/></p>
<p>The most important feature for predicting whether the customer will default next month or whether the customer defaulted the month before is <kbd>pay_1</kbd>. Here, we just have to verify whether the customer paid last month or not. The other important features of this model are the bill amounts of two months, while the other feature in terms of importance is age.</p>
<p>The features that are not important for predicting the target are gender, marital status, and the education level of the customer.</p>
<p>Overall, the random forest model has proved to be better than the logistic regression model.</p>
<div class="packt_infobox">According to the no free lunch theorem, there is no single model that works best for every problem in every dataset. This means that ensemble learning cannot always outperform simpler methods because sometimes simpler methods perform better than complex methods. So, for every machine learning problem, we must use simple methods over complex methods and then evaluate the performance of both approaches to get the best results.</div>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we introduced different ensemble methods such as bootstrap sampling, bagging, random forest, and boosting, and their working was explained with the help of some examples. We then used them for regression and classification. For regression, we took the example of a diamond dataset, and we also trained some KNN and other regression models. Later, their performance was compared. For classification, we took the example of a credit card dataset. Again, we trained all of the regression models. We compared their performance, and we found that the random forest model was the best performer.</p>
<p>In the next chapter, we will study k-fold cross-validation and parameter tuning. We will compare different ensemble learning models with k-fold cross-validation and later, we'll use k-fold cross-validation for hyperparameter tuning.</p>


            </article>

            
        </section>
    </body></html>