- en: The History of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **Artificial Intelligence** (**AI**) carries a great deal of weight.
    AI has benefited from over 70 years of research and development. The history of
    AI is varied and winding, but one ground truth remains – tireless researchers
    have worked through funding growths and lapses, promise and doubt, to push us
    toward achieving ever more realistic AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin, let''s weed through the buzzwords and marketing and establish
    what AI really is. For the purposes of this book, we will rely on this definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '*AI is a system or algorithm that allows computers to perform tasks without
    explicitly being programmed to do so.*'
  prefs: []
  type: TYPE_NORMAL
- en: AI is an interdisciplinary field. While we'll focus largely on utilizing deep
    learning in this book, the field also encompasses elements of robotics and IoT,
    and has a strong overlap (if it hasn't consumed it yet) with generalized natural
    language processing research. It's also intrinsically linked with fields such
    as **Human**-**Computer Interaction** (**HCI**) as it becomes increasingly important
    to integrate AI with our lives and the modern world around us.
  prefs: []
  type: TYPE_NORMAL
- en: AI goes through waves, and is bound to go through another (perhaps smaller)
    wave in the future. Each time, we push the limits of AI with the computational
    power that is available to us, and research and development stops. This day and
    age may be different, as we benefit from the confluence of increasingly large
    and efficient data stores, rapid fast and cheap computing power, and the funding
    of some of the most profitable companies in the world. To understand how we ended
    up here, let's start at the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The beginnings of AI – 1950–1974
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rebirth – 1980–1987
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The modern era takes hold – 1997–2005
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deep learning and the future – 2012–Present
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The beginnings of AI –1950–1974
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since some of the earliest mathematicians and thinkers, AI has been a long sought
    after concept. The ancient Greeks developed myths of the *automata*, a form of
    robot that would complete tasks for the Gods that they considered menial, and
    throughout early history thinkers pondered what it meant to human, and if the
    notion of human intelligence could be replicated. While it's impossible to pinpoint
    an exact beginning for AI as a field of research, its development parallels the
    early advances of computer science. One could argue that computer science as a
    field developed out of this early desire to create self-thinking machines.
  prefs: []
  type: TYPE_NORMAL
- en: During the second world war, British mathematician and code breaker Alan Turing
    developed ...
  prefs: []
  type: TYPE_NORMAL
- en: Rebirth –1980–1987
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The 1980s saw the birth of deep learning, the brain of AI that has become the
    focus of most modern AI research. With the revival of neural network research
    by John Hopfield and David Rumelhart, and several funding initiatives in Japan,
    the United States, and the United Kingdom, AI research was back on track.
  prefs: []
  type: TYPE_NORMAL
- en: In the early 1980s, while the United States was still toiling from the effects
    of the AI Winter, Japan was funding the fifth generation computer system project
    to advance AI research. In the US, DARPA once again ramped up funding for AI research,
    with business regaining interest in AI applications. IBM's T.J. Watson Research
    Center published a statistical approach to language translation ([https://aclanthology.info/pdf/J/J90/J90-2002.pdf](https://aclanthology.info/pdf/J/J90/J90-2002.pdf)),
    which replaced traditional rule-based NLP models with probabilistic models, the shepherding
    in the modern era of NLP.
  prefs: []
  type: TYPE_NORMAL
- en: Hinton, the student from the University of Cambridge who persisted in his research,
    would make a name for himself by coining the term **deep learning**. He joined
    forces with Rumelhart to become one of the first researchers to introduce the
    backpropagation algorithm for training ANNs, which is the backbone of all of modern
    deep learning. Hinton, like many others before him, was limited by computational
    power, and it would take another 26 years before the weight of his discovery was
    really felt.
  prefs: []
  type: TYPE_NORMAL
- en: By the late 1980s, the personal computing revolution and missed expectations
    threatened the field. Commercial development all but came to a halt, as mainframe
    computer manufacturers stopped producing hardware that could handle AI-oriented
    languages, and AI-oriented mainframe manufacturers went bankrupt. It had seemed
    as if all had come to a standstill.
  prefs: []
  type: TYPE_NORMAL
- en: The modern era takes hold – 1997-2005
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI further entered the public discourse in 1997 when IBM's Deep Blue system
    beat world champion chess grandmaster Garry Kasparov. Within a year, a former
    student of Geoffrey Hinton's, Yann LeCun, developed the Convolutional Neural Network
    at Bell Labs, which was enabled by the backpropagation algorithm and years of
    research into computer vision tasks. Hochreiter and Schmidhuber invented the first
    memory unit, the **long short**-**term memory unit** (**LSTM**), which is still
    used today for sequence modeling.
  prefs: []
  type: TYPE_NORMAL
- en: ANNs still had a way to go. Computing and storage limitations prevented these
    networks from scaling, and other methods such as **support vector machines** (**SVMs**)
    were developed as alternatives.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning and the future – 2012-Present
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI has made further strides in the past several years than in the 60-odd years
    since its birth. Its popularity has further been fueled by the increasingly public
    nature of its benefits – self-driving cars, personal assistants, and its ever-ubiquitous
    use in social media and advertising. For most of its history, AI was a field with
    little interaction with the average populace, but now it's come to the forefront
    of international discourse.
  prefs: []
  type: TYPE_NORMAL
- en: 'Today''s age of AI has been the result of three trends:'
  prefs: []
  type: TYPE_NORMAL
- en: The increasing amount of data and computing power available to AI researchers
    and practitioners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ongoing research by Geoffrey Hinton and his lab at the University of Toronto
    into deep neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increasingly public applications of AI that have driven adoption and further
    acceptance into mainstream technology culture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Today, companies, governments, and other organizations have benefited from the
    big data revolution of the mid 2000s, which has brought us a plethora of data
    stores. At last, AI applications have the requisite data to train. Computational
    power is cheap and only getting cheaper.
  prefs: []
  type: TYPE_NORMAL
- en: On the research front, in 2012, Hinton and two of his students were finally
    able to show that deep neural networks were able to outperform all other methods
    in image recognition in the large-scale visual recognition challenge. The modern
    era of AI was born.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly enough, Hinton's team's work on computer vision also introduced
    the idea of utilizing **Graphics Processing Units** (**GPUs**) to train deep networks.
    It also introduced dropout and ReLu, which have become cornerstones of deep learning.
    We'll discuss these in the coming chapters. Today, Hinton is the most cited AI
    researcher on the planet. He is a lead data scientist at Google Brain and has
    been tied to many major developments in AI in the modern era.
  prefs: []
  type: TYPE_NORMAL
- en: 'AI was further thrown into the public sphere when, in 2011, IBM Watson defeated
    the world Jeopardy champions, and in 2016 Google''s AlphaGo defeated the world
    grand champion at one of the most challenging games known to man: Go.'
  prefs: []
  type: TYPE_NORMAL
- en: Today, we are closer than ever to having machines that can pass the Turing test.
    Networks are able to generate ever more realistic sounding imitations of speeches,
    images, and writing. Reinforcement learning methods and Ian Goodfellow's GANs
    have made incredible strides. Recently, there has been emerging research that
    is working to demystify the inner workings of deep neural networks. As the field
    progresses, however, we should all be mindful of overpromising. For most of its
    history, companies have often overpromised regarding what AI can do, and in turn,
    we've seen a consistent disappointment in its abilities. Focusing the abilities
    of AI on only certain applications, and continuing to view research in the field
    from a biological perspective, will only hurt its advancement going forward. In
    this book, however, we'll see that today's practical applications are directed
    and realistic, and that the field is making more strides toward true AI than ever
    before.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since its beginnings in the 1940s and 1950s, AI has made great bounds. Many
    of the technologies and ideas that we are utilizing today are directly based on
    these early discoveries. Over the course of the latter half of the 20th century,
    pioneers such as Geoffrey Hinton have pushed AI forward through peaks and busts.
    Today, we are on track to achieve sustained AI development for the foreseeable
    future.
  prefs: []
  type: TYPE_NORMAL
- en: The development of AI technology has been closely aligned with the development
    of new hardware and increasingly large data sources. As we'll see throughout this
    book, great AI applications are built with data constraints and hardware optimization
    in mind. The next chapter will introduce you to the fundamentals of machine learning
    and ...
  prefs: []
  type: TYPE_NORMAL
