<html><head></head><body>
		<div id="_idContainer013">
			<h1 id="_idParaDest-41" class="chapter-number"><a id="_idTextAnchor067"/>2</h1>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor068"/>Model Development and Maintenance for AI Products</h1>
			<p>In this chapter, we will be exploring the nuances of model development, from linear regression to deep learning neural network models. We’ll cover the variety of models that are available to use, as well as what’s entailed for the maintenance of those models, from how they’re developed and trained to how they’re deployed and ultimately tested. This will be a basic overview to understand the end-to-end process of model maintenance that product managers can expect from the engineering and dev ops teams that support <span class="No-Break">their products.</span></p>
			<p>There’s a lot involved with bringing any new product to market, and if you’ve been a product manager <a id="_idIndexMarker082"/>for a while, you’re likely familiar with the <strong class="bold">new product development</strong> (<strong class="bold">NPD</strong>) process – or set of steps. As a precursor to the rest of the chapter, particularly for those that are unfamiliar with the NPD process, we’re going to be summarizing each of the steps in the first section of this chapter. Overall, this chapter will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Understanding the stages <span class="No-Break">of NPD</span></li>
				<li>Model types – from linear regression to <span class="No-Break">neural networks</span></li>
				<li>Training – when is a model ready <span class="No-Break">for market?</span></li>
				<li>Deployment – what happens after <span class="No-Break">the workstation?</span></li>
				<li>Testing <span class="No-Break">and troubleshooting</span></li>
				<li>Refreshing – the ethics of how often we update <span class="No-Break">our models</span><a id="_idTextAnchor069"/></li>
			</ul>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor070"/>Understanding the stages of NPD</h1>
			<p>In this section, we will <a id="_idIndexMarker083"/>be covering the various stages of the NPD cycle as it relates to the emergence of an AI/ML product. Through each stage, we’ll cover the major foundational areas, from the ideation to the launch of an acceptable first version of a product. The steps are laid out incrementally from the discovery stage, in which you brainstorm about the need you’re looking to address in the market and why that need needs to be bolstered by AI. In the define stage, you bring in your product requirements for your product. In the design stage, you bring in the <a id="_idIndexMarker084"/>active visual and experiential elements of your end product. In the implementation stage, you build it out. In the marketing stage, you craft a message for your broader audience. In the training stage, you put your product to the test and make sure it’s being used as intended. Finally, in the launch stage, you release your product to a broader audience for feedback. Let’s get into these stages in more detail in the <span class="No-Break">following sections.</span><a id="_idTextAnchor071"/></p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor072"/>Step 1 – Discovery</h2>
			<p>In this <a id="_idIndexMarker085"/>phase, you’re ideating. You look to isolate the particular problem you’re trying to solve, and in the context of a <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) product, a <a id="_idIndexMarker086"/>crucial part of this first phase is understanding why you’re trying to solve that particular problem with ML in the first place. To borrow a phrase from Simon Sinek’s popular book <em class="italic">Find Your Why</em> (<a href="https://simonsinek.com/books/find-your-why/">https://simonsinek.com/books/find-your-why/</a>), this is where you “find your why.” This is the phase in which you contemplate the fundamentals of the problem at hand and look to isolate what is most urgent about the problem so that you can later address an unmet need or <span class="No-Break">under-served customers.</span></p>
			<p>This requires gathering qualitative and quantitative customer feedback about the particular issue they’re facing that you’re looking to address. The biggest focus here is creativity – to brainstorm potential solutions that you can then analyze and further explore (or <span class="No-Break">discard) late<a id="_idTextAnchor073"/>r.</span></p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor074"/>Step 2 – Define</h2>
			<p>The <a id="_idIndexMarker087"/>second phase is all about defining your <strong class="bold">minimal viable product</strong> (<strong class="bold">MVP</strong>). You’ve taken all the feedback about the problem <a id="_idIndexMarker088"/>and potential solutions in the first step, but now you’re actually building a plan from those ideas. You have to start somewhere, right? So, this step is all about screening your ideas from the discovery stage to select the one that has the highest potential to solve your customers’ biggest problem. This is where all those creative brainstorming sessions are put to the test and analyzed to best understand which of the ideas from phase one have legs. What you’re looking for here is the minimum number of features you’d need to create a version of your product that will address the main problem areas – or assumptions of – for the customers you’re looking <span class="No-Break">to serve.</span></p>
			<p>As far as your model goes, this is also where you define some metrics for model performance that will mark the minimum performance your model will need to reach in order to <a id="_idIndexMarker089"/>be a good, viable option for your customer. Remember, this is just for your MVP. The idea is that you first begin with your MVP and then you iterate through sprints or product development processes to incrementally make your product perform better or build in features your customers might prefer or need over time. Model performance will work the same way. As you partner with your customers, you will refine the product, the models, and the performance of those models together <span class="No-Break">ove<a id="_idTextAnchor075"/>r time.</span></p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor076"/>Step 3 – Design</h2>
			<p>In the <a id="_idIndexMarker090"/>first and second steps of this process, you identify the problem you want to solve, come up with ideas, and then define the minimum amount of work you’ll need to take on the problem at hand. Now, in this third design step, you actually build out that MVP and start to piece together what it might look like. This is the step that’s most heavy on finding the solution. In this step, you’re coming up with mockups for how folks might interact with your product, what the UI might look like, and how the product experience might unfold. For AI products, this is also where you start to identify which of the models mentioned in the following section will best serve <span class="No-Break">your product.</span></p>
			<p>This step is all about creating a roadmap of the UI/UX elements. It’s where you will want to involve some of your customers in the solution and, for an AI product, where you’ll set some performance benchmarks and goals for your model to hit. Building performance into the design process and managing these expectations with eventual users of your product is a great way to crystalize the concept and test it <span class="No-Break">e<a id="_idTextAnchor077"/>arly on.</span></p>
			<h2 id="_idParaDest-47"><a id="_idTextAnchor078"/>Step 4 – Implementation</h2>
			<p>The <a id="_idIndexMarker091"/>implementation phase is where all the ideating and planning from the first three steps are put to the ultimate test. This is the phase in which you’re actually working to materialize everything you just worked hard on strategizing. For all intents and purposes, this is essentially your first sprint, and as a product manager, you’re effectively working as a project manager in this phase to make sure that what you end up with meets the needs you set out <span class="No-Break">to address.</span></p>
			<p>This is <a id="_idIndexMarker092"/>the doing part in which you actually bring in your engineers, ML engineers, developers, UI/UX folks, and project managers to create the MVP and achieve the performance your customers and the leadership are expecting. What you should be left with is a version of your MVP that does what you said it would do, as you said it would. You know you’ve succeeded with this step when your MVP meets the <span class="No-Break">planning <a id="_idTextAnchor079"/>criteria.</span></p>
			<h2 id="_idParaDest-48">Step 5 – <a id="_idTextAnchor080"/>Marketing</h2>
			<p>Marketing is happening in the background of all these steps because even part of <em class="italic">step 1</em> relates <a id="_idIndexMarker093"/>heavily to marketing. Understanding the language of your customer, their needs, and their pain points is a huge prerequisite for getting your messaging right. Marketing is the delivery and communication of your message to your wider market base, and the reason why it’s <em class="italic">step 5</em> is that you want to have a working MVP before you craft the official message that will go out for your current and prospective custome<a id="_idTextAnchor081"/>rs <span class="No-Break">to see.</span></p>
			<p>With AI products, marketing undergoes specific scrutiny because the AI market is heavily competitive and companies are in a communication quagmire. If you communicate too much about your product and which models make it worthy of the AI stamp, you’re giving away too much of the secret sauce. If you communicate too little about the actual tech that’s giving it AI/ML capabilities, you’re likely to face criticism that you’re overselling your solutions’ AI capabilities. We can say with a lot of confidence that most companies err on the side of under-communicating when it comes to AI products. This is the step in which you will need to agree with all your stakeholders on how you best want to communicate AI capabilities to the <span class="No-Break">out<a id="_idTextAnchor082"/>side world.</span></p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor083"/>Step 6 – Training</h2>
			<p>The process <a id="_idIndexMarker094"/>of training users and documenting your product happens in this sixth phase so that you can create the justifications for the choices you’ve made for your MVP and your product overall. Part of training your users on your product is also managing expectations for how they are to interpret the performance of your product. This part will be especially important with AI/ML products because they often optimize, rank, classify, recommend, or predict future values, and it will be especially important to help your customers understand when they can trust or question <span class="No-Break">certain results.</span></p>
			<p>This process is intuitive for the most part because when it comes to AI/ML, we don’t know how <a id="_idIndexMarker095"/>far off we are from the predictions or optimizations until a future point in time. Part of the training that must happen, then, is to manage expectations with your customers about what margins of error are healthy for them to expect. This step is all about informing others about your product and how to best inter<a id="_idTextAnchor084"/>act <span class="No-Break">with it.</span></p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor085"/>Step 7 – Launch</h2>
			<p>In this <a id="_idIndexMarker096"/>final step, we launch the product into the market officially. So far, you’ve spoken to your internal stakeholders and teams, received customer feedback, and maybe one or two customers have partnered with you to help create your offering and bring it to market. Maybe you’ve had a soft launch or gotten other beta testers/users to help you as well, but ultimately, the final step is your official hard launch. A big part of this final step is actually scaling back to your original definitions for performance and customer success. Is this final version of your product hitting the metrics you originally set with your customers? Is the performance of the product what everyone expected? Are you actively seeking to define future <span class="No-Break">achievable goals?</span></p>
			<p>Now that we’ve covered the process that’s commonly followed in NPD, we can move on to the models that are commonly employed in that development cycle. In the following section, we will review the most popular ML model types that are commonly used in production, as well as some of the characteristics those <a id="_idTextAnchor086"/><span class="No-Break">models share.</span></p>
			<h1 id="_idParaDest-51"><a id="_idTextAnchor087"/>Model types – from linear regression to neural networks</h1>
			<p>In the <a id="_idIndexMarker097"/>previous chapter, we looked at a few model types that you’ll likely encounter, use, and implement in various types of products for different purposes. To jog your memory, here’s a list of the ML models/algorithms you’ll likely use in production for <span class="No-Break">various products:</span></p>
			<ul>
				<li><strong class="bold">Naive Bayes classifier</strong>: This algorithm “<em class="italic">naively</em>” considers every feature in your <a id="_idIndexMarker098"/>dataset as its own independent <a id="_idIndexMarker099"/>variable, so it’s essentially trying to find associations probabilistically without holding any assumptions about the data. It’s one of the simpler algorithms out there and its simplicity is actually what makes it so successful with classification. It’s commonly used for binary values, such as trying to decipher whether something is spam <span class="No-Break">or not.</span></li>
				<li><strong class="bold">Support Vector Machine</strong> (<strong class="bold">SVM</strong>): This algorithm is also largely used for classification <a id="_idIndexMarker100"/>problems and will <a id="_idIndexMarker101"/>essentially try to split your dataset into two classes so that you can use it to group your data and try to predict where future data points will land along these major splits. If you don’t see compelling groups within the data, SVMs allow you to add more dimensions to be able to see groupings <span class="No-Break">more easily.</span></li>
				<li><strong class="bold">Linear regression</strong>: These models have been around since the 50s and they’re the simplest <a id="_idIndexMarker102"/>models we have for regression <a id="_idIndexMarker103"/>problems, such as predicting future data points. They essentially use one or more variables in your dataset to predict your dependent variable. The “linear” part of this model tries to find the best line to fit your data, and this line is what dictates how it makes predictions. Here, we once again see a relatively simple model heavily used because of how versatile and dependable <span class="No-Break">it is.</span></li>
				<li><strong class="bold">Logistic regression</strong>: This model works a lot like linear regression in that you have <a id="_idIndexMarker104"/>independent and dependent variables, but it <a id="_idIndexMarker105"/>doesn’t predict a numerical value – it predicts a future binary categorical state, such as whether or not someone might default on a loan in the future, <span class="No-Break">for instance.</span></li>
				<li><strong class="bold">Decision trees</strong>: This algorithm works well for both categorical and numerical predictions, so it’s <a id="_idIndexMarker106"/>used for both kinds of ML problems, such as <a id="_idIndexMarker107"/>predicting a future state or a future price. Decision trees are used often for both kinds of problems, which has contributed to its popularity. Its comparison to a tree comes from the nodes and branches, which effectively function like a flow chart. The model learns from the flow of past data to predict <span class="No-Break">future values.</span></li>
				<li><strong class="bold">Random forest</strong>: This <a id="_idIndexMarker108"/>algorithm builds from the <a id="_idIndexMarker109"/>previous decision trees and is also used for both categorical and numerical problems. The way it works is it splits the data into different “random” samples, creates decision trees for each sample, and then takes an average or majority vote for its predictions (depending on whether you’re using it for categorical or numerical predictions). It’s hard to understand how random forest comes to conclusions, so if interpretability isn’t super high on the list of concerns, you can <span class="No-Break">use it.</span></li>
				<li><strong class="bold">K-Nearest Neighbors</strong> (<strong class="bold">KNNs</strong>): This algorithm exclusively works on categorical <a id="_idIndexMarker110"/>and numerical predictions, so it looks for <a id="_idIndexMarker111"/>a future state and offers results in groups. The number of data points in the group is set by the engineer/data scientist and the way the model works is by grouping the data and determining characteristics that data shares with its neighbors and making the best guess for future values based on <span class="No-Break">those neighbors.</span></li>
				<li><strong class="bold">K-means clustering</strong>: This <a id="_idIndexMarker112"/>algorithm will group data points to see patterns (or clusters) better, but it looks for <a id="_idIndexMarker113"/>an optimal number of clusters as well. This is unsupervised learning, so the model looks to find patterns that it can learn from because it’s not given any information (or supervision) to go off of from the engineer that’s using it. Also, the number of clusters assigned is a hyperparameter, and you will need to choose what number of clusters <span class="No-Break">is optimal.</span></li>
				<li><strong class="bold">Principal component analysis</strong> (<strong class="bold">PCA</strong>): Often, the largest problem with using <a id="_idIndexMarker114"/>unsupervised ML on <a id="_idIndexMarker115"/>very large datasets is there’s actually too much uncorrelated data to find meaningful patterns. This is why PCA is used so often, because it’s a great way to reduce dimensions without actually losing or discarding information. This is especially useful for massive datasets, such as finding patterns in genome sequencing or drug <span class="No-Break">discovery trials.</span></li>
				<li><strong class="bold">Neural networks</strong>: Deep learning models are lumped under the term neural networks <a id="_idIndexMarker116"/>for the most part because they all <a id="_idIndexMarker117"/>mimic the way the human brain processes information through layers of nodes and their edges. There are several neural network types with their own particulars, but for now, it suffices to say that neural networks <a id="_idIndexMarker118"/>are what make up the models used in what we call <span class="No-Break"><strong class="bold">deep learning</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>If you see that a product is labeled as an AI/ML product, it likely uses some form or combination of these aforementioned models. We will be going over these models in later chapters of this book but for now, this is a good introduction to the model types you’ll most often come across where ML and AI are referenced. Now that we’ve introduced the models, let’s go into how those models are trained a<a id="_idTextAnchor088"/>nd made ready for use <span class="No-Break">in production.</span></p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor089"/>Training – when is a model ready for market?</h1>
			<p>In this section, we will explore the standard process for gathering data to train a model and tune <a id="_idIndexMarker119"/>hyperparameters optimally to achieve a certain level of performance and optimization. In the implementation phase (<em class="italic">step 4</em> of the NPD process), we’re looking for a level of performance that would be considered optimal based on the define phase (<em class="italic">step 2</em> of the NPD process) before we move to the next phase of marketing and crafting our message for what success looks like when using our product. A lot has to happen in the implementation phase before we can <span class="No-Break">do that.</span></p>
			<p>Data accessibility is the most important factor when it comes to AI/ML products. At first, you might have to start with third-party data, which you’ll have to purchase, or public data that’s freely available or easily scraped. This is why you’ll likely want or need to partner with a few potential customers. Partnering with customers you can trust to stick with you and help you build a product that can be successful with real-world data is crucial to ending up with a product that’s ready for market. The last thing you want is to create a product based on pristine third-party datasets or free ones that then becomes overfitted to real-world data and performs poorly with data coming from your real customers that it’s never <span class="No-Break">seen before.</span></p>
			<p>Having a wide <a id="_idIndexMarker120"/>variety of data is important here, so in addition to making sure it’s real-world data, you also need to make sure that your data is representative of many types of users. Unless your product caters to very specific user demographics, you’re going to want to have a model trained on data that’s as varied as possible for good model performance as well as good usability ethics. There will be more on that in the <span class="No-Break">final section.</span></p>
			<p>Iterative hyperparameter tuning will also be hugely important as you continuously retrain your models for performance. The performance metrics and benchmarks in the define phase (<em class="italic">step 2</em> of the NPD) will inform how your ML engineers will go about tuning their hyperparameters. Most of the time, we don’t yet know what the optimal model architecture for a certain use case is. We want to explore how a model functions with various datasets and start somewhere so that we can see which hyperparameters give us <span class="No-Break">superior performance.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We always use the term hyperparameters when defining model optimizations because “parameters” refer to the boundaries within the training data that the model is using to make predictions. When it comes to adjustments to the model and how it functions, the term will <a id="_idIndexMarker121"/>always <span class="No-Break">be </span><span class="No-Break"><strong class="bold">hyperparameter</strong></span><span class="No-Break">.</span></p>
			<p>Examples of what hyperparameters do include the degree of features that should be used in a linear model, the maximum depth that should be allowed for a decision tree model, how many trees should be included in a random forest model, or how many neurons or layers should be included for a neural network layer. In all these cases, we’re looking at the external settings of the model itself and all these settings are worthy of scrutiny based on the model performance they produce. Having competent AI/ML engineers that are comfortable with navigating these shifts in performance will be important in creating a product that’s set up <span class="No-Break">for success.</span></p>
			<p>We want to go into some applied examples of models and their comparisons to give product managers out there who are unfamiliar with AI/ML performance benchmarks a sense of how you can go about evaluating whether one model is better than another. The following are a few examples of performance metrics that your ML engineers will look at as they evaluate whether or not they’re using optimal models. You’ll notice some of the names are familiar from our previous list of <span class="No-Break">model types.</span></p>
			<p>These <a id="_idIndexMarker122"/>comparisons were done on a personal project, which was a model we had created to predict the price of Ether, a form of cryptocurrency. If you’d like to see the entire project outlined, you can do so <span class="No-Break">here: </span><a href="https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3"><span class="No-Break">https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3</span></a><span class="No-Break">.</span></p>
			<p>The first model <a id="_idIndexMarker123"/>we wanted to use was an <strong class="bold">Ordinary Least Squares</strong> (<strong class="bold">OLS</strong>) regression model because this is the most straightforward of the linear regression models that we wanted to select to give us a good baseline before we approached other <span class="No-Break">model types.</span></p>
			<p>The results of the OLS regression model are <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/Image98224.jpg" alt="Figure 2.1 – OLS regression model results"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.1 – OLS regression model results</p>
			<p>There are a number of metrics that are automatically generated when you train a model. Here is an example of what the full set looks like, but for the purpose of comparison, we will be focusing on the <strong class="bold">R-squared of the model in the test set</strong> line in <span class="No-Break"><em class="italic">Figure 2</em></span><em class="italic">.1</em> to get the rate of error that’s comparable between models. The <strong class="bold">R-squared</strong> metric is also <a id="_idIndexMarker124"/>referred to as the “coefficient of determination” and <a id="_idIndexMarker125"/>the reason why we use this particular metric so often in regression models is that it best assesses how far the data lies from the fitted regression line that the regression model creates. With the preceding OLS regression model, we see an R-squared of <strong class="bold">0.889</strong> for the test set using an 80/20 split of the training data. We used 80% of the data for training and the remaining 20% of the data <span class="No-Break">for testing.</span></p>
			<p>The next model we tested was a random forest to compare results with a tree-based model. One of our hyperparameters for this random forest example was setting our cross-validation to <strong class="source-inline">10</strong> so that it would run through the training 10 times and produce an average of <a id="_idIndexMarker126"/>those 10 as a final score. That average was an R-squared of 0.963, higher than our <span class="No-Break">OLS model!</span></p>
			<p>The results of the random forest model are <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/Image98234.jpg" alt="Figure 2.2 – Random forest model results"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.2 – Random forest model results</p>
			<p>Finally, the last comparison was with our KNN model, which produced a score of 0.994. The hyperparameter we chose in this model was 6, which means we are looking for a group of 6 neighbors for each grouping. This KNN model gives us our best performance because we’re ideally looking for the closest we can get to a perfect score of 1. However, we must keep this in mind with a caveat: although you are looking to get as close as you can to 1, the closer you get to 1, the more suspicious you should be of <span class="No-Break">your model.</span></p>
			<p>The results of the KNN model are <span class="No-Break">as follows:</span></p>
			<div>
				<div id="_idContainer012" class="IMG---Figure">
					<img src="image/Image98243.jpg" alt="Figure 2.3 – KNN model results"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 2.3 – KNN model results</p>
			<p>Getting this high <a id="_idIndexMarker127"/>a score likely means that our model is not working well at all, or that it’s working especially well on the training data but won’t perform as well <a id="_idIndexMarker128"/>on new datasets. This phenomenon is called <strong class="bold">overfitting</strong> and it’s a big topic of conversation in data science and ML circles. The reason for it is that, fundamentally, all models are flawed and are not to be trusted until you’ve done your due diligence in selecting the best model. This game of choosing the right model, training it, and releasing it into the wild must be done under intense supervision. This is especially true if you’re charging for a product or service and attempting to win the confidence of customers that will be vouching on behalf of you and your products someday. If you’re an AI/ML product manager, you should look for good performance that gets better and better incrementally with time, and you should be highly suspicious of excellent model performance from <span class="No-Break">the get-go.</span></p>
			<p>Once you have comprehensive, representative data that you’re training your models on, and you’ve trained those models enough times and adjusted those models accordingly to get the performance you’re seeking (and promising to customers), you’re ready to <span class="No-Break">move forward!</span></p>
			<p>Now that we’ve gone over some of the major aspects of model maintenance, we can move on to what deployment looks like. Keep in mind that the entire process of ideating your product, choosing the right model to employ in your product, and gauging the performance <a id="_idIndexMarker129"/>of that model based on your training efforts is a collaborative effort. That collaboration doesn’t end when you’ve trained your models; it intensifies. This is because you’re now tasked with how exactly to integrate those models into the infrastructure of your product for your customers. L<a id="_idTextAnchor090"/>et’s get into that in the <span class="No-Break">following section.</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor091"/>Deployment – what happens after the workstation?</h1>
			<p>In <a href="B18935_01.xhtml#_idTextAnchor012"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, we discussed deployment strategies that can be used as you manage your AI/ML products in production. In this section, we’d like you to <a id="_idIndexMarker130"/>understand the avenues available from a DevOps perspective, where you will ultimately use and deploy the models in production outside of the training workstation or training environment itself. Perhaps you’re using something such as GitLab to manage the branches of your code repository for various applications of AI/ML in your product and experimenting there. However, once you are ready to make changes or update your models after retraining, you’ll push the new models into production regularly. This means you need a pipeline that can support this kind of experimentation, retraining, and deployment regularly. This section will primarily focus on the considerations after we place a finished ML model into production (a live environment) where it will be accessed by <span class="No-Break">end users.</span></p>
			<p>How you manage these future deployments will vary widely depending on whether your AI/ML product <a id="_idIndexMarker131"/>offering is <strong class="bold">business-to-business</strong> (<strong class="bold">B2B</strong>) or <strong class="bold">business-to-consumer</strong> (<strong class="bold">B2C</strong>). If <a id="_idIndexMarker132"/>you’re managing a B2C product, you’ll likely make changes in phases and you’ll likely use the deployment strategies outlined in <a href="B18935_01.xhtml#_idTextAnchor012"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, to manage how your updated product is received and when certain groups of users will see the new updated models. This is just the nature of a B2C product: it’s one product going out to thousands, if not millions, of individual consumers, and your one product will mean many different things to individual users. If your product is a B2B product, then you manage expectations often at the customer level. One customer might have a different experience of your AI/ML product than another. The models you use could also very well change from one customer to another because the data you’re using to train your models will be different from one customer <span class="No-Break">to another.</span></p>
			<p>Another thing to keep in mind is how you’re going to handle discussions about your models and the collective training data you have among all your customers. With some products, you might not face much discussion about whether you use all your data to train your models. Some companies, however, are very particular about how their data is accessed and used. They might be okay with giving you historical data to train your model with as long as that data isn’t being used to help the performance of other customers in their peer group, <span class="No-Break">for example.</span></p>
			<p>On the other hand, some customers might expect you to train your models on all the data you have to give your models the best shot at having as comprehensive a dataset as they possibly can. Remember that, as the strength of the models currently stands, the general rule is that the more data you have, the more examples you’re able to give your models. This means <a id="_idIndexMarker133"/>that the more examples you have, theoretically, the stronger performance you should have across the board. Managing expectations with your customers and their threshold for data sharing is an important part of the deployment cycle because it’s going to inform how often you update and how you <span class="No-Break">deploy responsibly.</span></p>
			<p>You’ll likely have different teams that manage different areas of the deployment process. Perhaps your data scientists create and develop the models and train them, another team validates that work and the training data as well, and a third team of engineers deploys the models into the production environment. You might also have a team of ML engineers that specialize in different areas of this <span class="No-Break">entire process.</span></p>
			<p>Once you are ready to deploy your models, you will need to have a team analyze the deployment environment for the <span class="No-Break">following reasons:</span></p>
			<ul>
				<li>To choose the best way to access the model (most often through an API or some UI/platform that’s currently being used by your <span class="No-Break">end user)</span></li>
				<li>To get a sense of how often it will <span class="No-Break">be called</span></li>
				<li>To determine how many GPUs/CPUs and how much memory it will need <span class="No-Break">to run</span></li>
				<li>To figure out how it will be continuously <span class="No-Break">fed data</span></li>
			</ul>
			<p>We’ll leave the solutioning up to your onsite experts, but this is an important point for the AI/ML product manager to keep in mind: the time/money/effort/resources that will be required to keep your AI/ML algorithms running for your product will be a huge consideration when you choose the models and strategize how you’ll deploy them <span class="No-Break">in production.</span></p>
			<p>The final part of deployment is training the end users on how to use the model and its results. Interpretability is important for any AI/ML project to succeed, but in the context of a product that’s used and relied upon by end users, whether they are B2B or B2C customers, you will <a id="_idIndexMarker134"/>need to account for how to communicate through potentially confusing moments. Training your customers through in-app prompts or your customer success teams will allow your end users to learn how to activate your AI/ML features, access the data they need from these features, and interpret the output it gives them in a way that continuously reinforces your product’s value<a id="_idTextAnchor092"/> – this is all part of managing <span class="No-Break">your deployment.</span></p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor093"/>Testing and troubleshooting</h1>
			<p>In <a href="B18935_01.xhtml#_idTextAnchor012"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, we discussed the idea of continuous maintenance, which included continuous integration, continuous delivery, continuous training, and continuous monitoring. This section will build on that and expand on how to test and <a id="_idIndexMarker135"/>troubleshoot issues related to ML products on an ongoing basis so that your product is set up for success. Once you’ve made your first deployment, we <a id="_idIndexMarker136"/>jump right into the continuous training and continuous maintenance portion of the continuous maintenance process we discussed in <a href="B18935_01.xhtml#_idTextAnchor012"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><span class="No-Break">.</span></p>
			<p>Remember, managing the performance of your models post-deployment is crucial and it will be a highly iterative, never-ending process of model maintenance. As is the case with traditional software development, you will continue to test, troubleshoot, and fix bugs for your AI/ML products as well. The only difference is that you will also screen for lags in performance and bugs related to <span class="No-Break">your model.</span></p>
			<p>Continuously monitoring your model makes sure that it’s always working properly and that the outputs it generates are effective. The last thing you want is for your product to be spewing out wildly inaccurate recommendations or predictions. Imagine that your model operated incorrectly and it took your customer weeks or months to notice that this had serious negative consequences downstream. They would question your integrity as a company because they trusted you to maintain and keep up the platform that they rely on for their own workflows. As a result, they might cancel their contract with you, pull their data out of your database, or give you negative reviews and negative referrals to other <span class="No-Break">prospective customers.</span></p>
			<p>Even when all the aspects of your model work properly, you will still need to track the continuous performance of your model and its outputs. The metrics for success we looked at in the training section previously are the same metrics you’ll create a log of that you routinely monitor to make sure model performance isn’t lagging. In addition to statistical performance metrics such as the F-score or R-squared, you’ll also want to keep track of your accuracy, recall, and precision rates. This entire process of monitoring your model’s performance should be automated so that you’re alerted when certain metrics go over a certain threshold, in the form of a flag of some sort so that you’re not always having to <span class="No-Break">manually check.</span></p>
			<p>We don’t just monitor the models themselves but we also continuously maintain the supporting code and documentation as well. This is notoriously a last priority for most companies that <a id="_idIndexMarker137"/>ultimately rely on the historical knowledge of the few developers that have been there the longest. Get it all documented and make it a practice <a id="_idIndexMarker138"/>of doing so regularly. You might find that there isn’t enough training material or that the resources that currently exist just aren’t adequate to explain what the product does. You might also find that the data feed that your model uses for training has issues with updates or wasn’t properly connected in the first place. Perhaps it’s an issue on your end users’ side and they might not be accessing the AI/ML features of your product properly. Any number of these issues can happen routinely, which is why having teams devoted to the successful execution of your AI/ML product is crucial to <span class="No-Break">its success.</span></p>
			<p>Every model is going to have some form of degradation or drift over time. For example, if new data comes in that the model is training on that’s not been cleaned in the same way that the training data was, your model’s performance is going to suffer from a lack of uniformity in the data. Data hygiene is generally an important consideration when evaluating performance because it can wreak havoc and these kinds of changes might be hard <span class="No-Break">to pinpoint.</span></p>
			<p>Over months and years, if you see changes to how data is being reported and formatted, or if there are new fields or categories of data being added that weren’t present when the models were first being trained, you’re going to see the variance in your results. Data also can morph over time if your market changes or if the demographics of your users change. If major events impact the entirety of your dataset, this will adversely impact your model results because the baseline you built as your foundation will have been rendered unreliable because the majority of the training data might not apply to the new or <span class="No-Break">current situation.</span></p>
			<p>Outside of the training data, there is one last important area of drift, and that’s what’s often referred to as concept drift – or changes in your customer’s expectations of what a correct prediction might be. For example, in some contexts, such as optimizing for a spam filter, you might find that certain new tactics mean that model outputs need to be reimagined to keep up with new trends in how spam emails evade the filter settings that originally worked well. Change is the only constant and the outside world is large and full of unpredictability. Any changes coming from outside factors could contribute to various types of concept drift, requiring us to go back to the drawing board and tweak our models and redeploy them to address a <span class="No-Break">changing world.</span></p>
			<p>Continuous monitoring and testing are a big reason why many companies will use an enterprise <a id="_idIndexMarker139"/>data science platform to keep track of their deployments. We highly recommend this if you have the budget for it because if you’re working with <a id="_idIndexMarker140"/>many customers, as well as internal and external applications of your AI/ML models, you’ll likely have many “reuse” use cases for your models. You’ll benefit from the project tracking these platforms offer if you’re managing <span class="No-Break">at scale.</span></p>
			<p>In this section, we covered some of the most important considerations when testing and troubleshooting the use of your models in production, and the importance of regular monitoring for maintaining a level of oversight, not only to keep on top of the technical performance and robustness of your models but also to remain ethical. In the following section, we will focus more on the ethical considerations when building products with AI/ML components to build<a id="_idTextAnchor094"/> responsibly and harness some industry <span class="No-Break">best practices.</span></p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor095"/>Refreshing – the ethics of how often we update our models</h1>
			<p>When we think about the amazing power we have as humans, the complex brain operations <a id="_idIndexMarker141"/>we employ for things such as weighing up different choices or deciding whether or not we can trust someone, we may find it hard or impossible to believe that we could ever use machines to do even a fraction of what our minds can do. Most of us make choices, selections, and judgments without fully understanding the mechanism that powers those experiences. However, when it comes to ML, with the exception of neural networks, we can understand the underlying mechanisms that power certain determinations and classifications. We love the idea that ML can mirror our own ability to come to conclusions and that we can employ our critical thinking skills to make sure that process is as free from bias <span class="No-Break">as possible.</span></p>
			<p>The power of AI/ML allows us to automate repetitive, boring, uninspiring actions. We’d rather have content moderators, for instance, be replaced with algorithms so that humans don’t have to suffer through flagging disturbing content on the internet on a daily basis. However, ML models, for all their wonderful abilities, aren’t able to reason the way we can. Automated structures that are biased or that degrade over time have the power to cause a lot of harm when they’re deployed in a way that directly impacts humans and <a id="_idIndexMarker142"/>when that deployment isn’t closely and regularly monitored for performance. The harm that can cause at scale, across all live deployments of AI/ML, is what keeps ethicists and futurists up <span class="No-Break">at night.</span></p>
			<p>Part of the danger with AI/ML is in the automation process itself. The types of drift we went over in the prior section impact how models derive meaning from the training data they learn from. Even when performance and maintenance appear normal, that doesn’t mean that the models aren’t taking liberties, resulting in real-world harm for the end user or for human beings that could be impacted downstream from the end user, whether or not they actually interact with the models themselves. A common example of this is the pervasive and unnecessary use of facial <span class="No-Break">recognition software.</span></p>
			<p>In February 2022, President Biden signed two pieces of legislation into law that expanded on AI accountability in the US: Artificial Intelligence for the Military Act of 2021 and the AICT Act of 2021. Will Griffin from <em class="italic">Fortune</em> magazine writes “<em class="italic">While this legislation falls far short of the calls for regulation consistent with the European Union model and desired by many in the A.I. ethics community, it plants the seeds of a thoughtful and inevitable A.I. ethics regulatory regime</em>.” It’s important to remember that AI ethics and regulations vary depending on where you live. In the US, we still lag behind European standards both in terms of legislation that’s put in place to rein in AI misconduct and in terms of how we enforce <span class="No-Break">existing laws.</span></p>
			<p>AI is still considered a wild west legislatively speaking, and we will likely see strides being made toward further defining the scope for how AI can interact with us as we see more and more use cases for AI products expand during this decade. Recently, the US made strides toward publishing a blueprint for an AI Bill of Rights that covers the <span class="No-Break">following areas:</span></p>
			<ul>
				<li>Safe and <span class="No-Break">effective systems</span></li>
				<li>Algorithmic <span class="No-Break">discrimination protections</span></li>
				<li>Data privacy notices <span class="No-Break">and explanation</span></li>
				<li>Human alternatives, consideration, <span class="No-Break">and fallback</span></li>
			</ul>
			<p>For now, we will use the European standards for framing how AI/ML product managers should think <a id="_idIndexMarker143"/>about their products because, even without deliberate laws that enforce AI ethics, entrepreneurs and technologists still face risks, such as losing customers, receiving bad press, or being taken to court, as a result of their <span class="No-Break">algorithmic choices.</span></p>
			<p>The European <a id="_idIndexMarker144"/>Commission outlines the following four key areas as <span class="No-Break">ethical principles:</span></p>
			<ul>
				<li><strong class="bold">Respect for human autonomy</strong>: “<em class="italic">AI systems should not unjustifiably subordinate, coerce, deceive, manipulate, condition or herd humans. Instead, they should be designed to augment, complement and empower human cognitive, social and cultural skills. The allocation of functions between humans and AI systems should follow human-centric design principles and leave meaningful opportunity for </em><span class="No-Break"><em class="italic">human choice.</em></span><span class="No-Break">”</span></li>
				<li><strong class="bold">Prevention of harm</strong>: “<em class="italic">AI systems should neither cause nor exacerbate harm or otherwise adversely affect human beings. This entails the protection of human dignity as well as mental and </em><span class="No-Break"><em class="italic">physical integrity</em></span><span class="No-Break">.”</span></li>
				<li><strong class="bold">Fairness</strong>: “<em class="italic">While we acknowledge that there are many different interpretations of fairness, we believe that fairness has both a substantive and a procedural dimension. The substantive dimension implies a commitment to: ensuring equal and just distribution of both benefits and costs, and ensuring that individuals and groups are free from unfair bias, discrimination </em><span class="No-Break"><em class="italic">and stigmatisation.</em></span><span class="No-Break">”</span></li>
				<li><strong class="bold">Explicability</strong>: “<em class="italic">This means that processes need to be transparent, the capabilities and purpose of AI systems openly communicated, and decisions – to the extent possible – explainable to those directly and indirectly affected. Without such information, a decision cannot be duly contested. An explanation as to why a model has generated a particular output or decision (and what combination of input factors contributed to that) is not always possible. These cases are referred to as ‘black box’ algorithms and require </em><span class="No-Break"><em class="italic">special attention.</em></span><span class="No-Break">”</span></li>
			</ul>
			<p class="callout-heading">Citation</p>
			<p class="callout">Bruschi, D., Diomede, N. <em class="italic">A framework for assessing AI ethics with applications to cybersecurity</em>. <em class="italic">AI Ethics</em> (<span class="No-Break">2022). </span><a href="https://doi.org/10.1007/s43681-022-00162-8&#13;"><span class="No-Break">https://doi.org/10.1007/s43681-022-00162-8</span></a></p>
			<p>Many companies might be tempted to create an AI ethics role within their companies and make it that person’s problem or scapegoat if and when they fail to meet certain standards, but this is a lazy and unethical way of managing the ethics around your AI programs if that’s all you choose to do. A better way would be to train and empower all of the resources that are involved in building your AI/ML products to be aware of the surrounding ethics and potential harm that could be caused to the customers or third parties interacting with <span class="No-Break">your product.</span></p>
			<p>While we must recognize the importance of understanding that recurring model updates are vital <a id="_idIndexMarker145"/>to maintaining good ethics with regard to ML and AI, as we’ve discussed previously in this chapter, it’s also important to look into how your product can affect groups of people downstream who don’t even use <span class="No-Break">your product.</span></p>
			<p>We don’t exist in a vacuum. As we saw in the previous sections of this chapter, many factors at play already work against algorithms used in AI/ML products, which you have to keep track of even to stay on top of the natural chaos created by the constant input and output of data. This natural tendency that models have toward various types of drift is what demands a focus on ethics. According to a recent episode from TechTarget’s <em class="italic">Today I Learned</em> podcast, FICO, the credit reporting and analytics vendor, conducted a survey of AI users and it showed that 67% of respondents do not monitor their models for accuracy or drift, which is pretty mind-blowing. These were AI users who were directly responsible for building and maintaining AI systems, which shows that the problems that come with unethical AI/data practices are <span class="No-Break">a norm.</span></p>
			<p>Ethical AI practices should be applied throughout every step we’ve outlined in this in-depth chapter on model maintenance. If we build AI/ML products that we are sure don’t cause harm, both directly as part of our products’ integrity and indirectly as part of our products’ model maintenance, we can confidently market and promote our products without fear of retribution or punishment from the market that we want to serve. Every entrepreneur and technologist will have their own relationship with ethical business practices but, eventually, if you are a champion, promoter, or leader of a product that has come to <a id="_idIndexMarker146"/>market that harms others, you will be asked to explain what measures were p<a id="_idTextAnchor096"/>ut in place to inform your customers of the <span class="No-Break">potential risks.</span></p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor097"/>Summary</h1>
			<p>In this chapter, we covered the NPD cycle and a review of the common AI/ML model types. We also covered an overview of how to train, deploy, and troubleshoot the models that are chosen, giving us a reasonable foundation on what to expect when working with models in production. We also touched on some of the most important ethical practices, coming from some of the most rigorous standards that exist, when building products with <span class="No-Break">AI/ML components.</span></p>
			<p>If you’re interested in expanding further on building ethical AI, we’ve provided some handy links in the following section for additional study. Keep in mind that we’re at a critical juncture with regard to AI/ML ethics. We’re building this ship as we’re sailing it, and as AI/ML products continue to enter the zeitgeist, we will see additional measures put in place to reign in the potential harm caused by improper AI deployments through the diligent work of lawmakers and activists. We’re not there yet, but with each new development, we get closer and closer to building a world that doesn’t just embrace the promise of AI but limits the issues that AI poses <span class="No-Break">as well.</span></p>
			<p>So far, we’ve had a chance to introduce some of the main concepts we’ll discuss throughout the book in <a href="B18935_01.xhtml#_idTextAnchor012"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>. We’ve also gotten further into the requirements of maintaining ML models and familiarizing ourselves with the process of building products with AI/ML components in this chapter. These first two chapters are meant to serve as an introductory foundation so that we can get deeper into the concepts we’ve brought up so far in subsequent chapters. In <a href="B18935_03.xhtml#_idTextAnchor101"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, we’ll focus on splitting deep learning from the broader umbrella term of ML, and discuss some of the differences between<a id="_idTextAnchor098"/> traditional ML algorithms and deep learning <span class="No-Break">neural networks.</span></p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor099"/>Additional resources</h1>
			<p>Reading about and familiarizing ourselves with AI ethics is important for everyone because AI is becoming increasingly impossible to avoid in our day-to-day lives. Additionally, if you actively work in the field of AI/ML as a data scientist, developer, engineer, product manager, or leader, it’s doubly important that you’re aware of the potential risks AI poses and how to build <span class="No-Break">AI responsibly.</span></p>
			<p>For further reading on ethical AI principles, we recommend the following <span class="No-Break">reputable publications:</span></p>
			<ul>
				<li><em class="italic">Blueprint for An AI Bill of </em><span class="No-Break"><em class="italic">Rights</em></span><span class="No-Break">: </span><a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/&#13;"><span class="No-Break">https://www.whitehouse.gov/ostp/ai-bill-of-rights/</span></a></li>
				<li>DoD Joint Artificial Intelligence Center Ethical Principles for <span class="No-Break">AI: </span><a href="https://www.defense.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/&#13;"><span class="No-Break">https://www.defense.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/</span></a></li>
				<li>National AI Initiative Office on <em class="italic">Advancing Trustworthy </em><span class="No-Break"><em class="italic">AI</em></span><span class="No-Break">: </span><a href="https://www.ai.gov/strategic-pillars/advancing-trustworthy-ai/&#13;"><span class="No-Break">https://www.ai.gov/strategic-pillars/advancing-trustworthy-ai/</span></a></li>
				<li>Algorithmic Justice <span class="No-Break">League: </span><a href="https://www.ajl.org/library/research&#13;"><span class="No-Break">https://www.ajl.org/library/research</span></a></li>
				<li>AItruth.org 12 Tenets of <span class="No-Break">Trust: </span><a href="https://www.aitruth.org/aitrustpledge&#13;"><span class="No-Break">https://www.aitruth.org/aitrustpledge</span></a></li>
				<li>Intel.gov’s <em class="italic">Principles of AI ethics for the intelligence </em><span class="No-Break"><em class="italic">community</em></span><span class="No-Break">: </span><a href="https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community&#13;"><span class="No-Break">https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community</span></a></li>
				<li>European Commission’s <em class="italic">Ethics Guidelines for Trustworthy </em><span class="No-Break"><em class="italic">AI</em></span><span class="No-Break">: </span><a href="https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html&#13;"><span class="No-Break">https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html</span></a></li>
				<li>Ethics Guidelines for Trustworthy <span class="No-Break">AI: </span><a href="https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf&#13;"><span class="No-Break">https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf</span></a></li>
				<li>UNESCO Recommendations on AI <span class="No-Break">Ethics: </span><a href="https://en.unesco.org/artificial-intelligence/ethics&#13;"><span class="No-Break">https://en.unesco.org/artificial-intelligence/ethics</span></a></li>
				<li>“<em class="italic">Today I Learned</em>” podcast on ethical AI, with insights from Scott Zoldi, the chief analytics officer at <span class="No-Break">FICO: </span><a href="https://www.techtarget.com/searchcio/podcast/How-machine-learning-model-management-plays-into-AI-ethics&#13;"><span class="No-Break">https://www.techtarget.com/searchcio/podcast/How-machine-learning-model-management-plays-into-AI-ethics</span></a></li>
			</ul>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor100"/>References</h1>
			<ul>
				<li><em class="italic">Find Your Why</em>, Simon <span class="No-Break">Sinek: </span><a href="https://simonsinek.com/books/find-your-why/&#13;"><span class="No-Break">https://simonsinek.com/books/find-your-why/</span></a></li>
				<li>High-Level Expert Group on Artificial Intelligence Set Up By The European Commision:  <a href="https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf"><span class="No-Break">https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf</span></a></li>
				<li>Framing TRUST in Artificial Intelligence (AI) Ethics Communication: Analysis of AI Ethics Guiding Principles through the Lens of Framing <span class="No-Break">Theory: </span><a href="https://www.proquest.com/docview/2721197134"><span class="No-Break">https://www.proquest.com/docview/2721197134</span></a></li>
				<li>America must win the race for A.I. <span class="No-Break">ethics: </span><a href="https://fortune.com/2022/02/15/america-must-win-the-race-for-a-i-ethics-tech-artificial-intelligence-politics-biden-dod-will-griffin/"><span class="No-Break">https://fortune.com/2022/02/15/america-must-win-the-race-for-a-i-ethics-tech-artificial-intelligence-politics-biden-dod-will-griffin/</span></a></li>
				<li>S.1776 - Artificial Intelligence for the Military Act of <span class="No-Break">2021: </span><a href="https://www.congress.gov/bill/117th-congress/senate-bill/1776/text?q=%7B%22search%22%3A%5B%22s1776%22%5D%7D&amp;r=1&amp;s=1"><span class="No-Break">https://www.congress.gov/bill/117th-congress/senate-bill/1776/text?q=%7B%22search%22%3A%5B%22s1776%22%5D%7D&amp;r=1&amp;s=1</span></a></li>
				<li>S.1705 - AICT Act of <span class="No-Break">2021: </span><a href="https://www.congress.gov/bill/117th-congress/senate-bill/1705/text?r=82&amp;s=1"><span class="No-Break">https://www.congress.gov/bill/117th-congress/senate-bill/1705/text?r=82&amp;s=1</span></a></li>
			</ul>
		</div>
	</body></html>