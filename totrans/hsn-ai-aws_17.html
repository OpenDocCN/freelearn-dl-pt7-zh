<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">What Is Next?</h1>
                </header>
            
            <article>
                
<p><span>In the preceding chapters, as the title of this book suggests, we took a hands-on approach to help you become better AI practitioners. Through the hands-on projects in this book, you developed the skills to embed AWS AI capabilities into applications and create custom AI capabilities using AWS ML platforms. More importantly, you developed the intuition to create well-designed, intelligence-enabled solutions that can help solve real-world problems. These projects not only taught you about a variety of AI technologies, they also showed you the various problem domains and business contexts where AI can be applied. As AI practitioners, it is important to see AI through the lens of business capabilities rather than just technologies.</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Summarizing the concepts we learned in Part I</li>
<li><span>Summarizing the concepts we learned in Part II</span></li>
<li><span>Summarizing the concepts we learned in Part III</span></li>
<li><span>Summarizing the concepts we learned in Part IV</span></li>
<li>What's next?</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing the concepts we learned in Part I</h1>
                </header>
            
            <article>
                
<p>In Part I, we introduced you to a plethora of AI offerings from AWS and grouped them into two categories:</p>
<ul>
<li>AI services</li>
<li>ML platforms</li>
</ul>
<p>Our recommendation to you is to first leverage AWS-managed AI services, such as Rekogntion, Translate, and Comprehend, in your solution development. Only when there is a need for custom AI capabilities should you then build them with AWS ML platforms such as SageMaker. This approach will improve your speed to market and the return on investment for your intelligent-enabled applications. We also explained that the true power of developing intelligent-enabled solutions on AWS is to combine AWS AI offerings with the rest of the AWS cloud computing ecosystem, including S3, DynamoDB, and EMR.</p>
<p>We also discussed architecture design for AI applications and how a well-designed architecture allows for rapid iteration and adaptability to market changes. We laid out an architecture design template for the hands-on projects in Part II and also showed you how the custom AI capabilities we built in Part III can easily integrate into this architecture. This architecture template can be adopted and modified for your next intelligent solution that's built on top of AWS AI services or your own custom AI capabilities.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing the concepts we learned in Part II</h1>
                </header>
            
            <article>
                
<p>In Part II, we focused on embedding AI capabilities into applications by doing the following:</p>
<ul>
<li>We used many AWS-managed AI services to build several end-to-end intelligent-enabled solutions.</li>
<li>We introduced to you the AWS SDK, boto3, to interact with cloud services and their infrastructure.</li>
<li>We used the AWS Chalice framework to develop and deploy serverless applications to the API Gateway and AWS Lambda.</li>
<li>We used HTML, CSS, and JavaScript to build user interfaces for these solutions.</li>
<li>Along the way, we shared our tips and tricks for the development, testing, maintenance, and evolution of AI applications on AWS.</li>
</ul>
<p>In <a href="504c5915-cf10-4cd0-8f5c-3c75466f7dc6.xhtml">Chapter 3</a>, <em>Detecting and Translating Text with Amazon Rekognition and Translate</em>, we built a Pictorial Translator that not only detects text within an image but also translates it into any language (English, for our project). This application can be used by travelers to a foreign land or by the visually impaired who wish to interact with the real world.</p>
<p>In <a href="df16cdd8-9f43-4d5c-88d8-49b1f2a67748.xhtml">Chapter 4</a>, <em>Performing Speech-to-Text and Vice Versa with Amazon Transcribe and Polly</em>, we built a modestly named Universal Translator that can enable verbal communication between people who are speaking different languages. This application can be used by travelers, students, and so on.</p>
<p>In <a href="cffd245d-bee7-40bc-a64f-e108c039a8ec.xhtml">Chapter 5</a>, <em>Extracting Information from Text with Amazon Comprehend</em>, we built a Contact Organizer that helps automate the extraction of contact information from pictures of business cards. We introduced the human-in-the-loop concept to improve our end-to-end solution's accuracy. This type of application can help reduce manual works for many back-office tasks so that workers can focus on more creative tasks.</p>
<p>In <a href="2e03dd94-bf8a-4583-9a77-e780a67e11d7.xhtml">Chapter 6</a>, <em>Building a Voice Chatbot with Amazon Lex,</em> we built an intelligent assistant, Contact Assistant, that can search for contact information through a conversational interface. This intelligent assistant not only understands us through natural language, it also remembers the context of the conversation to make the interface even more fluid. These types of intelligent assistant interface improve many of our daily tasks, such as information searches, communication, reminders, and much more.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing the concepts we learned in Part III</h1>
                </header>
            
            <article>
                
<p>In Part III, we focused on how SageMaker can be leveraged to train and deploy ML models, both built-in and custom, to solve business problems that cannot be readily solved using AWS AI services.</p>
<p>We started with <a href="ece77200-0c6c-44f8-986a-bc08531989b1.xhtml">Chapter 7</a>, <em>Working with Amazon SageMaker</em>, where we learned how to process large datasets, conduct training, and optimize hyperparameters in SageMaker.</p>
<ul>
<li>Additionally, we looked at how SageMaker makes it seamless to run multiple experiments and deploy the best performing model for inference.</li>
<li>We also illustrated how bringing your own model and container to SageMaker allows you to readily leverage capabilities such as model training, deployment, and inference at scale.</li>
</ul>
<p>In <a href="16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml">Chapter 8</a>, <em>Creating Machine Learning Inference Pipelines</em><em>,</em> we learned how to conduct data preprocessing via Glue, a serverless ETL AWS service. A machine learning pipeline was built to reuse data preprocessing logic for both training and inference. We also learned how to use the ML pipeline for both real-time and batch predictions.</p>
<p>In <a href="0537c904-c763-496c-bfd2-f18042dcd0a2.xhtml">Chapter 9</a>, <em>Discovering Topics in Text Collection, </em>we reviewed various approaches—linear and non-linear <span>–</span> so that we could discover topics in text collection. Then, we delved into how topic modeling can be handled through the built-in NTM algorithm (variational autoencoder). The model training, deployment, and inference steps in SageMaker were explained through a sample dataset of <em>Enron Emails.</em></p>
<p>In <a href="504e6f30-cb03-44c3-843f-a7c67f478809.xhtml">Chapter 10</a>, <em>Sales Forecasting with Deep Learning and Auto Regression</em>, we looked at the difference between traditional time series forecasting methods, such as exponential smoothing and ARIMA, and more flexible and scalable methods, such as auto-regressive recurrent networks. We then looked at how the DeepAR algorithm in SageMaker can be used to model retail sales given a variety of factors, such as holidays, promotions, and unemployment.</p>
<p>In <a href="349450a8-2e51-4ea9-b533-dec8081cd71c.xhtml">Chapter 11</a>, <em>Classifying Images using Amazon SageMaker, </em>we reviewed convolutional neural networks and the purpose of residual networks. Then, we introduced the concept of incremental learning through transfer learning. We also explained how to classify bakery items through transfer learning, even with small image datasets.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summarizing the concepts we learned in Part IV</h1>
                </header>
            
            <article>
                
<p>In Part IV, that is, <a href="bc4728ee-263d-4713-8f3c-816336624043.xhtml">Chapter 12</a>, <em>Model Accuracy Degradation and Feedback Loops</em><em>,</em> we defined the concept of model performance deterioration through an ad-click conversion dataset. We walked through the idea of a feedback loop and why it becomes important in modeling dynamic ad-click behavior. Then, we demonstrated how model performance improves—through a feedback loop—in predicting whether an ad click results in app downloads.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">What's next?</h1>
                </header>
            
            <article>
                
<p>We've covered a lot of concepts and techniques in AI, but with this book we have only scratched the surface of this broad and deep field. Armed with the necessary AI skills and intuition, what's next for an AI practitioner? The following are some recommendations from us so that you can explore this growing field more comprehensively.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Artificial intelligence in the physical world</h1>
                </header>
            
            <article>
                
<p>One way to grow as an AI practitioner is to broaden your experience with different applications of AI. One growing group of AI applications aims to combine AI capabilities with sensors and actuators in the physical world. Examples of such physical-world applications include home automation, smart factories, self-driving cars, and robots. The idea of building physical machinery, vehicles, and robots might be daunting to some AI practitioners. Luckily, AWS provides several products to make getting started with this group of AI applications easier.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AWS DeepLens</h1>
                </header>
            
            <article>
                
<p>AWS DeepLens is a physical device that has a video camera and compute, storage, and internet connectivity packaged into a small device. Along with other AWS AI services and tools, DeepLens becomes a powerful platform when you want to get hands-on experience with deep learning applications. Take a look at the following screenshot showing AWS DeepLens:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/ff420db1-fd86-4fbc-b1d3-f429954c7881.png" style=""/></div>
<p>Let's talk about some of the remarkable features of DeepLens:</p>
<ul>
<li>DeepLens can capture images and videos in <strong>high definition</strong> (<strong>HD</strong>), and has enough onboard power to process HD videos in real-time.</li>
<li>AI practitioners can quickly get started with projects on DeepLens with AWS AI services. For example, it integrates with Amazon Rekognition to analyze images and videos that have been taken by the camera.</li>
<li>DeepLens is fully programmable using AWS Lambda to invoke a broad set of functionalities and actuators connected to the internet.</li>
<li>DeepLens also supports custom ML models that are trained with Amazon SageMaker.</li>
<li>AI practitioners can choose from a broad set of deep learning frameworks, including TensorFlow and Caffe, to train ML models and run them on DeepLens' onboard inference engine.</li>
<li>These custom ML models can be deployed to DeepLens with just a few clicks or API calls.</li>
</ul>
<p>By reading this book, you are already familiar with many of the tools that we just mentioned and have already developed many of the skills you need to get started with AWS DeepLens. With this powerful platform, AI practitioners can build a broad set of applications. A few example applications include home security, bird watching, traffic monitoring, delivery notification, home automation, and many more. Combined with other sensors and actuators, the possibilities are endless.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">AWS DeepRacer</h1>
                </header>
            
            <article>
                
<p>AWS DeepRacer is a 1/18<sup>th</sup> scale race car with an integrated camera, accelerometer, and gyroscope; it also has compute, storage, and internet connectivity <span>onboard</span>. DeepRacer is designed to help AI practitioners get hands-on experience with reinforcement learning through autonomous car racing. Reinforcement learning is a branch of ML that aims to create intelligent agents that learn from optimizing reward functions rather than learning from examples (supervised learning) or the inherent structure of the data (unsupervised learning). This AI technique has been used to train intelligent agents to run, drive, and play games. For example, Google's AlphaGo program that beat the top Go player in the world uses this ML technique. The following shows AWS DeepRacer:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/990b4862-2ae0-4dc8-abb3-15f65bfed48d.png" style=""/></div>
<p>DeepRacer brings the following AI capabilities into the real world:</p>
<ul>
<li>By using the camera and other on-board sensors, an AI practitioner can develop reinforcement models to control <span>DeepRacer's </span>throttle and steer it.</li>
<li>DeepRacer comes with a 3D racing simulator for easy development and testing of its AI racing capabilities.</li>
<li>Like DeepLens, DeepRacer also integrates with AWS AI services and the cloud infrastructure.</li>
<li>You can use Amazon SageMaker to train reinforcement learning models and deploy them to your racer with ease.</li>
<li>There is even a DeepRacer League to test out any AI racing capabilities you've developed for prizes and glory.</li>
</ul>
<p>The applications that are built on top of this platform don't have to be limited to racing either. With a camera on wheels, there are many options available, such as home surveillance, pet training, and item delivery. We are willing to bet that a DeepDrone has been proposed at AWS at some point.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Internet of Things and AWS IoT Greengrass</h1>
                </header>
            
            <article>
                
<p>For AI applications to function well in the physical world, there is a need for AI capabilities at the edge.</p>
<p><span>AWS IoT </span>Greengrass lets connected devices seamlessly and securely interact with other devices and cloud applications. Greengrass brings many benefits to AI applications, including the following:</p>
<ul>
<li>It brings faster response times when you wish to act on local events and data without needing a trip to the cloud.</li>
<li>It improves the cost efficiency of running IoT by reducing the bandwidth requirements for data transport between the edge and the cloud.</li>
<li>It simplifies data security and privacy by processing and anonymizing sensitive information locally for applications in certain sectors such as healthcare.</li>
</ul>
<p>AWS IoT Greengrass can also extend the power of AI capabilities to edge devices, thus creating an intelligent edge. The following architectural diagram shows how edge devices can run machine learning inferences locally and then connect to AWS IoT Core to send messages or inferences to the cloud for further analytics through Greengrass Core:</p>
<div class="CDPAlignCenter CDPAlign"><img src="assets/053f360f-6867-4a31-b80c-4e6b7cf4e97d.png" style=""/></div>
<p>In this architecture, we can see the following:</p>
<ul>
<li>Models that are trained in Amazon SageMaker are persisted in the S3 bucket.</li>
<li>Data that's generated at the edge is then scored by these trained models via local lambda functions.</li>
<li>AWS Greengrass' core controls communication between the edge and the cloud, including security, messaging, and offline compute operations.</li>
<li>AWS IoT Core, on the other hand, orchestrates a connection with other AWS services, that is, durable storage or analytics.</li>
</ul>
<p>Several business problems can be solved by leveraging the edge intelligent architecture. With autonomous vehicles, there's a need for an intelligent edge to steer the car around the local environment without latency from the network. If you manufacture plants, by running ML inferences on the edge, you can predict the end of life of machinery locally and take instant actions to improve safety. With health care applications, sensitive medical information can be used locally to perform intelligent diagnoses with low latency and without putting the patient's privacy at risk in the cloud.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Artificial intelligence in your own field</h1>
                </header>
            
            <article>
                
<p>Another way to grow as an AI practitioner is to delve more deeply into a particular field or business domain. A good approach is to apply AI to a field you have expertise in or have an interest in. You know better than anyone else which field to choose.</p>
<p>In that chosen field, you will find a particular set of business problems, and then develop the relevant AI skills that are needed to solve those problems. The problems in your field might require computer vision, natural language processing, speech recognition, knowledge reasoning, or a combination of these techniques. As an AI practitioner, you will then develop more specialized skills in those AI techniques.</p>
<p>In that chosen field, you might know about some existing problems you wish to solve or you might need to discover new problems to solve. Finding and defining those problems is the key to gaining a competitive advantage over other AI generalists. To start on this path, however, we recommend that you just get started with small hands-on projects related to the field. Just like the recommendation from this book, you should develop your intuition by doing hands-on work, even if it's just replicating an existing solution from your field. Over time, you will gradually build up better insights into how to solve related problems.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this book, we have covered various AI fundamentals in AWS, highlighting AI application development, pre-defined AI APIs, model building, training, deployment, management, and experimentation through ML pipelines. We have suggested two ways that you can continue your journey as an AI practitioner on AWS, that is, either going broad or going deep. We hope that you've enjoyed reading (and working through) this book and that you are all set to solve challenging business problems through AWS Artificial Intelligence-related services.</p>


            </article>

            
        </section>
    </body></html>