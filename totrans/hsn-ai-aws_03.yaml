- en: Anatomy of a Modern AI Application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will discuss the importance of good architecture design
    for **artificial intelligence** (**AI**) applications. First, we will cover the
    architecture design principles and then create a reference architecture for our
    hands-on projects. In this chapter, we will recreate the Amazon Rekognition demo
    with our reference architecture and the components that make it up. We will learn
    how to use several AWS tools and services to build our hands-on project in the
    serverless style and then deploy it to the AWS cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the success factors of artificial intelligence applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the architecture design principles for AI applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the architecture of modern AI applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating custom AI capabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing an AI application locally using AWS Chalice
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing a demo application web user interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book's GitHub repository, which contains the source code for this chapter,
    can be found at [https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-on-Amazon-Web-Services).
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the success factors of artificial intelligence applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s talk about what makes an AI application successful, and really, what
    makes any software application successful. There are two main factors that determine
    application success:'
  prefs: []
  type: TYPE_NORMAL
- en: The first factor is whether the application is a solution that actually solves
    a particular problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second factor is how well the application is implemented to deliver the
    solution to the problem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basically, we are talking about *what to build* and *how to build it*. Both
    of these factors are difficult to get right and for the majority of cases, both
    of them are required to make an application successful.
  prefs: []
  type: TYPE_NORMAL
- en: The fact is, deciding on precisely *what to build* is the more important factor
    of the two. If we get this factor wrong, we will have a flawed product that will
    not deliver a viable solution to the problem. It will not matter how elegant the
    architecture is or how clean the code base isâ€”a flawed product will be unsuccessful.
    Deciding on precisely what to build is rarely a one-shot deal, though. It is a
    fallacy to believe that the perfect solution can be designed in advance. In many
    cases, your target customers don't even know what they want or need. Successful
    solutions require extensive iterations of product development, customer feedback,
    and a tremendous amount of effort to refine the product requirements.
  prefs: []
  type: TYPE_NORMAL
- en: This need to iterate and experiment with the solution makes *how to build it*
    an important factor for finding out *what to build*. It doesn't take a tremendous
    amount of skill to get an application to work. You can always get the first iteration,
    the first version, or the first pivot, to work with sheer determination and brute
    force. It might not be elegant, but the application works. However, when the first
    iteration is not the right solution to the problem, then a more elegant architecture
    and a cleaner code base will enable faster iterations and pivots, thus giving
    you more opportunities to figure out *what to build*.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the architecture design principles for AI applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Building elegant applications is not trivial, but building elegant AI applications
    can be even harder. As AI practitioners in a rapidly changing technology landscape,
    it''s important to understand good architecture design principles and to have
    a passion for software craftsmanship since it takes relentless discipline to build
    and maintain applications that can adapt to the fast-evolving AI technologies.
    Good architecture design can easily adapt to changes. However, it is impossible
    to predict all future changes. Therefore, we need to rely on a set of well-accepted
    design principles to guide us on good application architecture. Let''s go over
    them now:'
  prefs: []
  type: TYPE_NORMAL
- en: A well-architected application should be built on top of small services with
    focused business capabilities. By small, we don't necessarily mean a small amount
    of code. Instead, small services should follow the single responsibility principle;
    that is, to do one or very few things well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These small services are much easier to implement, test, and deploy. They are
    also easier to reuse and to compose more business capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A good application architecture should have well-defined boundaries to enforce
    separation of concerns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The services and components of the application should maintain this separation
    by hiding internal implementation details from the others.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This separation allows services and components to be replaceable with minimal
    impact on the rest of the application, thus supporting easier evolution and improvement
    of the solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are new to software architecture design, the differences between good
    and bad designs might appear subtle. It will take you a lot of experience to acquire
    the knowledge and skills you need to truly appreciate good design. In this book,
    we will provide you with examples of elegant designs that are good starting points
    for AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the architecture of modern AI applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Defining a clean architecture design is a necessary step for developing successful
    AI applications, and we recommend four basic components that make it up.
  prefs: []
  type: TYPE_NORMAL
- en: 'These four components are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User interfaces**: These are the user-facing components that deliver the
    business capabilities of your application to the end users:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are also known as frontends. Examples of user interfaces include websites,
    mobile apps, wearables, and voice assistant interfaces.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The same application can deliver different tailored user experiences by choosing
    different device form factors, interaction modalities, and user interfaces.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How you deliver intelligent capabilities on a web page is going to be very different
    than how you would do so on wearable devices.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As an AI practitioner, an important skill is designing the user experience to
    deliver your intelligent capabilities to the users. Getting this part right is
    one of the most important factors for the success of your AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: '**Orchestration layer**: These are the public APIs that will be called by your
    user interfaces to deliver the business capabilities:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, these APIs are the entry points to the backend.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The public APIs should be tailored to the specific interfaces and modalities
    in order to deliver the best experiences to the users.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The public APIs will call upon one or more small services (through private APIs)
    to deliver business capabilities.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: They play an orchestration role to combine several lower-level capabilities
    to compose higher-level capabilities that are needed by the user interfaces. There
    are other names for these public APIs that you might be familiar with; that is,
    **Backends for Frontends** (or **BFFs**) and experience APIs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Private APIs**: The private APIs define the interaction contracts that are
    used by the public APIs to access lower-level services:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The private APIs wrap the service implementations, which provide certain capabilities,
    in order to hide their details.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These APIs play a key role in the composability and the replaceability qualities
    of software systems.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The private APIs are the interfaces for the common capabilities that can be
    composed and reused by multiple applications.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These private APIs follow the service-oriented design pattern. You might be
    familiar with this pattern from similar architectures, such as microservices architecture
    and **service-oriented architecture** (or **SOA**).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: They should be designed with the single responsibility principle in mind.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: A set of well-designed private APIs is a valuable asset and competitive advantage
    for any organization. The organization will be able to rapidly innovate, improve,
    and deploy solutions to the market.
  prefs: []
  type: TYPE_NORMAL
- en: '**Vendor/custom services:** These are the implementations of the business capabilities,
    whether they are AI or otherwise:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These implementations can be provided by vendors as web services or hosted within
    your infrastructure. They can also be custom solutions that have been built by
    your organization.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These services have their own APIs, such as RESTful endpoints or SDKs that the
    private APIs will call upon to wrap the implementations.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In this book, we will be leveraging Amazon as the vendor to provide many of
    the web services via the *boto3* SDK. Later in this book, we will also teach you
    how to build custom AI capabilities using AWS' Machine Learning services and deploy
    them as ML models with RESTful endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the organization of these basic architecture
    components and layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fb81a005-0eec-4874-9c04-307294527e17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The key to a clean architecture is to keep these components separated through
    well-defined interaction contracts between each layer:'
  prefs: []
  type: TYPE_NORMAL
- en: The user interfaces should only know about the public APIs in the orchestration
    layer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The public APIs should only know about the private APIs that they depend on.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The private APIs should only know about the service implementations they wrap
    around.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is the principle of information hiding, which is applied at the architecture
    level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many benefits to enforcing these logical boundaries at the architecture
    level, for example, if we would like to switch to a better vendor service. All
    we need to do is create a new set of private APIs to wrap around the new vendor
    service while keeping the same private API contracts to the public APIs (and then
    retire the old private APIs). This way, the public APIs, as well as the user interfaces,
    won't be affected by this change. This limits the impact of the change to a specific
    part of the application.
  prefs: []
  type: TYPE_NORMAL
- en: Most of the applications we use today are composed of a frontend and a backend.
    The frontend usually runs in a browser or on a mobile device, while the backend
    runs on server infrastructure in the cloud or in a private data center. The architecture
    that's recommended here is a good starting point for these types of applications.
    There are more specialized applications, such as embedded systems, that might
    require a different architecture design. We will not dive into the architecture
    needs of these more specialized applications in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Creation of custom AI capabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As AI practitioners, there are two distinct development life cycles we can
    be involved in:'
  prefs: []
  type: TYPE_NORMAL
- en: The AI application development life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AI capability development life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, especially in larger organizations where roles are more specialized,
    an AI practitioner only participates in one of these life cycles. Even if you
    do not participate in one of these life cycles, getting a good understanding of
    both is useful for all AI practitioners.
  prefs: []
  type: TYPE_NORMAL
- en: '**The AI application development life cycle** involves iterating the solution,
    designing the user experience, defining the application architecture, and integrating
    the various business capabilities. This is similar to the traditional software
    development life cycle, but with the intent of embedding intelligence into the
    solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: '**The AI capability development life cycle** deals with developing intelligent
    capabilities using data and machine learning techniques. The data products that
    are created during the AI capability''s development life cycle can then be integrated
    into the applications as AI capabilities or AI services. In other words, the AI
    capability development life cycle produces custom AI capabilities that the AI
    application development life cycle consumes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Different sets of technical and problem-solving skills are needed by these
    two life cycles. The following diagram provides an overview of the steps that
    are required to create AI capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/897a3bf6-815d-4db1-80cf-baf25c9f4427.png)'
  prefs: []
  type: TYPE_IMG
- en: AI capabilities are at the heart of AI applications. As we mentioned in [Chapter
    1](606f673e-f72c-43ed-9a1e-fc06796b1303.xhtml), *Introduction to Artificial Intelligence
    and Amazon Web Services*, data is the new intellectual property. Any successful
    organization should have a well-defined data strategy to collect, store, process,
    and disseminate data. Raw and processed datasets should be safely placed and made
    available in data storage systems such as databases, data lakes, and data warehouses.
    From these data stores, data scientists can access data to support the analysis
    that's specific to a business problem or question they are working on. Some of
    the analysis results will generate useful business insights with the potential
    to perform predictive analysis. With these insights, data scientists can then
    choose from various machine learning algorithms to train machine learning models
    to perform automated predictions and decision-making, including classifications
    and regression analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Once trained and tuned, machine learning models can then be deployed as AI services
    with interfaces for applications to access their intelligence. For example, Amazon
    SageMaker lets us train machine learning models and then deploy them as web services
    with RESTful endpoints. Finally, as a part of your data strategy, the feedback
    data from deployed AI services should be collected to improve future iterations
    of the AI services.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned in the previous chapter, we highly recommend that you first
    leverage existing AI services from vendors such as AWS as much as possible for
    your intelligent-enabled applications. Each one of the AWS AI capabilities has
    gone through numerous iterations of the AI capability development life cycle with
    a massive amount of data that most organizations do not have access to. It only
    makes sense to build your own AI capabilities if you have a true data intellectual
    property or a need that's not addressed by the vendor solutions. It takes a tremendous
    amount of effort, skill, and time to train production-ready machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: The second part of this book will focus on the AI application development life
    cycle, while the third part of this book will focus on the AI capability development
    life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Working with a hands-on AI application architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we recommended an architecture design for modern AI
    applications. In this section, we will define the specific technologies and tech
    stacks we will use in this book to implement the recommended architecture design.
    We evaluated several factors when deciding on the best choices for this book,
    including simplicity, learning curve, industry trends, and others. Keep in mind
    that there can be many valid technology choices and implementations for the recommended
    architecture design.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the hands-on AI application development projects, we will use the following
    architecture and technology stack:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2048621a-c064-47d8-9366-ce21c016120b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'As the preceding diagram illustrates, the AI application projects will be made
    up of the four basic architectural components we discussed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '**User interfaces**: We will be using web pages as user interfaces. We will
    develop relatively simple user interfaces using HTML, CSS, and JavaScript. HTML
    and CSS will display the UI components and handle user inputs. JavaScript will
    communicate with the server backend via the public APIs in the orchestration layer.
    The project web pages will be deployed on AWS S3 as a static website without the
    need for traditional web servers. This is known as serverless because we don''t
    need to manage and maintain any server infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are using plain HTML and JavaScript to limit the scope of this book. You
    should consider single-page web application frameworks such as Angular, React,
    or Vue for your web user interfaces after finishing the hands-on projects in this
    book.
  prefs: []
  type: TYPE_NORMAL
- en: Also, you are not limited to web applications as the only choice for AI applications.
    Other user interfaces and modalities, such as mobile or voice assistant devices,
    can sometimes provide a better user experience. We recommend that you think about
    how the application design should be changed in order to support these other user
    interfaces and modalities. These thought experiments will help you build the design
    muscles for AI practitioners.
  prefs: []
  type: TYPE_NORMAL
- en: '**Orchestration layer**: We will be using AWS Chalice, a Python serverless
    microframework for AWS. Chalice allows us to quickly develop and test Python applications
    in its local development environment, and then easily deploy the Python applications
    to Amazon API Gateway and AWS Lambda as highly available and scalable serverless
    backends. Amazon API Gateway is a fully managed service that will host our public
    APIs as RESTful endpoints. The API Gateway will forward the RESTful requests that
    were issued to our public APIs to AWS Lambda functions where our orchestration
    logic will be deployed to. AWS Lambda is a serverless technology that lets us
    run code without provisioning or manage servers. When a Lambda function is invoked,
    for instance, from the API Gateway, the code is automatically triggered and run
    on the AWS infrastructure. You only pay for the computing resources that are consumed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Private APIs**: We will be packaging the private APIs as Python libraries
    within the Chalice framework. Chalice allows us to write code in a modular way
    by structuring some services as libraries in the `Chalicelib` directory. In our
    hands-on projects, the private APIs are plain old Python classes with well-defined
    method signatures to provide access to the service implementations. In our projects,
    the boundary between the public and private APIs is logical rather than physical;
    therefore, attention must be paid to ensure the cleanliness of the architecture
    layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will be reusing some of the private APIs in multiple projects. Our mechanism
    of reuse is similar to shared libraries. In larger organizations, the private
    APIs are usually deployed as RESTful endpoints so that different applications
    can easily share them.
  prefs: []
  type: TYPE_NORMAL
- en: '**Vendor services**: We will be leveraging AWS for various capabilities. For
    example, we need to develop these intelligent-enabled applications, including
    AI capabilities and more. The private APIs will access the AWS services in the
    cloud via the *boto3* SDK. Clean design requires *boto3* and AWS implementation
    details to be completely wrapped and hidden by the private APIs; the public APIs
    should not know which vendor services or custom solutions are used by the private
    APIs to provide these capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Object detector architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We will be recreating the *Amazon Rekognition* demo with our own web frontend
    and Python backend. First, let's understand the architecture of the Object Detector
    application we are about to develop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the reference architecture design and the technology stack we discussed
    previously, here is the architecture for the Object Detector application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e5a349ff-420e-4d9a-b779-3d33dd3aadb6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The user will interact with the Object Detector through a web user interface:'
  prefs: []
  type: TYPE_NORMAL
- en: We will provide a web user interface for users so that they can see the Object
    Detection demo.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The web user interface will interact with the orchestration layer containing
    just one RESTful endpoint: the Demo Object Detection endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The endpoint interacts with both the Storage Service and the Recognition Service
    to perform the Object Detection demo.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Storage Service and the Recognition Service calls the Amazon S3 and Amazon
    Rekognition services using the *Boto3* SDK, respectively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Component interactions of the Object Detector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s understand the interactions between the various components of the Object
    Detector application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5055dc1a-60b4-46cb-844c-a2297ee05f35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'From the user''s perspective, the application loads a random image and displays
    the objects (or labels) that have been detected within that image. The demo workflow
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The object detector application's web interface calls the Demo Object Detection
    endpoint to start the demo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The endpoint calls the Storage Service to get a list of files that are stored
    in a specified S3 bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving the list of files, the endpoint randomly selects an image file
    for the demo.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The endpoint then calls the Recognition Service to perform object detection
    on the selected image file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After receiving the object labels, the endpoint packages the results in JSON
    format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the web interface displays the randomly selected image and its detection
    results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Creating the base project structure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, let''s create the hands-on project structure. Follow these steps to create
    the architecture and technology stack:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Terminal, we will create the root project directory and enter it with the
    following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create placeholders for the web frontend by creating a directory named
    `Website`. Within this directory, we will have two files, `index.html` and `scripts.js`,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'We will create a Python 3 virtual environment with `pipenv` in the project''s
    root directory. Our Python portion of the project needs two packages, `boto3`
    and `chalice`. We can install them with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Remember that the Python packages that were installed via `pipenv` are only
    available if we activate the virtual environment. One way to do this is with the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, while still in the virtual environment, we will create the orchestration
    layer as an AWS Chalice project named `Capabilities` with the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will create a Chalice project structure within the `ObjectDetector`
    directory. The Chalice project structure should look similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In this project structure, we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The `config.json` file contains configuration options for deploying our Chalice
    application to AWS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `app.py` file is the main Python file where our public orchestration APIs
    are defined and implemented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `requirements.txt` file specifies the Python packages that are needed by
    the application when it is deployed to AWS. These packages are different from
    the packages we installed using Pipenv. The Pipenv installed packages are the
    ones we need during development in the local environment; the packages in the
    `requirements.txt` file are the ones the application needs to run in the AWS cloud.
    For example, AWS Chalice is required during the development of the application
    but it is not needed once the application has been deployed to AWS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`boto3` is required when we''re running our projects in the AWS cloud; however,
    it is already provided in the AWS Lambda runtime environment, and so we do not
    need to explicitly specify it in the `requirements.txt` file. Do remember to include
    any other Python packages that the applications need in that file, though.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we need to create a `chalicelib` Python package within the Chalice project
    structure in the `Capabilities` directory. Chalice will automatically include
    any of the Python files in `chalicelib` in the deployment package. We will use
    `chalicelib` to hold the Python classes that implement our private APIs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To create the `chalicelib` package, issue the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Note that `__init__.py` makes `chalicelib` a proper Python package.
  prefs: []
  type: TYPE_NORMAL
- en: 'We should have the following project directory structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is the project structure for the `ObjectDetector` application. It contains
    all the layers of the AI application architecture we defined earlier. This project
    structure is also the base structure for all the hands-on projects in part 2 of
    this book.
  prefs: []
  type: TYPE_NORMAL
- en: Developing an AI application locally using AWS Chalice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, let''s implement the private APIs and services that provide common capabilities.
    We will have two services; both of them should be created in the `chalicelib`
    directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StorageService`:The `StorageService` class that''s implemented in the `storage_service.py`
    file connects to AWS S3 via `boto3` to perform tasks on files we need for the
    applications.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s implement `StorageService`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'In the class, there is currently a constructor and two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: The `__init__()` constructor takes a parameter, `storage_location`. In this
    implementation of `StorageService`, `storage_location` represents the S3 bucket
    where files will be stored. However, we purposely gave this parameter a generic
    name so that different implementations of `StorageService` can use other storage
    services besides AWS S3.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The first method, `get_storage_location()`, just returns the S3 bucket name
    as `storage_location`. Other service implementations will use this method to get
    the generic storage location.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The second method, `list_files()`, retrieves a list of files from an S3 bucket
    specified by `storage_location`. The files in this bucket are then returned as
    a list of Python objects. Each object describes a file, including its location,
    filename, and URL.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that we are also describing the files using more generic terms, such as
    location, filename, and URL, rather than bucket, key, and s3 URL. In addition,
    we are returning a new Python list with our own JSON format, rather than returning
    the available response from *boto3*. This prevents AWS implementation details
    from leaking out of this private API's implementation.
  prefs: []
  type: TYPE_NORMAL
- en: The design decisions in `StorageService` are made to hide the implementation
    details from its clients. Because we are hiding the `boto3` and S3 details, we
    are free to change `StorageService` so that we can use other SDKs or services
    to implement the file storage capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '`RecognitionService`: The `RecognitionService` class that''s implemented in
    the `recognition_service.py` file calls the Amazon Rekognition service via `boto3`
    to perform image and video analysis tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s implement `RecognitionService`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In this class, it currently has a constructor and one method:'
  prefs: []
  type: TYPE_NORMAL
- en: The `__init__()` constructor takes in `StorageService` as a dependency to get
    the necessary files. This allows new implementations of `StorageService` to be
    injected and used by `RecognitionService`; that is, as long as the new implementations
    of `StorageService` implement the same API contract. This is known as the dependency
    injection design pattern, which makes software components more modular, reusable,
    and readable.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: The `detect_objects()` method takes in an image filename, including both the
    path and name portions, and then performs object detection on the specified image.
    This method implementation assumes that the image file is stored in an S3 bucket
    and calls Rekognition's `detect_labels()` function from the `boto3` SDK. When
    the labels are returned by *boto3*, this method constructs a new Python list,
    with each item in the list describing an object that was detected and the confidence
    level of the detection.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that, from the method's signatures (the parameters and return value), it
    does not expose the fact that the S3 and Rekognition services are used. This is
    the same information-hiding practice we used in `StorageService`.
  prefs: []
  type: TYPE_NORMAL
- en: In `RecognitionService`, we could use the `StorageService` that was passed in
    through the constructor to get the actual image files and perform detection on
    the image files. Instead, we are directly passing the image files' buckets and
    names through the `detect_labels()` function. This latter implementation choice
    takes advantage of the fact that AWS S3 and Amazon Rekognition are nicely integrated.
    The important point is that the private API's contract allows both implementations,
    and our design decision picked the latter implementation.
  prefs: []
  type: TYPE_NORMAL
- en: '`app.py`:Next, let''s implement the public APIs that are tailored for our image
    recognition web application. We only need one public API for the demo application.
    It should be implemented in the `app.py` file in the Chalice project structure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Replace the existing contents of `app.py` with the following code block. Let''s
    understand the components of the class:'
  prefs: []
  type: TYPE_NORMAL
- en: The `demo_object_detection()` function uses `StorageService` and `RecognitionService`
    to perform its tasks; therefore, we need to import these from `chalicelib` and
    create new instances of these services.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: '`storage_location` is initialized to `contents.aws.ai`, which contains the
    image files we uploaded in the previous chapter. You should replace `contents.aws.ai`
    with your own S3 bucket.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This function is annotated with `@app.route(''/demo-object-detection'', cors
    = True)`. This is a special construct used by Chalice to define a RESTful endpoint
    with a URL path called `/demo-object-detection`:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chalice maps this endpoint to the `demo_object_detection()` Python function.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The annotation also sets `cors` to true, which enables **Cross-Origin Resource
    Sharing** (**CORS**) by adding certain HTTP headers to the response of this endpoint.
    These extra HTTP headers tell a browser to let a web application running at one
    origin (domain) so that it has permission to access resources from a different
    origin (domain, protocol, or port number) other than its own. Let''s have a look
    at the implementations in the following class:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The Chalice annotation syntax might look familiar to Flask developers. AWS Chalice
    borrows a lot of its design and syntax from the Flask framework.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s talk about the preceding code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: The `demo_object_detection()` function gets a list of image files (files that
    have a `.jpg` extension) from `StorageService` and then randomly selects one of
    them to perform the object detection demo.
  prefs:
  - PREF_UL
  - PREF_UL
  type: TYPE_NORMAL
- en: Random selection is implemented here to simplify our demo application so that
    it only displays one image and its detection results.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the image has been randomly selected, the function calls `detect_objects()`
    from `RecognitionService` and then generates an HTTP response in the **JavaScript
    Object Notation** (**JSON**) format.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Chalice automatically wraps the response object in the proper HTTP headers,
    response code, and the JSON payload. The JSON format is part of the contract between
    our frontend and this public API.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We are ready to run and test the application's backend locally. Chalice provides
    a local mode, which includes a local HTTP server that you can use to test the
    endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: 'Start the `chalice local` mode within the `pipenv` virtual environment with
    the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, the local HTTP server is running at the address and port number in the
    Terminal output; that is, `http://127.0.0.1:8000`. Keep in mind that even though
    we are running the endpoint locally, the services that the endpoint calls are
    making requests to AWS via the `boto3` SDK.
  prefs: []
  type: TYPE_NORMAL
- en: Chalice's local mode automatically detected the AWS credentials in the `~/.aws/credentials`
    file. Our service implementations, which are using `boto3`, will use the key pairs
    that are found there and will issue requests with the corresponding user's permissions.
    If this user does not have permissions for S3 or Rekognition, the request to the
    endpoint will fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now issue HTTP requests to the local server to test the `/demo-object-detection`
    endpoint. For example, you can use the Unix `curl` command as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Note that, in this code, we just append the endpoint URL path to the base address
    and port number where the local HTTP server is running. The request should return
    JSON output back from the local endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: This is the JSON that our web user interface will receive and use to display
    the detection results to the user.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a demo application web user interface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let's create a simple web user interface with HTML and JavaScript in the
    `index.html` and `script.js` files in the website directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Refer to the code in the `index.html` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We are using standard HTML tags here, so the code of the web page should be
    easy to follow for anyone familiar with HTML. A few things worth pointing out
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: We are including a couple of **Cascading Style Sheets** (**CSS**) from [www.w3schools.com](http://www.w3schools.com)
    to make our web interface a bit prettier than plain HTML. Most of the classes
    in the HTML tags are defined in these style sheets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `<img>` tag with the `image` ID will be used to display the randomly selected
    demo image. This ID will be used by JavaScript to add the image dynamically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `<div>` tag with the `objects` ID will be used to display the objects that
    were detected in the demo image. This ID will also be used by JavaScript to add
    the object labels and confidence levels dynamically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `scripts.js` file is included toward the bottom of the HTML file. This adds
    the dynamic behaviors that were implemented in JavaScript to this HTML page.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `runDemo()` function from `scripts.js` is run when the HTML page is loaded
    in a browser. This is accomplished in the `index.html` page's `<body>` tag with
    the `onload` attribute.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please refer to the code of the `scripts.js` file, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s talk about the preceding code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: The script has only one function, `runDemo()`. This function makes an HTTP `GET`
    request to the `/demo-object-detection` endpoint running on the local HTTP server
    via the Fetch API that's available in JavaScript.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the response from the local endpoint is `ok`, then it converts the payload
    into a JSON object and passes it down to the next processing block.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `runDemo()` function then looks for an HTML element with the `image` ID,
    which is the `<img>` tag in HTML, and specifies the `src` attribute as the `imageUrl`
    returned by the endpoint. Remember, this `imageUrl` is set to the URL of the image
    file stored in S3\. The `<img>` tag's `alt` attribute is set to `imageName`. `imageName`
    will be displayed to the user if the image cannot be loaded for some reason.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that the image in S3 must be set to public readable in order for the website
    to display it. If you only see the `alt` text, double-check that the image is
    readable by the public.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `runDemo()` function then looks for an HTML element with the `objects` ID,
    which is a `<div>` tag, and appends a `<h6>` heading element for each object returned
    by the local endpoint, including each object's label and detection confidence
    level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we are ready to see this website in action. To run the website locally,
    simply open the `index.html` file in your browser. You should see a web page similar
    to the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/857da830-9229-4755-8b7f-a17b6a98b505.png)'
  prefs: []
  type: TYPE_IMG
- en: Upload a few JPEG image files and refresh the page a few times to see the object
    detection demo run; the demo will select a different image that's stored in your
    S3 bucket each time it runs. The `ObjectDetector` application is not as fancy
    as the Amazon Rekognition demo, but pat yourself on the back for creating a well-architected
    AI application!
  prefs: []
  type: TYPE_NORMAL
- en: The local HTTP server will run continuously unless you explicitly stop it. To
    stop the local HTTP server, go to the Terminal window that's running `chalice
    local` and press *Ctrl* + *C*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The final project structure for the `ObjectDetector` application should look
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It's now time to make our AI application public and deploy it to the AWS cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying AI application backends to AWS via Chalice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deployment to AWS with Chalice is amazingly simple yet powerful. Chalice automatically
    translates the endpoint annotations in `app.py` into HTTP endpoints and deploys
    them onto the Amazon API Gateway as public APIs. Chalice also deploys the Python
    code in `app.py` and `chalicelib` as AWS Lambda functions and then connects the
    API gateway endpoints as triggers to these Lambda functions. This simplicity is
    the reason why we chose a serverless framework such as AWS Chalice to develop
    our hands-on projects.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we ran the backend locally, Chalice automatically detected the AWS credentials
    in our development environment and made them available to the application. Which
    credentials will the application use when it is running in AWS? Chalice automatically
    creates an AWS IAM role for the application during the deployment process. Then,
    the application will run with the permissions that have been granted to this role.
    Chalice can automatically detect the necessary permissions, but this feature is
    considered experimental at the time of writing and does not work well with our
    projects'' structures. For our projects, we need to tell Chalice to *not* perform
    this analysis for us by setting `autogen_policy` to `false` in the `config.json`
    file in the `.chalice` directory of the project structure. The following is the
    `config.json` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Note that, in this configuration, there is a `dev` stage in `config.json`. Chalice
    provides us with the ability to deploy our application in multiple environments.
    Different environments are used by mature software organizations to perform various
    software life cycle tasks, such as testing and maintenance in an isolated manner.
    For example, we have the development (`dev`) environment for rapid experimentation,
    quality assurance (`qa`) for integration testing, user acceptance testing (`uat`)
    for business requirement validation, performance (`prof`) for stress testing,
    and product (`prod`) for live traffic from end users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to create a new file, `policy-dev.json`, in the `.chalice` directory
    to manually specify the AWS services the project needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are specifying S3 and Rekognition, in addition to some permissions
    to allow the project to push logs to CloudWatch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we are ready to deploy the backend on the AWS Chalice framework:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command within the `Capabilities` directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: When the deployment is complete, in the output, Chalice will show a RESTful
    API URL that looks similar to `https://<UID>.execute-api.us-east-1.amazonaws.com/api/`,
    where `<UID>` is a unique identifier string. This is the server URL your frontend
    app should hit to access the application backend running on AWS.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now verify the results of the Chalice deployment in the AWS Management
    Console under three services:'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon API Gateway
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Lambda
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identity and Access Management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take a look at the console pages of these services and see what AWS Chalice
    has set up for our application.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `curl` command to test the remote endpoint, as follows. You should
    get similar output to when we were testing with the local endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You've just deployed a serverless backend for an AI application
    that is highly available and scalable, running in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a static website via AWS S3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let's deploy the frontend web user interface to AWS S3.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the buckets we created in the previous chapter was for the purpose of
    website hosting. Let''s configure it via the AWS Management Console for static
    website hosting:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the **Amazon S3** service in the management console and click on
    your bucket.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Properties** tab, as shown in the following screenshot, click on the
    **Static website hostin****g** card:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/de924c16-f2ea-40f6-8a72-28eda90e4419.png)'
  prefs: []
  type: TYPE_IMG
- en: When you click on the **Static website hosting** card, a configuration card
    will pop up.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Use this bucket to host a website** and enter `index.html` and `error.html`
    for the **Index document** and **Error document** fields, respectively.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Copy the **Endpoint** URL on your configuration page and then click **Save**.
    This endpoint URL will be the public address of your static website:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/14db876d-8b7d-4fae-8b14-d25048edacde.png)'
  prefs: []
  type: TYPE_IMG
- en: Next, we can upload the `index.html` and `scripts.js` files to this S3 bucket.
    Before we do that, we need to make a change in `scripts.js`. Remember, the website
    will be running in the cloud now, and won't have access to our local HTTP server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Replace the local server URL in the `scripts.js` file with the one from our
    backend deployment, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Finally, set the permissions of the `index.html` and `scripts.js` files to publicly
    readable. To do that, we need to modify the S3 bucket permissions under the **Permissions**
    tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the **Public access settings** button, uncheck all four checkboxes,
    and then type `confirm` to confirm these changes. This will allow the contents
    of this S3 bucket to be made publicly accessible, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/825dc8b3-2ef9-4727-8b52-dfb95c14ac50.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now, we are able to make the files public by selecting both files, clicking
    on **Actions**, and clicking on **Make public**, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/77181fa1-98ed-4025-a675-8cf253bb64bb.png)'
  prefs: []
  type: TYPE_IMG
- en: Open the S3 endpoint URL in your browser. The URL should look something like
    `http://<BUCKET>.s3-website-us-east-1.amazonaws.com/`.
  prefs: []
  type: TYPE_NORMAL
- en: Your `ObjectDetector` website is now running in your browser and it's communicating
    with the backend running on AWS to demo your intelligent-enabled application's
    capability. Both the frontend and the backend are serverless and both are running
    on the AWS cloud infrastructure, which scales automatically with demand.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You've just developed an end-to-end AI application to AWS!
    You can now share this AI application with anyone in the world with a browser.
  prefs: []
  type: TYPE_NORMAL
- en: Even though your new AWS account might have free-tier services, you should still
    limit the number of people you share the website URL and API endpoints with. You
    will be charged if the AWS resources that are consumed exceed the amount that's
    covered under the free-tier plan.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed the importance of good architecture design for
    artificial intelligence applications. We created a reference architecture design
    for web applications that will be the template for all of our hands-on projects
    in part 2 of this book. Using this reference architecture, we recreated the Amazon
    Rekognition demo application using several AWS tools and services in the serverless
    style. We built the demo application's backend with AWS Chalice and *boto3* and
    leveraged AWS S3 and Amazon Rekognition to provide the business capabilities.
    Through the hands-on project, we showed you how architecture boundaries and good
    design allow for flexible application development and evolution. We also built
    a simple web user interface for the demo application with HTML, CSS, and JavaScript.
    Finally, we deployed the demo application as a serverless application to the AWS
    cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have experience building a simple yet elegant intelligent-enabled
    application, we are ready to use the same architecture template and toolset to
    build more AI applications in part 2 of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following links for more information on the anatomy of
    a modern AI application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://www.cs.nott.ac.uk/~pszcah/G51ISS/Documents/NoSilverBullet.html](http://www.cs.nott.ac.uk/~pszcah/G51ISS/Documents/NoSilverBullet.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
