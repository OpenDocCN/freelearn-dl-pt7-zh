["```py\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n```", "```py\ninitializer = tf.contrib.layers.xavier_initializer()\n\ndef encoder(x):\n    input_layer = tf.layers.dense(inputs=x, units=784, activation=tf.nn.relu,\n                                 kernel_initializer=initializer, bias_initializer=initializer \n                                 )\n    z_prime = tf.layers.dense(inputs=input_layer, units=256, activation=tf.nn.relu,\n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n    z = tf.layers.dense(inputs=z_prime, units=128, activation=tf.nn.relu,\n                       kernel_initializer=initializer, bias_initializer=initializer\n                       )\n    return z\n```", "```py\ndef decoder(x):\n    x_prime_one = tf.layers.dense(inputs=x, units=128, activation=tf.nn.relu,\n                                 kernel_initializer=initializer, bias_initializer=initializer\n                                 )\n    x_prime_two = tf.layers.dense(inputs=x_prime_one, units=256, activation=tf.nn.relu,\n                                 kernel_initializer=initializer, bias_initializer=initializer\n                                 )\n    output_layer = tf.layers.dense(inputs=x_prime_two, units=784, activation=tf.nn.relu,\n                                  kernel_initializer=initializer, bias_initializer=initializer\n                                  )\n    return output_layer\n```", "```py\ninput_dim = 784 \nlearning_rate = 0.001\nnum_steps = 1000\nbatch_size = 256\ndisplay = 1\n```", "```py\nx = tf.placeholder(\"float\", [None, input_dim])\n```", "```py\n# Construct the full autoencoder\nz = encoder(x)\n\n## x_prime represents our predicted distribution\nx_prime = decoder(z) \n\n# Define the loss function and the optimizer\nloss = tf.reduce_mean(tf.pow(x - x_prime, 2))\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n```", "```py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    ## Training Loop\n    for i in range(1, num_steps+1):\n\n        ## Feed Batches of MNIST Data\n        batch_x, _ = mnist.train.next_batch(batch_size)\n\n        ## Run the Optimization Process\n        _, l = sess.run([optimizer, loss], feed_dict={x: batch_x})\n\n        ## Display the loss at every 1000 out of 30,000 steps\n        if i % display == 0 or i == 1:\n            print('Step %i: Loss: %f' % (i, l))\n```", "```py\n    n = 4\n    canvas_orig = np.empty((28 * n, 28 * n))\n    canvas_recon = np.empty((28 * n, 28 * n))\n\n    for i in range(n):\n\n        batch_x, _ = mnist.test.next_batch(n)\n\n        # Encode and decode each individual written digit\n        g = sess.run(decoder, feed_dict={x: batch_x})\n\n        # Display original images\n        for j in range(n):\n\n            # Draw the original digits\n            canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch_x[j].reshape([28, 28])\n\n        # Display reconstructed images\n        for j in range(n):\n\n            # Draw the reconstructed digits\n            canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n\n    # Plot the original image vs the reconstructed images. \n    print(\"Original Images\")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_orig, origin=\"upper\", cmap=\"gray\")\n    plt.show()\n\n    print(\"Reconstructed Images\")\n    plt.figure(figsize=(n, n))\n    plt.imshow(canvas_recon, origin=\"upper\", cmap=\"gray\")\n    plt.show()\n```", "```py\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.examples.tutorials.mnist import input_data\n```", "```py\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n```", "```py\ndef encoder(x):\n\n    input_layer = tf.layers.dense(inputs=x, units=784, activation=tf.nn.elu,\n                                 kernel_initializer=initializer, bias_initializer=initializer,\n                                 name='input_layer'\n                                 )\n\n    hidden_1 = tf.layers.dense(inputs=input_layer, units=256, activation=tf.nn.elu,\n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n\n    hidden_2 = tf.layers.dense(inputs=hidden_1, units=128, activation=tf.nn.elu,\n                       kernel_initializer=initializer, bias_initializer=initializer\n                       )\n```", "```py\nmu = tf.layers.dense(inputs=z, units=10, activation=None)\nsigma = tf.layers.dense(inputs=z, units=10, activation=None)\n```", "```py\nkl_div = -0.5 * tf.reduce_sum( 1 + sigma - tf.square(mu) - tf.exp(sigma), axis=1)\n\nkl_div = tf.reduce_mean(latent_loss)\n```", "```py\ndef decoder(z, initializer):\n    layer_1 = fully_connected(z, 256, scope='dec_l1', activation_fn=tf.nn.elu, \n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n    layer_2 = fully_connected(layer_1, 384, scope='dec_l2', activation_fn=tf.nn.elu,\n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n    layer_3 = fully_connected(layer_2, 512, scope='dec_l3', activation_fn=tf.nn.elu,\n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n    dec_out = fully_connected(layer_3, input_dim, scope='dec_l4', activation_fn=tf.sigmoid,\n                             kernel_initializer=initializer, bias_initializer=initializer\n                             )\n```", "```py\nepsilon = 1e-10\n\nrec_loss = -tf.reduce_sum(x * tf.log(epsilon + dec_out) + (1 - x) * tf.log(epsilon + 1 - dec_out), axis=1)\n\nrec_loss = tf.reduce_mean(rec_loss)\n```", "```py\nlearning_rate = 1e-4\nbatch_size = 100\nepochs = 100\ninput_dim = 784 \nnum_sample = 55000\nn_z = 10\n```", "```py\nx = tf.placeholder(name='x', dtype='float', shape=[None, input_dim])\n```", "```py\n## initialize the models\nz, kl_div = encoder(x)\ndec_out, rec_loss = decoder(x)\n\n## Calculate the overall model loss term\nloss = tf.reduce_mean(rec_loss + kl_div)\n\n## Create the optimizer\noptimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n\n## Create the weight initializer\ninitializer = tf.contrib.layers.xavier_initializer()\n```", "```py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\n    for epoch in range(epochs):\n        for iter in range(num_sample // batch_size):\n\n            batch_x = mnist.train.next_batch(batch_size)\n\n            _, l, rl, ll = sess.run([optimizer, loss, rec_loss, kl_div], feed_dict={x: batch_x[0]})\n\n        if epoch % 5 == 0:\n            print('[Epoch {}] Total Loss: {}, Reconstruction Loss: {}, Latent Loss: {}'.format(epoch, l, rl, ll))\n```", "```py\nz = np.random.normal(size=[batch_size, n_z])\nx_generated = x_hat = self.sess.run(dec_out, feed_dict={z: z})\n\nn = np.sqrt(batch_size).astype(np.int32)\nI_generated = np.empty((h*n, w*n))\nfor i in range(n):\n    for j in range(n):\n        I_generated[i*h:(i+1)*h, j*w:(j+1)*w] = x_generated[i*n+j, :].reshape(28, 28)\n\nplt.figure(figsize=(8, 8))\nplt.imshow(I_generated, cmap='gray')\n```", "```py\ndef discriminator(x, initializer, dropout_rate):\n\n    layer_1 = tf.layers.dense(x, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,\n                              bias_initializer=initializer, name='input_layer')\n    dropout_1 = tf.layers.dropout(inputs=layer_1, rate=dropout_rate, training=True)\n\n    layer_2 = tf.layers.dense(dropout_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,\n                              bias_initializer=initializer, name='disc_layer_1')\n    dropout_2 = tf.layers.dropout(inputs=layer_2, rate=dropout_rate, training=True)\n\n    layer_3 = tf.layers.dense(dropout_2, units=256, activation=tf.nn.relu, kernel_initializer=initializer,\n                              bias_initializer=initializer, name='disc_layer_2')\n    dropout_3 = tf.layers.dropout(inputs=layer_3, rate=dropout_rate, training=True)\n\n    output_layer = tf.layers.dense(dropout_3, units=1, activation=tf.sigmoid, kernel_initializer=initializer,\n                              bias_initializer=initializer, name='disc_output')\n\n    return output_layer\n```", "```py\nlearning_rate = 0.0002\nbatch_size = 100\nepochs = 100\ndropout_rate=0.5\n\n```", "```py\nz = tf.placeholder(tf.float32, shape=(None, 100))\nx = tf.placeholder(tf.float32, shape=(None, 784))\n```", "```py\ninitializer = tf.contrib.layers.xavier_initializer()\n```", "```py\nG = generator(z, initializer)\n\nwith tf.variable_scope('discriminator_scope') as scope:\n    disc_real = discriminator(x, initializer, 0.5)\n    scope.reuse_variables()\n    disc_fake = discriminator(G, initializer, 0.5)\n```", "```py\nepsilon = 1e-2\ndisc_loss = tf.reduce_mean(-tf.log(disc_real + epsilon) - tf.log(1 - disc_fake + epsilon))\ngen_loss = tf.reduce_mean(-tf.log(disc_fake + epsilon))\n\ndisc_optim = tf.train.AdamOptimizer(lr).minimize(disc_loss)\ngen_optim = tf.train.AdamOptimizer(lr).minimize(gen_loss)\n```", "```py\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer()) \n    for epoch in range(epochs):\n\n        ## Define the loss to update as a list\n        gen_loss = []\n        disc_loss = []\n\n        ## Run the training iteration\n        for iter in range(training_data.shape[0] // batch_size):\n\n            ## Batch the input for the discriminator\n            x_prime = training_data[iter*batch_size:(iter+1)*batch_size]\n            z_prime = np.random.normal(0, 1, (batch_size, 100))\n\n            ## Run the discriminator session\n            _, DLoss = sess.run([disc_optim, disc_loss], {x: x_prime, z: z_prime, drop_out: 0.3})\n            disc_loss.append(DLoss)\n\n            ## Run the generator session \n            z_prime = np.random.normal(0, 1, (batch_size, 100))\n            _, GLoss = sess.run([gen_optim, gen_loss], {z: z_prime, drop_out: 0.3})\n            gen_loss.append(GLoss)\n\n        if epoch % 5 == 0:\n            print('[%d/%d] - loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), epochs, np.mean(D_losses), np.mean(G_losses)))\n```"]