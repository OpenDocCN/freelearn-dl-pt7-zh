<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer303">
			<h1 id="_idParaDest-197"><em class="italic"><a id="_idTextAnchor202"/>Chapter 17</em>: Visualizing Insights from Handwritten Content</h1>
			<p>In the previous chapters, we talked about and learned how to build <strong class="bold">Intelligent Document Processing</strong> (<strong class="bold">IDP</strong>) pipelines using <strong class="bold">Amazon Textract</strong>, <strong class="bold">Amazon Comprehend</strong>, and <strong class="bold">Amazon A2I</strong>. The advantage of setting up such pipelines is that you introduce automation into your operational processes and unlock insights that were previously not so evident. Speaking of insights, what are they exactly and why is everyone so interested in mining text, and of what use can they be? </p>
			<p>To answer this, let's summon <em class="italic">Doc Brown</em> and <em class="italic">Marty McFly's</em> time-traveling car, the <em class="italic">DeLorean</em> from the movie <em class="italic">Back to the Future</em>, and travel back to <a href="B17528_01_Final_SB_ePub.xhtml#_idTextAnchor020"><em class="italic">Chapter 1</em></a>, <em class="italic">NLP in the Business Context and Introduction to AWS AI Services</em>, to re-read the <em class="italic">Understanding why NLP is becoming mainstream</em> section. Remember now? Maybe this will help: according to <em class="italic">Webster's dictionary</em> (<a href="https://www.merriam-webster.com/">https://www.merriam-webster.com/</a>), the word "<em class="italic">insight</em>" is defined as "<em class="italic">the act or result of apprehending the inner nature of things or of seeing intuitively</em>." You got it – it is all about uncovering useful information from seemingly vague or even mundane data. Simply put, it means to "<em class="italic">see with clarity</em>."  </p>
			<p>This chapter is all about how to visualize insights from text – that is, handwritten text – and make use of it to drive decision-making. According to Wikipedia, the earliest known handwritten script was <strong class="bold">Cuneiform</strong> (<a href="https://en.wikipedia.org/wiki/Cuneiform">https://en.wikipedia.org/wiki/Cuneiform</a>), which was prevalent almost 5,500 years ago. Equally old in spoken and written form is the native language of one of the authors, the Tamil language. That said, let's now head back to our favorite fictional organization, <strong class="bold">LiveRight Holdings</strong>, to solve a new challenge they seem to be having. </p>
			<p>You have been given the task of running the Founder's Day for the firm, which is touted to be a spectacular gala, considering how popular LiveRight has become. To keep up with LiveRight's culture of benefiting the community, you will have to work with several local vendors to source what you need, such as furniture, food, and other items, for the event. You have been told that the management needs aggregated reports of all expenditure, so you decide to use your existing Document Processing pipeline to process their receipts. However, to your chagrin, you discover that the local vendors only provide handwritten receipts. You remember from a previous solution you built that Amazon Textract supports handwritten content, so you start thinking about how best to design for the situation. </p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Extracting text from handwritten images </li>
				<li>Visualizing insights using Amazon QuickSight</li>
			</ul>
			<h1 id="_idParaDest-198"><a id="_idTextAnchor203"/>Technical requirements</h1>
			<p>For this chapter, you will need access to an AWS account, which you can do at <a href="https://aws.amazon.com/console/">https://aws.amazon.com/console/</a>. Please refer to the <em class="italic">Signing up for an AWS account</em> sub-section within the <em class="italic">Setting up your AWS environment</em> section of <a href="B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Introducing Amazon Textract</em>, for detailed instructions on how you can signup for an AWS account and sign into the <strong class="bold">AWS Management Console</strong>.</p>
			<p>The Python code and sample datasets for the solution discussed in this chapter can be found at <a href="https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017">https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2017</a>.</p>
			<p>Check out the following video to see the Code in Action at <a href="https://bit.ly/3vLX5j0">https://bit.ly/3vLX5j0</a>.</p>
			<h1 id="_idParaDest-199"><a id="_idTextAnchor204"/>Extracting text from handwritten images </h1>
			<p>At this point, you are ready to start designing and building the approach. You realize that what will you <a id="_idIndexMarker930"/>build for this use case will become an extension of the existing Document Processing solution, so it will have long-term usage within the organization. So, you need to design for future scalability. With this <a id="_idIndexMarker931"/>in mind, you decide to use <strong class="bold">Amazon S3</strong> (<a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>) for object <a id="_idIndexMarker932"/>storage, <strong class="bold">Amazon Textract</strong> (<a href="https://aws.amazon.com/textract/">https://aws.amazon.com/textract/</a>) for handwriting <a id="_idIndexMarker933"/>detection, and <strong class="bold">Amazon QuickSight</strong> (<a href="https://aws.amazon.com/quicksight/">https://aws.amazon.com/quicksight/</a>), a serverless ML-powered business intelligence service, for visualizing the insights from the handwritten content. We will be using an Amazon SageMaker Jupyter notebook for text extraction, followed by the AWS Management Console to set up the QuickSight visualizations. Let's get started.</p>
			<h2 id="_idParaDest-200"><a id="_idTextAnchor205"/>Creating the SageMaker Jupyter notebook </h2>
			<p>If you have not done so in the previous chapters, you will have to create an Amazon SageMaker Jupyter <a id="_idIndexMarker934"/>notebook and set up <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) permissions for that Notebook Role to access the AWS <a id="_idIndexMarker935"/>services we will use in this notebook. After that, you will need to clone this book's GitHub repository (<a href="https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services">https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services</a>), create an Amazon S3 bucket (<a href="https://aws.amazon.com/s3/">https://aws.amazon.com/s3/</a>), and provide the bucket name in the notebook to start execution.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Please ensure you have completed the tasks mentioned in the <em class="italic">Technical requirements</em> section.</p>
			<p>Follow these steps to complete these tasks before we execute the cells from our notebook:</p>
			<ol>
				<li>Follow the instructions documented in the <em class="italic">Creating an Amazon SageMaker Jupyter notebook instance</em> sub-section in the <em class="italic">Setting up your AWS environment</em> section of <a href="B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Introducing Amazon Textract</em>, to create your Jupyter notebook instance.<p class="callout-heading">IAM Role Permissions While Creating Amazon SageMaker Jupyter Notebooks</p><p class="callout">Accept the default for the IAM Role at notebook creation time to allow access to an S3 bucket. </p></li>
				<li>Once you have created the notebook instance and its status is <strong class="bold">InService</strong>, click on <strong class="bold">Open Jupyter</strong> from the <strong class="bold">Actions</strong> menu heading to get the notebook instance. </li>
				<li>This will take you to the home folder of your notebook instance. </li>
				<li>Click on <strong class="bold">New</strong> and select <strong class="bold">Terminal</strong>.</li>
				<li>If you've not done so already, in the terminal window, type <strong class="source-inline">cd SageMaker</strong>, followed by <strong class="source-inline">git clone https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services</strong>.</li>
				<li>Now, exit the <a id="_idIndexMarker936"/>terminal window and go back to the home folder; you will see a folder called <strong class="source-inline">Natural-Language-Processing-with-AWS-AI-Services</strong>. Click this folder to bring up the chapter folders and click on <strong class="bold">Chapter 17</strong>.</li>
				<li>Open this folder by clicking on it. You should see a notebook called<strong class="source-inline"> chapter17-deriving-insights-from-handwritten-content-forGitHub.ipynb</strong>. Open this notebook by clicking on it. We will need this notebook in the upcoming sections. For now, leave this window open.</li>
			</ol>
			<p>Next, we'll cover some additional IAM prerequisites. </p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor206"/>Additional IAM prerequisites</h2>
			<p>We have to enable <a id="_idIndexMarker937"/>additional policies for our SageMaker notebook role. Please refer to the <em class="italic">Changing IAM permissions and trust relationships for the Amazon SageMaker notebook execution role</em> sub-section in the <em class="italic">Setting up your AWS environment</em> section of <a href="B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Introducing Amazon Textract</em>, for detailed instructions for executing the following steps:</p>
			<ol>
				<li value="1">Please attach all the <strong class="source-inline">TextractFullAccess</strong> policies to your Amazon SageMaker Notebook IAM Role if you haven't done so already.</li>
				<li>Add an <strong class="source-inline">iam:PassRole</strong> permission as an inline policy to your SageMaker Notebook Execution Role:<p class="source-code">{ "Version": "2012-10-17", "Statement": [ {</p><p class="source-code">  "Action": [</p><p class="source-code">      "iam:PassRole"</p><p class="source-code">  ],</p><p class="source-code">  "Effect": "Allow",</p><p class="source-code">  "Resource": "&lt;your sagemaker notebook execution role ARN"&gt;</p><p class="source-code">  }</p><p class="source-code"> ]</p><p class="source-code">}</p></li>
			</ol>
			<p>Now that we have set up our Notebook and set up an IAM Role to run the walkthrough notebook, in the next section, we will create an Amazon S3 bucket.</p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor207"/>Creating an Amazon S3 bucket</h2>
			<p>Follow the instructions documented in the <em class="italic">Creating an Amazon S3 bucket, a folder, and uploading objects</em> sub-section in the <em class="italic">Setting up your AWS environment</em> section of <a href="B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Introducing Amazon Textract</em>, to create your Amazon S3 bucket. If you created an S3 bucket in the previous sections, please reuse that bucket. For this chapter, you just need to <a id="_idIndexMarker938"/>create the S3 bucket; we will create the folders and upload the necessary objects directly from the notebook. Let's get started:</p>
			<ol>
				<li value="1">Once you have the bucket's name, please type it in <em class="italic">STEP 0 – CELL 1</em> of the notebook:<p class="source-code">bucket = "&lt;enter-S3-bucket-name&gt;"</p></li>
				<li>Execute <em class="italic">STEP 0 – CELL 1</em> of the notebook by clicking the <strong class="bold">Run</strong> button at the top menu of the notebook UI. Alternatively, you can press <strong class="bold">Shift </strong><strong class="bold">+ Enter</strong> to execute the cell. This will import the libraries we need, initialize their variables, and get our kernel ready for the next set of steps.</li>
			</ol>
			<p>Now that we have created the S3 bucket and imported the libraries we need, let's extract the contents using <strong class="bold">Amazon Textract</strong>.</p>
			<h2 id="_idParaDest-203"><a id="_idTextAnchor208"/>Extracting text using Amazon Textract</h2>
			<p>We will now continue <a id="_idIndexMarker939"/>executing the rest of the cells in the <a id="_idIndexMarker940"/>notebook to update the QuickSight manifest <a id="_idIndexMarker941"/>file with our bucket and prefix entries. The manifest <a id="_idIndexMarker942"/>file provides metadata for the QuickSight dataset to correctly import the content for visualization. Please <a id="_idIndexMarker943"/>see the documentation (<a href="https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html">https://docs.aws.amazon.com/quicksight/latest/user/create-a-data-set-s3.html</a>) for more details. Let's get started:</p>
			<ol>
				<li value="1">Execute <em class="italic">STEP 1 – CELL 1</em> in the notebook to format the manifest file with the bucket and prefix names.</li>
				<li>Now, execute <em class="italic">STEP 1 – CELL 2</em> to upload the formatted manifest file to the S3 bucket:<p class="source-code">s3 = boto3.client('s3')</p><p class="source-code">s3.upload_file(outfile,bucket,prefix+'/'+outfile)</p></li>
				<li>We will get the following output. Take a copy of the S3 location that is printed here as we will need it when we set up QuickSight:<p class="source-code">Manifest file uploaded to: s3://&lt;your-bucket-name&gt;/chapter17/qsmani-formatted.json</p></li>
				<li>Now, execute <em class="italic">STEP 2 – CELL 1</em> to install the <strong class="bold">Amazon Textract Response Parser</strong> (<strong class="bold">TRP</strong>) (<a href="https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md">https://github.com/aws-samples/amazon-textract-response-parser/blob/master/src-python/README.md</a>), a helper library that provides you with an <a id="_idIndexMarker944"/>easy way to parse the JSON response from Textract:<p class="source-code">!python -m pip install amazon-textract-response-parser</p></li>
				<li>Execute <em class="italic">STEP 2 – CELL 2</em> to import the parser's Document class, which we need to initialize the boto3 handle for Textract.</li>
				<li><em class="italic">STEP 2 – CELL 3</em> does a few things, so let's examine it in parts. First, it searches the current directory for the presence of files ending with a <em class="italic">.jpg</em> extension. These are our input image files of the receipts. The following is one of these receipts:<div id="_idContainer293" class="IMG---Figure"><img src="Images/B17528_17_01.jpg" alt="Figure 17.1 – A sample handwritten receipt&#13;&#10;" width="612" height="767"/></div><p class="figure-caption">Figure 17.1 – A sample handwritten receipt</p></li>
				<li>When they're found, the <a id="_idIndexMarker945"/>files are read <a id="_idIndexMarker946"/>one at a time and converted into bytearrays:<p class="source-code">for docs in os.listdir('.'):</p><p class="source-code">    if docs.endswith('jpg'):</p><p class="source-code">        with open(docs, 'rb') as img:</p><p class="source-code">            img_test = img.read()</p><p class="source-code">            bytes_test = bytearray(img_test)</p></li>
				<li>Next, it calls the <strong class="source-inline">AnalyzeDocument</strong> Textract API and passes <strong class="source-inline">bytearray</strong> as an input, specifically looking for tables and forms from the input image. The Textract response <a id="_idIndexMarker947"/>is then parsed by the Textract Response Parser library and the results are stored in a variable. Then, we <a id="_idIndexMarker948"/>must loop through the results to get to the table and initialize a variable denoting the CSV file we will write to:<p class="source-code">response = textract.analyze_document(Document={'Bytes': bytes_test}, FeatureTypes=['TABLES','FORMS'])</p><p class="source-code">        text = Document(response)</p><p class="source-code">        for page in text.pages:</p><p class="source-code">            for table in page.tables:</p><p class="source-code">                csvout = docs.replace('jpg','csv')</p><p class="source-code">                with open(csvout, 'w', newline='') as csvf:</p></li>
				<li>Finally, the individual cell values are written to the CSV file, along with the column headings by stripping spaces, if any, as well as the <strong class="source-inline">$</strong> symbol, denoting the currency. Finally, the newly created CSV files are uploaded to the S3 bucket. This is repeated for each image file that's found in the input folder:<p class="source-code">tab = csv.writer(csvf, delimiter=',')</p><p class="source-code">                    for r, row in enumerate(table.rows):</p><p class="source-code">                        csvrow = []</p><p class="source-code">                        for c, cell in enumerate(row.cells):</p><p class="source-code">                            if cell.text:</p><p class="source-code">                                csvrow.append(cell.text.replace('$','').rstrip())</p><p class="source-code">                        tab.writerow(csvrow)</p><p class="source-code">        s3.upload_file(csvout,bucket,prefix+'/dashboard/'+csvout)</p></li>
				<li>Execute <em class="italic">STEP 2 – CELL 3</em> to complete the tasks outlined in the preceding steps. We will get <a id="_idIndexMarker949"/>the following output. Please <a id="_idIndexMarker950"/>make a note of the S3 location of the CSV files. The manifest file we formatted earlier contains these locations to allow QuickSight to upload these CSV files:<p class="source-code">Extracted text from hw-receipt2.jpg</p><p class="source-code">CSV file for document hw-receipt2.jpg uploaded to: s3://&lt;s3-bucket-name&gt;/chapter17/dashboard/hw-receipt2.csv</p><p class="source-code">Extracted text from hw-receipt1.jpg</p><p class="source-code">CSV file for document hw-receipt1.jpg uploaded to: s3://&lt;s3-bucket-name&gt;/chapter17/dashboard/hw-receipt1.csv</p><p class="callout-heading">Note</p><p class="callout">You can also use <strong class="bold">Amazon A2I</strong> in this solution to set up a human loop to review the Textract outputs, as well <a id="_idIndexMarker951"/>as to make changes to the content as required, before creating the CSV files. For more details, please refer to <a href="B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 13</em></a>, <em class="italic">Improving the Accuracy of Document Processing Workflows</em>, onward.</p></li>
			</ol>
			<p>This concludes the steps from the notebook. Now, we will log into the AWS Management Console to set up QuickSight for visualization.</p>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor209"/>Visualizing insights using Amazon QuickSight</h1>
			<p>First, we need to <a id="_idIndexMarker952"/>enable QuickSight for <a id="_idIndexMarker953"/>your AWS account before we can import the data and run the visualizations. Please execute the following steps to proceed:</p>
			<ol>
				<li value="1">Log into AWS Management Console (refer to the <em class="italic">Technical requirements</em> section if <a id="_idIndexMarker954"/>you don't have access to the AWS Management Console) and type <strong class="source-inline">QuickSight</strong> in the services search bar at the top <a id="_idIndexMarker955"/>center of the page. Click <strong class="bold">QuickSight</strong> from the results to be navigated to the <strong class="bold">QuickSight registration</strong> page.</li>
				<li>Enter your email address and click <strong class="bold">Continue</strong>:<div id="_idContainer294" class="IMG---Figure"><img src="Images/B17528_17_02.jpg" alt="Figure 17.2 – Registering for QuickSight" width="773" height="260"/></div><p class="figure-caption">Figure 17.2 – Registering for QuickSight</p></li>
				<li>Once you've logged in, click <strong class="bold">Datasets</strong> on the left pane and click the <strong class="bold">New dataset</strong> button at the top right:<div id="_idContainer295" class="IMG---Figure"><img src="Images/B17528_17_03.jpg" alt="Figure 17.3 – New dataset&#13;&#10;" width="1022" height="366"/></div><p class="figure-caption">Figure 17.3 – New dataset</p></li>
				<li>Click on <strong class="bold">S3</strong> on the <strong class="bold">Datasets</strong> page:<div id="_idContainer296" class="IMG---Figure"><img src="Images/B17528_17_04.jpg" alt="Figure 17.4 – S3&#13;&#10;" width="937" height="235"/></div><p class="figure-caption">Figure 17.4 – S3</p></li>
				<li>In the popup <a id="_idIndexMarker956"/>that appears, for <strong class="bold">Data source name</strong>, type <strong class="source-inline">handwritten-receipts</strong>. In the <strong class="bold">Upload a manifest file</strong> input <a id="_idIndexMarker957"/>area, copy and paste the S3 location that was printed in the Jupyter notebook in <em class="italic">STEP 1 – CELL 2</em>. Then, click on <strong class="bold">Connect</strong>:<div id="_idContainer297" class="IMG---Figure"><img src="Images/B17528_17_05.jpg" alt="Figure 17.5 – Specifying the S3 manifest file&#13;&#10;" width="572" height="257"/></div><p class="figure-caption">Figure 17.5 – Specifying the S3 manifest file</p></li>
				<li>Once the dataset has been imported, click the <strong class="bold">Visualize</strong> button at the bottom right of the popup to open the QuickSight console. In the console, you should see a small popup that displays the import status. Verify that the import was successful. If you see errors at this stage, verify the contents of the CSV file to ensure there are no issues. These should be available in the S3 bucket in the <strong class="source-inline">Chapter17/dashboard</strong> prefix:<div id="_idContainer298" class="IMG---Figure"><img src="Images/B17528_17_06.jpg" alt="Figure 17.6 – Dataset import successful&#13;&#10;" width="206" height="107"/></div><p class="figure-caption"> </p><p class="figure-caption">Figure 17.6 – Dataset import successful</p></li>
				<li>You should see <a id="_idIndexMarker958"/>the column names from the CSV file displayed to the left, under <strong class="bold">Fields list</strong>. You should see a center pane <a id="_idIndexMarker959"/>with space for a graph named <strong class="bold">AutoGraph</strong>. When you add fields from the list on the left, QuickSight automatically creates the appropriate graph based on your data. </li>
				<li>For our use case, we will create a pie chart and a donut chart to visualize the quantity of furniture that's been ordered and how much it cost us. Under the <strong class="bold">Visual types</strong> section on the left, click on the symbol for the pie chart and add fields from <strong class="bold">Fields list</strong> to the chart, as shown here:<div id="_idContainer299" class="IMG---Figure"><img src="Images/B17528_17_07.jpg" alt="Figure 17.7 – Visualizing furniture quantities across types" width="1146" height="900"/></div><p class="figure-caption">Figure 17.7 – Visualizing furniture quantities across types</p></li>
				<li>Now, let's add <a id="_idIndexMarker960"/>a new visual to this <a id="_idIndexMarker961"/>dashboard. Click on <strong class="bold">Add</strong> at the top left and select <strong class="bold">Add visual</strong>:<div id="_idContainer300" class="IMG---Figure"><img src="Images/B17528_17_08.jpg" alt="Figure 17.8 – Add visual&#13;&#10;" width="490" height="349"/></div><p class="figure-caption">Figure 17.8 – Add visual</p></li>
				<li>Now, add a <a id="_idIndexMarker962"/>donut chart to display the <a id="_idIndexMarker963"/>total costs and cost by furniture type, as shown in the following screenshot. Begin by selecting the donut visual in the <strong class="bold">Visual types</strong> section on the left, select <strong class="bold">ITEM</strong> and <strong class="bold">PRICE</strong>, and then add them to the <strong class="bold">Group/Color</strong> and <strong class="bold">Value</strong> fields:<div id="_idContainer301" class="IMG---Figure"><img src="Images/B17528_17_09.jpg" alt="Figure 17.9 – Donut chart for visualizing the total costs and cost by furniture type" width="1210" height="528"/></div><p class="figure-caption">Figure 17.9 – Donut chart for visualizing the total costs and cost by furniture type</p></li>
				<li>Click on the <strong class="bold">Insights</strong> option on the middle left of the console to display the insights that QuickSight was able to gather from our data:</li>
			</ol>
			<div>
				<div id="_idContainer302" class="IMG---Figure">
					<img src="Images/B17528_17_10.jpg" alt="Figure 17.10 – QuickSight insights from our data&#13;&#10;" width="399" height="799"/>
				</div>
			</div>
			<p class="figure-caption">Figure 17.10 – QuickSight insights from our data</p>
			<p>It is as simple <a id="_idIndexMarker964"/>as that. Feel free to try out the other visual types, as well as ML-powered forecasting and insights. For more details, please refer to the following documentation: <a href="https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html">https://docs.aws.amazon.com/quicksight/latest/user/making-data-driven-decisions-with-ml-in-quicksight.html</a>. You can set up, share, publish, or export your dashboard for consumption by your management and other stakeholders. And that concludes the solution build for this use case. </p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor210"/>Summary</h1>
			<p>We have just scratched the surface with what we can do with written text with this use case – the possibilities are truly endless! With just a few steps, by leveraging the advanced AI capabilities offered by services such as Amazon Textract, and the serverless scalable visualization offered by Amazon QuickSight, we were able to create powerful visuals from content scribbled on a piece of paper. </p>
			<p>We began by creating the SageMaker Jupyter notebook instance we needed for this solution, cloned the GitHub repository for this chapter, created an S3 bucket, and executed the steps in the notebook to format the QuickSight S3 manifest file. Then, we used Amazon Textract and the Textract Response Parser library to read the contents of the handwritten receipts before creating CSV files that were uploaded to the S3 bucket. We concluded the notebook after executing these steps and then logged into the AWS Management Console and registered to use Amazon QuickSight.</p>
			<p>In QuickSight, we imported the S3 dataset, which comprised our CSV files, and created two visuals and an insight. The first visual was a pie chart that showed the items that have been ordered against their quantities, while the second visual was a donut chart that showed the total cost of the two receipts, along with the cost per item. Finally, we displayed the insights that QuickSight had automatically generated, giving us a summary of what it was able to read from our content. We briefly discussed how we can export or share the dashboard and QuickSight's ML-based insights. And that concluded our solution build for this chapter. </p>
			<p>Based on the myriad of use cases we have covered in this book so far, you know how to solve mainstream challenges in NLP for you and your customers, and we did all this without the need to tune a hyperparameter or train a model from the ground up. Granted, we trained a few custom Comprehend models, but that was without the overhead of a traditional ML workflow. </p>
			<p>In the next chapter, we will conclude this book, so we thought we would leave you with some best practices, techniques, and guidelines to keep in your back pocket as you navigate your career as an NLP and AI expert. We will talk about document pre-processing, post-processing, and other items to consider during solution design. We are almost there!</p>
		</div>
	</div></body></html>