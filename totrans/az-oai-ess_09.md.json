["```py\npip install openai==0.28\npip install dotenv\npip install azure-ai-textanalytics\npip install azure-cognitiveservices-speech\npip install moviepy\n```", "```py\nimport openai\nimport os\nfrom dotenv import load_dotenv\nimport azure.cognitiveservices.speech as speechsdk\nfrom azure.ai.textanalytics import TextAnalyticsClient\nfrom azure.core.credentials import AzureKeyCredential\nimport urllib.request\nfrom moviepy.editor import *\nimport numpy as np\nfrom PIL import Image\n```", "```py\n# Azure\nload_dotenv()\nOPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\nOPENAI_DEPLOYMENT_ENDPOINT = os.getenv(\"OPENAI_DEPLOYMENT_ENDPOINT\")\nOPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\nOPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\nOPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\nOPENAI_DEPLOYMENT_VERSION = os.getenv(\"OPENAI_DEPLOYMENT_VERSION\")\n#init Azure OpenAI\nopenai.api_type = \"azure\"\nopenai.api_version = OPENAI_DEPLOYMENT_VERSION\nopenai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\nopenai.api_key = OPENAI_API_KEY\nOPENAI_LANGUAGE_KEY = os.getenv(\"OPENAI_LANGUAGE_KEY\")\nOPENAI_LANGUAGE_ENDPOINT = os.getenv(\"OPENAI_LANGUAGE_ENDPOINT\")\nOPENAI_SPEECH_KEY = os.getenv(\"OPENAI_SPEECH_KEY\")\nOPENAI_SPEECH_REGION = os.getenv(\"OPENAI_SPEECH_REGION\")\nload_dotenv()\n```", "```py\nOPENAI_LANGUAGE_KEY = {OPENAI_LANGUAGE_KEY}\nOPENAI_LANGUAGE_ENDPOINT = {OPENAI_LANGUAGE_ENDPOINT}\nOPENAI_SPEECH_KEY = {OPENAI_SPEECH_KEY}\nOPENAI_SPEECH_REGION = {OPENAI_SPEECH_REGION}\n```", "```py\n    Here’s an example prompt: HTML Hello World Tutorial: Generate a beginner-friendly tutorial for creating a basic “Hello World” webpage using HTML:\n    ```", "```py\n    num_of_sentences = 1\n    content = input(\"Please enter the content: \")\n    prompt = 'Provide a summary of the text below that captures its main idea in '+ str(num_of_sentences) +'sentences. \\n' + content\n    ```", "```py\n    response_summ = openai.Completion.create(\n      engine=OPENAI_DEPLOYMENT_NAME,\n      prompt=prompt,\n      temperature=0.3,\n      max_tokens=100,\n      top_p=1,\n    )\n    print(response_summ.choices[0].text)\n    In the above code lets understand what each parameter means -\n    openai.Completion.create:\n    This is a method call to the OpenAI API to create a text completion.\n    engine=OPENAI_DEPLOYMENT_NAME:\n    Specifies the engine to use for generating the completion. OPENAI_DEPLOYMENT_NAME is a variable that holds the name of the deployment or model you want to use.\n    prompt=prompt:\n    The prompt parameter is the input text that you provide to the model. The model will generate a completion based on this input.\n    temperature=0.3:\n    The temperature parameter controls the randomness of the output. Lower values (like 0.3) make the output more focused and deterministic, while higher values make it more random.\n    max_tokens=100:\n    The max_tokens parameter specifies the maximum number of tokens (words or word pieces) to generate in the completion.\n    top_p=1:\n    The top_p parameter is used for nucleus sampling. It controls the diversity of the output by considering only the top p probability mass. A value of 1 means no filtering based on probability mass.\n    ```", "```py\n    def authenticate_client():\n         def authenticate_client():\n        try:\n            ta_credential = AzureKeyCredential(OPENAI_LANGUAGE_KEY)\n            text_analytics_client = TextAnalyticsClient(\n                endpoint=OPENAI_LANGUAGE_ENDPOINT,\n                credential=ta_credential\n            )\n            return text_analytics_client\n        except AzureError as e:\n            print(f\"An error occurred while authenticating the client: {e}\")\n            return None\n    client = authenticate_client()\n    ```", "```py\n    def key_phrase_extraction_example(client):\n        try:\n            phrase_list, phrases = [], ''\n            documents = [response_summ.choices[0].text]\n            response_kp = client.extract_key_phrases(\n                documents = documents)[0]\n            if not response_kp.is_error:\n                print(\"\\tKey Phrases:\")\n                for phrase in response_kp.key_phrases:\n                    print(\"\\t\\t\", phrase)\n                    phrase_list.append(phrase)\n                    phrases = phrases +\"\\n\"+ phrase\n            else:\n                print(response_kp.id, response_kp.error)\n        except Exception as err:\n            print(\"Encountered exception. {}\".format(err))\n        return phrase_list, phrases\n    ```", "```py\n    phrase_list, phrases = key_phrase_extraction_example(client)\n    ```", "```py\n    prompt = ''' Provide an image idea for each phrases: ''' + phrases\n    ```", "```py\n    response_phrase  = openai.Completion.create(\n      engine=OPENAI_DEPLOYMENT_NAME,\n      prompt=prompt,\n      temperature=0.3,\n      max_tokens=100,\n      top_p=1,\n    )\n    image_phrases = response_phrase.choices[0].text.split(\"\\n\")[1:]\n    print(image_phrases)\n    ```", "```py\n    and to optimize the efficiency of the image generation process:\n    ```", "```py\n    im_ph = []\n    for image_phrase in image_phrases:\n       if(len(image_phrase) > 0):\n            im_ph.append(image_phrase.split(\":\")[0])\n    # Convert the list to a set to remove duplicates, then back to a list\n    im_ph = list(set(im_ph))\n    print(im_ph)\n    ```", "```py\n    images = []\n    for phrase in im_ph:\n        response = openai.Image.create(\n            prompt=phrase,\n            size='1024x1024',\n            n=1\n        )\n        image_url = response[\"data\"][0][\"url\"]\n        images.append(image_url)\n    ```", "```py\n    counter = 0\n    image_list = []\n    for url in images:\n        counter += 1\n        filename = \"file\" + str(counter) + \".jpg\"\n        urllib.request.urlretrieve(url, filename)\n        image_list.append(filename)\n    print (\"Downloading done.....\")\n    ```", "```py\n    speech_config = speechsdk.SpeechConfig(\n        subscription=OPENAI_SPEECH_KEY, \n        region=OPENAI_SPEECH_REGION)\n    print(speech_config)\n    ```", "```py\n    def text_to_speech(text, filename):\n        audio_config = speechsdk.AudioConfig(filename=filename)\n        speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n        result = speech_synthesizer.speak_text_async(text).get()\n        print(result)\n        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n            print(f\"Audio saved to {filename}\")\n        else:\n            print(f\"Error: {result.error_details}\")\n    text = response_summ.choices[0].text\n    filename = \"audio.mp4\"\n    text_to_speech(text, filename)\n    ```", "```py\nprint(\"Creating the video.....\")\ndef create_video(images, audio, output):\n    resized_images = [np.array(Image.open(img).resize((1024, 1024))) for img in images]\n    clips = [ImageClip(img).set_duration(2) for img in resized_images]\n    concat_clip = concatenate_videoclips(clips, method=\"compose\")\n    audio_clip = AudioFileClip(audio)\n    final_clip = concat_clip.set_audio(audio_clip)\n    final_clip.write_videofile(output, fps=24)\nimages = image_list\naudio = filename\noutput = \"video.mp4\"\ncreate_video(images, audio, output)\nprint(\"Video created.....\")\n```"]