- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: About the Book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Various intelligent applications such as video games, inventory management software,
    warehouse robots, and translation tools use **Reinforcement Learning** (**RL**)
    to make decisions and perform actions that maximize the probability of the desired
    outcome. This book will help you to get to grips with the techniques and the algorithms
    for implementing RL in your machine learning models.
  prefs: []
  type: TYPE_NORMAL
- en: Starting with an introduction to RL, you'll be guided through different RL environments
    and frameworks. You'll learn how to implement your own custom environments and
    use OpenAI baselines to run RL algorithms. Once you've explored classic RL techniques
    such as Dynamic Programming, Monte Carlo, and TD Learning, you'll understand when
    to apply the different deep learning methods in RL and advance to deep Q-learning.
    The book will even help you understand the different stages of machine-based problem-solving
    by using DARQN on a popular video game Breakout. Finally, you'll find out when
    to use a policy-based method to tackle an RL problem.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of *The Reinforcement Learning Workshop*, you'll be equipped with
    the knowledge and skills needed to solve challenging machine learning problems
    using reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: Audience
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are a data scientist, machine learning enthusiast, or a Python developer
    who wants to learn basic to advanced deep reinforcement learning algorithms, this
    workshop is for you. A basic understanding of the Python language is necessary.
  prefs: []
  type: TYPE_NORMAL
- en: About the Chapters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Chapter 1*, *Introduction to Reinforcement Learning*, introduces you to RL,
    which is one of the most exciting fields in machine learning and artificial intelligence.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 2*, *Markov Decision Processes and Bellman Equations*, teaches you
    about Markov chains, Markov reward processes, and Markov decision processes. You
    will learn about state values and action values, as well as using the Bellman
    equation to calculate these quantities.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 3*, *Deep Learning in Practice with TensorFlow 2*, introduces you
    to TensorFlow and Keras, giving you an overview of their key features and applications
    and how they work in synergy.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 4*, *Getting Started with OpenAI and TensorFlow for Reinforcement
    Learning*, sees you working with two popular OpenAI tools, Gym and Universe. You
    will learn how to formalize the interfaces of these environments, how to interact
    with them, and how to create a custom environment for a specific problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 5*, *Dynamic Programming*, teaches you how to use dynamic programming
    to solve problems in RL. You will learn about the concepts of policy evaluation,
    policy iteration, and value iteration, and see how to implement them.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 6*, *Monte Carlo Methods,* teaches you how to implement the various
    types of Monte Carlo methods, including the "first visit" and "every visit" techniques.
    You will see how to use these Monte Carlo methods to solve the frozen lake problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 7*, *Temporal Difference Learning*, prepares you to implement TD(0),
    SARSA, and TD(λ) Q-learning algorithms in both stochastic and deterministic environments.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 8*, *The Multi-Armed Bandit Problem*, introduces you to the popular
    multi-armed bandit problem and shows you some of the most commonly used algorithms
    to solve the problem.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 9*, *What Is Deep Q-Learning?*, educates you on deep Q-learning and
    covers some hands-on implementations of advanced variants of deep Q-learning,
    such as double deep Q-learning, with PyTorch.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 10*, *Playing an Atari Game with Deep Recurrent Q-Networks*, introduces
    you to **Deep Recurrent Q-Networks** and its variants. You will get hands-on experience
    in training RL agents to play an Atari game.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 11*, *Policy-Based Methods for Reinforcement Learning*, teaches you
    how to implement different policy-based methods of RL, such as policy gradients,
    deep deterministic policy gradients, trust region policy optimization, and proximal
    policy optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Chapter 12*, *Evolutionary Strategies for RL*, combines evolutionary strategies
    with traditional machine learning methods, specifically in the selection of neural
    network hyperparameters. You will also identify the limitations of these evolutionary
    methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The interactive version of *The Reinforcement Learning Workshop* contains a
    bonus chapter, *Recent Advancements* and *Next Steps*. This chapter teaches you
    novel methods of implementing reinforcement learning algorithms with an emphasis
    on areas of further exploration such as one-shot learning and transferable domain
    priors. You can find the interactive version here: [courses.packtpub.com](http://courses.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Conventions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Code words in text, database table names, folder names, filenames, file extensions,
    pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "Recall
    that an algorithm class'' implementation needs two specific methods to interact
    with the bandit API, `decide()` and `update()`, the latter of which is simpler
    and is implemented."'
  prefs: []
  type: TYPE_NORMAL
- en: 'Words that you see onscreen (for example, in menus or dialog boxes) also appear
    in the text like this: "The `DISTRIBUTIONS` tab provides an overview of how the
    model parameters are distributed across epochs."'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'New terms and important words are shown like this: "Its architecture allows
    users to run it on a wide variety of hardware, from CPUs to **Tensor Processing
    Units** (**TPUs**), including GPUs as well as mobile and embedded platforms."'
  prefs: []
  type: TYPE_NORMAL
- en: Code Presentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Lines of code that span multiple lines are split using a backslash ( `\` ).
    When the code is executed, Python will ignore the backslash, and treat the code
    on the next line as a direct continuation of the current line.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Comments are added into code to help explain specific bits of logic. Single-line
    comments are denoted using the `#` symbol, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Multi-line comments are enclosed by triple quotes, as shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Setting up Your Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we explore the book in detail, we need to set up specific software and
    tools. In the following section, we shall see how to do that.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Anaconda for Jupyter Notebook
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jupyter notebooks are available once you install Anaconda on your system. Anaconda
    can be installed on Windows systems using the steps available at [https://docs.anaconda.com/anaconda/install/windows/](https://docs.anaconda.com/anaconda/install/windows/).
  prefs: []
  type: TYPE_NORMAL
- en: For other systems, navigate to the respective installation guide from [https://docs.anaconda.com/anaconda/install/](https://docs.anaconda.com/anaconda/install/).
  prefs: []
  type: TYPE_NORMAL
- en: Installing a Virtual Environment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In general, it is good practice to use separate virtual environments when installing
    Python modules, to be sure that the dependencies of different projects do not
    conflict with one another. So, it is recommended that you adopt this approach
    before executing these instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since we are using Anaconda here, it is highly recommended that you use conda-based
    environment management. Run the following commands in Anaconda Prompt to create
    an environment and activate it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Installing Gym
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To install Gym, please make sure you have Python 3.5+ installed on your system.
    You can simply install Gym using `pip`. Run the code in Anaconda Prompt, as shown
    in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also build the Gym installation from source, by cloning the Gym Git
    repository directly. This type of installation proves useful when modifying Gym
    or adding environments if required. Use the following code to install Gym from
    source:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the following code to perform a full installation of Gym. This installation
    may need you to install other dependencies, which include `cmake` and a recent
    version of `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'In *Chapter 11, Policy-Based Methods for Reinforcement Learning*, you will
    be working in the `Box2D` environment available in Gym. You can install the `Box2D`
    environment by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Installing TensorFlow 2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To install TensorFlow 2, run the following command in Anaconda Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are using a GPU, you can use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Installing PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PyTorch can be installed on Windows using the steps available at [https://pytorch.org/](https://pytorch.org/).
  prefs: []
  type: TYPE_NORMAL
- en: 'In the case of non-availability of a GPU on your system, you can install the
    CPU version of PyTorch by running the following code in Anaconda Prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Installing OpenAI Baselines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenAI Baselines can be installed using the instructions at [https://github.com/openai/baselines](https://github.com/openai/baselines).
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the OpenAI Baselines repository, check out the TensorFlow 2 branch,
    and install it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We use OpenAI Baselines in *Chapter 1, Introduction to Reinforcement Learning*,
    and *Chapter 4, Getting Started with OpenAI and TensorFlow* for Reinforcement
    Learning. As OpenAI Baselines uses a version of Gym that is not the latest version,
    `0.14`, you might get an error as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The solution to this bug is to change the two `env.entry_point` attributes in
    `baselines/run.py` back to `env._entry_point`.
  prefs: []
  type: TYPE_NORMAL
- en: The detailed solution is available at [https://github.com/openai/baselines/issues/977#issuecomment-518569750](https://github.com/openai/baselines/issues/977#issuecomment-518569750).
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, you can also use the following command to upgrade the Gym installation
    in that environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Installing Pillow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following command in Anaconda Prompt to install Pillow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can also run the following command using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can read more about Pillow at [https://pypi.org/project/Pillow/2.2.1/](https://pypi.org/project/Pillow/2.2.1/).
  prefs: []
  type: TYPE_NORMAL
- en: Installing Torch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Use the following command to install `torch` using `pip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that you will be using version `0.4.1` of `torch` only in *Chapter 11,
    Policy-Based Methods for Reinforcement Learning*. You can revert to the updated
    version of PyTorch by using the command under the *Installing PyTorch* section
    for the other chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Other Libraries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`pip` comes pre-installed with Anaconda. Once Anaconda is installed on your
    machine, all the required libraries can be installed using `pip`, for example,
    `pip install numpy`. Alternatively, you can install all the required libraries
    using `pip install –r requirements.txt`. You can find the `requirements.txt` file
    at [https://packt.live/311jlIu](https://packt.live/311jlIu).'
  prefs: []
  type: TYPE_NORMAL
- en: The exercises and activities will be executed in Jupyter Notebooks. Jupyter
    is a Python library and can be installed in the same way as the other Python libraries
    – that is, with `pip install jupyter`, but fortunately, it comes pre-installed
    with Anaconda. To open a notebook, simply run the command `jupyter notebook` in
    the Terminal or Command Prompt.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the Code Files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can find the complete code files of this book at [https://packt.live/2V1MwHi](https://packt.live/2V1MwHi).
  prefs: []
  type: TYPE_NORMAL
- en: We've tried to support interactive versions of all activities and exercises,
    but we recommend a local installation as well for instances where this support
    isn't available.
  prefs: []
  type: TYPE_NORMAL
- en: If you have any issues or questions about installation, please email us at `workshops@packt.com`.
  prefs: []
  type: TYPE_NORMAL
