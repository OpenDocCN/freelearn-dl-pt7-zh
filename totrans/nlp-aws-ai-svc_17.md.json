["```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [ {\n      \"Action\": [\n          \"iam:PassRole\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"<your sagemaker notebook execution role ARN\">\n      }\n     ]\n    }\n    ```", "```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [\n      { \"Effect\": \"Allow\", \n        \"Principal\": \n          { \"Service\": \n              [ \"sagemaker.amazonaws.com\", \n                \"s3.amazonaws.com\", \n                \"comprehend.amazonaws.com\" ] \n              }, \n              \"Action\": \"sts:AssumeRole\" } \n          ] \n      }\n    ```", "```py\n    bucket = '<bucket-name>'\n    ```", "```py\n    comprehend = boto3.client('comprehend')\n    ```", "```py\n    s3_raw_key = prefix + \"/train/raw_txt.csv\" \n    s3_entity_key = prefix + \"/train/entitylist.csv\"\n    s3.upload_file('train/raw_txt.csv',bucket,s3_raw_key)\n    s3.upload_file('train/entitylist.csv',bucket,s3_entity_key)\n    ```", "```py\n    import datetime\n    cer_name = \"loan-app-recognizer\"+str(datetime.datetime.now().strftime(\"%s\"))\n    cer_response = comprehend.create_entity_recognizer(\n            RecognizerName = cer_name, \n            DataAccessRoleArn = role,\n            InputDataConfig = cer_input_object,\n            LanguageCode = \"en\"\n    )\n    ```", "```py\n    import pprint\n    pp = pprint.PrettyPrinter(indent=4)\n    response = comprehend.describe_entity_recognizer(\n        EntityRecognizerArn=cer_response['EntityRecognizerArn']\n    )\n    pp.pprint(response)\n    ```", "```py\n    WORKTEAM_ARN= '<workteam-arn>'\n    ```", "```py\n    documentName = \"input/sample-loan-application.png\"\n    display(Image(filename=documentName))\n    ```", "```py\n    s3.upload_file(documentName,bucket,prefix+'/'+documentName)\n    ```", "```py\n     !pip install amazon-textract-response-parser        \n    ```", "```py\n    textract = boto3.client('textract')\n    response = textract.analyze_document(Document={'S3Object': {\n                'Bucket': bucket,\n                'Name': prefix+'/'+documentName\n            }}, FeatureTypes=['FORMS'])\n    ```", "```py\n    from trp import Document\n    doc = Document(response)\n    df = pd.DataFrame()\n    # Iterate over elements in the document\n    x = 0\n    for page in doc.pages:\n        for field in page.form.fields:   \n            if field.key is not None and field.value is not None:\n                if field.value.text not in ('SELECTED','NOT_SELECTED'):\n                    df.at[x,'key'] = field.key.text\n                    df.at[x,'value'] = field.value.text\n                    x+=1\n    df\n    ```", "```py\n    df_T.columns = df_T.columns.str.rstrip()\n    df_T['doc'] = 1\n    df_T\n    for idx, row in df_T.iterrows():\n            entry = 'Country'+':'+str(row['Country']).strip()+\" \"+'Years'+':'+str(row['Years']).strip()+\" \"+'Cell Phone'+':'+str(row['Cell Phone']).strip()+\" \"+'Name'+':'+str(row['Name']).strip()+\" \"+'Social Security Number'+':'+str(row['Social Security Number']).strip()+\" \"+'TOTAL $'+':'+str(row['TOTAL $']).strip()+\" \"+'Date of Birth'+':'+str(row['Date of Birth']).strip()\n    ```", "```py\n    custom_recognizer_arn=cer_response['EntityRecognizerArn']\n    endpoint_response = comprehend.create_endpoint(\n        EndpointName='nlp-chapter4-cer-endpoint',\n        ModelArn=custom_recognizer_arn,\n        DesiredInferenceUnits=2,\n        DataAccessRoleArn=role\n    )\n    endpoint_response['EndpointArn']\n    ```", "```py\n    arn:aws:comprehend:us-east-1:<aws-account-nr>:entity-recognizer-endpoint/nlp-chapter4-cer-endpoint\n    ```", "```py\n    response = comprehend.detect_entities(Text=entry,\n                        LanguageCode='en',\n    EndpointArn=endpoint_response['EndpointArn']\n                )\n    print(response)\n    ```", "```py\n    {'Entities': [{'Score': 0.9999999403953552, 'Type': 'PERSON', 'Text': 'Years:18', 'BeginOffset': 11, 'EndOffset': 19}, {'Score': 0.9999998211860657, 'Type': 'PERSON', 'Text': 'Cell Phone:(555 ) 0200 1234', 'BeginOffset': 20, 'EndOffset': 47}, {'Score': 1.0, 'Type': 'PERSON', 'Text': 'Name:Kwaku Mensah', 'BeginOffset': 48, 'EndOffset': 65}, {'Score': 1.0, 'Type': 'PERSON', 'Text': 'Social Security Number:123 - 45 - 6789', 'BeginOffset': 66, 'EndOffset': 104}, {'Score': 1.0, 'Type': 'PERSON', 'Text': 'TOTAL $:8000.00/month', 'BeginOffset': 105, 'EndOffset': 126}, {'Score': 1.0, 'Type': 'PERSON', 'Text': 'Date of Birth:01 / 01 / 1953', 'BeginOffset': 127, 'EndOffset': 155}], 'ResponseMetadata': {'RequestId': 'ecbd75fd-22bc-4dca-9aa0-73f58f6784e4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ecbd75fd-22bc-4dca-9aa0-73f58f6784e4', 'content-type': 'application/x-amz-json-1.1', 'content-length': '620', 'date': 'Tue, 06 Jul 2021 22:26:11 GMT'}, 'RetryAttempts': 0}}\n    ```", "```py\n    import json\n    human_loop_input = []\n    data = {}\n    ent = response['Entities']\n    existing_entities = []\n    if ent != None and len(ent) > 0:\n        for entity in ent:       \n            current_entity = {}\n            current_entity['label'] = entity['Type']\n            current_entity['text'] = entity['Text']\n            current_entity['startOffset'] = entity['BeginOffset']\n            current_entity['endOffset'] = entity['EndOffset']\n            existing_entities.append(current_entity)\n        data['ORIGINAL_TEXT'] = entry\n        data['ENTITIES'] = existing_entities   \n        human_loop_input.append(data)\n    print(human_loop_input)        \n    126}, {'label': 'PERSON', 'text': 'Date of Birth:01 / 01 / 1953', 'startOffset': 127, 'endOffset': 155}]}]\n    ```", "```py\n    timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n    # Amazon SageMaker client\n    sagemaker = boto3.client('sagemaker')\n    # Amazon Augment AI (A2I) client\n    a2i = boto3.client('sagemaker-a2i-runtime')\n    # Flow definition name\n    flowDefinition = 'fd-nlp-chapter14-' + timestamp\n    # Task UI name - this value is unique per account and region. You can also provide your own value here.\n    taskUIName = 'ui-nlp-chapter14-' + timestamp\n    # Flow definition outputs\n    OUTPUT_PATH = f's3://' + bucket + '/' + prefix + '/a2i-results'\n    ```", "```py\n    def create_task_ui():\n        '''\n        Creates a Human Task UI resource.\n        Returns:\n        struct: HumanTaskUiArn\n        '''\n        response = sagemaker.create_human_task_ui(\n            HumanTaskUiName=taskUIName,\n            UiTemplate={'Content': template})\n        return response\n    # Create task UI\n    humanTaskUiResponse = create_task_ui()\n    humanTaskUiArn = humanTaskUiResponse['HumanTaskUiArn']\n    print(humanTaskUiArn)\n    ```", "```py\n    arn:aws:sagemaker:us-east-1:<aws-account-nr>:human-task-ui/ui-nlp-chapter14-<timestamp>\n    ```", "```py\n    completed_human_loops = []\n    a2i_resp = a2i.describe_human_loop(HumanLoopName=humanLoopName)\n    print(f'HumanLoop Name: {humanLoopName}')\n    print(f'HumanLoop Status: {a2i_resp[\"HumanLoopStatus\"]}')\n    print(f'HumanLoop Output Destination: {a2i_resp[\"HumanLoopOutput\"]}')\n    print('\\n')\n    if a2i_resp[\"HumanLoopStatus\"] == \"Completed\":\n        completed_human_loops.append(resp)\n    ```", "```py\n    HumanLoop Name: 0fe076a4-b6eb-49ea-83bf-78f953a71c89\n    HumanLoop Status: InProgress\n    HumanLoop Output Destination: {'OutputS3Uri': 's3://<your-bucket-name>/chapter4/a2i-results/fd-nlp-chapter4-2021-07-06-22-32-21/2021/07/06/22/33/08/<hashnr>/output.json'\n    ```", "```py\n    workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n    print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n    print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])\n    ```", "```py\n    retrain='N'\n    el = open('train/entitylist.csv','r').read()\n    for annotated_entity in a2i_entities:\n        if original_text[annotated_entity['startOffset']:annotated_entity['endOffset']] not in el:\n            retrain='Y'\n            word = '\\n'+original_text[annotated_entity['startOffset']:annotated_entity['endOffset']]+','+annotated_entity['label'].upper()\n            print(\"Updating Entity List with: \" + word)\n            open('train/entitylist.csv','a').write(word)\n    if retrain == 'Y':\n        print(\"Entity list updated, model to be retrained\")\n    ```", "```py\n    Updating Entity List with: \n    Country:US,GHOST\n    Updating Entity List with: \n    Years:18,PERSON\n    Updating Entity List with: \n    Cell Phone:(555 ) 0200 1234,PERSON\n    Entity list updated, model to be retrained\n    ```", "```py\n    Import datetime\n    cer_name = \"retrain-loan-recognizer\"+str(datetime.datetime.now().strftime(\"%s\"))\n    cer_response = comprehend.create_entity_recognizer(\n            RecognizerName = cer_name, \n            DataAccessRoleArn = role,\n            InputDataConfig = cer_input_object,\n            LanguageCode = \"en\"\n    )\n    ```", "```py\n    {   'EntityRecognizerProperties': {   'DataAccessRoleArn': 'arn:aws:iam::<aws-account-nr>:role/service-role/<execution-role>',\n                                          'EntityRecognizerArn': 'arn:aws:comprehend:us-east-1:<aws-account-nr>:entity-recognizer/retrain-loan-recognizer1625612436',\n                                          'InputDataConfig': {   'DataFormat': 'COMPREHEND_CSV',\n                                                                 'Documents': {   'S3Uri': 's3://<s3-bucket>/chapter4/train/raw_txt.csv'},\n                                                                 'EntityList': {   'S3Uri': 's3://<s3-bucket>/chapter4/train/entitylist.csv'},\n                                                                 'EntityTypes': [   {   'Type': 'PERSON'},\n                                                                                    {   'Type': 'GHOST'}]},\n                                          'LanguageCode': 'en',\n                                          'Status': 'SUBMITTED',\n                                          'SubmitTime': datetime.datetime(2021, 7, 6, 23, 0, 36, 759000, tzinfo=tzlocal())}}\n    ```", "```py\n    [{'endOffset': 10, 'label': 'GHOST', 'startOffset': 0},\n     {'endOffset': 19, 'label': 'PERSON', 'startOffset': 11},\n     {'endOffset': 47, 'label': 'PERSON', 'startOffset': 20},\n     {'endOffset': 65, 'label': 'PERSON', 'startOffset': 48},\n     {'endOffset': 104, 'label': 'PERSON', 'startOffset': 66},\n     {'endOffset': 126, 'label': 'PERSON', 'startOffset': 105},\n     {'endOffset': 155, 'label': 'PERSON', 'startOffset': 127}]\n    ```", "```py\n    from collections import Counter\n    docstatus = ''\n    ghost = float(Counter(labellist)['GHOST'])\n    person = float(Counter(labellist)['PERSON'])\n    if ghost >= len(labellist)*.5:\n        docstatus = 'REJECT'\n    elif min(len(labellist)*.5, len(labellist)*.8) < person < max(len(labellist)*.5, len(labellist)*.8):\n        docstatus = 'SUMMARY APPROVE'\n    elif person > len(labellist)*.8:\n        docstatus = 'APPROVE'\n    print(docstatus)    \n    ```"]