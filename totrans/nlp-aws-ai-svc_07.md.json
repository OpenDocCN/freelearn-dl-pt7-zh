["```py\n    def handler(event, context):\n    bucket = event['Records'][0]['s3']['bucket']['name']\n    key = unquote_plus(event['Records'][0]['s3']['object']['key'])\n    ```", "```py\n           s3.Bucket(bucket).download_file(Key=key,Filename='/tmp/{}')\n            with open('/tmp/{}', 'rb') as document:\n                imageBytes = bytearray(document.read())\n            print(\"Object downloaded\")\n    ```", "```py\n    response = textract.analyze_document(Document={'Bytes': imageBytes},FeatureTypes=[\"TABLES\", \"FORMS\"])\n    document = Document(response)\n    ```", "```py\n     blocks=response['Blocks']\n            for block in blocks:\n                if block['BlockType'] == 'LINE':\n                     text += block['Text']+\"\\n\"\n              print(text)\n    ```", "```py\n    keyphrase_response = comprehend.detect_key_phrases(Text=text, LanguageCode='en')\n    KeyPhraseList=keyphrase_response.get(\"KeyPhrases\")\n     for s in KeyPhraseList:\n                                textvalues.append(s.get(\"Text\")\n    ```", "```py\n    detect_entity= comprehend.detect_entities(Text=text, LanguageCode='en')\n    EntityList=detect_entity.get(\"Entities\")\n    for s in EntityList:\n                                             textvalues_entity.update([(s.get(\"Type\").strip('\\t\\n\\r'),s.get(\"Text\").strip('\\t\\n\\r'))]\n    ```", "```py\n    s3url='https://s3.console.aws.amazon.com/s3/object/'+bucket+'/'+key+'?region='+region\n    ```", "```py\n    searchdata={'s3link':s3url,'KeyPhrases':textvalues,'Entity':textvalues_entity,'text':text, 'table':table, 'forms':forms}\n    print(searchdata)\n    print(\"connecting to ES\")\n    es=connectES()\n    es.index(index=\"document\", doc_type=\"_doc\", body=searchdata)\n    ```", "```py\n    # Define IAM role\n    role = get_execution_role()\n    print(\"RoleArn: {}\".format(role))\n    sess = sagemaker.Session()\n    s3BucketName = '<your s3 bucket name>'\n    prefix = 'chapter5'\n    ```", "```py\n    comprehend = boto3.client('comprehend')\n    textract= boto3.client('textract')\n    kendra= boto3.client('kendra')\n    ```", "```py\n    text=\"\"\n    for resultPage in response:\n        for item in resultPage[\"Blocks\"]:\n            if item[\"BlockType\"] == \"LINE\":\n                #print ('\\033[94m' +  item[\"Text\"] + '\\033[0m')\n                text += item['Text']+\"\\n\"\n    print(text)\n    ```", "```py\n    entities= comprehend.detect_entities(Text=text, LanguageCode='en')\n    ```", "```py\n    response = kendra.create_index(\n        Name='Search',\n        Edition='DEVELOPER_EDITION',\n        RoleArn='<enter IAM role by creating IAM role in IAM console')\n    print(response)\n    ```", "```py\n    response = kendra.update_index(\n        Id=\"<paste Index Id from Create Index response>\",\n        DocumentMetadataConfigurationUpdates=[\n            {\n                'Name':'ORGANIZATION',\n                'Type':'STRING_LIST_VALUE',\n                'Search': {\n                    'Facetable': True,\n                    'Searchable': True,\n                    'Displayable': True\n                }\n            }}\n    ```", "```py\n    categories = [\"ORGANIZATION\", \"PERSON\", \"DATE\", \"COMMERCIAL_ITEM\", \"OTHER\", \"TITLE\", \"QUANTITY\"]\n    ```", "```py\n    for e in entities[\"Entities\"]:\n        if (e[\"Text\"].isprintable()) and (not \"\\\"\" in e[\"Text\"]) and (not e[\"Text\"].upper() in category_text[e[\"Type\"]]):\n                    #Append the text to entity data to be used for a Kendra custom attribute\n                    entity_data[e[\"Type\"]].add(e[\"Text\"])\n                    #Keep track of text in upper case so that we don't treat the same text written in different cases differently\n                    category_text[e[\"Type\"]].append(e[\"Text\"].upper())\n                    #Keep track of the frequency of the text so that we can take the text with highest frequency of occurrance\n                    text_frequency[e[\"Type\"]][e[\"Text\"].upper()] = 1\n        elif (e[\"Text\"].upper() in category_text[e[\"Type\"]]):\n                    #Keep track of the frequency of the text so that we can take the text with highest frequency of occurrance\n                    text_frequency[e[\"Type\"]][e[\"Text\"].upper()] += 1\n    print(entity_data)\n    ```", "```py\n    elimit = 10\n    for et in categories:\n    ```", "```py\n        el = [pair[0] for pair in sorted(text_frequency[et].items(), key=lambda item: item[1], reverse=True)][0:elimit]\n        metadata[et] = [d for d in entity_data[et] if d.upper() in el]\n    metadata[\"_source_uri\"] = documentName\n    attributes[\"Attributes\"] = metadata\n    ```", "```py\n    s3 = boto3.client('s3')\n    prefix= 'meta/'\n    with open(\"metadata.json\", \"rb\") as f:\n        s3.upload_file( \"metadata.json\", s3BucketName,'%s/%s' % (\"meta\",\"resume_Sample.pdf.metadata.json\"))\n    ```"]