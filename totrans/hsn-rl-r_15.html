<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Exploring Deep Reinforcement Learning Methods</h1>
                </header>
            
            <article>
                
<p class="mce-root"><strong>Neural networks</strong> (<strong>NNs</strong>) are exceptionally effective at getting good characteristics for highly structured data. We could then represent our Q function with a neural network, which takes the status and action as input and outputs (gives) the corresponding Q value. <strong>Deep reinforcement learning</strong> (<strong>DRL</strong>) methods use deep neural networks to approximate any of the following reinforcement learning components: value function, policy, and model.</p>
<p class="mce-root">In this chapter, we will deal with DRL gradually. First, we will learn the basic concepts of artificial neural networks and see how to apply them by taking a practical example. Later, we will see how to apply these concepts to reinforcement learning to improve the performance of the algorithms.</p>
<p><span>By</span> <span>the</span> <span>end</span> <span>of this chapter, we will learn the fundamentals of artificial neural networks, how to apply feedforward neural network methods to your data, and how neural network algorithms work. We will understand the basic concepts that deep neural networks use to approximate reinforcement learning components and we will learn how to implement a deep Q network using R. Finally, we will learn how to implement a deep recurrent Q network using R.</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Introducing neural network basic concepts</li>
<li>Managing feed-forward neural networks</li>
<li>Neural network for regression</li>
<li>Approaching DRL</li>
<li>Deep recurrent Q-networks</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/35szk1D">http://bit.ly/35szk1D</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introducing neural network basic concepts</h1>
                </header>
            
            <article>
                
<p><strong>Artificial neural networks</strong> (<strong>ANNs</strong>) are mathematical models whose purpose is to try to simulate some typical human brain activities such as pattern recognition, language comprehension, image perception, and so on. The architecture of an ANN is composed of a system of nodes, which refer to the neurons of a human brain, interconnected between them by weighted connections, which simulate synapses between neurons. The output of the network is updated iteratively through the link weights up to the convergence. The data collected in the experimental fields are provided at the input level and the network result is provided by the output level. The input nodes represent the independent or predictive variables necessary to predict the dependent variables that represent the output neurons.</p>
<p>Neural networks offer a very powerful set of tools that can solve problems in the field of classification, regression, and non-linear control. In addition to having a high processing speed, neural networks can learn the solution from a certain set of examples. In many applications, this allows us to circumvent the need to develop a model of the physical processes underlying the problem, which can often be difficult, if not impossible, to find.</p>
<p>ANNs try to emulate the behavior of biological neurons. Let's see how.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Biological neural networks</h1>
                </header>
            
            <article>
                
<p>The inspiration for neural networks derives from studies on information-processing mechanisms in the biological nervous system, the human brain; in fact, much of the research on neural networks has precisely the purpose of investigating these mechanisms. An artificial neural network is made up of many neurons or simple processors. An artificial neuron mimics the characteristics of a biological neuron—every cell in the human nervous system can receive, process, and transmit electrical signals.</p>
<p>It consists of four basic parts, namely, the following:</p>
<ul>
<li>Body cell</li>
<li>Synapses</li>
</ul>
<ul>
<li>Axon</li>
<li>Dendrites</li>
</ul>
<p>The dendrites receive electrical information from other neurons through the synapses and transmit them to the body of the cell. Here, they are added together and, if the total excitation exceeds a threshold limit, the cell reacts by passing the signal to another cell through the axon.</p>
<p>The following diagram shows the structure of a biological neuron:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-552 image-border" src="assets/73296bdf-c324-4417-a0c0-dc8611f99d3a.png" style="width:33.50em;height:15.92em;"/></p>
<p>When the signal reaches the synapse, it causes the release of chemicals called neurotransmitters, which enter the bodies of other neurons. Depending on the type of synapse, which can be excitatory or inhibitory, these substances respectively increase or decrease the probability that the next neuron becomes active. At each synapse, a weight is associated, which determines the type and magnitude of the exciter or inhibitor effect. Hence, each neuron carries out a weighted sum of the inputs coming from the other neurons and, if this sum exceeds a certain threshold, the neuron is activated.</p>
<p>Each operation performed by the neuron has a millisecond duration, so it represents a relatively slow processing system. However, the entire network has a very large number of neurons and synapses that can operate in parallel and simultaneously, making the actual processing power very high. Furthermore, the biological neural network has a high tolerance to inaccurate or even wrong information; it has the capacity for learning and generalization, which makes it so efficient in identification and classification operations.</p>
<p>The functioning of neurons regulates the activities of the brain, which is a naturally optimized machine for solving complex problems. Its structure, made of simple elements, has evolved over time in the direction of improving its capabilities: there is no central control, and all areas of the brain contribute together to the realization of a task or the solution of a problem in a contributory way. If one part of the brain stops working, it continues to perform its tasks, perhaps not with the same performance. The brain is fault-tolerant; its performance slowly degrades in proportion to the destruction of its neurons.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Artificial neural networks</h1>
                </header>
            
            <article>
                
<p>In a similar way to a biological neuron, an artificial neuron receives various stimuli in input, each of which is the output of another neuron. Each input is then multiplied by a corresponding weight and added to the others to determine the level of neuron activation by another function.</p>
<p>The architecture of a neural network is characterized by the distinction between input neurons and output neurons, the number of layers of synapses (or neurons), and the presence of feedback connections, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-553 image-border" src="assets/3f591bb8-d3f4-4be8-bbb0-be0b3f1a1306.png" style="width:27.83em;height:17.67em;"/></p>
<p>When an input vector (stimulus) is applied to the input neurons of the neural network, the signals travel in parallel along the connections through the internal nodes, up to the output and hence produce the response of the neural network. In the simplest formulation, each node processes only the local information, does not know the overall purpose of the processing, and has no memory. The response and behavior of the network depend intrinsically on its architecture and the value of artificial synapses.</p>
<p>In some cases, a single layer of synapses is not sufficient to learn the desired association between input and output patterns: in these cases, it is necessary to use multi-layer networks that possess internal neurons and more than one layer of synapses. These networks are called deep neural networks. The response of such a network is obtained by calculating the activation of a layer of neurons at a time proceeding gradually from the internal nodes toward the exit nodes.</p>
<p>An artificial neural network goal is simply the computation of the outputs of all of the neurons, through a deterministic calculation. Basically, ANN is a set of mathematical function approximations. The following elements are essential in an ANN architecture:</p>
<ul>
<li>Layers</li>
<li>Weights</li>
<li>Bias</li>
<li>Activation function</li>
</ul>
<p>In the following sections, we will dive deeper into these concepts.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Layers types</h1>
                </header>
            
            <article>
                
<p>We already introduced the architecture of an artificial neural network in the <em>Artificial neural networks</em> section, and we have been able to analyze a scheme in which different types of neurons were highlighted. In that scheme, it is possible to identify a structure in layers. In fact, we can easily identify an input layer, a middle layer (named hidden layer), and an output layer, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-554 image-border" src="assets/625dcdbc-3f1d-4829-b703-2cbfaf8b798c.png" style="width:27.00em;height:19.50em;"/></p>
<p>In the previous diagram, it is possible to identify the simplest of architectures that includes an input layer, a single hidden layer, and an output layer.</p>
<p>Each layer has its own task that it performs through the action of the neurons it contains. The input layer is intended to introduce the initial data into the system for further processing by the subsequent layers. From the input level, the workflow of the artificial neural network begins.</p>
<p>In the input layer, artificial neurons have a different role to play in some <em>passive</em> way because they do not receive information from previous levels. In general, they receive a series of inputs and introduce the information into the system for the first time. This level then sends the data to the next levels, where the neurons receive weighted inputs.</p>
<p>The hidden layer in an artificial neural network is interposed between input levels and output levels. The neurons of the hidden layer receive a set of weighted inputs and produce an output according to the indications received from an activation function. It represents the essential part of the entire network, as it is here that the magic of transforming the input data into output responses takes place.</p>
<p>Hidden levels can operate in many ways. In some cases, the inputs are weighted randomly; in others they are calibrated through an iterative process. In general, the neuron of the hidden layer functions as a biological neuron in the brain: it takes its probabilistic input signals, processes them, and converts them into an output corresponding to the axon of the biological neuron.</p>
<p>Finally, the output layer produces certain outputs for the model. Although they are made in a way very similar to other artificial neurons in the neural network, the type and number of neurons in the output layer depend on the type of response the system must provide. For example, if we are designing a neural network for the classification of an object, the output layer will consist of a single node that will provide us with this value. In fact, the output of this node must simply provide a positive or negative indication of the presence or absence of the target in the input data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Weights and biases</h1>
                </header>
            
            <article>
                
<p>In an artificial neural network, the conversion of an input into an output takes place thanks to the contribution of the weights of the connections. In linear regression, the slope is multiplied by the input to provide the output. The same argument can be made for weights in a neural network. In fact, they represent numerical parameters that specify the contribution of each neuron to the final result. For example, if the inputs are <em>x<sub>1</sub></em>, <em>x<sub>2</sub></em>, and <em>x<sub>3</sub></em>, the synaptic weights to be applied to these are indicated as <em>w<sub>1</sub></em>, <em>w<sub>2</sub></em>, and <em>w<sub>3</sub></em>.</p>
<p>In this assumption, we can represent the output returned by the neuron through the following formula:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4256d04d-bce5-4e1b-88ed-11f17e638b6d.png" style="width:12.83em;height:2.08em;"/></p>
<p>In the previous formula, <em>i</em> is the number of inputs.</p>
<p>In the preceding formula, the matrix multiplication defines a weighted sum. To this weighted sum, it is necessary to add the bias that can be compared to the added intercept in a linear equation. The bias is, therefore, an additional parameter that is used to adjust the output of each neuron.</p>
<p>The processing done by a neuron is hence denoted as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/c0f19659-6821-499f-8683-42de46ad1f66.png" style="width:17.92em;height:1.75em;"/></p>
<p>The output is adjusted by the activation function. The output of neurons in a level will represent the input of the next level, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-555 image-border" src="assets/29ed19a0-afef-442c-8bab-2f7cb2683f12.png" style="width:26.33em;height:14.25em;"/></p>
<p>The meaning of this scheme is that we are giving the input signal (<em>x<sub>i</sub></em>) a weight (<em>w<sub>i</sub></em>), which is a real number that reproduces the natural synapse. When the value <em>w<sub>i</sub></em> is greater than zero, the channel is called <strong>excitatory</strong>; if the value is less than zero, the channel is inhibitory. The absolute value of <em>w<sub>i</sub></em> represents the strength of the connection.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p>The activation function plays a crucial role in processing system output. The activation function represents a mathematical function that converts the input into output and defines the process based on neural networks. Without the contribution of the activation function, a neural network is trivialized to a simple linear function. In a linear function, the conversion from input to output is realized through a direct proportionality, as shown in the following example:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/aa07f9f6-1e5d-4eda-9545-da04c1ead7e7.png" style="width:7.33em;height:1.33em;"/></p>
<p>Simply, a linear function is a polynomial of the first degree, then a straight line. In the real world, most problems are non-linear and complex in nature. To deal with non-linear problems, it is necessary to use the activation functions. Nonlinear functions are high degree polynomial functions, as shown in the following example:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/66702e7f-863e-4487-aa2f-756cbdbf85f8.png" style="width:5.83em;height:1.58em;"/></p>
<p>It is a non-linear function that contains a factor of complexity. The activation functions add the non-linearity property to neural networks and characterize them as approximators of universal functions.</p>
<p>There are many activation functions available for a neural network to use. The following are the most used:</p>
<ul>
<li><strong>Sigmoid</strong>: This function is represented by a sigmoid curve, typical for its S shape. This is the most used activation function. Its action is to transform the input into a value between 0 and 1. In this way, the model takes on a logistical nature.</li>
<li><strong>Unit step</strong>: This function transforms the input into 0 if the argument is negative and 1 if the argument is positive. In this way, the output takes on a binary nature. These activation functions are used for binary schemes.</li>
<li><strong>Hyperbolic tangent</strong>: It is a non-linear function, defined in the range of values (-1, 1). These functions are interesting because they allow the neuron to have a continuous output, which allows a probabilistic interpretation.</li>
<li><strong>Rectified Linear Unit</strong> (<strong>ReLU</strong>): It is a function with linear characteristics for parts of the existence domain that will output the input directly if is positive; otherwise, it will output zero. The range of output is between 0 and infinity. ReLU finds applications in computer vision and speech recognition using deep neural networks.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managing feedforward neural networks</h1>
                </header>
            
            <article>
                
<p>When the flow passes from the input layer to the hidden layers and therefore to the output layer, we talk about feed-forward propagation. In this case, the transfer function is applied to each hidden level. Hence, the value of the activation function is propagated to the next level. The next layer can be another hidden layer or the output layer.</p>
<p>The term <strong>feedforward</strong> is used to indicate the networks in which each node receives connections only from the lower layers. These networks emit a response for each input pattern but fail to capture the possible temporal structure of the input information or to exhibit endogenous temporal dynamics.</p>
<p>Now let's move on to a crucial topic for neural networks: neural network training.</p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural network training</h1>
                </header>
            
            <article>
                
<p>To choose the input values for which a neuron turns on or off, the network is trained. This is a crucial step in the realization of the model, which consists of training the neural network to generalize the information, starting from a set of inputs corresponding to known outputs. The performances of the network depend very much on the information presented to them: they must be representative of what the network must learn. Training is a fundamental part of building a neural network and the examples to be used (training set) must be carefully chosen.</p>
<p>We shall take a step-by-step approach to understand the neural network training with a single hidden layer. Let's take the input layer has one neuron and the output will solve a binary classification problem (predict 0 or 1). Here's a list of all the steps for training a network:</p>
<ol>
<li>Load the input as a matrix.</li>
<li>Use random values to initialize weights and biases. This step must be done only at the beginning, then just update them.</li>
<li>Repeat the following steps from 4 to 9 for each epoch, until convergence.</li>
<li>Send the inputs to the network.</li>
<li>Estimate the output from the input layer, through the hidden layer(s), to the output layer.</li>
<li><span>Estimate</span> the error at the outputs.</li>
<li>Adopt the output error to calculate error signals for previous layers.</li>
<li><span>Adopt</span> the error signals to <span>calculate</span> weight changes.</li>
<li>Use the weight changes to update them.</li>
</ol>
<p><em>Steps 4</em> and <em>5</em> are forward propagation and <em>steps 6</em> through <em>9</em> are backpropagation.</p>
<p>In general, the most used method to teach a network to generalize through the adjustment of neuron weights (<em>w<sub>i</sub></em>) is to follow the <strong>delta rule</strong>, which consists of comparing the network outputs with the desired values: subtract the two values and the difference is used to update all of the weights of the inputs that have different values of zero.</p>
<p>The process is iterated until convergence is reached. The following diagram shows a graph of the net weight adjustment procedure:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-556 image-border" src="assets/82ab85ec-fe9a-4657-8e9c-216e5cc8a8af.png" style="width:24.08em;height:16.42em;"/></p>
<p>In practice, the algorithm compares the inputs with the outputs: the difference between the weighted input values and the output or expected values is calculated and the difference (error) is used to recalculate all the input weights. The procedure is repeated until the error between input and output becomes close to zero.</p>
<p>In the following section, we will apply neural networks to solve a regression problem.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural network for regression</h1>
                </header>
            
            <article>
                
<p>Regression analysis is the starting point in data science; in fact, they are the most well-understood models in numerical simulation. Regression models are easily interpreted as they are based on solid mathematical bases<span>—</span>think of matrix algebra. Linear regression allows us to derive a mathematical formula representative of the corresponding model. Therefore, these techniques are extremely easy to understand.</p>
<p>Regression analysis is a statistical process aimed at identifying the relationship between a set of independent variables (explanatory variables) and the dependent variable (response variable). With this technique, it is possible to establish how the value of the response variable changes when the explanatory variable is varied.</p>
<p>In the following <span>paragraphs</span>, an example of a regression predictive modeling problem is proposed to understand how to solve it with neural networks. The Boston dataset will be used as a data source; the median values of owner-occupied homes are predicted for the test data. The dataset describes 12 numerical properties of houses in Boston suburbs and is concerned with modeling the price of houses in those suburbs in thousands of dollars. As such, this is a regression predictive modeling problem because the output is a continuous variable.</p>
<p class="mce-root"/>
<div class="packt_tip">Remember that regression and classification are both related to the forecast: in classification, we try to predict the output by grouping it into classes (categorical variable) while, in regression, we try to predict the output value in a continuous way (continuous variable).</div>
<p>The Boston dataset input attributes include features such as crime rate, the proportion of non-retail business acres, and chemical concentrations.</p>
<div class="packt_infobox">To get the data, we draw on the large collection of data available in the UCI Machine Learning Repository at the following link: <a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</a>.</div>
<p>The number of instances and the number of variables are shown here:</p>
<ul>
<li>Number of instances: 506</li>
<li>Number of variables: 13 continuous variables (including the class attribute, <kbd>medv</kbd>) and 1 binary-valued attribute</li>
</ul>
<p>All the variables are shown in the following list:</p>
<ul>
<li><kbd>crimper</kbd>: Capita crime rate by town</li>
<li><kbd>zn</kbd>: Proportion of residential land zoned for lots over 25,000 square feet</li>
<li><kbd>indus</kbd>: Proportion of non-retail business acres per town</li>
<li><kbd>chas</kbd>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)</li>
<li><kbd>nox</kbd>: Nitric oxides concentration (parts per 10 million)</li>
<li><kbd>rm</kbd>: Average number of rooms per dwelling</li>
<li><kbd>age</kbd>: Proportion of owner-occupied units built before 1940</li>
<li><kbd>dis</kbd>: Weighted distances to five Boston employment centers</li>
<li><kbd>rad</kbd>: Index of accessibility to radial highways</li>
<li><kbd>tax</kbd>: Full-value property-tax rate per $10,000</li>
<li><kbd>ptratio</kbd>: Pupil-teacher ratio by town</li>
</ul>
<ul>
<li><kbd>lstat</kbd>: Percent lower status of the population</li>
<li><kbd>medv</kbd>: Median value of owner-occupied homes in $1,000s</li>
</ul>
<p>In the previous list, <kbd>medv</kbd> represents the response variable, and the other thirteen variables are the predictors. Our goal is to develop a regression model that simulates the variation of the <kbd>medv</kbd> value. The model should be able to identify the relationship between the first thirteen columns and the response variable <kbd>medv</kbd>, if it exists.</p>
<p class="mce-root"/>
<div class="packt_tip">
<p>This dataset is already provided with R libraries (MASS), so we do not have to worry about retrieving the data.</p>
</div>
<p>First, we have to get the data. To do this, as we said, we can use the MASS libraries:</p>
<ol>
<li>Let's load the library:</li>
</ol>
<pre style="padding-left: 60px">library(MASS)</pre>
<div>
<p style="padding-left: 60px">To install a new library, you need to use the <kbd>install.packages()</kbd> function. This feature installs the packages. It is necessary to pass a vector of names and a destination library, after which the command downloads the packages from the repositories and installs them.</p>
</div>
<ol start="2">
<li>Let's now concern ourselves with making the experiment reproducible:</li>
</ol>
<pre style="padding-left: 60px">set.seed(5)</pre>
<p style="padding-left: 60px">The <kbd>set.seed()</kbd> <span>command</span> <span>makes the example reproducible, in the sense that all of the random numbers generated will always be the same, for each simulation.</span></p>
<ol start="3">
<li>We can now load the dataset:</li>
</ol>
<pre style="padding-left: 60px">InputData = Boston</pre>
<ol start="4">
<li>We will only use the variables necessary for our analysis:</li>
</ol>
<pre style="padding-left: 60px">InputData = subset(InputData, select = -c(12) )</pre>
<p>The dataframe also includes the names of the variables as they are in the original dataset.</p>
<p>Let's start by taking a look at the data.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exploratory analysis</h1>
                </header>
            
            <article>
                
<p>We now perform an exploratory analysis to see how the data is distributed and to extract the preliminary knowledge. Let's start by checking the dataset using the <kbd>str()</kbd> function. This function returns a tight summary of the internal structure of an R object.</p>
<p>Ideally, only one line for each basic structure is displayed:</p>
<pre>str(InputData)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>The following results are returned:</p>
<pre>'<strong>data.frame':  506 obs. of  13 variables:</strong><br/><strong> $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...</strong><br/><strong> $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...</strong><br/><strong> $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.8 ...</strong><br/><strong> $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...</strong><br/><strong> $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 ...</strong><br/><strong> $ rm     : num  6.58 6.42 7.18 7 7.15 ...</strong><br/><strong> $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100...</strong><br/><strong> $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...</strong><br/><strong> $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...</strong><br/><strong> $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...</strong><br/><strong> $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15. ...</strong><br/><strong> $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...</strong><br/><strong> $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5...</strong></pre>
<p>So, we got the confirmation that it was 506 observations of 13 variables: 11 numericals and 2 integers. Now, to obtain a brief summary of the dataset, we can use the <kbd>summary()</kbd> function, as follows:</p>
<pre>summary(InputData)</pre>
<p>The <kbd>summary()</kbd> function returns a series of data statistics.</p>
<p>The results are shown here:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-557 image-border" src="assets/f1d52e33-2f77-4138-9fae-ba4d6be8d2ce.png" style="width:26.92em;height:23.75em;"/></p>
<p>The analysis of the results shows that the variables have different intervals. When the predictors have very different extreme values, the weight on the response variables by the character with extreme values may be prevalent. This can affect the accuracy of the forecast. Hence, we may need to scale values under different features such that they fall under a common range. Through this statistical procedure, it is possible to compare identical variables belonging to different distributions and also different variables or variables expressed in different units.</p>
<div class="packt_tip">Remember, it is good practice to rescale the data before training a regression algorithm. Using the rescaling technique, data units are eliminated; this allows us to easily compare data from different locations.</div>
<p>To rescale the data, we will use the min-max method to get all the scaled data in the range [0, 1]. The formula to achieve this is as follows:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/312c9d15-12ff-45cc-940a-992681a690fb.png" style="width:12.67em;height:3.00em;"/></p>
<p>First, we need to calculate the minimum and maximum values of each column in the database. We will use the <kbd>apply()</kbd> function that applies a function to the values of a matrix:</p>
<pre>MaxData &lt;- apply(InputData, 2, max)</pre>
<p>Three arguments have been passed: the first specifies the data set on which to apply the function (<kbd>InputData</kbd>). The second argument specifies the indexes on which the function (2) will be applied. Being a matrix, 1 specifies the rows and 2 specifies the columns. The third argument specifies the function to be applied, in our case, the <kbd>max()</kbd> function.</p>
<p>Now, we will calculate the minimums for each column:</p>
<pre>MinData &lt;- apply(InputData, 2, min)</pre>
<p>Now we need to apply the <kbd>scale ()</kbd> <span>function</span> <span>to normalize the data. The <kbd>scale ()</kbd> function centers and/or resizes the columns of a numeric matrix, as shown here:</span></p>
<pre>DataScaled &lt;- scale(InputData,center = MinData, scale = MaxData - MinData)</pre>
<p>To confirm the normalization of the data, let's apply the <kbd>summary()</kbd> function again:</p>
<pre>summary(DataScaled)</pre>
<p>The following results are printed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-559 image-border" src="assets/907c7fbc-9270-456b-81ff-41f777c3e596.png" style="width:32.25em;height:27.42em;"/></p>
<p>Let's go into our exploratory analysis. We can do it by making a boxplot of the variables, as shown here:</p>
<pre>boxplot(BHDataScaled)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p>The following plot is printed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-624 image-border" src="assets/8e7c11ff-e4e7-448c-bea5-079223d09348.png" style="width:146.75em;height:77.00em;"/></p>
<p>The previous diagram clearly shows that some variables have anomalous values. For example, the variable crim shows the greatest number of outliers. Outliers are numerically different from the rest of the collected data. Statistics obtained from variables containing anomalous values may return incorrect information.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Training the network</h1>
                </header>
            
            <article>
                
<p>Before training the network, we must split the data. We will start with data splitting, subdividing data into exactly two subsets of a specified ratio for training and validation. This technique is particularly useful when you have a very large dataset. In this case, the dataset is divided into two partitions: training and test. The training set is used to train the model, while the test set will provide us with a significant performance estimate. This method is very advantageous when using slow methods and needing a quick approximation of performance.</p>
<p>The following example divides the dataset so that 70 percent is used to train a neural network model and the remaining 30 percent is used to evaluate model performance:</p>
<pre>IndexData = sample(1:nrow(InputData),round(0.70*nrow(InputData)))<br/>TrainData &lt;- as.data.frame(DataScaled[IndexData,])<br/>TestData &lt;- as.data.frame(DataScaled[-IndexData,])</pre>
<p>The code in the first line subdivides the 70:30 data, meaning to use 70 percent of the data to train the network and the remaining 30 percent to test the network. In the second and third row, the data of the dataframe named <kbd>DataScaled</kbd> is subdivided into two new dataframes called <kbd>TrainData</kbd> and <kbd>TestData</kbd>.</p>
<p>Now, we need to set the formula we will use to build the neural network:</p>
<pre>n = names(InputData)<br/>f = as.formula(paste("medv ~",<br/>                     paste(n[!n %in% "medv"],<br/>                           collapse = " + ")))</pre>
<p>In the previous piece of code, we first retrieve all variable names through the <kbd>names()</kbd> function. Next, we create the formula we will use to build the network.</p>
<p class="mce-root">The <kbd>neuralnet()</kbd> function uses formulas in a compact symbolic form. The <kbd>~</kbd> operator defines the model. For example, the <strong>formula y ~</strong> model is interpreted as meaning that the answer y is modeled by a predictor specified symbolically by the model. This model consists of a series of terms separated by <kbd>+</kbd> operators. Each term is a variable name separated from others by <kbd>:</kbd> operators.</p>
<p>Then, we will use the <kbd>neuralnet</kbd> library to build and train the network. Let's load the library:</p>
<pre>library("neuralnet")</pre>
<p>The <kbd>neuralnet</kbd> library is used to train neural networks using backpropagation, resilient backpropagation (RPROP) with or without weight backtracking, or the modified globally convergent version (GRPROP). The following table gives some information about this package:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Package</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><kbd>neuralnet</kbd></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Date</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">2019-02-07</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Version</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">1.44.2</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Title</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Training of Neural Networks</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Author</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Stefan Fritsch, Frauke Guenther, Marvin N. Wright, Marc Suling, Sebastian M. Mueller</p>
</td>
</tr>
</tbody>
</table>
<p>The following lists the most useful functions contained in this package:</p>
<ul>
<li><kbd>neuralnet</kbd>: Training of neural networks</li>
<li><kbd>compute</kbd>: Computation of a given neural network for given covariate vectors</li>
<li class="CDPAlignLeft CDPAlign"><kbd>prediction</kbd>: Summarizes the output of the neural network, the data and the fitted values of <kbd>glm</kbd> objects (if available)</li>
<li><kbd>plot.nn</kbd>: The plot method for neural networks</li>
</ul>
<p>Now, we can build and train the network. At first, we have to choose the number of neurons, and to do this, we need to know the following:</p>
<ul>
<li>The choice of a layer on a few neurons will cause a high error; this is because the predictive factors could be too complex.</li>
<li>On the contrary, too many neurons overload training data and do not allow generalization. The number of neurons in each hidden layer should be a number between the input size and the output layer, for example, an average.</li>
<li>The number of neurons in each hidden layer should not exceed twice the number of incoming neurons.</li>
</ul>
<p>We choose to set ten neurons in the hidden layer. Do not worry—the best choice is obtained with experience:</p>
<pre>NetDataModel = neuralnet(f,data=TrainData,hidden=10,linear.output=T)</pre>
<p>The hidden argument specifies the number of neurons for each hidden layer. The <kbd>linear.output</kbd> <span>argument performs a regression if</span> <kbd>linear.output=TRUE</kbd> or a classification if <kbd>linear.output=FALSE</kbd>.</p>
<p>To produce result summaries of the results of the model, we use the <kbd>summary()</kbd> function:</p>
<pre>summary(NetDataModel)</pre>
<p>The following results are returned:</p>
<pre>&gt; summary(NetDataModel)<br/><strong>                    Length Class      Mode   ca</strong><br/><strong>ll                   5   -none-     call   </strong><br/><strong>response             354   -none-     numeric</strong><br/><strong>covariate           4248   -none-     numeric</strong><br/><strong>model.list             2   -none-     list   </strong><br/><strong>err.fct                1   -none-     function</strong><br/><strong>act.fct                1   -none-     function</strong><br/><strong>linear.output          1   -none-     logical</strong><br/><strong>data                  13   data.frame list   </strong><br/><strong>net.result             1   -none-     list   </strong><br/><strong>weights                1   -none-     list   </strong><br/><strong>startweights           1   -none-     list   </strong><br/><strong>generalized.weights    1   -none-     list   </strong><br/><strong>result.matrix        144   -none-     numeric</strong></pre>
<p>Three features are displayed for each component of the neural network model:</p>
<ul>
<li><strong>Length:</strong> This feature specifies how many elements of this type are contained in it.</li>
<li><strong>Class:</strong> This <span>feature</span> returns a specific indication on the component class.</li>
<li><strong>Mode:</strong> This <span>feature describes</span> the type of component (numeric, list, function, logical, and so on).</li>
</ul>
<p>The <kbd>plot()</kbd> function draws a graph indicating the neural network architecture with layers, nodes, and weights on each connection:</p>
<pre>plot(NetDataModel)</pre>
<p>The neural network plot is shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-562 image-border" src="assets/40121ab6-a594-487d-b78a-296fd0071878.png" style="width:59.83em;height:35.50em;"/></p>
<p>In the previous diagram, the black lines represent the connections between each layer; also, the weight values on each connection are printed. The blue lines show the added bias in each step.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Neural network model evaluation</h1>
                </header>
            
            <article>
                
<p>Now, we can use the network to make predictions. For this, we had set aside 30% of the data in the <kbd>TestData</kbd> dataframe. It is time to use it:</p>
<pre>PredNetTest &lt;- compute(NetDataModel,TestData[,1:12])</pre>
<p>How can we figure whether the forecasts performed by the network are accurate? We can use the <strong>mean squared error</strong> (<strong>MSE</strong>) as a measure of how far our predictions are from the real data.</p>
<p>In the first part of the algorithm, we have normalized the data. To compare the data we need to step back and return to the original data. Once the values of the dataset are restored, we can calculate the MSE through the following equation:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/5799058f-14d5-4c07-a5d0-9a460b9f8f81.png" style="width:16.67em;height:4.75em;"/></p>
<p>The following code performs an MSE calculation:</p>
<pre>PredNetTestStart &lt;- PredNetTest$net.result*(max(InputData$medv)-<br/>                                                         min(InputData$medv))+min(InputData$medv)<br/>TestStart &lt;- as.data.frame((TestData$medv)*(max(InputData$medv)-<br/>                                                min(InputData$medv))+min(InputData$medv))<br/>MSENetData &lt;- sum((TestStart -<br/>                     PredNetTestStart)^2)/nrow(TestStart)</pre>
<p>Now we have results, but what do we compare them with? To compare the results with another model, we can construct a linear regression model. Then, we elaborate on a linear regression model by applying the <kbd>lm()</kbd> <span>function</span><span>. This function is used to process linear regression models, as follows:</span></p>
<pre>RegressionModel &lt;- lm(medv~., data=InputData)</pre>
<p>To produce a summary of the results of the model, we can use once again the <kbd>summary()</kbd> function as follows:</p>
<pre>summary(RegressionModel)</pre>
<p>The following results are returned:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-563 image-border" src="assets/1f091fae-3580-4f36-b6ea-949a7583f484.png" style="width:33.75em;height:25.83em;"/></p>
<p>Now, we will calculate the MSE for the model based on multiple regression:</p>
<pre>TestDataComp &lt;- InputData[-IndexData,]<br/>PredictLm &lt;- predict(RegressionModel,TestDataComp)<br/>MSERegrData &lt;- sum((PredictLm - TestDataComp$medv)^2)/nrow(TestDataComp)</pre>
<p>Finally, we can compare the results of both models:</p>
<pre>cat("MSE for Neural Network Model =",MSENetData,"\n")<br/>cat("MSE for Regression Model =",MSERegrData,"\n")</pre>
<p>The following results are printed:</p>
<pre>&gt; cat("MSE for Neural Network Model =",MSENetData,"\n")<br/><strong>MSE for Neural Network Model = 19.41977332</strong><br/>&gt; cat("MSE for Regression Model =",MSERegrData,"\n")<br/><strong>MSE for Regression Model = 34.83062039</strong></pre>
<p>From the comparison between the two models (neural network model versus linear regression model), the neural network wins (19.4 versus 34.8).</p>
<p>In the following section, we will see how it is possible to develop a DRL model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Approaching DRL</h1>
                </header>
            
            <article>
                
<p>In <a href="9a0709b1-fdad-4fba-8a06-30d68361b3b2.xhtml">Chapter 7</a>, <em>Temporal Difference Learning</em>, we addressed a practical example of using Q-learning to address a vehicle routing problem. In that case, the estimates of the value function were made using a table, in which each box represents a state or a state-action pair. The use of a table to represent the value function allows the creation of simple algorithms. Under Markovian environmental conditions, this table allows us to accurately estimate the value function since it assigns the expected performance during the iterations of the policies to every possible configuration from the environment. The use of the table, however, also leads to limitations. These methods apply only to environments with a reduced number of states and actions. The problem is not limited to the large amount of memory required to store the table, but above all, to the large amount of data and time required to accurately estimate each state-action pair. In other words, the main problem is generalization.</p>
<p>To solve this problem, we can adopt a method based on the combination of reinforcement learning methods with function approximation methods. The following diagram shows a deep Q-learning scheme:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-564 image-border" src="assets/0470eccc-f797-4e9e-af06-899bceb5684b.png" style="width:26.08em;height:17.83em;"/></p>
<p>The term deep Q-learning refers to a method of reinforcement learning that adopts a neural network as an approximation of a value function. It, therefore, represents an evolution of the basic Q-learning method, since the action-state table is replaced by a neural network, to approximate the optimal value function.</p>
<p>This is an innovative approach compared to those seen in the previous chapters. So far, the input of the algorithm has provided both the state and the action to provide the expected return. Deep Q-learning revolutionizes the structure, as it only requires the state of the environment as an input and provides all of the status-action values, as there are actions that can be performed in the environment.</p>
<p>Q-learning is an algorithm widely used in reinforcement learning. Initially, it was considered an unstable algorithm when used with neural networks and therefore its use was limited to tasks and problems that involved limited dimensional spaces of states. The Q-learning algorithms and techniques can be used with DNNs. These algorithms have shown excellent performance.</p>
<p>The Deep Q-learning or Deep Q-Network (DQN) is a reinforcement learning method for the approximation of the function. It represents an evolution of the Q-learning method where the action-state table is replaced by a neural network. In this algorithm, therefore, the learning does not consist of updating the table but consists of adjusting the weights of the neurons that make up the network. This update takes place using the backpropagation technique, which we have had the opportunity to learn more about in the <em>Neural network training</em> section of this chapter.</p>
<p>The learning of the value function is therefore based on the modification of the weights using the following function:</p>
<p class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="assets/4da55eb9-4a0c-4890-b0eb-9912439c6861.png" style="width:22.00em;height:1.42em;"/></p>
<p>In the previous equation, the two terms take on the following meaning:</p>
<ul>
<li><em>L<sub>t</sub></em> is the loss function.</li>
<li><img class="fm-editor-equation" src="assets/b29ae214-7f75-417a-93ee-075f338d8a92.png" style="width:12.08em;height:1.25em;"/>is the optimal expected return.</li>
<li><img class="fm-editor-equation" src="assets/bbc4d93f-23fa-43a5-8ab4-56bdc487feb9.png" style="width:3.67em;height:1.17em;"/>is the estimated value from the network.</li>
</ul>
<p>The errors calculated by the loss function will be propagated backward in the network using a backward step (backpropagation), following the gradient descent logic. In fact, the gradient indicates the direction of the greatest growth of a function; moving in the opposite direction, we reduce the error to the maximum. Policy behavior is given by an e-greedy approach to ensure enough exploration. The key aspect of DQN is the use of the experience replay. With this technique, the agent's experience is taken at every time step <em>t</em> and saved in a dataset called replay memory.</p>
<p>The training is carried out through a mini-batch technique, that is, by taking a sub-set of samples of experiences randomly extracted from the replay memory. In this way, past experiences are used to update the network. Furthermore, the sub-set chosen randomly by the replay memory allows interrupting the strong correlation between successive experiences, hence reducing the variance between updates.</p>
<p>Following is the algorithm in pseudo-code:</p>
<pre>Initialize Replay Memory D<br/>Initialize Q (s, a) with random weights<br/><strong>repeat<br/>    </strong>Observe initial state s1<br/>    for t = 1 to T do<br/>        Select an action using Q (greedy)<br/>        Perform the action at<br/>        Look at the reward rt and the new state st+1<br/>        Save the observation (st, at, rt, s+ 1) in the Replay Memory D<br/>        Take a sample (sj, aj, rj, sj+1) from D<br/>        Calculate the target T for each observation<br/>        if sj + 1 is Terminal state then<br/>            T = rj<br/>        else<br/>            T = rj + γ maxa Q (sj+1, aj)<br/>        end if<br/>        trains the Q network by minimizing (T - Q (sj, aj))2<br/>    end for<br/><strong>until</strong></pre>
<p>This algorithm can be implemented using R and the libraries available for neural networks and reinforcement learning.</p>
<p>Let's now see an advanced example of DRL.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep recurrent Q-networks</h1>
                </header>
            
            <article>
                
<p>In the last section, <em>Approaching DRL</em>, we have already said that deep Q-learning adopts a neural network as an approximation of a value function. However, this method has limited memory and relies on the possibility of perceiving the state of the environment at each decision point. To overcome this problem, we can add recurrence to a <strong>deep Q-network</strong> (<strong>DQN</strong>) by replacing the first level fully connected neural network with a recurring LSTM. In this way, the <strong>deep recurrent Q-network</strong> (<strong>DRQN</strong>) model is obtained.</p>
<p>Let's start with the recurrent neural networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Recurrent neural networks</h1>
                </header>
            
            <article>
                
<p>A <strong>recurrent neural network</strong> (<strong>RNN</strong>) is a neural model in which a bidirectional flow of information is present. In other words, while the propagation of signals in feedforward networks takes place only in a continuous manner in one direction from inputs to outputs, recurrent networks are different. In recurrent networks, this propagation can also occur from a neural layer following a previous one, between neurons belonging to the same layer, or even between a neuron and itself.</p>
<p>A recurring network will decide things at a particular time which will affect the decision it will take immediately after. Recurrent networks have two sources of input: the present and the recent past. This information is combined to determine how to respond to the new data. Recurrent networks differ from feedforward networks in that they add feedback linked to past decisions. This functionality gives the recurring networks a memory to perform tasks that feedforward networks cannot do.</p>
<p>Access to memory occurs through the content rather than by address or location. One approach to this is that the memory content is the pattern of activations on the nodes of an RNN. The idea is to start the network with an activation scheme that is a partial or noisy representation of the requested memory content and that the network stabilizes on the required content.</p>
<p>An RNN is a class of neural networks where there is at least one feedback connection between neurons that form a directed cycle. A typical RNN with connections between the output layer and the hidden layer is represented in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-565 image-border" src="assets/e7b4b40d-7067-4397-942b-a9e87dae5960.png" style="width:24.50em;height:16.50em;"/></p>
<p>In the recurring network shown in the preceding diagram, both the input level and the output level are used to define the weights of the hidden level. Ultimately, we can think of RNNs as a variant of ANNs: these variants can be characterized by a different number of hidden levels and different trends of the data flow. RNNs are characterized by different trends in the flow of data, in fact, the connections between the neurons form a cycle. Recurrent neural networks can use internal memory for their processing, as they have connections between hidden levels that propagate over time to learn sequences.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we explored the world of DRL. To start, we learned the basic concepts of neural networks. We understood the concepts of layers, nodes, biases and transfer functions. In a nutshell, we understood how the architecture of a fully connected neural network is structured. Later, we applied the acquired skills, building a neural network to solve a regression problem. Then, we learned what is meant by DRL and how neural networks are used to approximate the value function. Finally, we analyzed a further form of DRL in which the neural network is replaced by a recurring network. These are the DRQNs that have proven to be particularly efficient.</p>
<p>In the next chapter, we will explore the Keras model using TensorFlow as a backend engine. We will learn how to use Keras to set a multilayer perceptron model. Then, we will learn how to use DRL to balance a cart pole system.</p>


            </article>

            
        </section>
    </body></html>