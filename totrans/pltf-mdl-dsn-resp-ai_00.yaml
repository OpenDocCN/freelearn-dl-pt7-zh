- en: Preface
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial intelligence** (**AI**) has come a long way since its inception,
    transforming from a futuristic concept into a ubiquitous technology that permeates
    every aspect of our lives. From healthcare and finance to decision-making processes
    in both the public and private sectors, AI systems have become integral to our
    daily existence. As AI-powered applications such as ChatGPT become essential tools
    for individuals and businesses alike, it is of utmost importance that we address
    the ethical, social, and technical challenges that accompany this progress.'
  prefs: []
  type: TYPE_NORMAL
- en: The motivation behind this book is rooted in our belief that now, more than
    ever, we must lay the groundwork for a future where AI serves as a force for good.
    As AI continues to shape our world, this book seeks to provide AI engineers, business
    leaders, policymakers, and other stakeholders with comprehensive guidance on the
    development and implementation of responsible, trustworthy AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: In this comprehensive book, we will explore various facets of Responsible AI,
    including the vulnerabilities of **Machine Learning** (**ML**) models, susceptibility
    to adversarial attacks, and the importance of robust security measures. We will
    delve into risk-averse methodologies that prioritize safety and reliability, minimizing
    potential harm and unintended consequences. The book examines policy frameworks
    and strategies adopted by various countries to ensure ethical AI development and
    deployment, as well as the crucial aspects of data privacy, with techniques and
    best practices to protect user information and maintain trust in AI systems. Additionally,
    we will cover approaches to AI model evaluation, uncertainty, and validation;
    the roles of MLOps and AutoML in fostering efficient, scalable, and responsible
    AI practices in enterprise settings; and the importance of fairness in AI, addressing
    challenges in data collection, preprocessing, and model optimization to reduce
    biases and ensure equitable outcomes. We will also discuss the need for transparency
    and explainability in AI systems, ethical governance, and oversight, and cover
    techniques to build adaptable, calibrated AI models that can respond effectively
    to changing environments and requirements. Moreover, we will delve into the concept
    of sustainable feature stores to promote efficiency and consistency in the development
    of responsible AI models and present real-world case studies and applications,
    demonstrating the impact and benefits of responsible AI across various industries.
  prefs: []
  type: TYPE_NORMAL
- en: This book aims to serve as a comprehensive resource for those seeking to harness
    the power of AI while addressing the critical ethical and social challenges it
    presents. We hope this book inspires you to join the movement toward responsible
    AI and apply its principles and practices in your own professional and personal
    endeavors.
  prefs: []
  type: TYPE_NORMAL
- en: Who this book is for
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book is for experienced ML professionals looking to understand the risks
    and data leakages of ML models and frameworks, incorporate fairness by design
    in both models and platforms, and learn how to develop and use reusable components
    to reduce effort and cost when setting up and maintaining an AI ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: What this book covers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B18681_01.xhtml#_idTextAnchor014), *Risks and Attacks on ML Models*,
    presents a detailed overview of key terms related to different types of attacks
    possible on ML models, creating a basic understanding of how ML attacks are designed
    by attackers. In this chapter, you will get familiar with the attacks, both direct
    and indirect, that compromise the privacy of a system. In this context, this chapter
    highlights losses incurred by organizations due to the loss of sensitive information
    and how individuals remain vulnerable to losing confidential information into
    the hands of adversaries.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18681_02.xhtml#_idTextAnchor040), *The* *Emergence of Risk-Averse
    Methodologies and Frameworks*, presents an overall detailed overview of risk assessment
    frameworks, tools, and methodologies that can be directly applied to evaluate
    model risk. In this chapter, you will get familiar with the tools included in
    data platforms and model design techniques that will help to reduce the risk at
    scale. The primary objective of this chapter is to create awareness of data anonymization
    and validation techniques, in addition to the introduction of different terms
    and measures related to privacy.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18681_03.xhtml#_idTextAnchor066), *Regulations and Policies
    Surrounding Trustworthy AI*, introduces different laws being passed across nations
    to protect and prevent the loss of sensitive information of customers. You will
    get to know the formation of different ethics expert groups, government initiatives,
    and policies being drafted to ensure the ethics and compliance of all AI solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 4*](B18681_04.xhtml#_idTextAnchor093), *Privacy Management in Big
    Data and Model Design Pipelines*, presents a detailed overview of different components
    associated with a big data system, which serves as a building block atop which
    we can effectively deploy AI models. This chapter brings into the picture how
    compliance-related issues can be handled at a component level in a microservice-based
    architecture so that there is no information leakage. In this chapter, you get
    familiar with different security principles needed in individual microservices,
    as well as security measures that need to be incorporated in the cloud when deploying
    ML models at scale.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18681_05.xhtml#_idTextAnchor110), *ML Pipeline, Model Evaluation,
    and Handling Uncertainty*, introduces the AI/ML workflow. The chapter then delves
    into different ML algorithms used for classification, regression, generation,
    and reinforcement learning. The chapter also discusses issues related to the reliability
    and trustworthiness of these algorithms. We start by introducing the various components
    of an ML pipeline. The chapter then briefly explores the important AI/ML algorithms
    for the tasks of classification, regression, and clustering. Further, we discuss
    various types of uncertainties, their causes, and the techniques to quantify uncertainty.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18681_06.xhtml#_idTextAnchor126), *Hyperparameter Tuning, MLOPs,
    and AutoML*, continues from the previous chapter and explains the need for continuous
    training in an ML pipeline. Building an ML model is an iterative process, and
    the presence of so many models, each with a large number of hyperparameters, complicates
    things for beginners. This chapter provides a glimpse into the present AutoML
    options for your ML workflow. It expands on the situations where no-code/low-code
    solutions are useful. It explores the solutions provided by major cloud providers
    in terms of ease, features, and model explainability. Additionally, the chapter
    also covers orchestration tools, such as Kubeflow and Vertex AI, to manage the
    continuous training and deployment of your ML models.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18681_07.xhtml#_idTextAnchor146), *Fairness Notions and Fair
    Data Generation*, presents problems pertaining to unfair data collection for different
    types of data, ontologies, vocabularies, and so on, due to the lack of standardization.
    The primary objective of this chapter is to stress the importance of the quality
    of data, as biased datasets can introduce hidden biases in ML models. This chapter
    focuses on the guiding principles for better data collection, management, and
    stewardship that need to be practiced globally. You will further see how evaluation
    strategies initial steps can help to build unbiased datasets, enabling new AI
    analytics and digital transformation journeys for ML-based predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18681_08.xhtml#_idTextAnchor176), *Fairness in Model Optimization*,
    presents different optimization constraints and techniques that are essential
    to optimize and obtain fair ML models. The focus of this chapter is to enlighten
    you with different, new customized optimizers, unveiled by research, that can
    serve to build supervised, unsupervised, and semi-supervised fair ML models. The
    chapter, in a broader sense, prepares you with the foundational steps to create
    and define model constraints that can be used by different optimizers during the
    training process. You will also gain an understanding of how to evaluate such
    constraint-based models with proper metrics and the extra training overheads incurred
    during the optimization techniques, which will enable the models to design their
    own algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18681_09.xhtml#_idTextAnchor198), *Model Explainability*, introduces
    you to different methods that can be used to unravel the mystery of black boxes
    in ML models. We will talk about the need to be able to explain a model prediction.
    This chapter covers various algorithms and techniques, such as SHAP and LIME,
    to add an explainability component to existing models. We will explore the libraries,
    such as DoWhy and CausalNex, to see the explainability features available to an
    end user. We will also delve into the explainability features provided by Vertex
    AI, SageMaker, and H2O.ai.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18681_10.xhtml#_idTextAnchor218), *Ethics and Model Governance*,
    emphasizes the ethical governance processes that need to be established with models
    in production, for quick identification of all risks related to the development
    and deployment of a model. This chapter also covers best practices for monitoring
    all models, including those in an inventory. You will get more insights into the
    practical nuances of risks that emerge in different phases of a model life cycle
    and how these risks can be mitigated when models reside in the inventory. Here,
    you will also understand the different risk classification procedures and how
    they can help minimize the business loss resulting from low-performance models.
    Further, you will also get detailed insights into how to establish proper governance
    in data aggregation, iterative rounds of model training, and the hyperparameter
    tuning process.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 11*](B18681_11.xhtml#_idTextAnchor232), *The Ethics of Model Adaptability*,
    focuses on establishing ethical governance processes for models in production,
    with the aim of quickly detecting any signs of model failure or bias in output
    predictions. By reading this chapter, you will gain a deeper understanding of
    the practical details involved in monitoring the performance of models and contextual
    model predictions, by reviewing the data constantly and benchmarking against the
    past in order to draft proper actionable short-term and long-term plans. Further,
    you will also get a detailed understanding of the conditions leading to model
    retraining and the importance of having a perfectly calibrated model. This chapter
    also highlights the trade-offs associated with fairness and model calibration.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B18681_12.xhtml#_idTextAnchor243), *Building Sustainable Enterprise-Grade
    AI Platforms*, focuses on how organizational goals, initiatives, and support from
    leadership can enable us to build sustainable ethical AI platforms. The goal of
    this chapter is to stress the importance of organizations contextualizing and
    linking ethical AI principles to reflect the local values, human rights, social
    norms, and behaviors of the community in which the solutions operate. In this
    context, the chapter highlights the impact of large-scale AI solutions on the
    environment and the right procedures that need to be incorporated for model training
    and deployment, using federated learning. This chapter further delves into important
    concepts that strongly emphasize the need to stay socially responsible, as well
    as being able to design software, models, and platforms.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B18681_13.xhtml#_idTextAnchor267), *Sustainable Model Life Cycle
    Management, Feature Stores, and Model Calibration*, explores the best practices
    that need to be followed during the model development life cycle, which can lead
    to the creation of sustainable feature stores. In this chapter, we will highlight
    the importance of implementing privacy so that reusing stores and collaboration
    among teams are maximized, without compromising security and privacy aspects.
    This chapter further provides a deep dive into different model calibration techniques,
    which are essential in building scalable sustainable ML platforms. Here, you will
    also understand how to design adaptable feature stores and how best we can incorporate
    monitoring and governance in federated learning.'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B18681_14.xhtml#_idTextAnchor292), *Industry-Wide Use Cases*,
    presents a detailed overview of the different use cases across various industries.
    The primary aim of this is to inform readers coming from different industry domains
    on how ethics and compliance can be integrated into their systems, in order to
    build a fair and equitable AI system and win the confidence and trust of end users.
    You will also get a chance to apply algorithms and tools studied in previous chapters
    to different business problems. Further, you will gain an understanding of how
    ethical design patterns can be reused across different industry domains.'
  prefs: []
  type: TYPE_NORMAL
- en: To get the most out of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Each chapter has different requirements, which have been specified in their
    respective chapters.
  prefs: []
  type: TYPE_NORMAL
- en: You should have basic knowledge of ML, Python, scikit-learn, PyTorch, and TensorFlow
    to better understand the concepts of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Download the example code files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can download the example code files for this book from GitHub at [https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI](https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI).
    If there’s an update to the code, it will be updated in the GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: We also have other code bundles from our rich catalog of books and videos available
    at [https://github.com/PacktPublishing/](https://github.com/PacktPublishing/).
    Check them out!
  prefs: []
  type: TYPE_NORMAL
- en: Conventions used
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of text conventions used throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: '`Code in text`: Indicates code words in text, database table names, folder
    names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter
    handles. Here is an example: “Atlas offers great flexibility in dynamically creating
    classifications, such as PII, `EXPIRES_ON`, `DATA_QUALITY`, and `SENSITIVE`, with
    support for the `expiry_date` attribute in the `EXPIRES_ON` classification.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'A block of code is set as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Any command-line input or output is written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '**Bold**: Indicates a new term, an important word, or words that you see on
    screen. For instance, words in menus or dialog boxes appear in **bold**. Here
    is an example: “Moreover, we can see the sequential security controls that we
    can follow to enhance our security stack by going to **RBAC** | **Policy Management**
    | **Discovery** | **Settings** | **Real-Time Controls**.'
  prefs: []
  type: TYPE_NORMAL
- en: Tips or important notes
  prefs: []
  type: TYPE_NORMAL
- en: Appear like this.
  prefs: []
  type: TYPE_NORMAL
- en: Get in touch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Feedback from our readers is always welcome.
  prefs: []
  type: TYPE_NORMAL
- en: '**General feedback**: If you have questions about any aspect of this book,
    email us at [customercare@packtpub.com](mailto:customercare@packtpub.com) and
    mention the book title in the subject of your message.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Errata**: Although we have taken every care to ensure the accuracy of our
    content, mistakes do happen. If you have found a mistake in this book, we would
    be grateful if you would report this to us. Please visit [www.packtpub.com/support/errata](http://www.packtpub.com/support/errata)
    and fill in the form.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Piracy**: If you come across any illegal copies of our works in any form
    on the internet, we would be grateful if you would provide us with the location
    address or website name. Please contact us at [copyright@packt.com](mailto:copyright@packt.com)
    with a link to the material.'
  prefs: []
  type: TYPE_NORMAL
- en: '**If you are interested in becoming an author**: If there is a topic that you
    have expertise in and you are interested in either writing or contributing to
    a book, please visit [authors.packtpub.com](http://authors.packtpub.com).'
  prefs: []
  type: TYPE_NORMAL
- en: Share Your Thoughts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Once you’ve read *Platform and Model Design for Responsible AI*, we’d love to
    hear your thoughts! Please [click here to go straight to the Amazon review page](https://packt.link/r/1803237074)
    for this book and share your feedback.
  prefs: []
  type: TYPE_NORMAL
- en: Your review is important to us and the tech community and will help us make
    sure we’re delivering excellent quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Download a free PDF copy of this book
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Thanks for purchasing this book!
  prefs: []
  type: TYPE_NORMAL
- en: Do you like to read on the go but are unable to carry your print books everywhere?
    Is your eBook purchase not compatible with the device of your choice?
  prefs: []
  type: TYPE_NORMAL
- en: Don’t worry, now with every Packt book you get a DRM-free PDF version of that
    book at no cost.
  prefs: []
  type: TYPE_NORMAL
- en: Read anywhere, any place, on any device. Search, copy, and paste code from your
    favorite technical books directly into your application.
  prefs: []
  type: TYPE_NORMAL
- en: The perks don’t stop there, you can get exclusive access to discounts, newsletters,
    and great free content in your inbox daily
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these simple steps to get the benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link below
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/B18681_QR_Free_PDF.jpg)'
  prefs: []
  type: TYPE_IMG
- en: '[https://packt.link/free-ebook/9781803237077](https://packt.link/free-ebook/9781803237077)'
  prefs: []
  type: TYPE_NORMAL
- en: Submit your proof of purchase
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! We’ll send your free PDF and other benefits to your email directly
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Part 1: Risk Assessment Machine Learning Frameworks in a Global Landscape'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part provides a detailed introduction to the risks, threats, and challenges
    that machine learning models in production are vulnerable to. In this part, you
    will learn about different types of attacks that can be carried out by adversaries
    and the importance of protecting your models from such attacks. This part also
    covers the guidelines and standards set by different committees across the world,
    to facilitate various actions and initiatives at both a national and organizational
    level.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part is made up of the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 1*](B18681_01.xhtml#_idTextAnchor014), *Risks and Attacks on ML Models*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 2*](B18681_02.xhtml#_idTextAnchor040), *The Emergence of Risk-Averse
    Methodologies and Frameworks*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 3*](B18681_03.xhtml#_idTextAnchor066), *Regulations and Policies
    Surrounding Trustworthy AI*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
