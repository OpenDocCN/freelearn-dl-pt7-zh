<html><head></head><body>
		<div id="_idContainer005">
			<h1 id="_idParaDest-5"><a id="_idTextAnchor004"/>Preface</h1>
			<p><strong class="bold">Artificial intelligence</strong> (<strong class="bold">AI</strong>) has come a long way since its inception, transforming from a futuristic concept into a ubiquitous technology that permeates every aspect of our lives. From healthcare and finance to decision-making processes in both the public and private sectors, AI systems have become integral to our daily existence. As AI-powered applications such as ChatGPT become essential tools for individuals and businesses alike, it is of utmost importance that we address the ethical, social, and technical challenges that accompany <span class="No-Break">this progress.</span></p>
			<p>The motivation behind this book is rooted in our belief that now, more than ever, we must lay the groundwork for a future where AI serves as a force for good. As AI continues to shape our world, this book seeks to provide AI engineers, business leaders, policymakers, and other stakeholders with comprehensive guidance on the development and implementation of responsible, trustworthy <span class="No-Break">AI systems.</span></p>
			<p>In this comprehensive book, we will explore various facets of Responsible AI, including the vulnerabilities of <strong class="bold">Machine Learning</strong> (<strong class="bold">ML</strong>) models, susceptibility to adversarial attacks, and the importance of robust security measures. We will delve into risk-averse methodologies that prioritize safety and reliability, minimizing potential harm and unintended consequences. The book examines policy frameworks and strategies adopted by various countries to ensure ethical AI development and deployment, as well as the crucial aspects of data privacy, with techniques and best practices to protect user information and maintain trust in AI systems. Additionally, we will cover approaches to AI model evaluation, uncertainty, and validation; the roles of MLOps and AutoML in fostering efficient, scalable, and responsible AI practices in enterprise settings; and the importance of fairness in AI, addressing challenges in data collection, preprocessing, and model optimization to reduce biases and ensure equitable outcomes. We will also discuss the need for transparency and explainability in AI systems, ethical governance, and oversight, and cover techniques to build adaptable, calibrated AI models that can respond effectively to changing environments and requirements. Moreover, we will delve into the concept of sustainable feature stores to promote efficiency and consistency in the development of responsible AI models and present real-world case studies and applications, demonstrating the impact and benefits of responsible AI across <span class="No-Break">various industries.</span></p>
			<p>This book aims to serve as a comprehensive resource for those seeking to harness the power of AI while addressing the critical ethical and social challenges it presents. We hope this book inspires you to join the movement toward responsible AI and apply its principles and practices in your own professional and <span class="No-Break">personal endeavors.</span></p>
			<h1 id="_idParaDest-6"><a id="_idTextAnchor005"/>Who this book is for</h1>
			<p>This book is for experienced ML professionals looking to understand the risks and data leakages of ML models and frameworks, incorporate fairness by design in both models and platforms, and learn how to develop and use reusable components to reduce effort and cost when setting up and maintaining an <span class="No-Break">AI ecosystem.</span></p>
			<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/>What this book covers</h1>
			<p><a href="B18681_01.xhtml#_idTextAnchor014"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Risks and Attacks on ML Models</em>, presents a detailed overview of key terms related to different types of attacks possible on ML models, creating a basic understanding of how ML attacks are designed by attackers. In this chapter, you will get familiar with the attacks, both direct and indirect, that compromise the privacy of a system. In this context, this chapter highlights losses incurred by organizations due to the loss of sensitive information and how individuals remain vulnerable to losing confidential information into the hands <span class="No-Break">of adversaries.</span></p>
			<p><a href="B18681_02.xhtml#_idTextAnchor040"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">The </em><em class="italic">Emergence of Risk-Averse Methodologies and Frameworks</em>, presents an overall detailed overview of risk assessment frameworks, tools, and methodologies that can be directly applied to evaluate model risk. In this chapter, you will get familiar with the tools included in data platforms and model design techniques that will help to reduce the risk at scale. The primary objective of this chapter is to create awareness of data anonymization and validation techniques, in addition to the introduction of different terms and measures related <span class="No-Break">to privacy.</span></p>
			<p><a href="B18681_03.xhtml#_idTextAnchor066"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Regulations and Policies Surrounding Trustworthy AI</em>, introduces different laws being passed across nations to protect and prevent the loss of sensitive information of customers. You will get to know the formation of different ethics expert groups, government initiatives, and policies being drafted to ensure the ethics and compliance of all <span class="No-Break">AI solutions.</span></p>
			<p><a href="B18681_04.xhtml#_idTextAnchor093"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">Privacy Management in Big Data and Model Design Pipelines</em>, presents a detailed overview of different components associated with a big data system, which serves as a building block atop which we can effectively deploy AI models. This chapter brings into the picture how compliance-related issues can be handled at a component level in a microservice-based architecture so that there is no information leakage. In this chapter, you get familiar with different security principles needed in individual microservices, as well as security measures that need to be incorporated in the cloud when deploying ML models <span class="No-Break">at scale.</span></p>
			<p><a href="B18681_05.xhtml#_idTextAnchor110"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">ML Pipeline, Model Evaluation, and Handling Uncertainty</em>, introduces the AI/ML workflow. The chapter then delves into different ML algorithms used for classification, regression, generation, and reinforcement learning. The chapter also discusses issues related to the reliability and trustworthiness of these algorithms. We start by introducing the various components of an ML pipeline. The chapter then briefly explores the important AI/ML algorithms for the tasks of classification, regression, and clustering. Further, we discuss various types of uncertainties, their causes, and the techniques to <span class="No-Break">quantify uncertainty.</span></p>
			<p><a href="B18681_06.xhtml#_idTextAnchor126"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Hyperparameter Tuning, MLOPs, and AutoML</em>, continues from the previous chapter and explains the need for continuous training in an ML pipeline. Building an ML model is an iterative process, and the presence of so many models, each with a large number of hyperparameters, complicates things for beginners. This chapter provides a glimpse into the present AutoML options for your ML workflow. It expands on the situations where no-code/low-code solutions are useful. It explores the solutions provided by major cloud providers in terms of ease, features, and model explainability. Additionally, the chapter also covers orchestration tools, such as Kubeflow and Vertex AI, to manage the continuous training and deployment of your <span class="No-Break">ML models.</span></p>
			<p><a href="B18681_07.xhtml#_idTextAnchor146"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Fairness Notions and Fair Data Generation</em>, presents problems pertaining to unfair data collection for different types of data, ontologies, vocabularies, and so on, due to the lack of standardization. The primary objective of this chapter is to stress the importance of the quality of data, as biased datasets can introduce hidden biases in ML models. This chapter focuses on the guiding principles for better data collection, management, and stewardship that need to be practiced globally. You will further see how evaluation strategies initial steps can help to build unbiased datasets, enabling new AI analytics and digital transformation journeys for <span class="No-Break">ML-based predictions.</span></p>
			<p><a href="B18681_08.xhtml#_idTextAnchor176"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Fairness in Model Optimization</em>, presents different optimization constraints and techniques that are essential to optimize and obtain fair ML models. The focus of this chapter is to enlighten you with different, new customized optimizers, unveiled by research, that can serve to build supervised, unsupervised, and semi-supervised fair ML models. The chapter, in a broader sense, prepares you with the foundational steps to create and define model constraints that can be used by different optimizers during the training process. You will also gain an understanding of how to evaluate such constraint-based models with proper metrics and the extra training overheads incurred during the optimization techniques, which will enable the models to design their <span class="No-Break">own algorithms.</span></p>
			<p><a href="B18681_09.xhtml#_idTextAnchor198"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Model Explainability</em>, introduces you to different methods that can be used to unravel the mystery of black boxes in ML models. We will talk about the need to be able to explain a model prediction. This chapter covers various algorithms and techniques, such as SHAP and LIME, to add an explainability component to existing models. We will explore the libraries, such as DoWhy and CausalNex, to see the explainability features available to an end user. We will also delve into the explainability features provided by Vertex AI, SageMaker, <span class="No-Break">and H2O.ai.</span></p>
			<p><a href="B18681_10.xhtml#_idTextAnchor218"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Ethics and Model Governance</em>, emphasizes the ethical governance processes that need to be established with models in production, for quick identification of all risks related to the development and deployment of a model. This chapter also covers best practices for monitoring all models, including those in an inventory. You will get more insights into the practical nuances of risks that emerge in different phases of a model life cycle and how these risks can be mitigated when models reside in the inventory. Here, you will also understand the different risk classification procedures and how they can help minimize the business loss resulting from low-performance models. Further, you will also get detailed insights into how to establish proper governance in data aggregation, iterative rounds of model training, and the hyperparameter <span class="No-Break">tuning process.</span></p>
			<p><a href="B18681_11.xhtml#_idTextAnchor232"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">The Ethics of Model Adaptability</em>, focuses on establishing ethical governance processes for models in production, with the aim of quickly detecting any signs of model failure or bias in output predictions. By reading this chapter, you will gain a deeper understanding of the practical details involved in monitoring the performance of models and contextual model predictions, by reviewing the data constantly and benchmarking against the past in order to draft proper actionable short-term and long-term plans. Further, you will also get a detailed understanding of the conditions leading to model retraining and the importance of having a perfectly calibrated model. This chapter also highlights the trade-offs associated with fairness and <span class="No-Break">model calibration.</span></p>
			<p><a href="B18681_12.xhtml#_idTextAnchor243"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, <em class="italic">Building Sustainable Enterprise-Grade AI Platforms</em>, focuses on how organizational goals, initiatives, and support from leadership can enable us to build sustainable ethical AI platforms. The goal of this chapter is to stress the importance of organizations contextualizing and linking ethical AI principles to reflect the local values, human rights, social norms, and behaviors of the community in which the solutions operate. In this context, the chapter highlights the impact of large-scale AI solutions on the environment and the right procedures that need to be incorporated for model training and deployment, using federated learning. This chapter further delves into important concepts that strongly emphasize the need to stay socially responsible, as well as being able to design software, models, <span class="No-Break">and platforms.</span></p>
			<p><a href="B18681_13.xhtml#_idTextAnchor267"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>, <em class="italic">Sustainable Model Life Cycle Management, Feature Stores, and Model Calibration</em>, explores the best practices that need to be followed during the model development life cycle, which can lead to the creation of sustainable feature stores. In this chapter, we will highlight the importance of implementing privacy so that reusing stores and collaboration among teams are maximized, without compromising security and privacy aspects. This chapter further provides a deep dive into different model calibration techniques, which are essential in building scalable sustainable ML platforms. Here, you will also understand how to design adaptable feature stores and how best we can incorporate monitoring and governance in <span class="No-Break">federated learning.</span></p>
			<p><a href="B18681_14.xhtml#_idTextAnchor292"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, <em class="italic">Industry-Wide Use Cases</em>, presents a detailed overview of the different use cases across various industries. The primary aim of this is to inform readers coming from different industry domains on how ethics and compliance can be integrated into their systems, in order to build a fair and equitable AI system and win the confidence and trust of end users. You will also get a chance to apply algorithms and tools studied in previous chapters to different business problems. Further, you will gain an understanding of how ethical design patterns can be reused across different <span class="No-Break">industry domains.</span></p>
			<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/>To get the most out of this book</h1>
			<p>Each chapter has different requirements, which have been specified in their <span class="No-Break">respective chapters.</span></p>
			<p>You should have basic knowledge of ML, Python, scikit-learn, PyTorch, and TensorFlow to better understand the concepts of <span class="No-Break">this book.</span></p>
			<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/>Download the example code files</h1>
			<p>You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI">https://github.com/PacktPublishing/Platform-and-Model-Design-for-Responsible-AI</a>. If there’s an update to the code, it will be updated in the <span class="No-Break">GitHub repository.</span></p>
			<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check <span class="No-Break">them out!</span></p>
			<h1 id="_idParaDest-10"><a id="_idTextAnchor009"/>Conventions used</h1>
			<p>There are a number of text conventions used throughout <span class="No-Break">this book.</span></p>
			<p><strong class="source-inline">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: “Atlas offers great flexibility in dynamically creating classifications, such as PII, <strong class="source-inline">EXPIRES_ON</strong>, <strong class="source-inline">DATA_QUALITY</strong>, and <strong class="source-inline">SENSITIVE</strong>, with support for the <strong class="source-inline">expiry_date</strong> attribute in the <span class="No-Break"><strong class="source-inline">EXPIRES_ON</strong></span><span class="No-Break"> classification.”</span></p>
			<p>A block of code is set <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
model.compile(optimizer='rmsprop', loss=aleatoric_loss, metrics=['mae'])</pre>
			<p>Any command-line input or output is written <span class="No-Break">as follows:</span></p>
			<pre class="console">
roc_auc_score(y_test, y_pred_uncal)
&gt;&gt;&gt; 0. 9185432154389126</pre>
			<p><strong class="bold">Bold</strong>: Indicates a new term, an important word, or words that you see on screen. For instance, words in menus or dialog boxes appear in <strong class="bold">bold</strong>. Here is an example: “Moreover, we can see the sequential security controls that we can follow to enhance our security stack by going to <strong class="bold">RBAC</strong> | <strong class="bold">Policy Management </strong>| <strong class="bold">Discovery</strong> | <strong class="bold">Settings</strong> | <span class="No-Break"><strong class="bold">Real-Time Controls</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Tips or important notes</p>
			<p class="callout">Appear like this.</p>
			<h1 id="_idParaDest-11"><a id="_idTextAnchor010"/>Get in touch</h1>
			<p>Feedback from our readers is <span class="No-Break">always welcome.</span></p>
			<p><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, email us at <a href="mailto:customercare@packtpub.com">customercare@packtpub.com</a> and mention the book title in the subject of <span class="No-Break">your message.</span></p>
			<p><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a> and fill in <span class="No-Break">the form.</span></p>
			<p><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <a href="mailto:copyright@packt.com">copyright@packt.com</a> with a link to <span class="No-Break">the material.</span></p>
			<p><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please <span class="No-Break">visit </span><a href="http://authors.packtpub.com"><span class="No-Break">authors.packtpub.com</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-12"><a id="_idTextAnchor011"/>Share Your Thoughts</h1>
			<p>Once you’ve read <em class="italic">Platform and Model Design for Responsible AI</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1803237074">click here to go straight to the Amazon review page</a> for this book and share <span class="No-Break">your feedback.</span></p>
			<p>Your review is important to us and the tech community and will help us make sure we’re delivering excellent <span class="No-Break">quality content.</span></p>
			<h1 id="_idParaDest-13"><a id="_idTextAnchor012"/>Download a free PDF copy of this book</h1>
			<p>Thanks for purchasing <span class="No-Break">this book!</span></p>
			<p>Do you like to read on the go but are unable to carry your print <span class="No-Break">books everywhere?</span>
Is your eBook purchase not compatible with the device of <span class="No-Break">your choice?</span></p>
			<p>Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at <span class="No-Break">no cost.</span></p>
			<p>Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application. </p>
			<p>The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your <span class="No-Break">inbox daily</span></p>
			<p>Follow these simple steps to get <span class="No-Break">the benefits:</span></p>
			<ol>
				<li>Scan the QR code or visit the <span class="No-Break">link below</span></li>
			</ol>
			<div>
				<div id="_idContainer004" class="IMG---Figure">
					<img src="image/B18681_QR_Free_PDF.jpg" alt=""/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/9781803237077">https://packt.link/free-ebook/9781803237077</a></p>
			<ol>
				<li value="2">Submit your proof <span class="No-Break">of purchase</span></li>
				<li>That’s it! We’ll send your free PDF and other benefits to your <span class="No-Break">email directly</span></li>
			</ol>
		</div>
	

		<div id="_idContainer006">
			<h1 id="_idParaDest-14"><a id="_idTextAnchor013"/>Part 1: Risk Assessment Machine Learning Frameworks in a Global Landscape</h1>
			<p>This part provides a detailed introduction to the risks, threats, and challenges that machine learning models in production are vulnerable to. In this part, you will learn about different types of attacks that can be carried out by adversaries and the importance of protecting your models from such attacks. This part also covers the guidelines and standards set by different committees across the world, to facilitate various actions and initiatives at both a national and <span class="No-Break">organizational level.</span></p>
			<p>This part is made up of the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18681_01.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Risks and Attacks on ML Models</em></li>
				<li><a href="B18681_02.xhtml#_idTextAnchor040"><em class="italic">Chapter 2</em></a>, <em class="italic">The Emergence of Risk-Averse Methodologies and Frameworks</em></li>
				<li><a href="B18681_03.xhtml#_idTextAnchor066"><em class="italic">Chapter 3</em></a>, <em class="italic">Regulations and Policies Surrounding Trustworthy AI</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer007" class="Content">
			</div>
		</div>
		<div>
			<div id="_idContainer008" class="Basic-Graphics-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer009">
			</div>
		</div>
	</body></html>