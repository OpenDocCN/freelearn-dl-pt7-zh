<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Introduction to Artificial Neural Networks and TensorFlow</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will give an introduction to <strong>artificial neural networks</strong> (<strong>ANNs</strong>), which are basically computational models inspired by living brains, and perceptrons, which are the building blocks for ANNs. We will also talk about all of the elements to consider when building a deep neural network model. Then, we will talk about TensorFlow, which is the library that we will use to create these deep neural network models. Finally, we will talk about the core concepts that we need to understand about TensorFlow in order to use these library concepts, such as variables, placeholders, sessions, graphs, and others that are essential for using this library.</p>
<p>The following are the topics that will be covered as we progress:</p>
<ul>
<li>Introduction to ANNs</li>
<li>Elements of a deep neural network</li>
<li>Installation of and introduction to TensorFlow</li>
<li>Core concepts in TensorFlow</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to ANNs</h1>
                </header>
            
            <article>
                
<p>ANNs are biologically inspired computational models that can be used to train a computer to perform a task using data. These models are part of the broad category of machine learning models. The distinction between these models and others is that these models are based on a collection of connected units called <strong>artificial neurons</strong>.</p>
<p>There are many types of ANNs and, in this book, we will use one specific type, which is called the <strong>multilayer perceptron </strong>(<strong>MLP</strong>). Please note that there are a lot more variations of <span>ANNs</span>. These are machine learning models and we can use them for classification and regression tasks, but we can actually extend these models and apply them to other very specific tasks such as computer vision, speech recognition, and machine translation. These models are the basis of the exciting and growing field of deep learning, which has been really successful in the last few years in many areas.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Perceptrons</h1>
                </header>
            
            <article>
                
<p>Perceptrons are the simplest type of artificial neuron, invented as a simple model for binary classification. Let's use the context of the dataset that we have been using in this book, the credit card dataset. Let's say that we have only two features for classifying defaulters and nondefaulters: age and bill amount. So the idea of the perceptron is to create some kind of a score. To do so, you take one constant, <kbd>w1</kbd> ,and multiply it by the value of <kbd>age</kbd>, and then you add another constant, <kbd>w2</kbd>, which is multiplied by the value of the <kbd>bill</kbd> amount as follows:</p>
<pre class="mce-root"> score = w1age+w2bill</pre>
<p>As a rule, we classify this person as a defaulter if <kbd>score</kbd> &gt; <kbd>b</kbd>.</p>
<p>So, from this simple operation, we create a score. Then, we follow the rule to classify people as defaulters or as nondefaulters. So, if this <kbd>score</kbd> is greater than some number, then we classify this person as a defaulter.</p>
<p>An equivalent way to state this rule is shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/ee8e1fff-8952-4989-b6ff-f3a0dda854dd.png" style="width:19.58em;height:3.17em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So, the prediction of this model will be <kbd>1</kbd>, or defaulter, if the quantity is greater than <kbd>0</kbd>, and the prediction will be <kbd>0</kbd>, or nondefaulter, if this quantity is less than or equal to <kbd>0</kbd>. The <kbd>b</kbd> <span>value</span><span> </span><span>is also known as the threshold or bias.</span></p>
<p>In general, if we have <em>n</em> features, then our perceptron would look similar to the following screenshot:</p>
<p class="mce-root"/>
<p class="CDPAlignCenter CDPAlign"><img src="assets/7938be7f-8c64-4cdd-9d93-b6ba65e4d5a6.png" style="width:18.75em;height:9.50em;"/></p>
<p>As you can see, we have the same form. We predict <strong>1</strong> if the sum of the weights times the values of our features <strong>-b</strong> is actually greater than <strong>0</strong>, otherwise, we predict <strong>0</strong>. Assuming that all features are on the same scale, the weights would represent the importance of each feature in making the decision. So, we know that for this particular problem we have, all features are in very different scales. For example, ages are in different scales than bill amount, but let's say that you set all of  the features to a similar scale. You can think about the <strong>w</strong> <span>variables as </span>the weights, and they are the most important part of each feature while making the decision.</p>
<p>The following screenshot shows another way to visualize this perceptron:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/bd6b7f5e-ef5e-4f6e-aac0-a65a57a01b6b.png" style="width:41.00em;height:18.08em;"/></div>
<p>So, you have the values of the threshold or the bias, <strong>b</strong>, and you have the value of <strong>Age</strong>, <strong>x1</strong> ,and the value of <strong>Bill amount</strong>, <strong>x2</strong>. So the three values go into an operation, and then you get an output. Now, there is a little modification that we can do to the perceptron, and this is to add what is known as an <strong>activation function</strong>. An activation function is any function that takes the result of the operation and performs some transformation to the input values using the <strong>f</strong><span> </span><span>function</span><span>. So the input for the</span> <span>activation function</span> <span>is the resulting quantity from the operation, and then, after applying </span><span>activation function</span> <strong>f</strong><span>, we will get the following output:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/b2e13ce5-8226-4536-a9c6-c425619c50d0.png" style="width:42.58em;height:18.25em;"/></div>
<p>So, this is the perceptron. We can add an activation function to the perceptron and then we get the rule or the classification <kbd>1</kbd> or <kbd>0</kbd>.</p>
<p>Now, maybe you are wondering how do we decide which are the best weights and threshold for our perceptron? What activation function can we use? The answers to these questions are provided by the perceptron learning algorithm. So, there is a learning algorithm that we can use to actually train perceptrons. The good thing about perceptrons is that they are very simple to understand. However, they are very weak in performance when compared to more sophisticated methods, such as the methods that we used in previous chapters. So, it is not worth actually learning about this perceptron learning algorithm. However, these very simple models are the building blocks for ANNs.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multilayer perceptron</h1>
                </header>
            
            <article>
                
<p class="mce-root">ANNs are models based on perceptrons or other similar basic building blocks, and the ones that we will learn about in this book are based on perceptrons. One of the most popular ANN models is the MLP, which we will use in this book. The motivation for using perceptrons in an ANN is that, instead of using one single perceptron for classification, what if we used many of them? Take a look at the following screenshot:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/6f03b677-a86e-4f32-b98d-7818a77e2a6f.png" style="width:21.92em;height:24.67em;"/></div>
<p>Here, we have three perceptrons and we notice that we have a different bias for each perceptron. But the values for our features will be the same in all cases. If we use three perceptrons, we will get three output values, but we know that this is a binary classification problem so we need only one output. So, <span>now that we have three output values, we can combine them or we can view these output values as input values for another perceptron. </span><span>Take a look at the following screenshot:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/8a52b180-965c-47c4-993d-f34100c6e829.png" style="width:34.83em;height:22.67em;"/></div>
<p>As you can see in the following screenshot, we can take the output values from the preceding perceptrons and fit them as input values to another perceptron, and this perceptron will give us the output. So, this is the intuition on how to build neural networks or MLPs, and this is an example of an ANN:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/9d89276a-5c73-444d-a881-a2659c7699bc.png" style="width:36.75em;height:22.08em;"/></div>
<p>In the preceding screenshot, we have the following three layers of an MLP:</p>
<ul>
<li><strong>Input Layer</strong>: In this layer, you have the original data or the training data that you will use to train this model</li>
<li> <strong>Hidden Layer</strong>: This middle layer is the output from the preceding perceptron, which is used as the input for the next perceptron</li>
<li><span> </span><strong>Output Layer</strong>:<strong> </strong>In this layer, you have the output that you get from the network </li>
</ul>
<p>The following screenshot is another way to visualize the same ANN:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/d0c4a68a-1a43-4bc2-96a2-719ca85c0389.png" style="width:39.42em;height:18.58em;"/></div>
<p>This is a more compact way to visualize it, but it's actually the same network. So, instead of having three biases, we add one constant feature, <strong>1</strong>, for every observation. This value of <strong>1</strong> gets multiplied by the different biases and goes as input to the neurons in our hidden layer. The value of <strong>x1</strong> gets multiplied by some weight and goes as input for the next neurons, and the same happens with the value of <strong>x2</strong>. Then, the result of the neurons in the hidden layer is used as input for the last perceptron in our network, which is the overall output.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Elements of a deep neural network model</h1>
                </header>
            
            <article>
                
<p>The motivation for <strong>deep neural networks</strong> (<strong>DNNs</strong>) is similar, and the question here is, instead of using one single hidden layer, what if we use many hidden layers? So in that case, our model will look similar to the following:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0d594d3c-f5ca-4433-af2c-1299e12ae028.png" style="width:27.92em;height:13.83em;"/></p>
<p>Here, we have the same input layer. However, in this case, we will have many hidden layers and the output layer will stay the same. The key thing here is the hidden part of the network, the hidden layers; instead of having just one, we have many hidden layers and this is called a <strong>DNN</strong>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep learning</h1>
                </header>
            
            <article>
                
<p>Deep learning is a set of machine learning models based on neural networks and the associated techniques to train such models using data. There are many deep learning models. They are a class of machine learning algorithm with the following characteristics:</p>
<ul>
<li>These models use a set of many layers of nonlinear processing units, which can perform abstract feature extraction and transformation</li>
<li>These models use some form of gradient descent for training through backpropagation</li>
</ul>
<p class="mce-root"/>
<ul>
<li>They usually need a lot of data and a lot of computational power for these models to perform very well</li>
<li>These models are now considered state-of the-art for many applications such as computer vision, speech recognition, and game playing</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Elements of an MLP model</h1>
                </header>
            
            <article>
                
<p>There are a lot of things to consider when building a deep learning model in an multilayer perceptron. You have to consider the architecture, the activation function, the optimization algorithm, the <kbd>loss</kbd> function, the weight initialization strategy, the regularization strategy, and the training strategy. We will discuss more about them in the following list:</p>
<ul>
<li><strong>Architecture</strong>: The first element that you need to consider when building deep learning models is the architecture of your MLP. When we say architecture, we are talking about the number of layers and the number of neurons per layer. The number of neurons in the input layer is determined by the number of features that you have in your dataset. The same thing is true for the number of output values. So, they are basically determined by your problem in a classification setting. The number of output values is usually the number of classes in your classification problem, and in a regression problem you will have only one output in your output layer. The choice that you have to make is how many hidden layers you are going to use and the number of neurons per hidden layer. There are not easy rules to set these numbers; in practice, what we do is we use a few layers at first. If a few layers don't work, maybe we add more layers, and the number of neurons for each layer is a number between the number of input values and the number of outputs, <kbd>[n_inputs, n_outputs]</kbd>.</li>
</ul>
<div class="packt_tip">This is just a rule of thumb. However, there are more formal methods to choose the number of hidden layers and the number of neurons, and researchers are constantly trying to come up with better methods for choosing these values.</div>
<ul>
<li><strong>Activation function</strong>: The activation function is the function that is used in every neuron in the hidden layers. There are many choices; <strong>sigmoid</strong> was the first function used when these models were developed, but then researchers found that there are many problems with using this function, so they came up with other activation functions such as the <strong>rectified Linear Unit</strong> (<strong>ReLU</strong>), the <strong>hyperbolic tangent</strong>, the <strong>leaky ReLU</strong>, and some other choices that we will use in the examples as we progress.</li>
</ul>
<p class="mce-root"/>
<ul>
<li><strong>Optimization algorithm</strong>: This is the algorithm that will be used to learn the weights of the networks. Each algorithm that you choose has different hyperparameters that need to be chosen by you, the modeler. The most basic algorithm to train these networks is <strong>gradient descent</strong>. However, gradient descent can be slow and also has some problems, so researchers have come up with other algorithms such as <strong>momentum optimizers</strong>, <strong>AdaGrad</strong>, <strong>RMSProp</strong>, and the <strong>Adam</strong> moment algorithm. In TensorFlow, we have a lot of algorithms that we can choose from, including the Adam moment algorithm, and this is actually the one that we are going to use in the examples.</li>
<li><strong>Loss function</strong>: This is the function that will produce the quantity that will be minimized by the optimizer. The choice of loss function depends on the problem. If we are doing a regression problem, you can choose the mean squared error or the mean pairwise squared error. For classification problems, there are more choices such as cross entropy, square loss, and hinge loss. This is similar to trial and error; sometimes, one loss function will work for your problem and sometimes it will not. So, this is why you have to consider a lot of different loss functions. However, keep in mind that the loss function will produce the quantity that will be used for the optimization algorithm to adjust the different weights for the different perceptrons that will be part of your network. Hence, this is the function that will produce the quantity, and the goal of the optimizer is to make this quantity as small as possible.</li>
<li><strong>Weight initialization strategy</strong>: The weights for each perceptron in your network must be initialized with some values, and these values will be progressively changed by the optimization algorithm to minimize the loss. There are many ways in which you can initialize these values. You can initialize with all zeros. For many years, researchers used to initialize using a random normal distribution but, in recent years, researchers have come up with better choices, including Xavier initialization and He initialization.</li>
<li><strong>Regularization strategy</strong>: This is an optional but highly recommended function because deep learning models tend to overfit data due to the quantity of parameters that they calculate. You can use many choices, including the L1 regularization, L2 regularization, and dropout regularization strategies. In this book, we are not going to use regularization in our examples, but keep in mind that, if you want to build really effective deep learning models, you will very likely need a regularization strategy.</li>
</ul>
<ul>
<li><strong>Training strategy</strong>: The training strategy refers to the way the data will be presented to the training algorithm. This is not part of the model itself, but it will have an influence on the results and the performance of the model. When talking about training deep learning models, you will hear the word epoch. One epoch is one pass of all training examples through the network. In these deep learning models, you will have to present the data to the network many times so the network can learn the best parameters for the model. There is another concept here: batch size. This is the number of elements presented simultaneously to the training algorithm. So in the case of deep learning models, we don't present the whole training dataset to the model. What we do is we present batches of the dataset and, in each batch, we send just a few examples, maybe 100 or 50, and this is the way we train deep learning models. Now, you can use epoch and batch size to calculate the number of iterations that you will have in your model, and this is the number of training steps, which is the number of adjustments that the optimization algorithm makes to the weight in your model. So, for example, if you have 1,000 training examples and the batch size that you will use is 100, it will take 10 iterations to complete one epoch. You can get the total number of iterations with the following formula:</li>
</ul>
<p class="CDPAlignCenter CDPAlign"><img src="assets/c5dca712-14af-4483-8080-112349aedbb5.png" style="width:15.00em;height:3.58em;"/></p>
<p>So, there are a lot of decisions that you have to make as a modeler. These are very complex models and they can be very tricky to train. So, here is some guidance to consider before you start using these models:</p>
<ul>
<li>Because of the number of choices that we have in these models, they can be very tricky to build. So, they shouldn't be your first choice when trying to do predictions. Always begin with simpler and more understandable models, and then, if those models don't work, move to more complex models.</li>
<li>There are best practices for all of the choices that we have seen, but you need more knowledge about these elements if you want to build effective deep learning models.</li>
<li>For these models to perform really well, you need a lot of data. So, you cannot use these models with very small datasets.</li>
<li>Learn more about the theory of these models to understand how to use them better. So if you really want to use these models for solving real-world problems, learning more about the theory behind these models is a must.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to TensorFlow</h1>
                </header>
            
            <article>
                
<p>TensorFlow is an open source software library for numerical computation using data flow graphs. The concept of a computational graph is very important in TensorFlow and was specially designed for creating deep learning models. This library allows developers to deploy computations to one or more CPUs or GPUs in a desktop, a server, or even in mobile devices. This library was originally developed by researchers and engineers working at Google. It was open sourced in 2015 and, since then, it has become one of the major libraries in the machine learning world.</p>
<p>TensorFlow provides multiple APIs, and they can be categorized into the following two broad types:</p>
<ul>
<li><strong>Low level</strong>: Also known as TensorFlow Core, this is the lowest-level API. This API gives us complete programming control and is aimed at researchers and users who need a high degree of flexibility when building their deep learning models.</li>
<li><strong>High level</strong>: High-level APIs such as <kbd>tf.contrib.learn</kbd>, <kbd>keras</kbd>, and TF-Slim are typically easier to use. They take care of repetitive tasks and low-level details that, as a high-level user, you don't need to worry about. They are designed for the fast implementation of commonly used models.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">TensorFlow installation</h1>
                </header>
            
            <article>
                
<p>Now, in preparation for our installation, we will create a new virtual environment in Anaconda. We can do so by using the following instructions:</p>
<ol>
<li>We open the Anaconda prompt.</li>
<li>We type the following command line for creating a new virtual environment and pass the name of the environment with <kbd>anaconda</kbd>, which will install all of the packages that come with Anaconda:</li>
</ol>
<pre class="mce-root" style="padding-left: 60px"><strong>conda create-n apa anaconda</strong></pre>
<div class="packt_infobox"><span>Here <kbd>apa</kbd> stands for advanced predictive analytics. Installation can take some time depending on your internet spee</span><span>d.</span></div>
<ol start="3">
<li>Once the installation has been completed, type <kbd>activate apa</kbd> to activate the new virtual environment. Here is a screenshot of the Anaconda prompt, showing the installation of Anaconda packages:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/165875cf-3aff-4480-9425-a511a15e8cb8.png"/></div>
<p>Now, the new virtual environment has been activated and we are ready to install TensorFlow inside this new virtual environment.</p>
<p>But before installing TensorFlow, you must know that there are basically following two installations of TensorFlow:</p>
<ul>
<li>TensorFlow with CPU support only</li>
<li>TensorFlow with GPU support</li>
</ul>
<p>The second option is usually faster because it uses the GPUs in your computer or your devices, but this installation needs <strong>Nvidia</strong> support. You also need additional software in order to run this installation and it is a little bit more complicated to install.</p>
<p>Here, for easiness, we will install and use the CPU version as there is no difference in writing a program and running it in the CPU or the GPU versions, apart from the speed. We use the following line of code to install TensorFlow in our system:</p>
<pre><strong>pip install --ignore-installed --upgrade tensorflow</strong></pre>
<p>On running the code, the installation of TensorFlow will be initiated and, once the installation is completed, you will see the following output on your screen:</p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/095eddc0-a439-417a-b2c0-da57bc00ed32.png"/></div>
<p>Now, we will start a Python shell to test the installation by performing the following steps:</p>
<ol>
<li>We type <kbd>python</kbd> to start the Python shell.</li>
<li>We use <kbd>import tensorflow as tf</kbd> to import TensorFlow into our Python shell.</li>
<li>We run <kbd>hello = tf.constant("Hello")</kbd>; this will create a constant named <kbd>hello</kbd>.</li>
</ol>
<ol start="4">
<li>We create a session using <kbd>sess = tf.Session()</kbd>.</li>
</ol>
<div class="packt_infobox">If you see similar warning messages to the ones in the following screenshot, you can ignore them, as they are just telling you that you could install with different options so TensorFlow may run faster.</div>
<ol start="5">
<li>Let's print the result of <kbd>hello</kbd> by running the constant within the session using <kbd>print(sess.run(hello))</kbd>:</li>
</ol>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/06b5fd15-2128-45b1-a376-648c9ec656a7.png"/></div>
<p>If you get a result of <kbd>Hello</kbd>, similar to this screenshot, it means that our installation is correct. So, now we are ready to use TensorFlow to build some models.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Core concepts in TensorFlow</h1>
                </header>
            
            <article>
                
<p>There are some major concepts that we need to understand before actually using the <kbd>tensorflow</kbd> library. The following are the concepts that we will cover in this book:</p>
<ul>
<li>Tensors</li>
<li>Computational graphs</li>
<li>Sessions</li>
<li>Variables</li>
<li>Placeholders</li>
<li>Constants</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Tensors</h1>
                </header>
            
            <article>
                
<p>A <strong>tensor</strong> is the central unit of data in TensorFlow. A tensor consists of a set of primitive values shaped into an array of any number of dimensions. It is basically a multidimensional array similar to a NumPy array. The number of dimensions defines the rank of a tensor. Let's see some of the following examples:</p>
<ul>
<li><kbd>3</kbd>: If we have a single number, the tensor will be considered a rank <kbd>0</kbd> tensor. This can be a scalar with <kbd>shape[]</kbd>.</li>
<li><kbd>[2., 2., 1.]</kbd>: If we have a vector, it will be considered a rank <kbd>1</kbd> tensor, so this is what we call a vector of shape <kbd>3</kbd> because it has three elements.</li>
<li><kbd>[[9., 5., 3.], [4., 5., 7]]</kbd>: A matrix with shape <kbd>[2, 3]</kbd> would be a rank <kbd>2</kbd> tensor.</li>
<li><kbd>[[[8., 3.]], [[7., 9.,]]]</kbd>: A matrix with shape <kbd>[2, 1, 2]</kbd> would be a rank <kbd>3</kbd> tensor, as you can see in the outermost level we have two elements, then in the next level we have only one element, and in the last dimension, we have two elements. That's why we have <kbd>2</kbd>, <kbd>1</kbd>, and <kbd>2</kbd> as the values and these are all tensors.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Computational graph</h1>
                </header>
            
            <article>
                
<p>A computational graph is a series of TensorFlow operations, also known as <strong>ops</strong>, arranged into a graph of nodes. The following two principle steps are used by TensorFlow Core:</p>
<ol>
<li>Define a computational graph</li>
<li>Run the computational graph</li>
</ol>
<p>Let's try to understand this concept with a very simple example. Let's say that you have a function with two variables, <strong>x</strong> and <strong>y</strong> as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/5212c92e-d91d-4024-ac39-d753f31f3926.png" style="width:12.25em;height:2.42em;"/></p>
<p>We will use the preceding formula to calculate or to build a computational graph for the actual value of this function when you pass the values <strong>3</strong> and 2 for <strong>x</strong> and <strong>y</strong> respectively:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/4127c2a0-3c52-4a52-85a3-f1f9e63d87cf.png" style="width:13.42em;height:1.83em;"/></p>
<p class="mce-root"/>
<p>Now, let's build a computational graph for actually getting the result from this computation<span> </span><span>model</span><span>:</span></p>
<div class="packt_figure CDPAlignCenter CDPAlign"><img src="assets/ef618ce1-282e-41fd-9b3f-55b6317130f4.png" style="width:26.17em;height:16.08em;"/></div>
<p>In the preceding screenshot, we see the values that flow through the computational graph to different nodes in the graph. So, in the first node, the value <strong>3</strong> gets assigned to <strong>x</strong> and, in the other node, the value <strong>2</strong> gets assigned to <strong>y</strong>. Now, the value of <strong>x</strong> flows to an operation node where it gets squared, and the result of that node flows to another operation where it gets multiplied to the value of <strong>y</strong>. We also have another node, where the value of <strong>y</strong> gets multiplied by <strong>4</strong>. The result of the <strong>x</strong> and <strong>y</strong> multiplication node and the result of the <strong>y</strong> multiplication node flow to the final node, which is the addition node, which gives us the final output <strong>26</strong>. So this is essentially how TensorFlow works. What flows between nodes are tensors.</p>
<p>There are other following objects that we use in TensorFlow:</p>
<ul>
<li><strong>Session</strong>: A session is an object that encapsulates the environment in which operation objects are executed. So, sessions are objects that place operations onto devices such as CPUs or GPUs.</li>
<li><strong>Placeholders</strong>: A placeholder is a promise to provide a value later. These objects are usually used to provide training and testing values in machine learning models.</li>
<li><strong>Variables</strong>: These are objects that are initialized with a value, and that value can change during the execution of the graph. Typically, they are used as trainable variables in machine learning models.</li>
<li><strong>Constants</strong>: Constants are objects whose values never change.</li>
</ul>
<p>To have a better understanding of these object concepts, let's see an example. First, we will import the required libraries by executing the following code snippet:</p>
<pre>import tensorflow as tf<br/>import numpy as np<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</pre>
<p>We then define some TensorFlow objects, placeholders, and a constant by executing the following code snippet:</p>
<pre>#Placeholders<br/>x = tf.placeholder(tf.float32)<br/>y = tf.placeholder(tf.float32)<br/>c = tf.constant(5)</pre>
<p>Here, we define a placeholder called <kbd>x</kbd> and another placeholder called <kbd>y</kbd>. You have to explicitly give the type of object that you will use in TensorFlow, which we have in our example as <kbd>float32</kbd>. We then define a constant, <kbd>c</kbd> ,whose value is <kbd>5</kbd>.</p>
<p>After you create these objects, if you try to print them, you will not see the value of the object, but it will show the type of the object as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/0760ad7d-7c77-46e1-b4e7-fd8c6607998f.png" style="width:34.50em;height:9.25em;"/></p>
<p>Now, let's implement the following function with our placeholders:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/39bb9a13-593d-4fd6-a16f-23b7d66715fb.png" style="width:10.42em;height:2.17em;"/></p>
<p>We will use the placeholders that we just created to define the different nodes for our graph by executing the following code lines:</p>
<pre>square_node = x*x<br/>mult_node = square_node*y<br/>quadruple_node = 4*y<br/>adder_node = mult_node + quadruple_node</pre>
<p>Again, if you try to print the values of these objects, you will get the object type and not the values as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/a9eb5f4e-f40b-4fa1-8adf-bc449ca8d24d.png" style="width:33.83em;height:4.50em;"/></p>
<p>So, to perform the calculations for these objects, you must create a session object and then run all of the objects inside a session:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8ebba675-9c71-4e31-b536-c84c7098babd.png" style="width:24.58em;height:18.92em;"/></p>
<p>If you are doing some computations, you don't need to define the computational graph, as TensorFlow will do this behind the scenes. So, let's say that you want to calculate <kbd>f</kbd> and we print the value, it will still give the object type. But to actually see the value of <kbd>f</kbd> when you perform the computation, we will run the function in a session object again:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/e94fb92f-b91a-44bd-9843-10f8d1c6acb7.png" style="width:29.58em;height:10.75em;"/></p>
<p>There are two ways in which you can run objects in TensorFlow. There are other ways, but these are the basic and most common ways you can run objects. You can use the <kbd>run()</kbd> method from a session or you can use the <kbd>eval()</kbd> method from the tensor:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/3bd8b8d8-0c08-4461-a214-2376e38ce378.png" style="width:32.00em;height:7.00em;"/></p>
<p>As we can see, we created a session using the <kbd>with</kbd> statement and ran those two methods inside this statement.</p>
<p>Now, we will build a basic linear model. We will have TensorFlow guess the best values for the <kbd>b</kbd> and <kbd>w</kbd> parameters shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/270794dc-53bd-4673-8207-ca8fe98c51ec.png" style="width:11.67em;height:2.42em;"/></p>
<p>In the previous equation, the value of <kbd>w</kbd> is <kbd>5</kbd> and <kbd>b</kbd> is <kbd>1</kbd>. We will use these values for training and plot the values on a scatter plot:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/8ed0ddf5-88be-4207-9482-3e5d43cf1f3b.png" style="width:35.25em;height:23.08em;"/></p>
<p>As you can see, we have the linear relationship between the two values.</p>
<p>We will now initiate the variable objects, <kbd>w</kbd> and <kbd>b</kbd> ,with the value <kbd>0</kbd>, and they will be our trainable parameters. The placeholders are usually the objects that we use to pass the data, so we will create two placeholders, <kbd>x</kbd> and <kbd>y</kbd>, and now the linear model will be one of the nodes in our computational graph. Then, we will define a <kbd>loss</kbd> function, which will be used by the optimizer to actually change the values of our variable. Every time we run the training operation, the optimizer will adjust the values of <kbd>w</kbd> and <kbd>b</kbd> in order to minimize the loss. We will then initialize the variables and create a session to run the <kbd>init</kbd><span> </span><span>initializer node as shown in the following screenshot</span><span>:</span></p>
<p class="CDPAlignCenter CDPAlign"><br/>
<img src="assets/ba6befb8-56cb-4e28-b2eb-f0a824fec4ac.png" style="width:41.08em;height:28.00em;"/></p>
<p>Now, we can start training our machine learning model. We will run the training operation 20 times, which will make corrections to our values of <kbd>w</kbd> and <kbd>b</kbd> to minimize the loss:</p>
<p class="CDPAlignCenter CDPAlign"><img src="assets/fb974a24-7293-41d3-a968-b0adf65204e8.png"/></p>
<p>As we see, after the first iteration, the optimizer corrected the values of <kbd>w</kbd> and <kbd>b</kbd>, which is also carried out in every iteration.</p>
<p>We can also do this using some linear algebra, but remember that the goal of machine learning is to actually learn the parameters from the data, and in this case, we have run our first machine learning model using TensorFlow.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we talked about ANNs, deep learning, and the elements of a deep learning model. We then installed TensorFlow and learned about the core concepts that we use in TensorFlow.</p>
<p>In the next chapter, we will perform predictive analytics with TensorFlow and deep learning.</p>


            </article>

            
        </section>
    </body></html>