<html><head></head><body>
		<div id="_idContainer209" class="Content">
			<h1 id="_idParaDest-207"><a id="_idTextAnchor233"/>Appendix</h1>
		</div>
		<div id="_idContainer241" class="Content">
			<h1 id="_idParaDest-208"><a id="_idTextAnchor234"/>1. Introduction to Artificial Intelligence</h1>
			<h2 id="_idParaDest-209"><a id="_idTextAnchor235"/>Activity 1.01: Generating All Possible Sequences of Steps in a Tic-Tac-Toe Game</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<p><a id="_idTextAnchor236"/>The following steps will help you to complete this activity:</p>
			<ol>
				<li>Open a new Jupyter Notebook file.</li>
				<li>Reuse the function codes of <em class="italic">Steps 2–9</em> from the previous, <em class="italic">Exercise 1.02</em>, <em class="italic">Creating an AI with Random Behavior for the Tic-Tac-Toe Game</em>.</li>
				<li>Create a function that maps the <strong class="source-inline">all_moves_from_board_list</strong> function to each element of a list of boards. This way, we will have all of the nodes of a decision tree in each depth:<p class="source-code">def all_moves_from_board_list(board_list, sign):</p><p class="source-code">    move_list = []</p><p class="source-code">    for board in board_list:</p><p class="source-code">        move_list.extend(all_moves_from_board(board, sign))</p><p class="source-code">    return move_list</p><p>In the preceding code snippet, we have defined the <strong class="source-inline">all_moves_from_board</strong> function, which will enumerate all the possible moves from the board and add the move to a list called <strong class="source-inline">move_list</strong>. </p></li>
				<li>Create a variable called board that contains the <strong class="source-inline">EMPTY_SIGN * 9</strong> decision tree and calls the <strong class="source-inline">all_moves_from_board_list</strong> function with the board and <strong class="source-inline">AI_SIGN</strong>. Save its output in a variable called <strong class="source-inline">all_moves</strong> and print its content:<p class="source-code">board = EMPTY_SIGN * 9</p><p class="source-code">all_moves = all_moves_from_board(board, AI_SIGN )</p><p class="source-code">all_moves</p><p>The expected output is this:</p><p class="source-code">['X........',</p><p class="source-code"> '.X.......',</p><p class="source-code"> '..X......',</p><p class="source-code"> '...X.....',</p><p class="source-code"> '....X....',</p><p class="source-code"> '.....X...',</p><p class="source-code"> '......X..',</p><p class="source-code"> '.......X.',</p><p class="source-code"> '........X']</p></li>
				<li>Create a <strong class="source-inline">filter_wins</strong> function that takes the ended games out from the list of moves and appends them in an array containing the board states won by the AI player and the opponent player:<p class="source-code">def filter_wins(move_list, ai_wins, opponent_wins):</p><p class="source-code">    for board in move_list:</p><p class="source-code">        won_by = game_won_by(board)</p><p class="source-code">        if won_by == AI_SIGN:</p><p class="source-code">            ai_wins.append(board)</p><p class="source-code">            move_list.remove(board)</p><p class="source-code">        elif won_by == OPPONENT_SIGN:</p><p class="source-code">            opponent_wins.append(board)</p><p class="source-code">            move_list.remove(board)</p><p>In the preceding code snippet, we have defined a <strong class="source-inline">filter_wins</strong> function, which will add the winning state of the board for each player to a list.</p></li>
				<li>Use the <strong class="source-inline">count_possibilities</strong> function, which prints and returns the number of decision tree leaves that ended with a draw, that were won by the first player, and that were won by the second player, as shown in the following code snippet:<p class="source-code">def count_possibilities():</p><p class="source-code">    board = EMPTY_SIGN * 9</p><p class="source-code">    move_list = [board]</p><p class="source-code">    ai_wins = []</p><p class="source-code">    opponent_wins = []</p><p class="source-code">    for i in range(9):</p><p class="source-code">        print('step ' + str(i) + '. Moves: ' \</p><p class="source-code">              + str(len(move_list)))</p><p class="source-code">        sign = AI_SIGN if \</p><p class="source-code">               i % 2 == 0 else OPPONENT_SIGN</p><p class="source-code">        move_list = all_moves_from_board_list\</p><p class="source-code">                    (move_list, sign)</p><p class="source-code">        filter_wins(move_list, ai_wins, \</p><p class="source-code">                    opponent_wins)</p><p class="source-code">    print('First player wins: ' + str(len(ai_wins)))</p><p class="source-code">    print('Second player wins: ' + str(len(opponent_wins)))</p><p class="source-code">    print('Draw', str(len(move_list)))</p><p class="source-code">    print('Total', str(len(ai_wins) \</p><p class="source-code">          + len(opponent_wins) + len(move_list)))</p><p class="source-code">    return len(ai_wins), len(opponent_wins), \</p><p class="source-code">           len(move_list), len(ai_wins) \</p><p class="source-code">           + len(opponent_wins) + len(move_list)</p><p>We have up to <strong class="source-inline">9</strong> steps in each state. In the 0<span class="superscript">th</span>, 2<span class="superscript">nd</span>, 4<span class="superscript">th</span>, 6<span class="superscript">th</span>, and 8<span class="superscript">th</span> iterations, the AI player moves. In all the other iterations, the opponent moves. We create all possible moves in all steps and take out the completed games from the move list.</p></li>
				<li>Execute the number of possibilities to experience the combinatorial explosion and save the results in four variables called <strong class="source-inline">first_player</strong>, <strong class="source-inline">second_player</strong>, <strong class="source-inline">draw</strong>, and <strong class="source-inline">total</strong>:<p class="source-code">first_player, second_player, \</p><p class="source-code">draw, total = count_possibilities()</p><p>The expected output is this:</p><p class="source-code">step 0. Moves: 1</p><p class="source-code">step 1. Moves: 9</p><p class="source-code">step 2. Moves: 72</p><p class="source-code">step 3. Moves: 504</p><p class="source-code">step 4. Moves: 3024</p><p class="source-code">step 5. Moves: 13680</p><p class="source-code">step 6. Moves: 49402</p><p class="source-code">step 7. Moves: 111109</p><p class="source-code">step 8. Moves: 156775</p><p class="source-code">First player wins: 106279</p><p class="source-code">Second player wins: 68644</p><p class="source-code">Draw 91150</p><p class="source-code">Total 266073</p></li>
			</ol>
			<p>As you can see, the tree of the board states consists of a total of <strong class="source-inline">266073</strong> leaves. The <strong class="source-inline">count_possibilities</strong> function essentially implements a BFS algorithm to traverse all the possible states of the game. Notice that we count these states multiple times because placing an <strong class="source-inline">X</strong> in the top-right corner in <em class="italic">Step 1</em> and placing an <strong class="source-inline">X</strong> in the top-left corner in <em class="italic">Step 3</em> leads to similar possible states as starting with the top-left corner and then placing an <strong class="source-inline">X</strong> in the top-right corner. If we implemented the detection of duplicate states, we would have to check fewer nodes. However, at this stage, due to the limited depth of the game, we will omit this step.</p>
			<p>A decision tree, however, is identical to the data structure examined by <strong class="source-inline">count_possibilities</strong>. In a decision tree, we explore the utility of each move by investigating all possible future steps up to a certain extent. In our example, we could calculate the utility of the initial moves by observing the number of wins and losses after fixing the first few moves.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The root of the tree is the initial state. An internal state of the tree is a state in which a game has not been ended and moves are still possible. A leaf of the tree contains a state where a game has ended.</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3doxPog">https://packt.live/3doxPog</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3dpnuIz">https://packt.live/3dpnuIz</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-210"><a id="_idTextAnchor237"/>Activity 1.02: Teaching the Agent to Realize Situations When It Defends Against Losses</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<p>The following steps will help you to complete this activity:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Reuse all the code from <em class="italic">Steps 2–6</em> from the previous, <em class="italic">Exercise 1.03</em>, <em class="italic">Teaching the Agent to Win</em>.</li>
				<li>Create a function called <strong class="source-inline">player_can_win</strong> that takes all the moves from the board using the <strong class="source-inline">all_moves_from_board</strong> function and iterates over them using the <strong class="source-inline">next_move</strong> variable.<p>In each iteration, it checks whether the game can be won by the player.</p><p class="source-code">def player_can_win(board, sign):</p><p class="source-code">    next_moves = all_moves_from_board(board, sign)</p><p class="source-code">    for next_move in next_moves:</p><p class="source-code">        if game_won_by(next_move) == sign:</p><p class="source-code">            return True</p><p class="source-code">    return False</p></li>
				<li>Extend the AI move so that it prefers making safe moves. A move is safe if the opponent cannot win the game in the next step:<p class="source-code">def ai_move(board):</p><p class="source-code">    new_boards = all_moves_from_board(board, AI_SIGN)</p><p class="source-code">    for new_board in new_boards:</p><p class="source-code">        if game_won_by(new_board) == AI_SIGN:</p><p class="source-code">            return new_board</p><p class="source-code">    safe_moves = []</p><p class="source-code">    for new_board in new_boards:</p><p class="source-code">        if not player_can_win(new_board, OPPONENT_SIGN):</p><p class="source-code">            safe_moves.append(new_board)</p><p class="source-code">    return choice(safe_moves) \</p><p class="source-code">    if len(safe_moves) &gt; 0 else new_boards[0]</p><p>In the preceding code snippet, we have defined the <strong class="source-inline">ai_move</strong> function, which tells the AI how to move by looking at the list of all the possibilities and choosing one where the player cannot win in the next move. If you test our new application, you will find that the AI has made the correct move.</p></li>
				<li>Now, place this logic in the state space generator and check how well the computer player is doing by generating all the possible games:<p class="source-code">def all_moves_from_board(board, sign):</p><p class="source-code">    move_list = []</p><p class="source-code">    for i, v in enumerate(board):</p><p class="source-code">        if v == EMPTY_SIGN:</p><p class="source-code">            new_board = board[:i] + sign + board[i+1:]</p><p class="source-code">            move_list.append(new_board)</p><p class="source-code">            if game_won_by(new_board) == AI_SIGN:</p><p class="source-code">                return [new_board]</p><p class="source-code">    if sign == AI_SIGN:</p><p class="source-code">        safe_moves = []</p><p class="source-code">        for move in move_list:</p><p class="source-code">            if not player_can_win(move, OPPONENT_SIGN):</p><p class="source-code">                safe_moves.append(move)</p><p class="source-code">        return safe_moves if len(safe_moves) &gt; 0 else move_list[0:1]</p><p class="source-code">    else:</p><p class="source-code">        return move_list</p><p>In the preceding code snippet, we have defined a function that generates all possible moves. As soon as we find the next move that can make the player win, we return a move to counter it. We do not care whether the player has multiple options to win the game in one move – we just return the first possibility. If the AI cannot stop the player from winning, we return all possible moves.</p><p>Let's see what this means in terms of counting all of the possibilities at each step.</p></li>
				<li>Count the options that are possible:<p class="source-code">first_player, second_player, \</p><p class="source-code">draw, total = count_possibilities()</p><p>The expected output is this:</p><p class="source-code">step 0. Moves: 1</p><p class="source-code">step 1. Moves: 9</p><p class="source-code">step 2. Moves: 72</p><p class="source-code">step 3. Moves: 504</p><p class="source-code">step 4. Moves: 3024</p><p class="source-code">step 5. Moves: 5197</p><p class="source-code">step 6. Moves: 18606</p><p class="source-code">step 7. Moves: 19592</p><p class="source-code">step 8. Moves: 30936</p><p class="source-code">First player wins: 20843</p><p class="source-code">Second player wins: 962</p><p class="source-code">Draw 20243</p><p class="source-code">Total 42048</p></li>
			</ol>
			<p>We are doing better than before. We not only got rid of almost 2/3 of possible games again, but, most of the time, the AI player either wins or settles for a draw.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2B0G9xf">https://packt.live/2B0G9xf</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2V7qLpO">https://packt.live/2V7qLpO</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-211"><a id="_idTextAnchor238"/>Activity 1.03: Fixing the First and Second Moves of the AI to Make It Invincible</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<p>The following steps will help you to complete this activity:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Reuse the code from <em class="italic">Steps 2–4</em> of the previous, <em class="italic">Activity 1.02</em>, <em class="italic">Teaching the Agent to Realize Situations When It Defends Against Losses</em>.</li>
				<li>Now, count the number of empty fields on the board and make a hardcoded move in case there are 9 or 7 empty fields. You can experiment with different hardcoded moves. We found that occupying any corner, and then occupying the opposite corner, leads to no loss. If the opponent occupies the opposite corner, making a move in the middle results in no losses:<p class="source-code">def all_moves_from_board(board, sign):</p><p class="source-code">    if sign == AI_SIGN:</p><p class="source-code">        empty_field_count = board.count(EMPTY_SIGN)</p><p class="source-code">        if empty_field_count == 9:</p><p class="source-code">            return [sign + EMPTY_SIGN * 8]</p><p class="source-code">        elif empty_field_count == 7:</p><p class="source-code">            return [board[:8] + sign if board[8] == \</p><p class="source-code">                    EMPTY_SIGN else board[:4] + sign + board[5:]]</p><p class="source-code">    move_list = []</p><p class="source-code">    for i, v in enumerate(board):</p><p class="source-code">        if v == EMPTY_SIGN:</p><p class="source-code">            new_board = board[:i] + sign + board[i+1:]</p><p class="source-code">            move_list.append(new_board)</p><p class="source-code">            if game_won_by(new_board) == AI_SIGN:</p><p class="source-code">                return [new_board]</p><p class="source-code">    if sign == AI_SIGN:</p><p class="source-code">        safe_moves = []</p><p class="source-code">        for move in move_list:</p><p class="source-code">            if not player_can_win(move, OPPONENT_SIGN):</p><p class="source-code">                safe_moves.append(move)</p><p class="source-code">        return safe_moves if len(safe_moves) &gt; 0 else move_list[0:1]</p><p class="source-code">    else:</p><p class="source-code">        return move_list</p></li>
				<li>Now, verify the state space:<p class="source-code">first_player, second_player, draw, total = count_possibilities()</p><p>The expected output is this:</p><p class="source-code">step 0. Moves: 1</p><p class="source-code">step 1. Moves: 1</p><p class="source-code">step 2. Moves: 8</p><p class="source-code">step 3. Moves: 8</p><p class="source-code">step 4. Moves: 48</p><p class="source-code">step 5. Moves: 38</p><p class="source-code">step 6. Moves: 108</p><p class="source-code">step 7. Moves: 76</p><p class="source-code">step 8. Moves: 90</p><p class="source-code">First player wins: 128</p><p class="source-code">Second player wins: 0</p><p class="source-code">Draw 60</p><p class="source-code">Total 188</p></li>
			</ol>
			<p>After fixing the first two steps, we only need to deal with 8 possibilities instead of 504. We also guided the AI into a state where the hardcoded rules were sufficient enough for it to never lose a game. Fixing the steps is not important because we would give the AI hardcoded steps to start with, but it is important because it is a tool that is used to evaluate and compare each step. After fixing the first two steps, we only need to deal with 8 possibilities instead of 504. We also guided the AI into a state, where the hardcoded rules were sufficient for never losing a game. As you can see, the AI is now nearly invincible and will only win or make a draw. </p>
			<p>The best that a player can hope to get against this AI is a draw.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YnUcpA">https://packt.live/2YnUcpA</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/318TBtq">https://packt.live/318TBtq</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-212"><a id="_idTextAnchor239"/>Activity 1.04: Connect Four</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.<p>Let's set up the <strong class="source-inline">TwoPlayersGame</strong> framework by writing the <strong class="source-inline">init</strong> method.</p></li>
				<li>Define the board as a one-dimensional list, like the tic-tac-toe example. We could use a two-dimensional list, too, but modeling will not get much easier or harder. Beyond making initialization like we did in the tic-tac-toe game, we will work a bit further ahead. We will generate all of the possible winning combinations in the game and save them for future use, as shown in the following code snippet:<p class="source-code">from easyAI import TwoPlayersGame, Human_Player</p><p class="source-code">class ConnectFour(TwoPlayersGame):</p><p class="source-code">    def __init__(self, players):</p><p class="source-code">        self.players = players</p><p class="source-code">        self.board = [0 for i in range(42)]</p><p class="source-code">        self.nplayer = 1  </p><p class="source-code">        def generate_winning_tuples():</p><p class="source-code">            tuples = []</p><p class="source-code">            # horizontal</p><p class="source-code">            tuples += [list(range(row*7+column, \</p><p class="source-code">                       row*7+column+4, 1)) \</p><p class="source-code">                       for row in range(6) \</p><p class="source-code">                       for column in range(4)]</p><p class="source-code">            # vertical</p><p class="source-code">            tuples += [list(range(row*7+column, \</p><p class="source-code">                       row*7+column+28, 7)) \</p><p class="source-code">                       for row in range(3) \</p><p class="source-code">                       for column in range(7)]</p><p class="source-code">            # diagonal forward</p><p class="source-code">            tuples += [list(range(row*7+column, \</p><p class="source-code">                       row*7+column+32, 8)) \</p><p class="source-code">                       for row in range(3) \</p><p class="source-code">                       for column in range(4)]</p><p class="source-code">            # diagonal backward</p><p class="source-code">            tuples += [list(range(row*7+column, \</p><p class="source-code">                       row*7+column+24, 6)) \</p><p class="source-code">                       for row in range(3) \</p><p class="source-code">                       for column in range(3, 7, 1)]</p><p class="source-code">            return tuples</p><p class="source-code">        self.tuples = generate_winning_tuples()</p></li>
				<li>Next, handle the <strong class="source-inline">possible_moves</strong> function, which is a simple enumeration. Notice that we are using column indices from <strong class="source-inline">1</strong> to <strong class="source-inline">7</strong> in the move names because it is more convenient to start a column indexing with <strong class="source-inline">1</strong> in the human player interface than with zero. For each column, we check whether there is an unoccupied field. If there is one, we will make the column a possible move:<p class="source-code">    def possible_moves(self):</p><p class="source-code">        return [column+1 \</p><p class="source-code">                for column in range(7) \</p><p class="source-code">                if any([self.board[column+row*7] == 0 \</p><p class="source-code">                        for row in range(6)])</p><p class="source-code">                ]</p></li>
				<li>Making a move is like the <strong class="source-inline">possible_moves</strong> function. We check the column of the move and find the first empty cell starting from the bottom. Once we find it, we occupy it. You can also read the implementation of the both the <strong class="source-inline">make_move</strong> function: <strong class="source-inline">unmake_move</strong>. In the <strong class="source-inline">unmake_move</strong> function, we check the column from top to down, and we remove the move at the first non-empty cell. Notice that we rely on the internal representation of <strong class="source-inline">easyAI</strong> so that it does not undo moves that it hasn't made. Otherwise, this function would remove a token of the other player without checking whose token was removed:<p class="source-code">    def make_move(self, move):</p><p class="source-code">        column = int(move) - 1</p><p class="source-code">        for row in range(5, -1, -1):</p><p class="source-code">            index = column + row*7</p><p class="source-code">            if self.board[index] == 0:</p><p class="source-code">                self.board[index] = self.nplayer</p><p class="source-code">                return</p><p class="source-code">    # optional method (speeds up the AI)</p><p class="source-code">    def unmake_move(self, move):</p><p class="source-code">        column = int(move) - 1</p><p class="source-code">        for row in range(6):</p><p class="source-code">            index = column + row*7</p><p class="source-code">            if self.board[index] != 0:</p><p class="source-code">                self.board[index] = 0</p><p class="source-code">                return</p></li>
				<li>Since we already have the tuples that we must check, we can mostly reuse the <strong class="source-inline">lose</strong> function from the tic-tac-toe example:<p class="source-code">    def lose(self):</p><p class="source-code">        return any([all([(self.board[c] == self.nopponent)</p><p class="source-code">                         for c in line])</p><p class="source-code">                    for line in self.tuples])</p><p class="source-code">    def is_over(self):</p><p class="source-code">        return (self.possible_moves() == []) or self.lose()</p></li>
				<li>Our final task is to implement the <strong class="source-inline">show</strong> method, which prints the board. We will reuse the tic-tac-toe implementation and just change the <strong class="source-inline">show</strong> and <strong class="source-inline">scoring</strong> variables:<p class="source-code">    def show(self):</p><p class="source-code">        print('\n'+'\n'.join([</p><p class="source-code">            ' '.join([['.', 'O', 'X']\</p><p class="source-code">                      [self.board[7*row+column]] \</p><p class="source-code">                      for column in range(7)])</p><p class="source-code">            for row in range(6)]))</p><p class="source-code">    def scoring(self):</p><p class="source-code">        return -100 if self.lose() else 0</p><p class="source-code">if __name__ == "__main__":</p><p class="source-code">    from easyAI import AI_Player, Negamax</p><p class="source-code">    ai_algo = Negamax(6)</p><p class="source-code">    ConnectFour([Human_Player(), \</p><p class="source-code">                 AI_Player(ai_algo)]).play()</p></li>
				<li>Now that all the functions are complete, you can try out the example. Feel free to play a round or two against your opponent. <p>The expected output is this:</p><div id="_idContainer210" class="IMG---Figure"><img src="image/B16060_01_30.jpg" alt="Figure 1.30: Expected output for the Connect Four game&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 1.30: Expected output for the Connect Four game</p>
			<p>By completing this activity, you have seen that the opponent is not perfect, but that it plays reasonably well. If you have a strong computer, you can increase the parameter of the <strong class="source-inline">Negamax</strong> algorithm. We encourage you to come up with a better heuristic.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3esk2hI">https://packt.live/3esk2hI</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3dnkfS5">https://packt.live/3dnkfS5</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h1 id="_idParaDest-213"><a id="_idTextAnchor240"/>2. An Introduction to Regression</h1>
			<h2 id="_idParaDest-214"><a id="_idTextAnchor241"/>Activity 2.01: Boston House Price Prediction with Polynomial Regression of Degrees 1, 2, and 3 on Multiple Variables</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a Jupyter Notebook.</li>
				<li>Import the required packages and load the Boston House Prices data from <strong class="source-inline">sklearn</strong> into a DataFrame:<p class="source-code">import numpy as np</p><p class="source-code">import pandas as pd</p><p class="source-code">from sklearn import preprocessing</p><p class="source-code">from sklearn import model_selection</p><p class="source-code">from sklearn import linear_model</p><p class="source-code">from sklearn.preprocessing import PolynomialFeatures</p><p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/'\</p><p class="source-code">           'The-Applied-Artificial-Intelligence-Workshop/'\</p><p class="source-code">           'master/Datasets/boston_house_price.csv'</p><p class="source-code">df = pd.read_csv(file_url)</p><p>The output of <strong class="source-inline">df</strong> is as follows:</p><div id="_idContainer211" class="IMG---Figure"><img src="image/B16060_02_28.jpg" alt="Figure 2.28: Output displaying the dataset&#13;&#10;"/></div><p class="figure-caption"><a id="_idTextAnchor242"/>Figure 2.28: Output displaying the dataset</p><p>Earlier in this chapter, you learned that most of the required packages to perform linear regression come from <strong class="source-inline">sklearn</strong>. We need to import the <strong class="source-inline">preprocessing</strong> module to scale the data, the <strong class="source-inline">linear_model</strong> module to train linear regression, the <strong class="source-inline">PolynomialFeatures</strong> module to transform the inputs for the polynomial regression, and the <strong class="source-inline">model_selection</strong> module to evaluate the performance of each model. </p></li>
				<li>Prepare the dataset for prediction by converting the label and features into NumPy arrays and scaling the features:<p class="source-code">features = np.array(df.drop('MEDV', 1))</p><p class="source-code">label = np.array(df['MEDV'])</p><p class="source-code">scaled_features = preprocessing.scale(features)</p><p>The output for <strong class="source-inline">features</strong> is as follows:</p><div id="_idContainer212" class="IMG---Figure"><img src="image/B16060_02_29.jpg" alt="Figure 2.29: Labels and features converted to NumPy arrays&#13;&#10;"/></div><p class="figure-caption">F<a id="_idTextAnchor243"/>igure 2.29: Labels and features converted to NumPy arrays</p><p>As you can see, our features have been converted into a NumPy array.</p><p>The output for the <strong class="source-inline">label</strong> is as follows:</p><div id="_idContainer213" class="IMG---Figure"><img src="image/B16060_02_30.jpg" alt="Figure 2.30: Output showing the expected labels&#13;&#10;"/></div><p class="figure-caption">Fi<a id="_idTextAnchor244"/>gure 2.30: Output showing the expected labels</p><p>As you can see, our labels have been converted into a NumPy array.</p><p>The output for <strong class="source-inline">scaled_features</strong> is as follows:</p><p class="source-code">array([[-0.41978194,  0.28482986, -1.2879095 , ..., </p><p class="source-code">        -0.66660821, -1.45900038, -1.0755623 ],</p><p class="source-code">       [-0.41733926, -0.48772236, -0.59338101, ..., </p><p class="source-code">        -0.98732948, -0.30309415, -0.49243937],</p><p class="source-code">       [-0.41734159, -0.48772236, -0.59338101, ..., </p><p class="source-code">        -0.98732948, -0.30309415, -1.2087274 ],</p><p class="source-code">       ...,</p><p class="source-code">       [-0.41344658, -0.48772236,  0.11573841, ..., </p><p class="source-code">        -0.80321172,  1.17646583, -0.98304761],</p><p class="source-code">       [-0.40776407, -0.48772236,  0.11573841, ..., </p><p class="source-code">        -0.80321172,  1.17646583, -0.86530163],</p><p class="source-code">       [-0.41500016, -0.48772236,  0.11573841, ..., </p><p class="source-code">        -0.80321172,  1.17646583, -0.66905833]])</p><p>As you can see, our features have been properly scaled.</p><p>As we don't have any missing values and we are not trying to predict a future value as we did in <em class="italic">Exercise 2.03</em>, <em class="italic">Preparing the Quandl Data for Prediction</em>, we can directly convert the label (<strong class="source-inline">'MEDV'</strong>) and features into NumPy arrays. Then, we can scale the arrays of features using the <strong class="source-inline">preprocessing.scale()</strong> function.</p></li>
				<li>Create three different set of features by transforming the scaled features into a suitable format for each of the polynomial regressions:<p class="source-code">poly_1_scaled_features = PolynomialFeatures(degree=1)\</p><p class="source-code">                         .fit_transform(scaled_features)</p><p class="source-code">poly_2_scaled_features = PolynomialFeatures(degree=2)\</p><p class="source-code">                         .fit_transform(scaled_features)</p><p class="source-code">poly_3_scaled_features = PolynomialFeatures(degree=3)\</p><p class="source-code">                         .fit_transform(scaled_features)</p><p>The output for <strong class="source-inline">poly_1_scaled_features</strong> is as follows:</p><p class="source-code">array([[ 1.        , -0.41978194,  0.28482986, ..., -0.66660821,</p><p class="source-code">        -1.45900038, -1.0755623 ],</p><p class="source-code">       [ 1.        , -0.41733926, -0.48772236, ..., -0.98732948,</p><p class="source-code">        -0.30309415, -0.49243937],</p><p class="source-code">       [ 1.        , -0.41734159, -0.48772236, ..., -0.98732948,</p><p class="source-code">        -0.30309415, -1.2087274 ],</p><p class="source-code">       ...,</p><p class="source-code">       [ 1.        , -0.41344658, -0.48772236, ..., -0.80321172,</p><p class="source-code">         1.17646583, -0.98304761],</p><p class="source-code">       [ 1.        , -0.40776407, -0.48772236, ..., -0.80321172,</p><p class="source-code">         1.17646583, -0.86530163],</p><p class="source-code">       [ 1.        , -0.41500016, -0.48772236, ..., -0.80321172,</p><p class="source-code">         1.17646583, -0.66905833]])</p><p>Our <strong class="source-inline">scaled_features</strong> variable has been properly transformed for the polynomial regression of degree <strong class="source-inline">1</strong>.</p><p>The output for <strong class="source-inline">poly_2_scaled_features</strong> is as follows:</p><div id="_idContainer214" class="IMG---Figure"><img src="image/B16060_02_31.jpg" alt="Figure 2.31: Output showing poly_2_scaled_features&#13;&#10;"/></div><p class="figure-caption">Fig<a id="_idTextAnchor245"/>ure 2.31: Output showing poly_2_scaled_features</p><p>Our <strong class="source-inline">scaled_features</strong> variable has been properly transformed for the polynomial regression of degree <strong class="source-inline">2</strong>.</p><p>The output for <strong class="source-inline">poly_3_scaled_features</strong> is as follows:</p><p class="source-code">array([[ 1.        , -0.41978194,  0.28482986, ..., -2.28953024,</p><p class="source-code">        -1.68782164, -1.24424733],</p><p class="source-code">       [ 1.        , -0.41733926, -0.48772236, ..., -0.04523847,</p><p class="source-code">        -0.07349928, -0.11941484],</p><p class="source-code">       [ 1.        , -0.41734159, -0.48772236, ..., -0.11104103,</p><p class="source-code">        -0.4428272 , -1.76597723],</p><p class="source-code">       ...,</p><p class="source-code">       [ 1.        , -0.41344658, -0.48772236, ..., -1.36060852,</p><p class="source-code">         1.13691611, -0.9500001 ],</p><p class="source-code">       [ 1.        , -0.40776407, -0.48772236, ..., -1.19763962,</p><p class="source-code">         0.88087515, -0.64789192],</p><p class="source-code">       [ 1.        , -0.41500016, -0.48772236, ..., -0.9260248 ,</p><p class="source-code">         0.52663205, -0.29949664]])</p><p>Our <strong class="source-inline">scaled_features</strong> variable has been properly transformed for the polynomial regression of degree <strong class="source-inline">3</strong>.</p><p>We had to transform the scaled features in three different ways as each degree of polynomial regression required a different input transformation.</p></li>
				<li>Split the data into a training set and a testing set with <strong class="source-inline">random state = 8</strong>:<p class="source-code">(poly_1_features_train, poly_1_features_test, \</p><p class="source-code">poly_label_train, poly_label_test) = \</p><p class="source-code">model_selection.train_test_split(poly_1_scaled_features, \</p><p class="source-code">                                 label, \</p><p class="source-code">                                 test_size=0.1, \</p><p class="source-code">                                 random_state=8)</p><p class="source-code">(poly_2_features_train, poly_2_features_test, \</p><p class="source-code">poly_label_train, poly_label_test) = \</p><p class="source-code">model_selection.train_test_split(poly_2_scaled_features, \</p><p class="source-code">                                 label, \</p><p class="source-code">                                 test_size=0.1, \</p><p class="source-code">                                 random_state=8)</p><p class="source-code">(poly_3_features_train, poly_3_features_test, \</p><p class="source-code">poly_label_train, poly_label_test) = \</p><p class="source-code">model_selection.train_test_split(poly_3_scaled_features, \</p><p class="source-code">                                 label, \</p><p class="source-code">                                 test_size=0.1, \</p><p class="source-code">                                 random_state=8)</p><p>As we have three different sets of scaled transformed features but the same set of labels, we had to perform three different splits. By using the same set of labels and <strong class="source-inline">random_state</strong> in each splitting, we ensure that we obtain the same <strong class="source-inline">poly_label_train</strong> and <strong class="source-inline">poly_label_test</strong> for every split.</p></li>
				<li>Perform a polynomial regression of degree 1 and evaluate whether the model is overfitting:<p class="source-code">model_1 = linear_model.LinearRegression()</p><p class="source-code">model_1.fit(poly_1_features_train, poly_label_train)</p><p class="source-code">model_1_score_train = model_1.score(poly_1_features_train, \</p><p class="source-code">                                    poly_label_train)</p><p class="source-code">model_1_score_test = model_1.score(poly_1_features_test, \</p><p class="source-code">                                   poly_label_test)</p><p>The output for <strong class="source-inline">model_1_score_train</strong> is as follows:</p><p class="source-code">0.7406006443486721</p><p>The output for <strong class="source-inline">model_1_score_test</strong> is as follows:</p><p class="source-code">0.6772229017901507</p><p>To estimate whether a model is overfitting or not, we need to compare the scores of the model applied to the training set and testing set. If the score for the training set is much higher than the test set, we are overfitting. This is the case here where the polynomial regression of degree 1 achieved a score of <strong class="source-inline">0.74</strong> for the training set compared to <strong class="source-inline">0.68</strong> for the testing set.</p></li>
				<li>Perform a polynomial regression of degree 2 and evaluate whether the model is overfitting:<p class="source-code">model_2 = linear_model.LinearRegression()</p><p class="source-code">model_2.fit(poly_2_features_train, poly_label_train)</p><p class="source-code">model_2_score_train = model_2.score(poly_2_features_train, \</p><p class="source-code">                                    poly_label_train)</p><p class="source-code">model_2_score_test = model_2.score(poly_2_features_test, \</p><p class="source-code">                                   poly_label_test)</p><p>The output for <strong class="source-inline">model_2_score_train</strong> is as follows:</p><p class="source-code">0.9251199698832675</p><p>The output for <strong class="source-inline">model_2_score_test</strong> is as follows:</p><p class="source-code">0.8253870684280571</p><p>Like with the polynomial regression of degree 1, our polynomial regression of degree 2 is overfitting even more than degree 1, but has managed to achieve better results at the end.</p></li>
				<li>Perform a polynomial regression of degree 3 and evaluate whether the model is overfitting:<p class="source-code">model_3 = linear_model.LinearRegression()</p><p class="source-code">model_3.fit(poly_3_features_train, poly_label_train)</p><p class="source-code">model_3_score_train = model_3.score(poly_3_features_train, \</p><p class="source-code">                                    poly_label_train)</p><p class="source-code">model_3_score_test = model_3.score(poly_3_features_test, \</p><p class="source-code">                                   poly_label_test)</p><p>The output for <strong class="source-inline">model_3_score_train</strong> is as follows:</p><p class="source-code">0.9910498071894897</p><p>The output for <strong class="source-inline">model_3_score_test</strong> is as follows:</p><p class="source-code">-8430.781888645262</p><p>These results are very interesting because the polynomial regression of degree 3 managed to achieve a near-perfect score with <strong class="source-inline">0.99</strong> (1 is the maximum). This is a warning sign that our model is overfitting too much. We have the confirmation of this warning when the model is applied to the testing set and achieves a very low negative score of <strong class="source-inline">-8430</strong>. As a reminder, a score of 0 can be achieved by using the mean of the data as a prediction. This means that our third model managed to make worse predictions than just using the mean.</p></li>
				<li>Compare the predictions of the 3 models against the label on the testing set:<p class="source-code">model_1_prediction = model_1.predict(poly_1_features_test)</p><p class="source-code">model_2_prediction = model_2.predict(poly_2_features_test)</p><p class="source-code">model_3_prediction = model_3.predict(poly_3_features_test)</p><p class="source-code">df_prediction = pd.DataFrame(poly_label_test)</p><p class="source-code">df_prediction.rename(columns = {0:'label'}, inplace = True)</p><p class="source-code">df_prediction['model_1_prediction'] = \</p><p class="source-code">pd.DataFrame(model_1_prediction)</p><p class="source-code">df_prediction['model_2_prediction'] = \</p><p class="source-code">pd.DataFrame(model_2_prediction)</p><p class="source-code">df_prediction['model_3_prediction'] = \</p><p class="source-code">pd.DataFrame(model_3_prediction)</p><p>The output of <strong class="source-inline">df_prediction</strong> is as follows:</p><div id="_idContainer215" class="IMG---Figure"><img src="image/B16060_02_32.jpg" alt="Figure 2.32: Output showing the expected predicted values&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 2.32: Output showing the expected predicted values</p>
			<p>After applying the <strong class="source-inline">predict</strong> function for each model on their respective testing set, in order to get the predicted values, we convert them into a single <strong class="source-inline">df_prediction</strong> DataFrame with the label values. Increasing the number of degrees in polynomial regressions does not necessarily mean that the model will perform better compared to one with a lower degree. In fact, increasing the degree will lead to more overfitting on the training data.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3eD8gAY">https://packt.live/3eD8gAY</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3etadjp">https://packt.live/3etadjp</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this activity, we learned how to perform polynomial regressions of degrees 1 to 3 with multiple variables on the Boston House Price dataset and saw how increasing the degrees led to overfitted models.</p>
			<h1 id="_idParaDest-215"><a id="_idTextAnchor246"/>3. An Introduction to Classification</h1>
			<h2 id="_idParaDest-216"><a id="_idTextAnchor247"/>Activity 3.01: Increasing the Accuracy of Credit Scoring</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file and execute all the steps from the previous exercise, <em class="italic">Exercise 3.04</em>, <em class="italic">K-Nearest Neighbors Classification in Scikit-Learn</em>.</li>
				<li>Import <strong class="source-inline">neighbors</strong> from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn import neighbors</p></li>
				<li>Create a function called <strong class="source-inline">fit_knn</strong> that takes the following parameters: <strong class="source-inline">k</strong>, <strong class="source-inline">p</strong>, <strong class="source-inline">features_train</strong>, <strong class="source-inline">label_train</strong>, <strong class="source-inline">features_test</strong>, and <strong class="source-inline">label_test</strong>. This function will fit <strong class="source-inline">KNeighborsClassifier</strong> with the training set and print the accuracy score for the training and testing sets, as shown in the following code snippet:<p class="source-code">def fit_knn(k, p, features_train, label_train, \</p><p class="source-code">            features_test, label_test):</p><p class="source-code">    classifier = neighbors.KNeighborsClassifier(n_neighbors=k, p=p)</p><p class="source-code">    classifier.fit(features_train, label_train)</p><p class="source-code">    return classifier.score(features_train, label_train), \</p><p class="source-code">           classifier.score(features_test, label_test)</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=5</strong> and <strong class="source-inline">p=2</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_1</strong> and <strong class="source-inline">acc_test_1</strong>:<p class="source-code">acc_train_1, acc_test_1 = fit_knn(5, 2, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_1, acc_test_1</p><p>The expected output is this:</p><p class="source-code">(0.78625, 0.75)</p><p>With <strong class="source-inline">k=5</strong> and <strong class="source-inline">p=2</strong>, KNN achieved a good accuracy score close to <strong class="source-inline">0.78</strong>. But the score is quite different from the training and testing sets, which means the model is overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=10</strong> and <strong class="source-inline">p=2</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_2</strong> and <strong class="source-inline">acc_test_2</strong>:<p class="source-code">acc_train_2, acc_test_2 = fit_knn(10, 2, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_2, acc_test_2</p><p>The expected output is this:</p><p class="source-code">(0.775, 0.785)</p><p>Increasing the number of neighbors to 10 has decreased the accuracy score of the training set, but now it is very close to the testing set.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=15</strong> and <strong class="source-inline">p=2</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_3</strong> and <strong class="source-inline">acc_test_3</strong>:<p class="source-code">acc_train_3, acc_test_3 = fit_knn(15, 2, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_3, acc_test_3</p><p>The expected output is this:</p><p class="source-code">(0.76625, 0.79)</p><p>With <strong class="source-inline">k=15</strong> and <strong class="source-inline">p=2</strong>, the difference between the training and testing sets has  increased.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=25</strong> and <strong class="source-inline">p=2</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_4</strong> and <strong class="source-inline">acc_test_4</strong>:<p class="source-code">acc_train_4, acc_test_4 = fit_knn(25, 2, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_4, acc_test_4</p><p>The expected output is this:</p><p class="source-code">(0.7375, 0.77)</p><p>Increasing the number of neighbors to <strong class="source-inline">25</strong> has a significant impact on the training set. However, the model is still overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=50</strong> and <strong class="source-inline">p=2</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_5</strong> and <strong class="source-inline">acc_test_5</strong>:<p class="source-code">acc_train_5, acc_test_5 = fit_knn(50, 2, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_5, acc_test_5</p><p>The expected output is this:</p><p class="source-code">(0.70625, 0.775)</p><p>Bringing the number of neighbors to <strong class="source-inline">50</strong> neither improved the model's performance or the overfitting issue.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=5</strong> and <strong class="source-inline">p=1</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_6</strong> and <strong class="source-inline">acc_test_6</strong>:<p class="source-code">acc_train_6, acc_test_6 = fit_knn(5, 1, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_6, acc_test_6</p><p>The expected output is this:</p><p class="source-code">(0.8, 0.735)</p><p>Changing to the Manhattan distance has helped increase the accuracy of the training set, but the model is still overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=10</strong> and <strong class="source-inline">p=1</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_7</strong> and <strong class="source-inline">acc_test_7</strong>:<p class="source-code">acc_train_7, acc_test_7 = fit_knn(10, 1, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_7, acc_test_7</p><p>The expected output is this:</p><p class="source-code">(0.77, 0.785)</p><p>With <strong class="source-inline">k=10</strong>, the accuracy score for the training and testing sets are quite close to each other: around <strong class="source-inline">0.78</strong>.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=15</strong> and <strong class="source-inline">p=1</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_8</strong> and <strong class="source-inline">acc_test_8</strong>:<p class="source-code">acc_train_8, acc_test_8 = fit_knn(15, 1, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_8, acc_test_8</p><p>The expected output is this:</p><p class="source-code">(0.7575, 0.775)</p><p>Bumping <strong class="source-inline">k</strong> to <strong class="source-inline">15</strong>, the model achieved a better accuracy score and is not overfitting very much.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=25</strong> and <strong class="source-inline">p=1</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_9</strong> and <strong class="source-inline">acc_test_9</strong>:<p class="source-code">acc_train_9, acc_test_9 = fit_knn(25, 1, features_train, \</p><p class="source-code">                                  label_train, \</p><p class="source-code">                                  features_test, label_test)</p><p class="source-code">acc_train_9, acc_test_9</p><p>The expected output is this:</p><p class="source-code">(0.745, 0.8)</p><p>With <strong class="source-inline">k=25</strong>, the difference between the training and testing sets' accuracy is increasing, so the model is overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">k=50</strong> and <strong class="source-inline">p=1</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_10</strong> and <strong class="source-inline">acc_test_10</strong>:<p class="source-code">acc_train_10, acc_test_10 = fit_knn(50, 1, features_train, \</p><p class="source-code">                                    label_train, \</p><p class="source-code">                                    features_test, label_test)</p><p class="source-code">acc_train_10, acc_test_10</p><p>The expected output is this:</p><p class="source-code">(0.70875, 0.78)</p><p>With <strong class="source-inline">k=50</strong>, the model's performance on the training set dropped significantly and the model is definitely overfitting.</p></li>
			</ol>
			<p>In this activity, we tried multiple combinations of hyperparameters for <strong class="source-inline">n_neighbors</strong> and <strong class="source-inline">p</strong>. The best one we found was for <strong class="source-inline">n_neighbors=10</strong> and <strong class="source-inline">p=2</strong>. With these hyperparameters, the model is not overfitting much and it achieved an accuracy score of around <strong class="source-inline">78%</strong> for both the training and testing sets.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2V5TOtG">https://packt.live/2V5TOtG</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2Bx0yd8">https://packt.live/2Bx0yd8</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-217"><a id="_idTextAnchor248"/>Activity 3.02: Support Vector Machine Optimization in scikit-learn</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file and execute all the steps mentioned in the previous, <em class="italic">Exercise 3.04</em>, <em class="italic">K-Nearest Neighbor Classification in scikit-learn</em>.</li>
				<li>Import <strong class="source-inline">svm</strong> from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn import svm</p></li>
				<li>Create a function called <strong class="source-inline">fit_knn</strong> that takes the following parameters: <strong class="source-inline">features_train</strong>, <strong class="source-inline">label_train</strong>, <strong class="source-inline">features_test</strong>, <strong class="source-inline">label_test</strong>, <strong class="source-inline">kernel="linear"</strong>, <strong class="source-inline">C=1</strong>, <strong class="source-inline">degree=3</strong>, and <strong class="source-inline">gamma='scale'</strong>. This function will fit an SVC with the training set and print the accuracy score for both the training and testing sets:<p class="source-code">def fit_svm(features_train, label_train, \</p><p class="source-code">            features_test, label_test, \</p><p class="source-code">            kernel="linear", C=1, \</p><p class="source-code">            degree=3, gamma='scale'):</p><p class="source-code">    classifier = svm.SVC(kernel=kernel, C=C, \</p><p class="source-code">                         degree=degree, gamma=gamma)</p><p class="source-code">    classifier.fit(features_train, label_train)</p><p class="source-code">    return classifier.score(features_train, label_train), \</p><p class="source-code">           classifier.score(features_test, label_test)</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with the default hyperparameter values, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_1</strong> and <strong class="source-inline">acc_test_1</strong>:<p class="source-code">acc_train_1, \</p><p class="source-code">acc_test_1 =  fit_svm(features_train, \</p><p class="source-code">                      label_train, \</p><p class="source-code">                      features_test, \</p><p class="source-code">                      label_test)</p><p class="source-code">acc_train_1,  acc_test_1</p><p>The expected output is this:</p><p class="source-code">(0.71625, 0.75)</p><p>With the default hyperparameter values (linear model), the performance of the model is quite different between the training and the testing set. </p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="poly"</strong>, <strong class="source-inline">C=1</strong>, <strong class="source-inline">degree=4</strong>, and <strong class="source-inline">gamma=0.05</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_2</strong> and <strong class="source-inline">acc_test_2</strong>:<p class="source-code">acc_train_2, \</p><p class="source-code">acc_test_2 = fit_svm(features_train, label_train, \</p><p class="source-code">                     features_test, label_test, \</p><p class="source-code">                     kernel="poly",  C=1, \</p><p class="source-code">                     degree=4, gamma=0.05)</p><p class="source-code">acc_train_2,  acc_test_2</p><p>The expected output is this:</p><p class="source-code">(0.68875, 0.745)</p><p>With a fourth-degree polynomial, the model is not performing well on the training set.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="poly"</strong>, <strong class="source-inline">C=2</strong>, <strong class="source-inline">degree=4</strong>, and <strong class="source-inline">gamma=0.05</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_3</strong> and <strong class="source-inline">acc_test_3</strong>:<p class="source-code">acc_train_3, \</p><p class="source-code">acc_test_3 = fit_svm(features_train, \</p><p class="source-code">                     label_train, features_test, \</p><p class="source-code">                     label_test, kernel="poly",  \</p><p class="source-code">                     C=2, degree=4, gamma=0.05)</p><p class="source-code">acc_train_3,  acc_test_3</p><p>The expected output is this:</p><p class="source-code">(0.68875, 0.745)</p><p>Increasing the regularization parameter, <strong class="source-inline">C</strong>, didn't impact the model's performance at all.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="poly"</strong>, <strong class="source-inline">C=1</strong>, <strong class="source-inline">degree=4</strong>, and <strong class="source-inline">gamma=0.25</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_4</strong> and <strong class="source-inline">acc_test_4</strong>:<p class="source-code">acc_train_4, \</p><p class="source-code">acc_test_4 = fit_svm(features_train, \</p><p class="source-code">                     label_train, features_test, \</p><p class="source-code">                     label_test, kernel="poly",  \</p><p class="source-code">                     C=1, degree=4, gamma=0.25)</p><p class="source-code">acc_train_4,  acc_test_4</p><p>The expected output is this:</p><p class="source-code">(0.84625, 0.775)</p><p>Increasing the value of gamma to <strong class="source-inline">0.25</strong> has significantly improved the model's performance on the training set. However, the accuracy on the testing set is much lower, so the model is overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="poly"</strong>, <strong class="source-inline">C=1</strong>, <strong class="source-inline">degree=4</strong>, and <strong class="source-inline">gamma=0.5</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_5</strong> and <strong class="source-inline">acc_test_5</strong>:<p class="source-code">acc_train_5, \</p><p class="source-code">acc_test_5 = fit_svm(features_train, \</p><p class="source-code">                     label_train, features_test, \</p><p class="source-code">                     label_test, kernel="poly",  \</p><p class="source-code">                     C=1, degree=4, gamma=0.5)</p><p class="source-code">acc_train_5,  acc_test_5</p><p>The expected output is this:</p><p class="source-code">(0.9575, 0.73)</p><p>Increasing the value of gamma to <strong class="source-inline">0.5</strong> has drastically improved the model's performance on the training set, but it is definitely overfitting as the accuracy score on the testing set is much lower.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="poly"</strong>, <strong class="source-inline">C=1</strong>, <strong class="source-inline">degree=4</strong>, and <strong class="source-inline">gamma=0.16</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_6</strong> and <strong class="source-inline">acc_test_6</strong>:<p class="source-code">acc_train_6, \</p><p class="source-code">acc_test_6 = fit_svm(features_train, label_train, \</p><p class="source-code">                     features_test, label_test, \</p><p class="source-code">                     kernel="poly",  C=1, \</p><p class="source-code">                     degree=4, gamma=0.16)</p><p class="source-code">acc_train_6,  acc_test_6</p><p>The expected output is this:</p><p class="source-code">(0.76375, 0.785)</p><p>With <strong class="source-inline">gamma=0.16</strong>, the model achieved a better accuracy score than it did for the best KNN model. Both the training and testing sets have a score of around <strong class="source-inline">0.77</strong>.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="sigmoid"</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_7</strong> and <strong class="source-inline">acc_test_7</strong>:<p class="source-code">acc_train_7, \</p><p class="source-code">acc_test_7 = fit_svm(features_train, label_train, \</p><p class="source-code">                     features_test, label_test, \</p><p class="source-code">                     kernel="sigmoid")</p><p class="source-code">acc_train_7,  acc_test_7</p><p>The expected output is this:</p><p class="source-code">(0.635, 0.66)</p><p>The sigmoid kernel achieved a low accuracy score.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="rbf"</strong> and <strong class="source-inline">gamma=0.15</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_8</strong> and <strong class="source-inline">acc_test_8</strong>:<p class="source-code">acc_train_8, \</p><p class="source-code">acc_test_8 = fit_svm(features_train, \</p><p class="source-code">                     label_train, features_test, \</p><p class="source-code">                     label_test, kernel="rbf", \</p><p class="source-code">                     gamma=0.15)</p><p class="source-code">acc_train_8,  acc_test_8</p><p>The expected output is this:</p><p class="source-code">(0.7175, 0.765)</p><p>The <strong class="source-inline">rbf</strong> kernel achieved a good score with <strong class="source-inline">gamma=0.15</strong>. The model is overfitting a bit, though.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="rbf"</strong> and <strong class="source-inline">gamma=0.25</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_9</strong> and <strong class="source-inline">acc_test_9</strong>:<p class="source-code">acc_train_9, \</p><p class="source-code">acc_test_9 = fit_svm(features_train, \</p><p class="source-code">                     label_train, features_test, \</p><p class="source-code">                     label_test, kernel="rbf", \</p><p class="source-code">                     gamma=0.25)</p><p class="source-code">acc_train_9,  acc_test_9</p><p>The expected output is this:</p><p class="source-code">(0.74, 0.765)</p><p>The model performance got better with <strong class="source-inline">gamma=0.25</strong>, but it is still overfitting.</p></li>
				<li>Call the <strong class="source-inline">fit_knn()</strong> function with <strong class="source-inline">kernel="rbf"</strong> and <strong class="source-inline">gamma=0.35</strong>, save the results in <strong class="source-inline">2</strong> variables, and print them. These variables are <strong class="source-inline">acc_train_10</strong> and <strong class="source-inline">acc_test_10</strong>:<p class="source-code">acc_train_10, \</p><p class="source-code">acc_test_10 = fit_svm(features_train, label_train, \</p><p class="source-code">                      features_test, label_test, \</p><p class="source-code">                      kernel="rbf", gamma=0.35)</p><p class="source-code">acc_train_10, acc_test_10</p><p>The expected output is this:</p><p class="source-code">(0.78125, 0.775)</p></li>
			</ol>
			<p>With the <strong class="source-inline">rbf</strong> kernel and <strong class="source-inline">gamma=0.35</strong>, we got very similar results for the training and testing sets and the model's performance is higher than the best KNN we trained in the previous activity. This is our best model for the German credit dataset.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fPZlMQ">https://packt.live/3fPZlMQ</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hVlEm3">https://packt.live/3hVlEm3</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this activity, we tried different values for the main hyperparameters of the SVM classifier: <strong class="source-inline">kernel</strong>, <strong class="source-inline">gamma</strong>, <strong class="source-inline">C</strong>, and <strong class="source-inline">degrees</strong>. We saw how they affected the model's performance and their tendency to overfit. With trial and error, we finally found the best hyperparameter combination and achieved an accuracy score close to 0.78. This process is called <strong class="bold">hyperparameter tuning</strong> and is an important step for any data science project.</p>
			<h1 id="_idParaDest-218"><a id="_idTextAnchor249"/>4. An Introduction to Decision Trees</h1>
			<h2 id="_idParaDest-219"><a id="_idTextAnchor250"/>Activity 4.01: Car Data Classification</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Import the <strong class="source-inline">pandas</strong> package as <strong class="source-inline">pd</strong>:<p class="source-code">import pandas as pd</p></li>
				<li>Create a new variable called <strong class="source-inline">file_url</strong> that will contain the URL to the raw dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/'\</p><p class="source-code">           'The-Applied-Artificial-Intelligence-Workshop/'\</p><p class="source-code">           'master/Datasets/car.csv'</p></li>
				<li>Load the data using the <strong class="source-inline">pd.read_csv()</strong> method.:<p class="source-code">df = pd.read_csv(file_url) </p></li>
				<li>Print the first five rows of <strong class="source-inline">df</strong>:<p class="source-code">df.head()</p><p>The output will be as follows:</p><div id="_idContainer216" class="IMG---Figure"><img src="image/B16060_04_13.jpg" alt="Figure 4.13: The first five rows of the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 4.13: The first five rows of the dataset</p></li>
				<li>Import the <strong class="source-inline">preprocessing</strong> module from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn import preprocessing</p></li>
				<li>Create a function called <strong class="source-inline">encode()</strong> that takes a DataFrame and column name as parameters. This function will instantiate <strong class="source-inline">LabelEncoder()</strong>, fit it with the unique value of the column, and transform its data. It will return the transformed column:<p class="source-code">def encode(data_frame, column):</p><p class="source-code">    label_encoder = preprocessing.LabelEncoder()</p><p class="source-code">    label_encoder.fit(data_frame[column].unique())</p><p class="source-code">    return label_encoder.transform(data_frame[column])</p></li>
				<li>Create a <strong class="source-inline">for</strong> loop that will iterate through each column of <strong class="source-inline">df</strong> and will encode them with the <strong class="source-inline">encode()</strong> function:<p class="source-code">for column in df.columns:</p><p class="source-code">    df[column] = encode(df, column)</p></li>
				<li>Now, print the first five rows of <strong class="source-inline">df</strong>:<p class="source-code">df.head()</p><p>The output will be as follows:</p><div id="_idContainer217" class="IMG---Figure"><img src="image/B16060_04_14.jpg" alt="Figure 4.14: The updated first five rows of the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 4.14: The updated first five rows of the dataset</p></li>
				<li>Extract the class column using <strong class="source-inline">.pop()</strong> from pandas and save it in a variable called <strong class="source-inline">label</strong>:<p class="source-code">label = df.pop('class')</p></li>
				<li>Import <strong class="source-inline">model_selection</strong> from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn import model_selection</p></li>
				<li>Split the dataset into training and testing sets with <strong class="source-inline">test_size=0.1</strong> and <strong class="source-inline">random_state=88</strong>:<p class="source-code">features_train, features_test, label_train, label_test = \</p><p class="source-code">model_selection.train_test_split(df, label, \</p><p class="source-code">                                 test_size=0.1, \</p><p class="source-code">                                 random_state=88)</p></li>
				<li>Import <strong class="source-inline">DecisionTreeClassifier</strong> from <strong class="source-inline">sklearn</strong>:<p class="source-code">from sklearn.tree import DecisionTreeClassifier</p></li>
				<li>Instantiate <strong class="source-inline">DecisionTreeClassifier()</strong> and save it in a variable called <strong class="source-inline">decision_tree</strong>:<p class="source-code">decision_tree = DecisionTreeClassifier()</p></li>
				<li>Fit the decision tree with the training set:<p class="source-code">decision_tree.fit(features_train, label_train)</p><p>The output will be as follows:</p><div id="_idContainer218" class="IMG---Figure"><img src="image/B16060_04_15.jpg" alt="Figure 4.15: Decision tree fit with the training set&#13;&#10;"/></div><p class="figure-caption">Figure 4.15: Decision tree fit with the training set</p></li>
				<li>Print the score of the decision tree on the testing set:<p class="source-code">decision_tree.score( features_test, label_test )</p><p>The output will be as follows:</p><p class="source-code">0.953757225433526</p><p>The decision tree is achieving an accuracy score of <strong class="source-inline">0.95</strong> for our first try. This is remarkable.</p></li>
				<li>Import <strong class="source-inline">classification_report</strong> from <strong class="source-inline">sklearn.metrics</strong>:<p class="source-code">from sklearn.metrics import classification_report</p></li>
				<li>Print the classification report of the test labels and predictions:<p class="source-code">print(classification_report(label_test, \</p><p class="source-code">      decision_tree.predict(features_test)))</p><p>The output will be as follows:</p><div id="_idContainer219" class="IMG---Figure"><img src="image/B16060_04_16.jpg" alt="Figure 4.16: Output showing the expected classification report&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 4.16: Output showing the expected classification report</p>
			<p>From this classification report, we can see that our model is performing quite well for the precision scores for all four classes. Regarding the recall score, we can see that it didn't perform as well for the last class.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3hQDLtr">https://packt.live/3hQDLtr</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2NkEEML">https://packt.live/2NkEEML</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>By completing this activity, you have prepared the car dataset and trained a decision tree model. You have learned how to get its accuracy score and a classification report so that you can analyze its precision and recall scores.</p>
			<h2 id="_idParaDest-220"><a id="_idTextAnchor251"/>Activity 4.02: Random Forest Classification for Your Car Rental Company</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a Jupyter Notebook.</li>
				<li>Reuse the code mentioned in <em class="italic">Steps 1 - 4</em> of <em class="italic">Activity 1</em>, <em class="italic">Car Data Classification</em>.</li>
				<li>Import <strong class="source-inline">RandomForestClassifier</strong> from <strong class="source-inline">sklearn.ensemble</strong>:<p class="source-code">from sklearn.ensemble import RandomForestClassifier</p></li>
				<li>Instantiate a random forest classifier with <strong class="source-inline">n_estimators=100</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">random_state=168</strong>. Save it to a variable called <strong class="source-inline">random_forest_classifier</strong>:<p class="source-code">random_forest_classifier = \</p><p class="source-code">RandomForestClassifier(n_estimators=100, \</p><p class="source-code">                       max_depth=6, random_state=168)</p></li>
				<li>Fit the random forest classifier with the training set:<p class="source-code">random_forest_classifier.fit(features_train, label_train)</p><p>The output will be as follows:</p><div id="_idContainer220" class="IMG---Figure"><img src="image/B16060_04_17.jpg" alt="Figure 4.17: Logs of the RandomForest classifier with its hyperparameter values&#13;&#10;"/></div><p class="figure-caption">Figure 4.17: Logs of the RandomForest classifier with its hyperparameter values</p><p>These are the logs of the <strong class="source-inline">RandomForest</strong> classifier with its hyperparameter values.</p></li>
				<li>Make predictions on the testing set using the random forest classifier and save them in a variable called <strong class="source-inline">rf_preds_test</strong>. Print its content:<p class="source-code">rf_preds_test = random_forest_classifier.fit(features_train, \</p><p class="source-code">                                             label_train)</p><p class="source-code">rf_preds_test</p><p>The output will be as follows:</p><div id="_idContainer221" class="IMG---Figure"><img src="image/B16060_04_18.jpg" alt="Figure 4.18: Output showing the predictions on the testing set&#13;&#10;"/></div><p class="figure-caption">Figure 4.18: Output showing the predictions on the testing set</p></li>
				<li>Import <strong class="source-inline">classification_report</strong> from <strong class="source-inline">sklearn.metrics</strong>:<p class="source-code">from sklearn.metrics import classification_report</p></li>
				<li>Print the classification report with the labels and predictions from the test set:<p class="source-code">print(classification_report(label_test, rf_preds_test))</p><p>The output will be as follows:</p><div id="_idContainer222" class="IMG---Figure"><img src="image/B16060_04_19.jpg" alt="Figure 4.19: Output showing the classification report with the labels and predictions from the test set&#13;&#10;"/></div><p class="figure-caption">Figure 4.19: Output showing the classification report with the labels and predictions from the test set</p><p>The F<span class="subscript">1</span> score in the preceding report shows us that the random forest is performing well on class <strong class="source-inline">2</strong> but not as good for classes <strong class="source-inline">0</strong> and <strong class="source-inline">3</strong>. The model is unable to predict accurately for class <strong class="source-inline">1</strong>, but there were only 9 observations in the testing set. The accuracy score is <strong class="source-inline">0.84</strong>, while the F<span class="subscript">1</span> score is <strong class="source-inline">0.82</strong>.</p></li>
				<li>Import <strong class="source-inline">confusion_matrix</strong> from <strong class="source-inline">sklearn.metrics</strong>:<p class="source-code">from sklearn.metrics import confusion_matrix</p></li>
				<li>Display the confusion matrix on the true and predicted labels of the testing set:<p class="source-code">confusion_matrix(label_test, rf_preds_test)</p><p>The output will be as follows:</p><p class="source-code">array([[ 32, 0, 10, 0], </p><p class="source-code">      [ 8, 0, 0, 1], </p><p class="source-code">      [ 5, 0, 109, 0], </p><p class="source-code">      [ 3, 0, 0, 5]])</p><p>From this confusion matrix, we can see that the <strong class="source-inline">RandomForest</strong> model is having difficulties accurately predicting the first class. It incorrectly predicted 16 cases (8 + 5 + 3) for this class.</p></li>
				<li>Print the feature importance score of the test set using <strong class="source-inline">.feature_importance_</strong> and save the results in a variable called <strong class="source-inline">rf_varimp</strong>. Print its contents:<p class="source-code">rf_varimp = random_forest_classifier.feature_importances_</p><p class="source-code">rf_varimp</p><p>The output will be as follows:</p><p class="source-code">array([0.12676384, 0.10366314, 0.02119621, 0.35266673, </p><p class="source-code">       0.05915769, 0.33655239])</p><p>The preceding output shows us that the most important features are the fourth and sixth ones, which correspond to <strong class="source-inline">persons</strong> and <strong class="source-inline">safety</strong>, respectively.</p></li>
				<li>Import <strong class="source-inline">ExtraTreesClassifier</strong> from <strong class="source-inline">sklearn.ensemble</strong>:<p class="source-code">from sklearn.ensemble import ExtraTreesClassifier</p></li>
				<li>Instantiate <strong class="source-inline">ExtraTreestClassifier</strong> with <strong class="source-inline">n_estimators=100</strong>, <strong class="source-inline">max_depth=6</strong>, and <strong class="source-inline">random_state=168</strong>. Save it to a variable called <strong class="source-inline">random_forest_classifier</strong>:<p class="source-code">extra_trees_classifier = \</p><p class="source-code">ExtraTreesClassifier(n_estimators=100, \</p><p class="source-code">                     max_depth=6, random_state=168)</p></li>
				<li>Fit the <strong class="source-inline">extratrees</strong> classifier with the training set:<p class="source-code">extra_trees_classifier.fit(features_train, label_train)</p><p>The output will be as follows:</p><div id="_idContainer223" class="IMG---Figure"><img src="image/B16060_04_20.jpg" alt="Figure 4.20: Output with the extratrees classifier with the training set&#13;&#10;"/></div><p class="figure-caption">Figure 4.20: Output with the extratrees classifier with the training set</p><p>These are the logs of the <strong class="source-inline">extratrees</strong> classifier with its hyperparameter values.</p></li>
				<li>Make predictions on the testing set using the <strong class="source-inline">extratrees</strong> classifier and save them in a variable called <strong class="source-inline">et_preds_test</strong>. Print its content:<p class="source-code">et_preds_test = extra_trees_classifier.predict(features_test)</p><p class="source-code">et_preds_test</p><p>The output will be as follows:</p><div id="_idContainer224" class="IMG---Figure"><img src="image/B16060_04_21.jpg" alt="Figure 4.21: Predictions on the testing set using extratrees&#13;&#10;"/></div><p class="figure-caption">Figure 4.21: Predictions on the testing set using extratrees</p></li>
				<li>Print the classification report with the labels and predictions from the test set:<p class="source-code">print(classification_report(label_test, \</p><p class="source-code">      extra_trees_classifier.predict(features_test)))</p><p>The output will be as follows:</p><div id="_idContainer225" class="IMG---Figure"><img src="image/B16060_04_22.jpg" alt="Figure 4.22: Classification report with the labels and predictions from the test set&#13;&#10;"/></div><p class="figure-caption">Figure 4.22: Classification report with the labels and predictions from the test set</p><p>The F<span class="subscript">1</span> score shown in the preceding report shows us that the random forest is performing well on class <strong class="source-inline">2</strong> but not as good for class <strong class="source-inline">0</strong>. The model is unable to predict accurately for classes <strong class="source-inline">1</strong> and <strong class="source-inline">3</strong>, but there were only <strong class="source-inline">9</strong> and <strong class="source-inline">8</strong> observations in the testing set, respectively. The accuracy score is <strong class="source-inline">0.82</strong>, while the F<span class="subscript">1</span> score is <strong class="source-inline">0.78</strong>. So, our <strong class="source-inline">RandomForest</strong> classifier performed better with <strong class="source-inline">extratrees</strong>.</p></li>
				<li>Display the confusion matrix of the true and predicted labels of the testing set:<p class="source-code">confusion_matrix(label_test, et_preds_test)</p><p>The output will be as follows:</p><p class="source-code">array([[ 28,   0,  14,   0],</p><p class="source-code">       [  9,   0,   0,   0],</p><p class="source-code">       [  2,   0, 112,   0],</p><p class="source-code">       [  7,   0,   0,   1]])</p><p>From this confusion matrix, we can see that the <strong class="source-inline">extratrees</strong> model is having difficulties accurately predicting the first and third classes.</p></li>
				<li>Print the feature importance score on the test set using <strong class="source-inline">.feature_importance_</strong> and save the results in a variable called <strong class="source-inline">et_varimp</strong>. Print its content:<p class="source-code">et_varimp = extra_trees_classifier.feature_importances_</p><p class="source-code">et_varimp</p><p>The output will be as follows:</p><p class="source-code">array([0.08844544, 0.0702334 , 0.01440408, 0.37662014, 0.05965896,</p><p class="source-code">       0.39063797])</p></li>
			</ol>
			<p>The preceding output shows us that the most important features are the sixth and fourth ones, which correspond to <strong class="source-inline">safety</strong> and <strong class="source-inline">persons</strong>, respectively. It is interesting to see that <strong class="source-inline">RandomForest</strong> has the same two most important features but in a different order.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YoUY5t">https://packt.live/2YoUY5t</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3eswBcW">https://packt.live/3eswBcW</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h1 id="_idParaDest-221"><a id="_idTextAnchor252"/>5. Artificial Intelligence: Clustering</h1>
			<h2 id="_idParaDest-222"><a id="_idTextAnchor253"/>Activity 5.01: Clustering Sales Data Using K-Means</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Load the dataset as a DataFrame and inspect the data:<p class="source-code">import pandas as pd</p><p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/'\</p><p class="source-code">           'The-Applied-Artificial-Intelligence-Workshop/'\</p><p class="source-code">           'master/Datasets/'\</p><p class="source-code">           'Sales_Transactions_Dataset_Weekly.csv'</p><p class="source-code">df = pd.read_csv(file_url)</p><p class="source-code">df</p><p>The output of <strong class="source-inline">df</strong> is as follows:</p><div id="_idContainer226" class="IMG---Figure"><img src="image/B16060_05_18.jpg" alt="Figure 5.18: Output showing the contents of the dataset&#13;&#10;"/></div><p class="figure-caption">Figure 5.18: Output showing the contents of the dataset</p><p>If you look at the output, you will notice that our dataset contains <strong class="source-inline">811</strong> rows, with each row representing a product. It also contains <strong class="source-inline">107</strong> columns, with the first column being the product code, then <strong class="source-inline">52</strong> columns starting with <strong class="source-inline">W</strong> representing the sale quantity for each week, and finally, the normalized version of the <strong class="source-inline">52</strong> columns, starting with the <strong class="source-inline">Normalized</strong> columns. The normalized columns will be a better choice to work with rather than the absolute sales columns, <strong class="source-inline">W</strong>, as they will help our k-means algorithms to find the center of each cluster faster. Since we are going to work on the normalized columns, we can remove every <strong class="source-inline">W</strong> column plus the <strong class="source-inline">Product_Code</strong> column. We can also remove the <strong class="source-inline">MIN</strong> and <strong class="source-inline">MAX</strong> columns as they do not bring any value to our clustering. Also notice that the weeks run from <strong class="source-inline">0</strong> to <strong class="source-inline">51</strong> and not <strong class="source-inline">1</strong> to <strong class="source-inline">52</strong>. </p></li>
				<li>Next, create a new DataFrame without the unnecessary columns, as shown in the following code snippet (the first <strong class="source-inline">55</strong> columns of the dataset). You should use the <strong class="source-inline">inplace</strong> parameter to help you:<p class="source-code">df2 = df.drop(df.iloc[:, 0:55], inplace = False, axis = 1)</p><p>The output of <strong class="source-inline">df2</strong> is as follows:</p><div id="_idContainer227" class="IMG---Figure"><img src="image/B16060_05_19.jpg" alt="Figure 5.19: Modified DataFrame&#13;&#10;"/></div><p class="figure-caption">Figure 5.19: Modified DataFrame</p><p>In the preceding code snippet, we used the <strong class="source-inline">drop</strong> function of the pandas DataFrame in order to remove the first <strong class="source-inline">55</strong> columns. We also set the <strong class="source-inline">inplace</strong> parameter to <strong class="source-inline">False</strong> in order to not remove the column of our original <strong class="source-inline">df</strong> DataFrame. As a result, we should only have the normalized columns from <strong class="source-inline">0</strong> to <strong class="source-inline">51</strong> in <strong class="source-inline">df2</strong> and <strong class="source-inline">df</strong> should still be unchanged.</p></li>
				<li>Create a k-means clustering model with <strong class="source-inline">8</strong> clusters and with <strong class="source-inline">random state = 8</strong>:<p class="source-code">from sklearn.cluster import KMeans</p><p class="source-code">k_means_model = KMeans(n_clusters=8, random_state=8)</p><p class="source-code">k_means_model.fit(df2)</p><p>We build a k-means model with the default value for every parameter except for <strong class="source-inline">n_clusters=8</strong> with <strong class="source-inline">random_state=8</strong> in order to obtain <strong class="source-inline">8</strong> clusters and reproducible results.</p></li>
				<li>Retrieve the labels from the clustering algorithm:<p class="source-code">labels = k_means_model.labels_</p><p class="source-code">labels</p><p>The output of <strong class="source-inline">labels</strong> will be as follows:</p><div id="_idContainer228" class="IMG---Figure"><img src="image/B16060_05_20.jpg" alt="Figure 5.20: Output array of labels&#13;&#10;"/></div><p class="figure-caption">Figure 5.20: Output array of labels</p><p>It is very hard to make sense out of this output, but each index of <strong class="source-inline">labels</strong> represents the cluster that the product has been assigned, based on similar weekly sales trends. We can now use these cluster labels to group products together.</p></li>
				<li>Now, from the first DataFrame, <strong class="source-inline">df</strong>, keep only the <strong class="source-inline">W</strong> columns and add the labels as a new column, as shown in the following code snippet:<p class="source-code">df.drop(df.iloc[:, 53:], inplace = True, axis = 1)</p><p class="source-code">df.drop('Product_Code', inplace = True, axis = 1)</p><p class="source-code">df['label'] = labels</p><p class="source-code">df</p><p>In the preceding code snippet, we removed all the unneeded columns and added <strong class="source-inline">labels</strong> as a new column in the DataFrame.</p><p>The output of <strong class="source-inline">df</strong> will be as follows:</p><div id="_idContainer229" class="IMG---Figure"><img src="image/B16060_05_21.jpg" alt="Figure 5.21: Updated DataFrame with the new labels as a new column&#13;&#10;"/></div><p class="figure-caption">Figure 5.21: Updated DataFrame with the new labels as a new column</p><p>Now that we have the label, we can perform aggregation on the <strong class="source-inline">label</strong> column in order to calculate the yearly average sales of each cluster.</p></li>
				<li>Perform the aggregation (use the <strong class="source-inline">groupby</strong> function from pandas) in order to obtain the yearly average sale of each cluster, as shown in the following code snippet:<p class="source-code">df_agg = df.groupby('label').sum()</p><p class="source-code">df_final = df[['label','W0']].groupby('label').count()</p><p class="source-code">df_final=df_final.rename(columns = {'W0':'count_product'})</p><p class="source-code">df_final['total_sales'] = df_agg.sum(axis = 1)</p><p class="source-code">df_final['yearly_average_sales']= \</p><p class="source-code">df_final['total_sales'] / df_final['count_product']</p><p class="source-code">df_final.sort_values(by='yearly_average_sales', \</p><p class="source-code">                     ascending=False, inplace = True)</p><p class="source-code">df_final</p><p>In the preceding code snippet, we first used the <strong class="source-inline">groupby</strong> function with the <strong class="source-inline">sum()</strong> method of the DataFrame to calculate the sum of every product's sales for each <strong class="source-inline">W</strong> column and cluster, and stored the results in <strong class="source-inline">df_agg</strong>. We then used the <strong class="source-inline">groupby</strong> function with the <strong class="source-inline">count()</strong> method on a single column (an arbitrary choice) of <strong class="source-inline">df</strong> to obtain the total number of products per cluster (note that we also had to rename the <strong class="source-inline">W0</strong> column after the aggregation). The next step was to sum all the sales columns of <strong class="source-inline">df_agg</strong> in order to obtain the total sales for each cluster. Finally, we calculated the <strong class="source-inline">yearly_average_sales</strong> for each cluster by dividing <strong class="source-inline">total_sales</strong> by <strong class="source-inline">count_product</strong>. We also included a final step to sort out the cluster by the highest <strong class="source-inline">yearly_average_sales</strong>.</p><p>The output of <strong class="source-inline">df_final</strong> will be as follows:</p><div id="_idContainer230" class="IMG---Figure"><img src="image/B16060_05_22.jpg" alt="Figure 5.22: Expected output on the sales transaction dataset&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 5.22: Expected output on the sales transaction dataset</p>
			<p>Now, with this output, we see that our k-means model has managed to put similarly performing products together. We can easily see that the <strong class="source-inline">115</strong> products in cluster <strong class="source-inline">3</strong> are the best-selling products, whereas the <strong class="source-inline">123</strong> products of cluster <strong class="source-inline">1</strong> are performing very badly. This is very valuable for any business, as it helps them automatically identify and group together a number of similarly performing products without having any bias in the product name or description.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3fVpSbT">https://packt.live/3fVpSbT</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hW24Gk">https://packt.live/3hW24Gk</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>By completing this activity, you have learned how to perform k-means clustering on multiple columns for many products. You have also learned how useful clustering can be for a business, even without label data. </p>
			<h2 id="_idParaDest-223"><a id="_idTextAnchor254"/>Activity 5.02: Clustering Red Wine Data Using the Mean Shift Algorithm and Agglomerative Hierarchical Clustering</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Load the dataset as a DataFrame with <strong class="source-inline">sep = ";"</strong> and inspect the data:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p><p class="source-code">from sklearn import preprocessing</p><p class="source-code">from sklearn.cluster import MeanShift</p><p class="source-code">from sklearn.cluster import AgglomerativeClustering</p><p class="source-code">from scipy.cluster.hierarchy import dendrogram</p><p class="source-code">import scipy.cluster.hierarchy as sch</p><p class="source-code">from sklearn import metrics</p><p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/'\</p><p class="source-code">           'The-Applied-Artificial-Intelligence-Workshop/'\</p><p class="source-code">           'master/Datasets/winequality-red.csv'</p><p class="source-code">df = pd.read_csv(file_url,sep=';')</p><p class="source-code">df</p><p>The output of <strong class="source-inline">df</strong> is as follows:</p><div id="_idContainer231" class="IMG---Figure"><img src="image/B16060_05_23.jpg" alt="Figure 5.23: df showing the dataset as the output&#13;&#10;"/></div><p class="figure-caption">Figure 5.23: df showing the dataset as the output</p><p class="callout-heading">Note</p><p class="callout">The output from the preceding screenshot is truncated.</p><p>Our dataset contains <strong class="source-inline">1599</strong> rows, with each row representing a red wine. It also contains <strong class="source-inline">12</strong> columns, with the last column being the quality of the wine. We can see that the remaining 11 columns will be our features, and we need to scale them in order to help the accuracy and speed of our models.</p></li>
				<li>Create <strong class="source-inline">features</strong>, <strong class="source-inline">label</strong>, and <strong class="source-inline">scaled_features</strong> variables from the initial DataFrame, <strong class="source-inline">df</strong>:<p class="source-code">features = df.drop('quality', 1)</p><p class="source-code">label = df['quality']</p><p class="source-code">scaled_features = preprocessing.scale(features)</p><p>In the preceding code snippet, we separated the label (<strong class="source-inline">quality</strong>) from the features. Then we used <strong class="source-inline">preprocessing.scale</strong> function from <strong class="source-inline">sklearn</strong> in order to scale our features, as this will improve our models.</p></li>
				<li>Next, create a mean shift clustering model, then retrieve the model's predicted labels and the number of clusters created:<p class="source-code">mean_shift_model = MeanShift()</p><p class="source-code">mean_shift_model.fit(scaled_features)</p><p class="source-code">n_cluster_mean_shift = len(mean_shift_model.cluster_centers_)</p><p class="source-code">label_mean_shift = mean_shift_model.labels_</p><p class="source-code">n_cluster_mean_shift</p><p>The output of <strong class="source-inline">n_cluster_mean_shift</strong> will be as follows:</p><p class="source-code">10</p><p>Our mean shift model has created <strong class="source-inline">10</strong> clusters, which is already more than the number of groups that we have in our <strong class="source-inline">quality</strong> label. This will probably affect our extrinsic scores and might be an early indicator that wines sharing similar physicochemical properties don't belong in the same quality group.</p><p>The output of <strong class="source-inline">label_mean_shift</strong> will be as follows:</p><div id="_idContainer232" class="IMG---Figure"><img src="image/B16060_05_24.jpg" alt="Figure 5.24: Output array of label_mean_shift&#13;&#10;"/></div><p class="figure-caption">Figure 5.24: Output array of label_mean_shift</p><p>This is a very interesting output because it clearly shows that most wines in our dataset are very similar; there are a lot more wines in cluster <strong class="source-inline">0</strong> than in the other clusters.</p></li>
				<li>Now create an agglomerative hierarchical clustering model after creating a dendrogram and selecting the optimal number of clusters for it:<p class="source-code">dendrogram = sch.dendrogram(sch.linkage(scaled_features, \</p><p class="source-code">                            method='ward'))</p><p class="source-code">agglomerative_model = \</p><p class="source-code">AgglomerativeClustering(n_clusters=7, \</p><p class="source-code">                        affinity='euclidean', \</p><p class="source-code">                        linkage='ward')</p><p class="source-code">agglomerative_model.fit(scaled_features)</p><p class="source-code">label_agglomerative = agglomerative_model.labels_</p><p>The output of <strong class="source-inline">dendrogram</strong> will be as follows:</p><p> </p><div id="_idContainer233" class="IMG---Figure"><img src="image/B16060_05_25.jpg" alt="Figure 5.25: Output showing the dendrogram for the clusters&#13;&#10;"/></div><p class="figure-caption">Figure 5.25: Output showing the dendrogram for the clusters</p><p>From this output, we can see that seven clusters seems to be the optimal number for our model. We get this number by searching for the highest difference on the <em class="italic">y</em> axis between the lowest branch and the highest branch. In our case, for seven clusters, the lowest branch has a value of <strong class="source-inline">29</strong> and the highest branch has a value of <strong class="source-inline">41</strong>.</p><p>The output of <strong class="source-inline">label_agglomerative</strong> will be as follows:</p><div id="_idContainer234" class="IMG---Figure"><img src="image/B16060_05_26.jpg" alt="Figure 5.26: Array showing label_agglomerative&#13;&#10;"/></div><p class="figure-caption">Figure 5.26: Array showing label_agglomerative</p><p>We can see that we have a predominant cluster, <strong class="source-inline">1</strong>, but not as much as was the case in the mean shift model.</p></li>
				<li>Now, compute the following extrinsic approach scores for both models:<p>a. Begin with the adjusted Rand index:</p><p class="source-code">ARI_mean=metrics.adjusted_rand_score(label, label_mean_shift)</p><p class="source-code">ARI_agg=metrics.adjusted_rand_score(label, label_agglomerative)</p><p class="source-code">ARI_mean</p><p>The output of <strong class="source-inline">ARI_mean</strong> will be as follows:</p><p class="source-code">0.0006771608724007207</p><p>Next, enter <strong class="source-inline">ARI_agg</strong> to get the expected values:</p><p class="source-code">ARI_agg</p><p>The output of <strong class="source-inline">ARI_agg</strong> will be as follows:</p><p class="source-code">0.05358047852603172</p><p>Our agglomerative model has a much higher <strong class="source-inline">adjusted_rand_score</strong> than the mean shift model, but both scores are very close to <strong class="source-inline">0</strong>, which means that neither model is performing very well with regard to the true labels.</p><p>b. Next, calculate the adjusted mutual information:</p><p class="source-code">AMI_mean = metrics.adjusted_mutual_info_score(label, \</p><p class="source-code">                                              label_mean_shift)</p><p class="source-code">AMI_agg = metrics.adjusted_mutual_info_score(label, \</p><p class="source-code">                                             label_agglomerative)</p><p class="source-code">AMI_mean</p><p>The output of <strong class="source-inline">AMI_mean</strong> will be as follows:</p><p class="source-code">0.004837187596124968</p><p>Next, enter <strong class="source-inline">AMI_agg</strong> to get the expected values:</p><p class="source-code">AMI_agg</p><p>The output of <strong class="source-inline">AMI_agg</strong> will be as follows:</p><p class="source-code">0.05993098663692826</p><p>Our agglomerative model has a much higher <strong class="source-inline">adjusted_mutual_info_score</strong> than the mean shift model, but both scores are very close to <strong class="bold">0</strong>, which means that neither model is performing very well with regard to the true labels.</p><p>c. Calculate the V-Measure:</p><p class="source-code">V_mean = metrics.v_measure_score(label, \</p><p class="source-code">                                 label_mean_shift, beta=1)</p><p class="source-code">V_agg = metrics.v_measure_score(label, \</p><p class="source-code">                                label_agglomerative, beta=1)</p><p class="source-code">V_mean</p><p>The output of <strong class="source-inline">V_mean</strong> will be as follows:</p><p class="source-code">0.021907254751144124</p><p>Next, enter <strong class="source-inline">V_agg</strong> to get the expected values:</p><p class="source-code">V_agg</p><p>The output of <strong class="source-inline">V_agg</strong> will be as follows:</p><p class="source-code">0.07549735446050691</p><p>Our agglomerative model has a higher V-Measure than the mean shift model, but both scores are very close to <strong class="bold">0</strong>, which means that neither model is performing very well with regard to the true labels.</p><p>d. Next, find the Fowlkes-Mallows score:</p><p class="source-code">FM_mean = metrics.fowlkes_mallows_score(label, \</p><p class="source-code">                                        label_mean_shift)</p><p class="source-code">FM_agg=  metrics.fowlkes_mallows_score(label, \</p><p class="source-code">                                       label_agglomerative)</p><p class="source-code">FM_mean</p><p>The output of <strong class="source-inline">FM_mean</strong> will be as follows:</p><p class="source-code">0.5721233634622408</p><p>Next, enter <strong class="source-inline">FM_agg</strong> to get the expected values:</p><p class="source-code">FM_agg</p><p>The output of <strong class="source-inline">FM_agg</strong> will be as follows:</p><p class="source-code">0.3300681478007641</p><p>This time, our mean shift model has a higher Fowlkes-Mallows score than the agglomerative model, but both scores are still on the lower range of the score, which means that neither model is performing very well with regard to the true labels.</p><p>In conclusion, with the extrinsic approach evaluation, neither of our models were able to find clusters containing wines of a similar quality based on their physicochemical properties. We will confirm this by using the intrinsic approach evaluation to ensure that our models' clusters are well defined and are properly grouping similar wines together.</p></li>
				<li>Now, compute the following intrinsic approach scores for both models:<p>a. Begin with the Silhouette Coefficient:</p><p class="source-code">Sil_mean = metrics.silhouette_score(scaled_features, \</p><p class="source-code">                                    label_mean_shift)</p><p class="source-code">Sil_agg = metrics.silhouette_score(scaled_features, \</p><p class="source-code">                                   label_agglomerative)</p><p class="source-code">Sil_mean</p><p>The output of <strong class="source-inline">Sil_mean</strong> will be as follows:</p><p class="source-code">0.32769323700400077</p><p>Next, enter <strong class="source-inline">Sil_agg</strong> to get the expected values:</p><p class="source-code">Sil_agg</p><p>The output of <strong class="source-inline">Sil_agg</strong> will be as follows:</p><p class="source-code">0.1591882574407987</p><p>Our mean shift model has a higher Silhouette Coefficient than the agglomerative model, but both scores are very close to <strong class="bold">0</strong>, which means that both models have overlapping clusters.</p><p>b. Next, find the Calinski-Harabasz index:</p><p class="source-code">CH_mean = metrics.calinski_harabasz_score(scaled_features, \</p><p class="source-code">                                          label_mean_shift)</p><p class="source-code">CH_agg = metrics.calinski_harabasz_score(scaled_features, \</p><p class="source-code">                                         label_agglomerative)</p><p class="source-code">CH_mean</p><p>The output of <strong class="source-inline">CH_mean</strong> will be as follows:</p><p class="source-code">44.62091774102674</p><p>Next, enter <strong class="source-inline">CH_agg</strong> to get the expected values:</p><p class="source-code">CH_agg</p><p>The output of <strong class="source-inline">CH_agg</strong> will be as follows:</p><p class="source-code">223.5171774491095</p><p>Our agglomerative model has a much higher Calinski-Harabasz index than the mean shift model, which means that the agglomerative model has much more dense and well-defined clusters than the mean shift model.</p><p>c. Finally, find the Davies-Bouldin index:</p><p class="source-code">DB_mean = metrics.davies_bouldin_score(scaled_features, \</p><p class="source-code">                                       label_mean_shift)</p><p class="source-code">DB_agg = metrics.davies_bouldin_score(scaled_features, \</p><p class="source-code">                                      label_agglomerative)</p><p class="source-code">DB_mean</p><p>The output of <strong class="source-inline">DB_mean</strong> will be as follows:</p><p class="source-code">0.8106334674570222</p><p>Next, enter <strong class="source-inline">DB_agg</strong> to get the expected values:</p><p class="source-code">DB_agg</p><p>The output of <strong class="source-inline">DB_agg</strong> will be as follows:</p><p class="source-code">1.4975443816135114</p><p>Our agglomerative model has a higher David-Bouldin index than the mean shift model, but both scores are close to <strong class="bold">0</strong>, which means that both models are performing well with regard to the definition of their clusters.</p><p class="callout-heading">Note</p><p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2YXMl0U">https://packt.live/2YXMl0U</a>.</p><p class="callout">You can also run this example online at <a href="https://packt.live/2Bs7sAp">https://packt.live/2Bs7sAp</a>.</p><p class="callout">You must execute the entire Notebook in order to get the desired result.</p></li>
			</ol>
			<p>In conclusion, with the intrinsic approach evaluation, both our models were well defined and confirm our intuition on the red wine dataset, that is, similar physicochemical properties are not associated with similar quality. We were also able to see that in most of our scores, the agglomerative hierarchical model performs better than the mean shift model.</p>
			<h1 id="_idParaDest-224"><a id="_idTextAnchor255"/>6. Neural Networks and Deep Learning</h1>
			<h2 id="_idParaDest-225"><a id="_idTextAnchor256"/>Activity 6.01: Finding the Best Accuracy Score for the Digits Dataset</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook file.</li>
				<li>Import <strong class="source-inline">tensorflow.keras.datasets.mnist</strong> as <strong class="source-inline">mnist</strong>:<p class="source-code">import tensorflow.keras.datasets.mnist as mnist</p></li>
				<li>Load the <strong class="source-inline">mnist</strong> dataset using <strong class="source-inline">mnist.load_data()</strong> and save the results into <strong class="source-inline">(features_train, label_train), (features_test, label_test)</strong>:<p class="source-code">(features_train, label_train), \</p><p class="source-code">(features_test, label_test) = mnist.load_data()</p></li>
				<li>Print the content of <strong class="source-inline">label_train</strong>:<p class="source-code">label_train</p><p>The expected output is this:</p><p class="source-code">array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)</p><p>The <strong class="source-inline">label</strong> column contains numeric values that correspond to the <strong class="source-inline">10</strong> handwritten digits: <strong class="source-inline">0</strong> to <strong class="source-inline">9</strong>.</p></li>
				<li>Print the shape of the training set:<p class="source-code">features_train.shape</p><p>The expected output is this:</p><p class="source-code">(60000, 28, 28)</p><p>The training set is composed of <strong class="source-inline">60,000</strong> observations of shape <strong class="source-inline">28</strong> by <strong class="source-inline">28</strong>. We will need to flatten the input for our neural network.</p></li>
				<li>Print the shape of the testing set:<p class="source-code">features_test.shape</p><p>The expected output is this:</p><p class="source-code">(10000, 28, 28)</p><p>The testing set is composed of <strong class="source-inline">10,000</strong> observations of shape <strong class="source-inline">28</strong> by <strong class="source-inline">28</strong>.</p></li>
				<li>Standardize <strong class="source-inline">features_train</strong> and <strong class="source-inline">features_test</strong> by dividing them by <strong class="source-inline">255</strong>:<p class="source-code">features_train = features_train / 255.0</p><p class="source-code">features_test = features_test / 255.0</p></li>
				<li>Import <strong class="source-inline">numpy</strong> as <strong class="source-inline">np</strong>, <strong class="source-inline">tensorflow</strong> as <strong class="source-inline">tf</strong>, and <strong class="source-inline">layers</strong> from <strong class="source-inline">tensorflow.keras</strong>:<p class="source-code">import numpy as np</p><p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow.keras import layers</p></li>
				<li>Set <strong class="source-inline">8</strong> as the seed for NumPy and TensorFlow using <strong class="source-inline">np.random_seed()</strong> and <strong class="source-inline">tf.random.set_seed()</strong>: <p class="source-code">np.random.seed(8)</p><p class="source-code">tf.random.set_seed(8)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.Sequential()</strong> class and save it into a variable called <strong class="source-inline">model</strong>:<p class="source-code">model = tf.keras.Sequential()</p></li>
				<li>Instantiate <strong class="source-inline">layers.Flatten()</strong> with <strong class="source-inline">input_shape=(28,28)</strong> and save it into a variable called <strong class="source-inline">input_layer</strong>:<p class="source-code">input_layer = layers.Flatten(input_shape=(28,28))</p></li>
				<li>Instantiate a <strong class="source-inline">layers.Dense()</strong> class with <strong class="source-inline">128</strong> neurons and <strong class="source-inline">activation='relu'</strong>, then save it into a variable called <strong class="source-inline">layer1</strong>:<p class="source-code">layer1 = layers.Dense(128, activation='relu')</p></li>
				<li>Instantiate a second <strong class="source-inline">layers.Dense()</strong> class with <strong class="source-inline">1</strong> neuron and <strong class="source-inline">activation='softmax'</strong>, then save it into a variable called <strong class="source-inline">final_layer</strong>:<p class="source-code">final_layer = layers.Dense(10, activation='softmax')</p></li>
				<li>Add the three layers you just defined to the model using <strong class="source-inline">.add()</strong> and add a <strong class="source-inline">layers.Dropout(0.25)</strong> layer in between each of them (except for the flatten layer):<p class="source-code">model.add(input_layer)</p><p class="source-code">model.add(layer1)</p><p class="source-code">model.add(layers.Dropout(0.25))</p><p class="source-code">model.add(final_layer)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.optimizers.Adam()</strong> class with <strong class="source-inline">0.001</strong> as learning rate and save it into a variable called <strong class="source-inline">optimizer</strong>:<p class="source-code">optimizer = tf.keras.optimizers.Adam(0.001)</p></li>
				<li>Compile the neural network using <strong class="source-inline">.compile()</strong> with <strong class="source-inline">loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']</strong>:<p class="source-code">model.compile(loss='sparse_categorical_crossentropy', \</p><p class="source-code">              optimizer=optimizer, \</p><p class="source-code">              metrics=['accuracy'])</p></li>
				<li>Print a summary of the model using <strong class="source-inline">.summary()</strong>:<p class="source-code">model.summary()</p><p>The expected output is this:</p><div id="_idContainer235" class="IMG---Figure"><img src="image/B16060_06_29.jpg" alt="Figure 6.29: Summary of the model&#13;&#10;"/></div><p class="figure-caption">Figure 6.29: Summary of the model</p><p>This output summarizes the architecture of our neural networks. We can see it is composed of four layers with one flatten layer, two dense layers, and one dropout layer.</p></li>
				<li>Instantiate the <strong class="source-inline">tf.keras.callbacks.EarlyStopping()</strong> class with <strong class="source-inline">monitor='val_loss'</strong> and <strong class="source-inline">patience=5</strong> as the learning rate and save it into a variable called <strong class="source-inline">callback</strong>:<p class="source-code">callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \</p><p class="source-code">                                            patience=5)</p></li>
				<li>Fit the neural networks with the training set and specify <strong class="source-inline">epochs=10</strong>, <strong class="source-inline">validation_split=0.2</strong>, <strong class="source-inline">callbacks=[callback]</strong>, and <strong class="source-inline">verbose=2</strong>:<p class="source-code">model.fit(features_train, label_train, epochs=10, \</p><p class="source-code">          validation_split = 0.2, \</p><p class="source-code">          callbacks=[callback], verbose=2)</p><p>The expected output is this:</p><div id="_idContainer236" class="IMG---Figure"><img src="image/B16060_06_30.jpg" alt="Figure 6.30: Fitting the neural network with the training set&#13;&#10;"/></div></li>
			</ol>
			<p class="figure-caption">Figure 6.30: Fitting the neural network with the training set</p>
			<p>We achieved an accuracy score of <strong class="source-inline">0.9825</strong> for the training set and <strong class="source-inline">0.9779</strong> for the validation set for recognizing hand-written digits after just <strong class="source-inline">10</strong> epochs. These are amazing results. In this section, you learned how to build and train a neural network from scratch using TensorFlow to classify digits. </p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/37UWf7E">https://packt.live/37UWf7E</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/317R2b3">https://packt.live/317R2b3</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<h2 id="_idParaDest-226"><a id="_idTextAnchor257"/>Activity 6.02: Evaluating a Fashion Image Recognition Model Using CNNs</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a new Jupyter Notebook.</li>
				<li>Import <strong class="source-inline">tensorflow.keras.datasets.fashion_mnist</strong> as <strong class="source-inline">fashion_mnist</strong>:<p class="source-code">import tensorflow.keras.datasets.fashion_mnist as fashion_mnist</p></li>
				<li>Load the Fashion MNIST dataset using <strong class="source-inline">fashion_mnist.load_data()</strong> and save the results into <strong class="source-inline">(features_train, label_train), (features_test, label_test)</strong>:<p class="source-code">(features_train, label_train), \</p><p class="source-code">(features_test, label_test) = fashion_mnist.load_data()</p></li>
				<li>Print the shape of the training set:<p class="source-code">features_train.shape</p><p>The expected output is this:</p><p class="source-code">(60000, 28, 28)</p><p>The training set is composed of <strong class="source-inline">60,000</strong> images of size <strong class="source-inline">28</strong>*<strong class="source-inline">28</strong>.</p></li>
				<li>Print the shape of the testing set:<p class="source-code">features_test.shape</p><p>The expected output is this:</p><p class="source-code">(10000, 28, 28)</p><p>The testing set is composed of <strong class="source-inline">10,000</strong> images of size <strong class="source-inline">28</strong>*<strong class="source-inline">28</strong>.</p></li>
				<li>Reshape the training and testing sets with the dimensions (<strong class="source-inline">number_rows</strong>, <strong class="source-inline">28</strong>, <strong class="source-inline">28</strong>, <strong class="source-inline">1</strong>), as shown in the following code snippet:<p class="source-code">features_train = features_train.reshape(60000, 28, 28, 1)</p><p class="source-code">features_test = features_test.reshape(10000, 28, 28, 1)</p></li>
				<li>Standardize <strong class="source-inline">features_train</strong> and <strong class="source-inline">features_test</strong> by dividing them by <strong class="source-inline">255</strong>:<p class="source-code">features_train = features_train / 255.0</p><p class="source-code">features_test = features_test / 255.0</p></li>
				<li>Import <strong class="source-inline">numpy</strong> as <strong class="source-inline">np</strong>, <strong class="source-inline">tensorflow</strong> as <strong class="source-inline">tf</strong>, and <strong class="source-inline">layers</strong> from <strong class="source-inline">tensorflow.keras</strong>:<p class="source-code">import numpy as np</p><p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow.keras import layers</p></li>
				<li>Set <strong class="source-inline">8</strong> as the seed for <strong class="source-inline">numpy</strong> and <strong class="source-inline">tensorflow</strong> using <strong class="source-inline">np.random_seed()</strong> and <strong class="source-inline">tf.random.set_seed()</strong>: <p class="source-code">np.random.seed(8)</p><p class="source-code">tf.random.set_seed(8)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.Sequential()</strong> class and save it into a variable called <strong class="source-inline">model</strong>:<p class="source-code">model = tf.keras.Sequential()</p></li>
				<li>Instantiate <strong class="source-inline">layers.Conv2D()</strong> with <strong class="source-inline">64</strong> kernels of shape <strong class="source-inline">(3,3), activation='relu' and input_shape=(28,28)</strong> and save it into a variable called <strong class="source-inline">conv_layer1</strong>:<p class="source-code">conv_layer1 = layers.Conv2D(64, (3,3), \</p><p class="source-code">              activation='relu', input_shape=(28, 28, 1))</p></li>
				<li>Instantiate <strong class="source-inline">layers.Conv2D()</strong> with <strong class="source-inline">64</strong> kernels of shape <strong class="source-inline">(3,3), activation='relu'</strong> and save it into a variable called <strong class="source-inline">conv_layer2</strong>:<p class="source-code">conv_layer2 = layers.Conv2D(64, (3,3), activation='relu')</p></li>
				<li>Instantiate <strong class="source-inline">layers.Flatten()</strong> with <strong class="source-inline">128</strong> neurons and <strong class="source-inline">activation='relu'</strong>, then save it into a variable called <strong class="source-inline">fc_layer1</strong>:<p class="source-code">fc_layer1 = layers.Dense(128, activation='relu')</p></li>
				<li>Instantiate <strong class="source-inline">layers.Flatten()</strong> with <strong class="source-inline">10</strong> neurons and <strong class="source-inline">activation='softmax'</strong>, then save it into a variable called <strong class="source-inline">fc_layer2</strong>:<p class="source-code">fc_layer2 = layers.Dense(10, activation='softmax')</p></li>
				<li>Add the four layers you just defined to the model using <strong class="source-inline">.add()</strong> and add a <strong class="source-inline">MaxPooling2D()</strong> layer of size <strong class="source-inline">(2,2)</strong> in between each of the convolutional layers:<p class="source-code">model.add(conv_layer1)</p><p class="source-code">model.add(layers.MaxPooling2D(2, 2))</p><p class="source-code">model.add(conv_layer2)</p><p class="source-code">model.add(layers.MaxPooling2D(2, 2))</p><p class="source-code">model.add(layers.Flatten())</p><p class="source-code">model.add(fc_layer1)</p><p class="source-code">model.add(fc_layer2)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.optimizers.Adam()</strong> class with <strong class="source-inline">0.001</strong> as the learning rate and save it into a variable called <strong class="source-inline">optimizer</strong>:<p class="source-code">optimizer = tf.keras.optimizers.Adam(0.001)</p></li>
				<li>Compile the neural network using <strong class="source-inline">.compile()</strong> with <strong class="source-inline">loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']</strong>:<p class="source-code">model.compile(loss='sparse_categorical_crossentropy', \</p><p class="source-code">              optimizer=optimizer, metrics=['accuracy'])</p></li>
				<li>Print a summary of the model using <strong class="source-inline">.summary()</strong>:<p class="source-code">model.summary()</p><p>The expected output is this:</p><div id="_idContainer237" class="IMG---Figure"><img src="image/B16060_06_31.jpg" alt="Figure 6.31: Summary of the model&#13;&#10;"/></div><p class="figure-caption">Figure 6.31: Summary of the model</p><p>The summary shows us that there are more than <strong class="source-inline">240,000</strong> parameters to be optimized with this model.</p></li>
				<li>Fit the neural network with the training set and specify <strong class="source-inline">epochs=5</strong>, <strong class="source-inline">validation_split=0.2</strong>, and <strong class="source-inline">verbose=2</strong>:<p class="source-code">model.fit(features_train, label_train, \</p><p class="source-code">          epochs=5, validation_split = 0.2, verbose=2)</p><p>The expected output is this:</p><div id="_idContainer238" class="IMG---Figure"><img src="image/B16060_06_32.jpg" alt="Figure 6.32: Fitting the neural network with the training set&#13;&#10;"/></div><p class="figure-caption">Figure 6.32: Fitting the neural network with the training set</p><p>After training for <strong class="source-inline">5</strong> epochs, we achieved an accuracy score of <strong class="source-inline">0.925</strong> for the training set and <strong class="source-inline">0.9042</strong> for the validation set. Our model is overfitting a bit.</p></li>
				<li>Evaluate the performance of the model on the testing set:<p class="source-code">model.evaluate(features_test, label_test)</p><p>The expected output is this:</p><p class="source-code">10000/10000 [==============================] - 1s 108us/sample - loss: 0.2746 - accuracy: 0.8976</p><p class="source-code">[0.27461639745235444, 0.8976]</p></li>
			</ol>
			<p>We achieved an accuracy score of <strong class="source-inline">0.8976</strong> on the testing set for predicting images of clothing from the Fashion MNIST dataset. You can try on your own to improve this score and reduce the overfitting.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/2Nzt6pn">https://packt.live/2Nzt6pn</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/2NlM5nd">https://packt.live/2NlM5nd</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this activity, we designed and trained a CNN architecture for recognizing images of clothing from the Fashion MNIST dataset.</p>
			<h2 id="_idParaDest-227"><a id="_idTextAnchor258"/>Activity 6.03: Evaluating a Yahoo Stock Model with an RNN</h2>
			<p><strong class="bold">Solution</strong>:</p>
			<ol>
				<li value="1">Open a Jupyter Notebook.</li>
				<li>Import <strong class="source-inline">pandas</strong> as <strong class="source-inline">pd</strong> and <strong class="source-inline">numpy</strong> as <strong class="source-inline">np</strong>:<p class="source-code">import pandas as pd</p><p class="source-code">import numpy as np</p></li>
				<li>Create a variable called <strong class="source-inline">file_url</strong> containing a link to the raw dataset:<p class="source-code">file_url = 'https://raw.githubusercontent.com/'\</p><p class="source-code">           'PacktWorkshops/'\</p><p class="source-code">           'The-Applied-Artificial-Intelligence-Workshop/'\</p><p class="source-code">           'master/Datasets/yahoo_spx.csv'</p></li>
				<li>Load the dataset using <strong class="source-inline">pd.read_csv()</strong> into a new variable called <strong class="source-inline">df</strong>:<p class="source-code">df = pd.read_csv(file_url)</p></li>
				<li>Extract the values of the second column using <strong class="source-inline">.iloc</strong> and <strong class="source-inline">.values</strong> and save the results in a variable called <strong class="source-inline">stock_data</strong>:<p class="source-code">stock_data = df.iloc[:, 1:2].values</p></li>
				<li>Import <strong class="source-inline">MinMaxScaler</strong> from <strong class="source-inline">sklearn.preprocessing</strong>:<p class="source-code">from sklearn.preprocessing import MinMaxScaler</p></li>
				<li>Instantiate <strong class="source-inline">MinMaxScaler()</strong> and save it to a variable called <strong class="source-inline">sc</strong>:<p class="source-code">sc = MinMaxScaler()</p></li>
				<li>Standardize the data with <strong class="source-inline">.fit_transform()</strong> and save the results in a variable called <strong class="source-inline">stock_data_scaled</strong>:<p class="source-code">stock_data_scaled = sc.fit_transform(stock_data)</p></li>
				<li>Create two empty arrays called <strong class="source-inline">X_data</strong> and <strong class="source-inline">y_data</strong>:<p class="source-code">X_data = []</p><p class="source-code">y_data = []</p></li>
				<li>Create a variable called <strong class="source-inline">window</strong> that will contain the value <strong class="source-inline">30</strong>:<p class="source-code">window = 30</p></li>
				<li>Create a <strong class="source-inline">for</strong> loop starting from the <strong class="source-inline">window</strong> value and iterate through the length of the dataset. For each iteration, append to <strong class="source-inline">X_data</strong> the previous rows of <strong class="source-inline">stock_data_scaled</strong> using <strong class="source-inline">window</strong> and append the current value of <strong class="source-inline">stock_data_scaled</strong>:<p class="source-code">for i in range(window, len(df)):</p><p class="source-code">    X_data.append(stock_data_scaled[i - window:i, 0])</p><p class="source-code">    y_data.append(stock_data_scaled[i, 0])</p><p><strong class="source-inline">y_data</strong> will contain the opening stock price for each day and <strong class="source-inline">X_data</strong> will contain the last 30 days' stock prices.</p></li>
				<li>Convert <strong class="source-inline">X_data</strong> and <strong class="source-inline">y_data</strong> into NumPy arrays:<p class="source-code">X_data = np.array(X_data)</p><p class="source-code">y_data = np.array(y_data)</p></li>
				<li>Reshape <strong class="source-inline">X_data</strong> as (number of rows, number of columns, 1):<p class="source-code">X_data = np.reshape(X_data, (X_data.shape[0], \</p><p class="source-code">                    X_data.shape[1], 1))</p></li>
				<li>Use the first <strong class="source-inline">1,000</strong> rows as the training data and save them into two variables called <strong class="source-inline">features_train</strong> and <strong class="source-inline">label_train</strong>:<p class="source-code">features_train = X_data[:1000]</p><p class="source-code">label_train = y_data[:1000]</p></li>
				<li>Use the rows after row <strong class="source-inline">1,000</strong> as the testing data and save them into two variables called <strong class="source-inline">features_test</strong> and <strong class="source-inline">label_test</strong>:<p class="source-code">features_test = X_data[:1000]</p><p class="source-code">label_test = y_data[:1000]</p></li>
				<li>Import <strong class="source-inline">numpy</strong> as <strong class="source-inline">np</strong>, <strong class="source-inline">tensorflow</strong> as <strong class="source-inline">tf</strong>, and <strong class="source-inline">layers</strong> from <strong class="source-inline">tensorflow.keras</strong>:<p class="source-code">import numpy as np</p><p class="source-code">import tensorflow as tf</p><p class="source-code">from tensorflow.keras import layers</p></li>
				<li>Set <strong class="source-inline">8</strong> as <strong class="source-inline">seed</strong> for NumPy and TensorFlow using <strong class="source-inline">np.random_seed()</strong> and <strong class="source-inline">tf.random.set_seed()</strong>:<p class="source-code">np.random.seed(8)</p><p class="source-code">tf.random.set_seed(8)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.Sequential()</strong> class and save it into a variable called <strong class="source-inline">model</strong>:<p class="source-code">model = tf.keras.Sequential()</p></li>
				<li>Instantiate <strong class="source-inline">layers.LSTM()</strong> with <strong class="source-inline">50</strong> units, <strong class="source-inline">return_sequences='True'</strong>, and <strong class="source-inline">input_shape=(X_train.shape[1], 1)</strong>, then save it into a variable called <strong class="source-inline">lstm_layer1</strong>:<p class="source-code">lstm_layer1 = layers.LSTM(units=50,return_sequences=True,\</p><p class="source-code">                          input_shape=(features_train.shape[1], 1))</p></li>
				<li>Instantiate <strong class="source-inline">layers.LSTM()</strong> with <strong class="source-inline">50</strong> units and <strong class="source-inline">return_sequences='True'</strong>, then save it into a variable called <strong class="source-inline">lstm_layer2</strong>:<p class="source-code">lstm_layer2 = layers.LSTM(units=50,return_sequences=True)</p></li>
				<li>Instantiate <strong class="source-inline">layers.LSTM()</strong> with <strong class="source-inline">50</strong> units and <strong class="source-inline">return_sequences='True'</strong>, then save it into a variable called <strong class="source-inline">lstm_layer3</strong>:<p class="source-code">lstm_layer3 = layers.LSTM(units=50,return_sequences=True)</p></li>
				<li>Instantiate <strong class="source-inline">layers.LSTM()</strong> with <strong class="source-inline">50</strong> units and save it into a variable called <strong class="source-inline">lstm_layer4</strong>:<p class="source-code">lstm_layer4 = layers.LSTM(units=50)</p></li>
				<li>Instantiate <strong class="source-inline">layers.Dense()</strong> with <strong class="source-inline">1</strong> neuron and save it into a variable called <strong class="source-inline">fc_layer</strong>:<p class="source-code">fc_layer = layers.Dense(1)</p></li>
				<li>Add the five layers you just defined to the model using <strong class="source-inline">.add()</strong> and add a <strong class="source-inline">Dropout(0.2)</strong> layer in between each of the LSTM layers:<p class="source-code">model.add(lstm_layer1)</p><p class="source-code">model.add(layers.Dropout(0.2))</p><p class="source-code">model.add(lstm_layer2)</p><p class="source-code">model.add(layers.Dropout(0.2))</p><p class="source-code">model.add(lstm_layer3)</p><p class="source-code">model.add(layers.Dropout(0.2))</p><p class="source-code">model.add(lstm_layer4)</p><p class="source-code">model.add(layers.Dropout(0.2))</p><p class="source-code">model.add(fc_layer)</p></li>
				<li>Instantiate a <strong class="source-inline">tf.keras.optimizers.Adam()</strong> class with <strong class="source-inline">0.001</strong> as the learning rate and save it into a variable called <strong class="source-inline">optimizer</strong>:<p class="source-code">optimizer = tf.keras.optimizers.Adam(0.001)</p></li>
				<li>Compile the neural network using <strong class="source-inline">.compile()</strong> with <strong class="source-inline">loss='mean_squared_error', optimizer=optimizer, metrics=[mse]</strong>:<p class="source-code">model.compile(loss='mean_squared_error', \</p><p class="source-code">              optimizer=optimizer, metrics=['mse'])</p></li>
				<li>Print a summary of the model using <strong class="source-inline">.summary()</strong>:<p class="source-code">model.summary()</p><p>The expected output is this:</p><div id="_idContainer239" class="IMG---Figure"><img src="image/B16060_06_33.jpg" alt="Figure 6.33: Summary of the model&#13;&#10;"/></div><p class="figure-caption">Figure 6.33: Summary of the model</p><p>The summary shows us that there are more than <strong class="source-inline">71,051</strong> parameters to be optimized with this model.</p></li>
				<li>Fit the neural network with the training set and specify <strong class="source-inline">epochs=10, validation_split=0.2, verbose=2</strong>:<p class="source-code">model.fit(features_train, label_train, epochs=10, \</p><p class="source-code">          validation_split = 0.2, verbose=2)</p><p>The expected output is this:</p><div id="_idContainer240" class="IMG---Figure"><img src="image/B16060_06_34.jpg" alt="Figure 6.34: Fitting the neural network with the training set&#13;&#10;"/></div><p class="figure-caption">Figure 6.34: Fitting the neural network with the training set</p><p>After training for <strong class="source-inline">10</strong> epochs, we achieved a mean squared error score of <strong class="source-inline">0.0025</strong> for the training set and <strong class="source-inline">0.0033</strong> for the validation set. Our model is overfitting a little bit.</p></li>
				<li>Finally, evaluate the performance of the model on the testing set:<p class="source-code">model.evaluate(features_test, label_test)</p><p>The expected output is this:</p><p class="source-code">1000/1000 [==============================] - 0s 279us/sample - loss: 0.0016 - mse: 0.0016</p><p class="source-code">[0.00158528157370165, 0.0015852816]</p></li>
			</ol>
			<p>We achieved a mean squared error score of <strong class="source-inline">0.0017</strong> on the testing set, which means we can quite accurately predict the stock price of Yahoo using the last 30 days' stock price data as features.</p>
			<p class="callout-heading">Note</p>
			<p class="callout">To access the source code for this specific section, please refer to <a href="https://packt.live/3804U8P">https://packt.live/3804U8P</a>.</p>
			<p class="callout">You can also run this example online at <a href="https://packt.live/3hWtU5l">https://packt.live/3hWtU5l</a>.</p>
			<p class="callout">You must execute the entire Notebook in order to get the desired result.</p>
			<p>In this activity, we designed and trained an RNN model to predict the Yahoo stock price from the previous 30 days of data.</p>
		</div>
		<div>
			<div id="_idContainer242" class="Content">
			</div>
		</div>
	</body></html>