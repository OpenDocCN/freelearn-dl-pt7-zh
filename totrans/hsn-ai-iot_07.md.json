["```py\nimport numpy as np\nimport tensorflow as tf\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom tensorflow.contrib.layers import fully_connected\n```", "```py\n# Load MNIST data in a format suited for tensorflow.\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets('MNIST_data', one_hot=True)\nn_samples = mnist.train.num_examples\nn_input = mnist.train.images[0].shape[0]\n```", "```py\nclass VariationalAutoencoder(object):\n    def __init__(self,n_input, n_z,\n        learning_rate=0.001, batch_size=100):\n        self.batch_size = batch_size\n        self.n_input = n_input\n        self.n_z = n_z\n\n        # Place holder for the input \n        self.x = tf.placeholder(tf.float32, shape = [None, n_input])\n\n        # Use Encoder Network to determine mean and \n        # (log) variance of Gaussian distribution in the latent space\n        self.z_mean, self.z_log_sigma_sq = self._encoder_network()\n        # Draw a sample z from Gaussian distribution\n        eps = tf.random_normal((self.batch_size, n_z), 0, 1, dtype=tf.float32)\n        # z = mu + sigma*epsilon\n        self.z = tf.add(self.z_mean,tf.multiply(tf.sqrt(tf.exp(self.z_log_sigma_sq)), eps))\n        # Use Decoder network to determine mean of\n        # Bernoulli distribution of reconstructed input\n        self.x_hat = self._decoder_network()\n\n        # Define loss function based variational upper-bound and \n        # corresponding optimizer\n        # define generation loss\n        reconstruction_loss = \\\n            -tf.reduce_sum(self.x * tf.log(1e-10 + self.x_hat)\n            + (1-self.x) * tf.log(1e-10 + 1 - self.x_hat), 1)\n        self.reconstruction_loss = tf.reduce_mean(reconstruction_loss)\n\n        latent_loss = -0.5 * tf.reduce_sum(1 + self.z_log_sigma_sq \n            - tf.square(self.z_mean)- tf.exp(self.z_log_sigma_sq), 1)\n        self.latent_loss = tf.reduce_mean(latent_loss)\n        self.cost = tf.reduce_mean(reconstruction_loss + latent_loss) \n        # average over batch\n        # Define the optimizer\n        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n\n        # Initializing the tensor flow variables\n        init = tf.global_variables_initializer()\n        # Launch the session\n        self.sess = tf.InteractiveSession()\n        self.sess.run(init)\n\n    # Create encoder network\n    def _encoder_network(self):\n        # Generate probabilistic encoder (inference network), which\n        # maps inputs onto a normal distribution in latent space.\n        layer_1 = fully_connected(self.x,500,activation_fn=tf.nn.softplus) \n        layer_2 = fully_connected(layer_1, 500, activation_fn=tf.nn.softplus) \n        z_mean = fully_connected(layer_2,self.n_z, activation_fn=None)\n        z_log_sigma_sq = fully_connected(layer_2, self.n_z, activation_fn=None)\n        return (z_mean, z_log_sigma_sq)\n\n    # Create decoder network\n    def _decoder_network(self):\n        # Generate probabilistic decoder (generator network), which\n        # maps points in the latent space onto a Bernoulli distribution in the data space.\n        layer_1 = fully_connected(self.z,500,activation_fn=tf.nn.softplus) \n        layer_2 = fully_connected(layer_1, 500, activation_fn=tf.nn.softplus) \n        x_hat = fully_connected(layer_2, self.n_input, activation_fn=tf.nn.sigmoid)\n\n        return x_hat\n\n    def single_step_train(self, X):\n        _,cost,recon_loss,latent_loss = self.sess.run([self.optimizer,         self.cost,self.reconstruction_loss,self.latent_loss],feed_dict={self.x: X})\n        return cost, recon_loss, latent_loss\n\n    def transform(self, X):\n        \"\"\"Transform data by mapping it into the latent space.\"\"\"\n        # Note: This maps to mean of distribution, we could alternatively\n        # sample from Gaussian distribution\n        return self.sess.run(self.z_mean, feed_dict={self.x: X})\n\n    def generate(self, z_mu=None):\n        \"\"\" Generate data by sampling from latent space.\n\n        If z_mu isn't None, data for this point in latent space is\n        generated. Otherwise, z_mu is drawn from prior in latent \n        space. \n        \"\"\"\n        if z_mu is None:\n            z_mu = np.random.normal(size=n_z)\n            # Note: This maps to mean of distribution, we could alternatively    \n            # sample from Gaussian distribution\n        return self.sess.run(self.x_hat,feed_dict={self.z: z_mu})\n\n    def reconstruct(self, X):\n        \"\"\" Use VAE to reconstruct given data. \"\"\"\n        return self.sess.run(self.x_hat, feed_dict={self.x: X})\n```", "```py\ndef train(n_input,n_z, learning_rate=0.001,\n    batch_size=100, training_epochs=10, display_step=5):\n    vae = VariationalAutoencoder(n_input,n_z, \n        learning_rate=learning_rate, \n        batch_size=batch_size)\n    # Training cycle\n    for epoch in range(training_epochs):\n        avg_cost, avg_r_loss, avg_l_loss = 0., 0., 0.\n        total_batch = int(n_samples / batch_size)\n        # Loop over all batches\n        for i in range(total_batch):\n            batch_xs, _ = mnist.train.next_batch(batch_size)\n            # Fit training using batch data\n            cost,r_loss, l_loss = vae.single_step_train(batch_xs)\n            # Compute average loss\n            avg_cost += cost / n_samples * batch_size\n            avg_r_loss += r_loss / n_samples * batch_size\n            avg_l_loss += l_loss / n_samples * batch_size\n        # Display logs per epoch step\n        if epoch % display_step == 0:\n            print(\"Epoch: {:4d} cost={:.4f} Reconstruction loss = {:.4f} Latent Loss = {:.4f}\".format(epoch,avg_cost,avg_r_loss,avg_l_loss))\n     return vae\n```", "```py\ntf.contrib.layers.fully_connected(\n    inputs,\n    num_outputs,\n    activation_fn=tf.nn.relu,\n    normalizer_fn=None,\n    normalizer_params=None,\n    weights_initializer=intializers.xavier_intializer(),\n    weights_regularizer= None, \n    biases_initializer=tf.zeros_intializer(),\n    biases_regularizer=None,\n    reuse=None,\n    variables_collections=None,\n    outputs_collections=None,\n    trainable=True,\n    scope=None\n)\n```", "```py\n# import the necessaey modules\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport os\nfrom tensorflow.contrib.layers import xavier_initializer\n%matplotlib inline\n```", "```py\n# Load data\nfrom tensorflow.examples.tutorials.mnist import input_data\ndata = input_data.read_data_sets('MNIST_data', one_hot=True)\n\n# define hyperparameters\nbatch_size = 128\nZ_dim = 100\nim_size = 28\nh_size=128\nlearning_rate_D = .0005\nlearning_rate_G = .0006\n```", "```py\n#Create Placeholder for input X and random noise Z\nX = tf.placeholder(tf.float32, shape=[None, im_size*im_size])\nZ = tf.placeholder(tf.float32, shape=[None, Z_dim])\ninitializer=xavier_initializer()\n\n# Define Discriminator and Generator training variables\n#Discriminiator\nD_W1 = tf.Variable(initializer([im_size*im_size, h_size]))\nD_b1 = tf.Variable(tf.zeros(shape=[h_size]))\n\nD_W2 = tf.Variable(initializer([h_size, 1]))\nD_b2 = tf.Variable(tf.zeros(shape=[1]))\n\ntheta_D = [D_W1, D_W2, D_b1, D_b2]\n\n#Generator\nG_W1 = tf.Variable(initializer([Z_dim, h_size]))\nG_b1 = tf.Variable(tf.zeros(shape=[h_size]))\n\nG_W2 = tf.Variable(initializer([h_size, im_size*im_size]))\nG_b2 = tf.Variable(tf.zeros(shape=[im_size*im_size]))\n\ntheta_G = [G_W1, G_W2, G_b1, G_b2]\n```", "```py\ndef sample_Z(m, n):\n    return np.random.uniform(-1., 1., size=[m, n])\n```", "```py\ndef generator(z):\n    \"\"\" Two layer Generator Network Z=>128=>784 \"\"\"\n    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1)\n    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2\n    G_prob = tf.nn.sigmoid(G_log_prob)\n    return G_prob\n\ndef discriminator(x):\n    \"\"\" Two layer Discriminator Network X=>128=>1 \"\"\"\n    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1)\n    D_logit = tf.matmul(D_h1, D_W2) + D_b2\n    D_prob = tf.nn.sigmoid(D_logit)\n    return D_prob, D_logit\n```", "```py\ndef plot(samples):\n    \"\"\"function to plot generated samples\"\"\"\n    fig = plt.figure(figsize=(10, 10))\n    gs = gridspec.GridSpec(5, 5)\n    gs.update(wspace=0.05, hspace=0.05)\n    for i, sample in enumerate(samples):\n        ax = plt.subplot(gs[i])\n        plt.axis('off')\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        ax.set_aspect('equal')\n        plt.imshow(sample.reshape(28, 28), cmap='gray')\n    return fig\n```", "```py\nG_sample = generator(Z)\nD_real, D_logit_real = discriminator(X)\nD_fake, D_logit_fake = discriminator(G_sample)\n```", "```py\nD_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real)))\nD_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake)))\nD_loss = D_loss_real + D_loss_fake\nG_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake)))\n\nD_solver = tf.train.AdamOptimizer(learning_rate=learning_rate_D).minimize(D_loss, var_list=theta_D)\nG_solver = tf.train.AdamOptimizer(learning_rate=learning_rate_G).minimize(G_loss, var_list=theta_G)\n```", "```py\nsess = tf.Session()\nsess.run(tf.global_variables_initializer())\nGLoss = []\nDLoss = []\nif not os.path.exists('out/'):\n    os.makedirs('out/')\n\nfor it in range(100000):\n    if it % 100 == 0:\n        samples = sess.run(G_sample, feed_dict={Z: sample_Z(25, Z_dim)})\n        fig = plot(samples)\n        plt.savefig('out/{}.png'.format(str(it).zfill(3)), bbox_inches='tight')\n        plt.close(fig)\n    X_mb, _ = data.train.next_batch(batch_size)\n    _, D_loss_curr = sess.run([D_solver, D_loss], feed_dict={X: X_mb, Z: sample_Z(batch_size, Z_dim)})\n    _, G_loss_curr = sess.run([G_solver, G_loss], feed_dict={Z: sample_Z(batch_size, Z_dim)})\n    GLoss.append(G_loss_curr)\n    DLoss.append(D_loss_curr)\n    if it % 100 == 0:\n        print('Iter: {} D loss: {:.4} G_loss: {:.4}'.format(it,D_loss_curr, G_loss_curr))\n\nprint('Done')\n```", "```py\nimport loader\nimport os\nfrom glob import glob\nimport numpy as np\nfrom matplotlib import pyplot\nimport tensorflow as tf\n%matplotlib inline\n```", "```py\nloader.download_celeb_a()\n\n# Let's explore the images\ndata_dir = os.getcwd()\ntest_images = loader.get_batch(glob(os.path.join(data_dir, 'celebA/*.jpg'))[:10], 56, 56)\npyplot.imshow(loader.plot_images(test_images))\n```", "```py\ndef discriminator(images, reuse=False):\n    \"\"\"\n    Create the discriminator network\n    \"\"\"\n    alpha = 0.2\n\n    with tf.variable_scope('discriminator', reuse=reuse):\n        # using 4 layer network as in DCGAN Paper\n\n        # First convolution layer\n        conv1 = tf.layers.conv2d(images, 64, 5, 2, 'SAME')\n        lrelu1 = tf.maximum(alpha * conv1, conv1)\n\n        # Second convolution layer\n        conv2 = tf.layers.conv2d(lrelu1, 128, 5, 2, 'SAME')\n        batch_norm2 = tf.layers.batch_normalization(conv2, training=True)\n        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n\n        # Third convolution layer\n        conv3 = tf.layers.conv2d(lrelu2, 256, 5, 1, 'SAME')\n        batch_norm3 = tf.layers.batch_normalization(conv3, training=True)\n        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n\n        # Flatten layer\n        flat = tf.reshape(lrelu3, (-1, 4*4*256))\n\n        # Logits\n        logits = tf.layers.dense(flat, 1)\n\n        # Output\n        out = tf.sigmoid(logits)\n\n        return out, logits\n```", "```py\ndef generator(z, out_channel_dim, is_train=True):\n    \"\"\"\n    Create the generator network\n    \"\"\"\n    alpha = 0.2\n\n    with tf.variable_scope('generator', reuse=False if is_train==True else True):\n        # First fully connected layer\n        x_1 = tf.layers.dense(z, 2*2*512)\n\n        # Reshape it to start the convolutional stack\n        deconv_2 = tf.reshape(x_1, (-1, 2, 2, 512))\n        batch_norm2 = tf.layers.batch_normalization(deconv_2, training=is_train)\n        lrelu2 = tf.maximum(alpha * batch_norm2, batch_norm2)\n\n        # Deconv 1\n        deconv3 = tf.layers.conv2d_transpose(lrelu2, 256, 5, 2, padding='VALID')\n        batch_norm3 = tf.layers.batch_normalization(deconv3, training=is_train)\n        lrelu3 = tf.maximum(alpha * batch_norm3, batch_norm3)\n\n        # Deconv 2\n        deconv4 = tf.layers.conv2d_transpose(lrelu3, 128, 5, 2, padding='SAME')\n        batch_norm4 = tf.layers.batch_normalization(deconv4, training=is_train)\n        lrelu4 = tf.maximum(alpha * batch_norm4, batch_norm4)\n\n        # Output layer\n        logits = tf.layers.conv2d_transpose(lrelu4, out_channel_dim, 5, 2, padding='SAME')\n\n        out = tf.tanh(logits)\n\n        return out\n```", "```py\ndef model_loss(input_real, input_z, out_channel_dim):\n    \"\"\"\n    Get the loss for the discriminator and generator\n    \"\"\"\n\n    label_smoothing = 0.9\n\n    g_model = generator(input_z, out_channel_dim)\n    d_model_real, d_logits_real = discriminator(input_real)\n    d_model_fake, d_logits_fake = discriminator(g_model, reuse=True)\n\n    d_loss_real = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real,\n                                                labels=tf.ones_like(d_model_real) * label_smoothing))\n    d_loss_fake = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                labels=tf.zeros_like(d_model_fake)))\n\n    d_loss = d_loss_real + d_loss_fake\n\n    g_loss = tf.reduce_mean(\n        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake,\n                                                labels=tf.ones_like(d_model_fake) * label_smoothing))\n\n    return d_loss, g_loss\n```", "```py\ndef model_opt(d_loss, g_loss, learning_rate, beta1):\n    \"\"\"\n    Get optimization operations\n    \"\"\"\n    t_vars = tf.trainable_variables()\n    d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n    g_vars = [var for var in t_vars if var.name.startswith('generator')]\n\n    # Optimize\n    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)): \n        d_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(d_loss, var_list=d_vars)\n        g_train_opt = tf.train.AdamOptimizer(learning_rate, beta1=beta1).minimize(g_loss, var_list=g_vars)\n\n    return d_train_opt, g_train_opt\n```", "```py\ndef generator_output(sess, n_images, input_z, out_channel_dim):\n    \"\"\"\n    Show example output for the generator\n    \"\"\"\n    z_dim = input_z.get_shape().as_list()[-1]\n    example_z = np.random.uniform(-1, 1, size=[n_images, z_dim])\n\n    samples = sess.run(\n        generator(input_z, out_channel_dim, False),\n        feed_dict={input_z: example_z})\n\n    pyplot.imshow(loader.plot_images(samples))\n    pyplot.show()\n```", "```py\ndef train(epoch_count, batch_size, z_dim, learning_rate, beta1, get_batches, data_shape, data_files):\n    \"\"\"\n    Train the GAN\n    \"\"\"\n    w, h, num_ch = data_shape[1], data_shape[2], data_shape[3]\n    X = tf.placeholder(tf.float32, shape=(None, w, h, num_ch), name='input_real') \n    Z = tf.placeholder(tf.float32, (None, z_dim), name='input_z')\n    #model_inputs(data_shape[1], data_shape[2], data_shape[3], z_dim)\n    D_loss, G_loss = model_loss(X, Z, data_shape[3])\n    D_solve, G_solve = model_opt(D_loss, G_loss, learning_rate, beta1)\n\n    with tf.Session() as sess:\n        sess.run(tf.global_variables_initializer())\n        train_loss_d = []\n        train_loss_g = []\n        for epoch_i in range(epoch_count):\n            num_batch = 0\n            lossD, lossG = 0,0\n            for batch_images in get_batches(batch_size, data_shape, data_files):\n\n                # values range from -0.5 to 0.5 so we scale to range -1, 1\n                batch_images = batch_images * 2\n                num_batch += 1\n\n                batch_z = np.random.uniform(-1, 1, size=(batch_size, z_dim))\n\n                _,d_loss = sess.run([D_solve,D_loss], feed_dict={X: batch_images, Z: batch_z})\n                _,g_loss = sess.run([G_solve,G_loss], feed_dict={X: batch_images, Z: batch_z})\n\n                lossD += (d_loss/batch_size)\n                lossG += (g_loss/batch_size)\n                if num_batch % 500 == 0:\n                    # After every 500 batches\n                    print(\"Epoch {}/{} For Batch {} Discriminator Loss: {:.4f} Generator Loss: {:.4f}\".\n                          format(epoch_i+1, epochs, num_batch, lossD/num_batch, lossG/num_batch))\n\n                    generator_output(sess, 9, Z, data_shape[3])\n            train_loss_d.append(lossD/num_batch)\n            train_loss_g.append(lossG/num_batch)\n\n    return train_loss_d, train_loss_g\n```", "```py\n# Data Parameters\nIMAGE_HEIGHT = 28\nIMAGE_WIDTH = 28\ndata_files = glob(os.path.join(data_dir, 'celebA/*.jpg'))\n\n#Hyper parameters\nbatch_size = 16\nz_dim = 100\nlearning_rate = 0.0002\nbeta1 = 0.5\nepochs = 2\nshape = len(data_files), IMAGE_WIDTH, IMAGE_HEIGHT, 3\nwith tf.Graph().as_default():\n    Loss_D, Loss_G = train(epochs, batch_size, z_dim, learning_rate, beta1, loader.get_batches, shape, data_files)\n```"]