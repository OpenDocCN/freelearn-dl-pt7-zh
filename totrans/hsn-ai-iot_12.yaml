- en: Combining It All Together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that we have understood and implemented different **Artificial Intelligence**
    (**AI**)/**machine learning** (**ML**) algorithms, it is time to combine it all
    together, understand which type of data is best suited for each, and, at the same
    time, understand the basic preprocessing required for each type of data. By the
    end of this chapter, you will know the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The different types of data that can be fed to your model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to process time series data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Preprocessing of textual data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different transforms that can be done on image data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to handle video files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to handle speech data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud computing options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Processing different types of data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data is available in all shapes, sizes, and forms: tweets, daily stock prices,
    per minute heartbeat signals, photos from cameras, video obtained from CCTV, audio
    recordings, and so on. Each of them contain information and when properly processed
    and used with the right model, we can analyze the data and, obtain advanced information
    about the underlying patterns. In this section, we will cover the basic preprocessing
    required for each type of data before it can be fed to a model and the models
    that can be used for it.'
  prefs: []
  type: TYPE_NORMAL
- en: Time series modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Time underlies many interesting human behaviors, and hence, it is important
    that AI-powered IoT systems know how to deal with time-dependent data. Time can
    be represented either explicitly, for example, capturing data at regular intervals
    where the time-stamp is also part of data, or implicitly, for example, in speech
    or written text. The methods that allow us to capture inherent patterns in time-dependent
    data is called **time series modeling**.
  prefs: []
  type: TYPE_NORMAL
- en: 'The data that is captured at regular intervals is a time series data, for example,
    stock price data is a time series data. Let''s take a look at Apple stock price
    data; this data can be downloaded from the NASDAQ site ([https://www.nasdaq.com/symbol/aapl/historical](https://www.nasdaq.com/symbol/aapl/historical)).
    Alternatively, you can use the `pandas_datareader` module to directly download
    the data by specifying the data source. To install `pandas_datareader` in your
    working environment, use the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code downloads the Apple Inc stock price from Yahoo Finance from
    1^(st) January 2010 to 31^(st) December 2015:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The downloaded DataFrame provides `High`, `Low`, `Open`, `Close`, `Volume`,
    and `Adj Close` values for each working day:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/1fb0ab65-15be-41bb-b84b-0aca162443a4.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s now plot it, shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/fa7e0db3-3e92-49f9-a9ef-bf5e5a396a44.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To be able to model time series data, we need to identify a few things: trend,
    seasonality, and stationarity.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trend** means to find whether, on average, the measurements tend to decrease
    (or increase) over time. The most common way to find a trend is by plotting a
    moving average, shown as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/860eb6d8-e51e-418e-a446-c6d9a88a5876.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see, with a window of 20, the upward and downward trend. For time series
    modeling, we should detrend the data. Detrending can be done by subtracting the
    trend (moving average) from the original signal. Another popular way is using
    the first order difference method, where you take the difference between successive
    data points:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/5730da71-8b00-4cf1-8b44-a59920e3cab6.png)'
  prefs: []
  type: TYPE_IMG
- en: '**Seasonality** is the presence of a regularly repeating pattern of highs and
    lows related to time (for example, sine series). The easiest way is to find autocorrelation
    in the data. Once you find the seasonality, you can remove it by differencing
    the data by a time lag corresponding to the season length:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d024cf46-d51b-45f2-a1d4-307cf981e712.png)'
  prefs: []
  type: TYPE_IMG
- en: The last thing is to ensure whether the series is **stationary**, that is, the
    mean of the series is no longer a function of time. Stationarity of data is essential
    for time series modeling. We achieve stationarity by removing any trends or seasonality
    present within the data. Once the data is stationary, we can use regression models
    to model it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Traditionally, time series data was modeled using auto-regressive and moving
    average based models like ARMA and ARIMA. To learn more about time series modeling,
    the interested reader can refer to these books:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pandit, S. M., and Wu, S. M. (1983). *Time Series and System Analysis with
    Applications*(Vol. 3). New York: Wiley.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brockwell, P. J., Davis, R. A., and Calder, M. V. (2002). *Introduction to
    Time Series and Forecasting*(Vol. 2). New York: Springer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The stationarity is an important property for any time series data, whether
    you are using traditional time series modeling or deep learning models. This is
    so because, if a series has stationarity (even if it is weak stationarity), then
    it means the data has same distribution across time, and hence, can be estimated
    in time. If you are planning to use deep learning models such as RNN or LSTM,
    then after confirming stationarity of the time series, additionally, you need
    to normalize the data and use a sliding window transform to convert the series
    in to input-output pairs on which regression can be done.  This can be very easily
    done using the scikit-learn library and NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s normalize the `close` DataFrame. Normalization ensures that data lies
    between `0` and `1`. Observe that the following plot is the same as the plot of
    the `close` DataFrame in the preceding *step 3* , however, the *y*-axis scale
    is now different:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/ea95f634-5716-4007-9e07-689e5f4b1095.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We define a `window_transform()` function, which will convert the data series
    into a sequence of input-output pairs. For example, you want to construct an RNN
    that takes the previous five values as output and predicts the sixth value. Then,
    you choose `window_size = 5`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Please refer to the GitHub repository, `Chapter-12/time_series_data_preprocessing.ipynb`,
    for the complete code of this section.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing textual data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Language plays a very important role in our daily life. For us, reading a written
    text is very natural, but what about computers? Can they read it? Can we make
    our deep learning models generate new text based on the old pattern? For example,
    if I say, "Yesterday, I had ____ at Starbucks," most of us will be able to guess
    that the blank space is coffee, but can our deep learning models do it? The answer
    is yes; we can train our deep learning models to guess the next word (or character).
    However, deep learning models run on computers, and computers understand only
    binary, only 0s and 1s. Hence, we need a way to process out textual data so that
    it can be converted in to a form that is easy for the computer to handle. Moreover,
    while cat or CAT or Cat have different ASCII representation, they mean the same;
    it is easy for us to see, but for models to take them as the same, we need to
    preprocess the textual data. This section will list the necessary preprocessing
    steps for the textual data, and you will learn how to do it in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For this section, we will consider a small text from my favorite science fiction
    novel, *Foundation,* by Isaac Asimov. The text is in the `foundation.txt` file.
    The first step is, we read in the text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step in text processing is cleaning the data. We retain only that
    part of the text that is relevant. In most cases, punctuation does not add any
    additional meaning to the text, so we can safely remove it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'After cleaning the data, we need to normalize the text. In text processing,
    normalizing the text means converting all text in to the same case, lowercase
    or uppercase. Conventionally, lowercase is preferred, so we convert the text in
    to lowercase:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the text is normalized, the next step is tokenizing the text. We can tokenize
    a text in word tokens or sentence tokens. To do this, you can use either the split
    function or use the powerful NLTK module. If you do not have NLTK installed in
    your system, you can do it using `pip install nltk`. In the following, we use
    NLTK''s word tokenizer to do the task:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Depending on the type of text you have and the work you are doing, you will
    need to remove stop words. Stop words are words that are present in most text
    samples, and hence, do not add any information to the context or meaning of the
    text. For example, the, a, and an. You can declare your own stop words or use
    the stop words provided by NLTK. Here, we remove `stopwords` of the `english`
    language from our text:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Another thing that you can perform on the textual data is stemming and lemmatization.
    These are used to convert the words into canonical form:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'You can access the notebook with this code at GitHub: `Chapter12/text_processing.ipynb`.'
  prefs: []
  type: TYPE_NORMAL
- en: Data augmentation for images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Python has OpenCV, which provides very good support for images. OpenCV can be
    downloaded from both Conda channels and PyPi for installation. Once the image
    is read using the OpenCV `imread()` function, the image is represented as an array.
    In case the image is coloured, the channels are stored in BGR order. Each element
    of the array represents the intensity of the corresponding pixel value (the values
    lie in the range 0 to 255).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say you have trained a model to recognize a ball: you present it with
    a tennis ball, and it recognizes it as a ball. The next image of the ball that
    we present is taken after zooming: will our model still recognize it? A model
    is just as good as the dataset it has been trained on, and so, if the model while
    training had seen rescaled images, it will be easy for it to identify the zoomed
    ball as a ball. One way to ensure that such images are available in your dataset
    is to implicitly include such variable images, however, since images are represented
    as an array, we can perform mathematical transformations to rescale, flip, rotate,
    and even change intensities. The process of performing these transformations on
    existing training images to generate new images is called **data augmentation**.
    Another advantage of using data augmentation  is that you are able to increase
    the size of your training dataset (when used with data generators, we can get
    infinite images).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Most deep learning libraries have standard APIs to perform data augmentation.
    In Keras ([https://keras.io/preprocessing/image/](https://keras.io/preprocessing/image/)
    ), there is `ImageDataGenerator`, and in TensorFlow-TfLearn, we have `ImageAugmentation`.
    TensorFlow also has Ops to perform image conversions and transformations ([https://www.tensorflow.org/api_guides/python/image](https://www.tensorflow.org/api_guides/python/image)).
    Here we will see how we can use OpenCV''s powerful library for data augmentation
    and create our own data generator:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We import the necessary modules: OpenCV to read and process images, `numpy`
    for matrix manipulations, Matplotlib to visualize images, `shuffle` from scikit-learn
    for randomly shuffling the data, and Glob to find files within directories:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We read the necessary files. For this example, we downloaded some images of
    the previous President of the United States, Barack Obama, from Google image search:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We create a function that can randomly introduce any of the following distortions
    in the image: random rotation in the range 0–50 degrees, randomly change the intensity,
    randomly shift the image horizontally and vertically by up to 50 pixels, or randomly
    flip the image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following image, you can see the result of the preceding function on
    randomly chosen images from our dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/e35d972d-8a55-4be5-88d9-647b3aaee380.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And finally, you can create a data generator using Python `yield` to generate
    as many images as you want:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The `Chapter12/data_augmentation.ipynb` file contains the code for this section.
  prefs: []
  type: TYPE_NORMAL
- en: Handling videos files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Videos are nothing but a collection of still images (frames), therefore, if
    we can extract images from the videos, we can apply our trusted CNN networks on
    the same. The only necessary thing to do is convert the video in to a list of
    frames:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we import are the requisite modules. We will need OpenCV to
    read the video and convert it in to frames. We will also need the `math` module
    for basic mathematical operations and Matplotlib for visualizing the frames:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We read the video file using the OpenCV function and get its frame rate by
    using the property identifier, `5` ([https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get](https://docs.opencv.org/2.4/modules/highgui/doc/reading_and_writing_images_and_video.html#videocapture-get)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'We loop through all of the frames of the video one by one using the `read()`
    function. Although we read only one frame at a time, we save only the first frame
    in each second. This way, we can cover the whole video, and yet reduce the data
    size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s visualize the fifth frame that we saved:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/7aa195c7-3649-451f-ad8c-5a1145c049e1.png)'
  prefs: []
  type: TYPE_IMG
- en: The video file for this code was taken from the site maintained by Ivan Laptev
    and Barbara Caputo ([http://www.nada.kth.se/cvap/actions/](http://www.nada.kth.se/cvap/actions/)).
    The code is available at GitHub: `Chapter12/Video_to_frames.ipynb`.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the best papers that uses CNN for classifying videos is *Large-scale
    Video Classification with Convolutional Neural Networks* by Andrej Karpathy et
    al.. You can access here: [https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2014/html/Karpathy_Large-scale_Video_Classification_2014_CVPR_paper.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Audio files as input data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Another interesting data type is audio files. Models that convert speech in
    to text or classify audio sounds take as input audio files. If you want to work
    with audio files, then you will need the `librosa` module. There are many ways
    to treat an audio file; we can convert it into a time series and use a recurrent
    network. Another way that has given good results is to use them as one-dimensional
    or two-dimensional patterns, and train a CNN to classify them. Some good papers
    that adopt this approach are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Hershey, S., Chaudhuri, S., Ellis, D. P., Gemmeke, J. F., Jansen, A., Moore,
    R. C., and Slaney, M. (2017, March). *CNN architectures for large-scale audio
    classification.* In Acoustics, Speech, and Signal Processing (ICASSP), 2017 IEEE
    International Conference on (pp. 131-135). IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Palaz, D., Magimai-Doss, M., and Collobert, R. (2015). *Analysis of CNN-based
    speech recognition system using raw speech as input*. In Sixteenth Annual Conference
    of the International Speech Communication Association.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang, H., McLoughlin, I., and Song, Y. (2015, April). *Robust sound event recognition
    using convolutional neural networks*. In Acoustics, Speech, and Signal Processing
    (ICASSP), 2015 IEEE International Conference on (pp. 559-563). IEEE.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Costa, Y. M., Oliveira, L. S., and Silla Jr, C. N. (2017). *An evaluation of
    convolutional neural networks for music classification using spectrograms*. Applied
    soft computing, 52, 28–38.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will use the `librosa` module to read an audio file and convert it in to
    a one-dimensional sound pattern and two-dimensional spectrogram. You can install
    `librosa` in your Anaconda environment using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we will import `numpy`, `matplotlib`, and `librosa`. We will take the
    example audio file from the `librosa` datasets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The `librosa` load function returns the audio data as time series represented
    as a one-dimensional NumPy floating-point array. We can use them as time series
    or even as a one-dimensional pattern for a CNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following, you can see the one-dimensional audio wave pattern after
    normalization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/058703e1-2a99-474e-b3d6-6aa9d4e0d830.png)'
  prefs: []
  type: TYPE_IMG
- en: '`librosa` also has a `melspectrogram` function that we can use to form a mel
    spectrogram, which can be used as a two-dimensional image for a CNN:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a mel spectrogram of the same audio signal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/d3217b50-224b-4b88-8a53-957f64dd20fb.png)'
  prefs: []
  type: TYPE_IMG
- en: You can find the code file for the example in the GitHub repository under the `Chapter12/audio_processing.ipynb`
    file.
  prefs: []
  type: TYPE_NORMAL
- en: Computing in the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Applying AI algorithms to IoT-generated data requires computing resources.
    With the availability of a large number of cloud platforms offering service at
    competitive prices, cloud computing offers a cost-effective solution. Out of the
    many cloud platforms available today, we will talk about three main cloud platform
    providers that occupy the majority of the market share: **Amazon Web Service**
    (**AWS**), **Google Cloud Platform** (**GCP**), and Microsoft Azure.'
  prefs: []
  type: TYPE_NORMAL
- en: AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Amazon offers almost every feature under the cloud, from a cloud database, to
    cloud computing resources, to even cloud analytics. It even provides space to
    build a secure data lake. Its IoT core allows users to connect devices to the
    cloud. It provides a single dashboard that can be used to control the services
    you sign for. It charges per hour for its services. It has been offering these
    services for almost 15 years. Amazon continuously upgrades the service providing
    a better user experience. You can learn more about AWS from its site: [https://aws.amazon.com/](https://aws.amazon.com/).
  prefs: []
  type: TYPE_NORMAL
- en: It allows new users to make use of many of its services for free for one whole
    year.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google Cloud Platform ([https://cloud.google.com/](https://cloud.google.com/))
    also offers a myriad of services. It offers cloud computing, data analytics, data
    storage, and even cloud AI products that provide users with pre-trained models
    and service to generate their own tailored models. The platform allows you to
    pay per minute. It offers enterprise-level secure services. The Google Cloud console
    is the one place stop to access and control all of your GCP services. GCP offers
    $300 credit for the first year, which allows you to access all of its services
    for free.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft Azure offers a wide variety of cloud services too. The best part of
    Microsoft Cloud services ([https://azure.microsoft.com/en-in/](https://azure.microsoft.com/en-in/))
    is its ease of use; you can integrate it easily with available Microsoft tools.
    It claims to be five times less expensive compared to AWS. Like AWS and GCP, Azure
    also offers a one-year free trial worth $200 credits.
  prefs: []
  type: TYPE_NORMAL
- en: You can use these cloud services to develop, test, and deploy your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter focused on providing the reader with tools to handle different
    types of data and how to prepare them for the deep learning models. We started
    with time series data. This chapter next detailed how textual data needs to be
    preprocessed. This chapter showed how to perform data augmentation, an important
    technique for image classification and object detection. We next moved on to handling
    video; we show how to form image frames from a video. Next, this chapter covered
    audio files; we formed a time series and mel spectrogram from an audio file. Finally,
    we moved on to cloud platforms and discussed the features and services provided
    by three major cloud service providers.
  prefs: []
  type: TYPE_NORMAL
