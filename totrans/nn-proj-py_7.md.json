["```py\n$ git clone https://github.com/PacktPublishing/Neural-Network-Projects-with-Python.git\n```", "```py\n$ cd Neural-Network-Projects-with-Python\n```", "```py\n$ conda env create -f environment.yml\n```", "```py\n$ conda activate neural-network-projects-python\n```", "```py\n$ cd Chapter07\n```", "```py\n$ python siamese_nn.py\n```", "```py\nimport cv2\n```", "```py\nface_cascades = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n```", "```py\ndef detect_faces(img, draw_box=True):\n    # convert image to grayscale\n    grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    # detect faces\n    faces = face_cascades.detectMultiScale(grayscale_img, scaleFactor=1.6)\n\n    # draw bounding box around detected faces\n    for (x, y, width, height) in faces:\n        if draw_box:\n            cv2.rectangle(img, (x, y), (x+width, y+height), (0, 255, 0), 5)\n    face_box = img[y:y+height, x:x+width]\n    face_coords = [x,y,width,height]\n    return img, face_box, face_coords\n```", "```py\nimport os\nfiles = os.listdir('sample_faces')\nimages = [file for file in files if 'jpg' in file]\nfor image in images:\n    img = cv2.imread('sample_faces/' + image)\n    detected_faces, _, _ = detect_faces(img)\n    cv2.imwrite('sample_faces/detected_faces/' + image, detected_faces)\n```", "```py\n'Chapter07/att_faces/'\n```", "```py\nfaces_dir = 'att_faces/'\n```", "```py\nfrom keras.preprocessing.image import load_img, img_to_array\n```", "```py\nimport numpy as np\n\nX_train, Y_train = [], []\nX_test, Y_test = [], []\n\n# Get list of subfolders from faces_dir\n# Each subfolder contains images from one subject\nsubfolders = sorted([f.path for f in os.scandir(faces_dir) if f.is_dir()])\n\n# Iterate through the list of subfolders (subjects)\n# Idx is the subject ID\nfor idx, folder in enumerate(subfolders):\n    for file in sorted(os.listdir(folder)):\n        img = load_img(folder+\"/\"+file, color_mode='grayscale')\n        img = img_to_array(img).astype('float32')/255\n        if idx < 35:\n            X_train.append(img)\n            Y_train.append(idx)\n        else:\n            X_test.append(img)\n            Y_test.append(idx-35)\n```", "```py\nX_train = np.array(X_train)\nX_test = np.array(X_test)\nY_train = np.array(Y_train)\nY_test = np.array(Y_test)\n```", "```py\nfrom matplotlib import pyplot as plt\n\nsubject_idx = 4\nfig, ((ax1,ax2,ax3),(ax4,ax5,ax6),\n      (ax7,ax8,ax9)) = plt.subplots(3,3,figsize=(10,10))\nsubject_img_idx = np.where(Y_train==subject_idx)[0].tolist()\n\nfor i, ax in enumerate([ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9]):\n    img = X_train[subject_img_idx[i]]\n    img = np.squeeze(img)\n    ax.imshow(img, cmap='gray')\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\nplt.tight_layout()\nplt.show()\n```", "```py\n# Plot the first 9 subjects\nsubjects = range(10)\n\nfig, ((ax1,ax2,ax3),(ax4,ax5,ax6),\n      (ax7,ax8,ax9)) = plt.subplots(3,3,figsize=(10,12))\nsubject_img_idx = [np.where(Y_train==i)[0].tolist()[0] for i in subjects]\n\nfor i, ax in enumerate([ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9]):\n    img = X_train[subject_img_idx[i]]\n    img = np.squeeze(img)\n    ax.imshow(img, cmap='gray')\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(\"Subject {}\".format(i))\nplt.show()\nplt.tight_layout()\n```", "```py\nfrom keras.models import Sequential, Input\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n\ndef create_shared_network(input_shape):\n    model = Sequential()\n    model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', \n                     input_shape=input_shape))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n    model.add(Flatten())\n    model.add(Dense(units=128, activation='sigmoid'))\n    return model\n```", "```py\ninput_shape = X_train.shape[1:]\nshared_network = create_shared_network(input_shape)\n```", "```py\ninput_top = Input(shape=input_shape)\ninput_bottom = Input(shape=input_shape)\n```", "```py\noutput_top = shared_network(input_top)\noutput_bottom = shared_network(input_bottom)\n```", "```py\nfrom keras import backend as K\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_square = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n```", "```py\nfrom keras.layers import Lambda\ndistance = Lambda(euclidean_distance, output_shape=(1,))([output_top, \n                  output_bottom])\n```", "```py\nfrom keras.models import Model\nmodel = Model(inputs=[input_top, input_bottom], outputs=distance)\n```", "```py\nprint(model.summary())\n```", "```py\nimport random \ndef create_pairs(X,Y, num_classes):\n    pairs, labels = [], []\n    # index of images in X and Y for each class\n    class_idx = [np.where(Y==i)[0] for i in range(num_classes)]\n    # The minimum number of images across all classes\n    min_images = min(len(class_idx[i]) for i in range(num_classes)) - 1\n    for c in range(num_classes):\n        for n in range(min_images):\n            # create positive pair\n            img1 = X[class_idx[c][n]]\n            img2 = X[class_idx[c][n+1]]\n            pairs.append((img1, img2))\n            labels.append(1)\n            # create negative pair\n            # list of classes that are different from the current class\n            neg_list = list(range(num_classes))\n            neg_list.remove(c)\n            # select a random class from the negative list. \n            # This class will be used to form the negative pair.\n            neg_c = random.sample(neg_list,1)[0]\n            img1 = X[class_idx[c][n]]\n            img2 = X[class_idx[neg_c][n]]\n            pairs.append((img1,img2))\n            labels.append(0)\n    return np.array(pairs), np.array(labels)\n\nnum_classes = len(np.unique(Y_train))\ntraining_pairs, training_labels = create_pairs(X_train, Y_train,\n                                              len(np.unique(Y_train)))\ntest_pairs, test_labels = create_pairs(X_test, Y_test,\n                                       len(np.unique(Y_test)))\n```", "```py\ndef contrastive_loss(Y_true, D):\n    margin = 1\n    return K.mean(Y_true*K.square(D)+(1 - Y_true)*K.maximum((margin-D),0))\n```", "```py\nmodel.compile(loss=contrastive_loss, optimizer='adam')\n```", "```py\nmodel.fit([training_pairs[:, 0], training_pairs[:, 1]], training_labels,\n          batch_size=64, epochs=10)\n```", "```py\nidx1, idx2 = 21, 29\nimg1 = np.expand_dims(X_test[idx1], axis=0)\nimg2 = np.expand_dims(X_test[idx2], axis=0)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nax1.imshow(np.squeeze(img1), cmap='gray')\nax2.imshow(np.squeeze(img2), cmap='gray')\n\nfor ax in [ax1, ax2]:\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\ndissimilarity = model.predict([img1, img2])[0][0]\nfig.suptitle(\"Dissimilarity Score = {:.3f}\".format(dissimilarity), size=30)\nplt.tight_layout()\nplt.show()\n```", "```py\nidx1, idx2 = 1, 39\nimg1 = np.expand_dims(X_test[idx1], axis=0)\nimg2 = np.expand_dims(X_test[idx2], axis=0)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,7))\nax1.imshow(np.squeeze(img1), cmap='gray')\nax2.imshow(np.squeeze(img2), cmap='gray')\n\nfor ax in [ax1, ax2]:\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\ndissimilarity = model.predict([img1, img2])[0][0]\nfig.suptitle(\"Dissimilarity Score = {:.3f}\".format(dissimilarity), size=30)\nplt.tight_layout()\nplt.show()\n```", "```py\nfor i in range(5):\n    for n in range(0,2):\n        fig, (ax1, ax2) = plt.subplots(1,2, figsize=(7,5))\n        img1 = np.expand_dims(test_pairs[i*20+n, 0], axis=0)\n        img2 = np.expand_dims(test_pairs[i*20+n, 1], axis=0)\n        dissimilarity = model.predict([img1, img2])[0][0]\n        img1, img2 = np.squeeze(img1), np.squeeze(img2)\n        ax1.imshow(img1, cmap='gray')\n        ax2.imshow(img2, cmap='gray')\n\n        for ax in [ax1, ax2]:\n            ax.grid(False)\n            ax.set_xticks([])\n            ax.set_yticks([])\n\n        plt.tight_layout()\n        fig.suptitle(\"Dissimilarity Score = {:.3f}\".format(dissimilarity), \n                      size=20)\nplt.show()\n```", "```py\nimport numpy as np\nimport random\nimport os\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\nfrom keras import backend as K\nfrom keras.preprocessing.image import load_img, img_to_array\n```", "```py\ndef euclidean_distance(vectors):\n    vector1, vector2 = vectors\n    sum_square = K.sum(K.square(vector1 - vector2), axis=1, keepdims=True)\n    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n\ndef contrastive_loss(Y_true, D):\n    margin = 1\n    return K.mean(Y_true*K.square(D)+(1 - Y_true)*K.maximum((margin-D),0))\n\ndef accuracy(y_true, y_pred):\n    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n```", "```py\ndef create_pairs(X,Y, num_classes):\n    pairs, labels = [], []\n    # index of images in X and Y for each class\n    class_idx = [np.where(Y==i)[0] for i in range(num_classes)]\n    # The minimum number of images across all classes\n    min_images = min(len(class_idx[i]) for i in range(num_classes)) - 1\n\n    for c in range(num_classes):\n        for n in range(min_images):\n            # create positive pair\n            img1 = X[class_idx[c][n]]\n            img2 = X[class_idx[c][n+1]]\n            pairs.append((img1, img2))\n            labels.append(1)\n\n            # create negative pair\n            neg_list = list(range(num_classes))\n            neg_list.remove(c)\n            # select a random class from the negative list. \n            # this class will be used to form the negative pair\n            neg_c = random.sample(neg_list,1)[0]\n            img1 = X[class_idx[c][n]]\n            img2 = X[class_idx[neg_c][n]]\n            pairs.append((img1,img2))\n            labels.append(0)\n\n    return np.array(pairs), np.array(labels)\n```", "```py\ndef create_shared_network(input_shape):\n    model = Sequential(name='Shared_Conv_Network')\n    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', \n                     input_shape=input_shape))\n    model.add(MaxPooling2D())\n    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n    model.add(Flatten())\n    model.add(Dense(units=128, activation='sigmoid'))\n    return model\n```", "```py\ndef get_data(dir):\n    X_train, Y_train = [], []\n    X_test, Y_test = [], []\n    subfolders = sorted([file.path for file in os.scandir(dir) if \n                         file.is_dir()])\n    for idx, folder in enumerate(subfolders):\n        for file in sorted(os.listdir(folder)):\n            img = load_img(folder+\"/\"+file, color_mode='grayscale')\n            img = img_to_array(img).astype('float32')/255\n            img = img.reshape(img.shape[0], img.shape[1],1)\n            if idx < 35:\n                X_train.append(img)\n                Y_train.append(idx)\n            else:\n                X_test.append(img)\n                Y_test.append(idx-35)\n\n    X_train = np.array(X_train)\n    X_test = np.array(X_test)\n    Y_train = np.array(Y_train)\n    Y_test = np.array(Y_test)\n    return (X_train, Y_train), (X_test, Y_test)\n```", "```py\n'''\nMain code for training a Siamese neural network for face recognition\n'''\nimport utils\nimport numpy as np\nfrom keras.layers import Input, Lambda\nfrom keras.models import Model\n\nfaces_dir = 'att_faces/'\n\n# Import Training and Testing Data\n(X_train, Y_train), (X_test, Y_test) = utils.get_data(faces_dir)\nnum_classes = len(np.unique(Y_train))\n\n# Create Siamese Neural Network\ninput_shape = X_train.shape[1:]\nshared_network = utils.create_shared_network(input_shape)\ninput_top = Input(shape=input_shape)\ninput_bottom = Input(shape=input_shape)\noutput_top = shared_network(input_top)\noutput_bottom = shared_network(input_bottom)\ndistance = Lambda(utils.euclidean_distance, output_shape=(1,))([output_top, output_bottom])\nmodel = Model(inputs=[input_top, input_bottom], outputs=distance)\n\n# Train the model\ntraining_pairs, training_labels = utils.create_pairs(X_train, Y_train, \n                                num_classes=num_classes)\nmodel.compile(loss=utils.contrastive_loss, optimizer='adam',\n              metrics=[utils.accuracy])\nmodel.fit([training_pairs[:, 0], training_pairs[:, 1]], training_labels,\n          batch_size=128,\n          epochs=10)\n\n# Save the model\nmodel.save('siamese_nn.h5')\n```", "```py\nimport cv2\nvideo_capture = cv2.VideoCapture(0)\n```", "```py\nimport math\nimport utils\nimport face_detection\n\ncounter = 5\n\nwhile True:\n    _, frame = video_capture.read()\n    frame, face_box, face_coords = face_detection.detect_faces(frame)\n    text = 'Image will be taken in {}..'.format(math.ceil(counter))\n    if face_box is not None:\n        frame = utils.write_on_frame(frame, text, face_coords[0], \n                                     face_coords[1]-10)\n    cv2.imshow('Video', frame)\n    cv2.waitKey(1)\n    counter -= 0.1\n    if counter <= 0:\n        cv2.imwrite('true_img.png', face_box)\n        break\n\n# When everything is done, release the capture\nvideo_capture.release()\ncv2.destroyAllWindows()\nprint(\"Onboarding Image Captured\")\n```", "```py\n$ python onboarding.py\n```", "```py\nname = input(\"What is your name?\")\n```", "```py\nfrom keras.models import load_model\nmodel = load_model('siamese_nn.h5', \n                    custom_objects={'contrastive_loss': \n                    utils.contrastive_loss, \n                    'euclidean_distance':utils.euclidean_distance})\n```", "```py\ntrue_img = cv2.imread('true_img.png', 0)\ntrue_img = true_img.astype('float32')/255\ntrue_img = cv2.resize(true_img, (92, 112))\ntrue_img = true_img.reshape(1, true_img.shape[0], true_img.shape[1], 1)\n```", "```py\nvideo_capture = cv2.VideoCapture(0)\npreds = collections.deque(maxlen=15)\n\nwhile True:\n    # Capture frame-by-frame\n    _, frame = video_capture.read()\n\n    # Detect Faces\n    frame, face_img, face_coords = face_detection.detect_faces(frame, \n                                 draw_box=False)\n\n    if face_img is not None:\n        face_img = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)\n        face_img = face_img.astype('float32')/255\n        face_img = cv2.resize(face_img, (92, 112))\n        face_img = face_img.reshape(1, face_img.shape[0], \n                   face_img.shape[1], 1)\n        preds.append(1-model.predict([true_img, face_img])[0][0])\n        x,y,w,h = face_coords\n        if len(preds) == 15 and sum(preds)/15 >= 0.3:\n            text = \"Identity: {}\".format(name)\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 5) \n        elif len(preds) < 15:\n            text = \"Identifying ...\"\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 165, 255), 5) \n        else:\n            text = \"Identity Unknown!\"\n            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 5)\n        frame = utils.write_on_frame(frame, text, face_coords[0], \n                                     face_coords[1]-10)\n    else:\n        # clear existing predictions if no face detected \n        preds = collections.deque(maxlen=15) \n\n    # Display the resulting frame\n    cv2.imshow('Video', frame)\n\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\n# When everything is done, release the capture\nvideo_capture.release()\ncv2.destroyAllWindows()\n```", "```py\n$ python face_recognition_system.py\n```"]