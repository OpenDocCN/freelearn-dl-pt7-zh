- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding the AI-Native Product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will go over the essential components for creating a strategy
    for building an AI product. This strategy will allow companies a process that
    will help them succeed in building an AI native tool. In [*Chapter 2*](B18935_02.xhtml#_idTextAnchor067),
    we briefly introduced the new product development stages, and in this chapter,
    we will build on that structure by focusing on the most important phases of introducing
    a new AI/ML native product: ideation, data management, research, development,
    and deployment. We will also address the main contributors to your AI/ML product
    team, as well as the tech stack that will empower them. AI native products begin
    and end with your data, and the roles you fill to support the team responsible
    for their creation will be critical to their success. When building an AI native
    tool, do your due diligence so that you aren’t being wasteful of your company’s
    finances and resources. A bad hire or incorrect tech investment can be costly
    in both time and resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter is primarily for **product managers** (**PMs**), technologists,
    and entrepreneurs coming into the AI space that want to inherently build AI tools.
    In this chapter, we will cover the following sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Stages of AI product development
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI/ML product dream team
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investing in your tech stack (further expanding on concepts from the preceding
    infrastructure section)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Productizing AI-powered outputs—how AI product management is different
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customization for groups—considerations for verticals and customer groupings
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selling AI—product management as a higher octave of sales
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll have a firm understanding of the most important
    considerations for every stage of your AI product development life cycle, as well
    as the development of your product team and the tech stack that will support them.
    You’ll also be able to think about some of the differences between traditional
    product management and AI product management, as well as some of the relevant
    elements when customizing your product for different audiences and how to craft
    a message that resonates with them.
  prefs: []
  type: TYPE_NORMAL
- en: Stages of AI product development
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Whether your organization is robust enough that you’re supporting multiple product
    teams for various stages of your AI product development or lean enough that you’re
    running on a skeleton crew that will see your product through each stage, you’ll
    want to be cognizant of what these different stages are so that you can define
    success through each phase. There are various schools of thought on what product
    management is or should be. We’ll do our best here to summarize the various phases
    in a way that best summarizes the core aspects of AI product development.
  prefs: []
  type: TYPE_NORMAL
- en: Either way, as an AI PM or leader of an AI product, you’ll want to consider
    how your product relates to each of the phases described in the following subsections
    so that you can identify the phase your product is currently in and what you need
    to do to bring it to full maturity.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 1 – Ideation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Just as with the traditional software product life cycle, as a PM you’ll be
    involved in the ideation phase. You might see this referred to as the innovation
    or design phase as well. Whatever you call it, this is the phase where the brainstorming
    on features is happening, and as a PM, you’re a key stakeholder in influencing
    the direction of the product. This is the phase where you’re also weighing the
    cost/benefit of incorporating various features, as well as the phase where you’re
    identifying what are the non-negotiables for your product.
  prefs: []
  type: TYPE_NORMAL
- en: One differentiator between traditional software development and AI product development
    in this phase is that the focus on ideation is paramount before continuing because
    the costs of investing in an AI product are great. Therefore, you want to be heavily
    focused on this phase before you move on in the product development life cycle.
    You don’t want to be going back to the drawing board after you’re in the thick
    of it with your product only to realize halfway through that you have a better
    idea of how to leverage AI for your product and have to lose months of work, time
    integrating a specific tech stack, storage, and expensive headcount.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, the work in the ideation phase results in getting a picture of what
    the product will look like using UX mockups/wireframes and surveys, as well as
    gathering the requirements you need to have in order to properly scope out your
    MVP. As a PM, perhaps the most important part of your role is understanding what
    the actual opportunity or problem is you’re addressing. This is true from the
    market perspective as well as the ML perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Where ML is concerned, you’re using AI to address six main types of problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Anomaly detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clustering/peer grouping
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommendations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ranking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting clear on which capital-P problem you’re addressing in the market, as
    well as which ML problem you’re solving based on the six competencies will be
    your most important task as a PM. Everything else is secondary.
  prefs: []
  type: TYPE_NORMAL
- en: As a PM, you’ll want to bring everyone together here. Your UX, data architects,
    data engineers, data analysts, data scientists, ML engineers, backend/frontend/full
    stack engineers, and leadership team will make up the key stakeholders that you’ll
    want to be involved in this phase so that every voice has a chance to be heard.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of the phase, you should have the following decided:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the outcome/requirements you must have to have a working MVP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How this MVP will be delivered
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Who will use this MVP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How they will use this MVP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A clear understanding of the problem/opportunity you’re addressing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phase 2 – Data management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you have a clear idea of what you’re building and why, you invest in setting
    up your product for success. Throughout this book, we refer to AI, ML, and **deep
    learning** (**DL**) products, but it’s important to remember the original colloquialism
    for any of these products is this: data product. At its core, any product that
    leverages AI/ML in any way is a data product first, and no data product can be
    good at anything without lots of quality, clean data. Organizing and expanding
    on the infrastructure needed to support all your data is the first applied step
    post-ideation. You’ll want to understand the requirements, constraints, and vocabulary
    required for a system that supports the data gathering and data processing that
    will be required to make your AI product function properly because you’ll be central
    in helping make decisions about this.'
  prefs: []
  type: TYPE_NORMAL
- en: In this phase, you’re also defining the best features to use in your AI/ML models.
    We discussed feature engineering in previous chapters. As a refresher, this is
    the idea that you’re looking for facets or *features* in your dataset that you’re
    primarily going to use for training your model. You can think of features as the
    individual columns of data elements that will be most important to include in
    your model preparation and training. You won’t want to leave this up to your data
    scientists, engineers, and architects either. As a PM, you’ll want to be intimately
    involved with and understand the various features that will be selected as the
    most relevant and final inputs in training the models that will make up your product.
  prefs: []
  type: TYPE_NORMAL
- en: Once that’s been decided, this is the phase where the data pipelines to support
    this data feed will be put in place. Having a good grasp on how you’re setting
    your organization and product up for sound data collection and preparation, data
    storage, and data pipeline practices will be crucial in this step as well. These
    data practices will allow you to leverage data for internal use cases and traditional
    analytics, and they will also serve as the true foundation of your AI product.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 3 – Research and development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, you’ve got your plan, you’ve got your data organized, and you’re ready to
    start building. In this phase, you’re **researching and developing** (**R&D**)
    the actual structure and substance that will make up your AI product. R&D can
    be synonymous with experimentation. You aren’t going to build a product around
    one model, and no matter how intuitive and talented your data scientists or ML
    engineers are, they likely won’t go with the first model that occurs to them either.
    We’ve gone over the various ML models in previous chapters, and we’ve mentioned
    a few times that most of the time, ensembles of models are what get used in products.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *Deployment strategies* section of [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012),
    we introduced the concept of **A/B testing**, which is sometimes referred to as
    split testing. Essentially, the process is relevant here as well because there
    will be a fair amount of A/B testing and evaluation in this process, so you’ll
    want to understand the basics of A/B testing as well as data distributions, cohorts,
    confidence intervals, and other probabilistic concepts. A/B testing is a common
    testing method used in ML, and if you’d like to get into this topic as it relates
    to AI/ML products, we recommend this resource: [https://mlops.community/the-what-why-and-how-of-a-b-testing-in-ml/#:~:text=An%20A%2FB%20test%2C%20also,guesswork](https://mlops.community/the-what-why-and-how-of-a-b-testing-in-ml/#:~:text=An%20A%2FB%20test%2C%20also,guesswork).'
  prefs: []
  type: TYPE_NORMAL
- en: This phase also means there’s a fair amount of experimentation that needs to
    take place before a model is selected for your specific use case. If you’re hiring
    the most experienced data scientists and ML engineers and you see them going back
    and forth with different models, seemingly unable to choose and wanting to further
    experiment until they see performance they can get on board with this is normal.
    Hiring a talented, knowledgeable, and experienced headcount is only one side of
    the coin with AI products.
  prefs: []
  type: TYPE_NORMAL
- en: Sure—they have the know-how, but they aren’t business experts. They’re experts
    in modeling and creating algorithms that will fit the use case the business experts
    outline for them. Use the R&D phase as a way to give your data scientists and
    ML engineers the proper direction, and manage expectations with them. You’ll want
    to properly set these hires up with the proper tools, stakeholders, and resources
    to make them successful. There are other considerations as well. Let’s take the
    notion of performance. As a PM, it could be up to you, rather than the data scientists,
    to decide what level of performance or precision level would be most acceptable
    for the customers you’re trying to serve. Establishing these thresholds and expectations
    is something you, as the AI PM, will be regularly doing with your team.
  prefs: []
  type: TYPE_NORMAL
- en: Phase 4 – Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’re using deployment as an umbrella term here for everything that comes after
    the R&D phase. At this point, you’ve settled on a model or a collection of models
    that satisfies your products’ ideation and MVP requirements, is supported by your
    data infrastructure, and has been thoroughly tested. Now, you’re ready to build
    the supporting infrastructure to make sure this model and its outputs can be integrated
    into the broader product that your end users will experience. This is the deployment
    phase where you’re marrying the work of your data scientists and ML engineers
    to the work of your full stack developers and actually integrating it into the
    greater product that will support these AI/ML outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Your product may have many *features*, and only a couple of them may be *AI
    features*, or the very heart of your product could be ML. Regardless of how rooted
    in AI your product is, you will need to deploy the ML findings from the models
    you’ve invested time in building in the context of the greater UI/UX. Because
    of this integrative dance that has to happen between your AI/ML code and your
    production code, you might go through your own R&D phase with deployment as well.
    Selecting the proper ML model and technique is a separate process from selecting
    the proper way to showcase and use the outputs of that ML R&D and how to maintain
    those outputs.
  prefs: []
  type: TYPE_NORMAL
- en: The broader context of the deployment phase is really to create continuity and
    delivery of the substance of your ML outputs. This is also where you’ll be creating
    processes and structure around the continuous maintenance and delivery of your
    product that were outlined in [*Chapter 2*](B18935_02.xhtml#_idTextAnchor067).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we’ve covered the various phases of the AI product development life
    cycle, let’s focus on the folks that will make the magic happen in the first place:
    the AI product team. Building a new team for a new AI product is tricky, and it
    can be tough to adequately hire for the needs your product will have. Every product
    and company will have different needs, so we will try to remain as objective as
    possible in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML product dream team
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be spending some time understanding the various roles
    that will empower your AI product team to maximize success. We’ll also be grouping
    these functions across the stages we outlined in the preceding sections so that
    we can get a sense of when these roles come into play. Note that not all these
    roles will be necessary in your organization. Every organization is different
    and will have different needs. Use your discretion when building your AI teams.
    You may include other stakeholders in your AI program, but the following is a
    relatively complete list of the main stakeholders you will want to include in
    your hiring process as your AI/ML product team grows.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll now look at a cumulative list of roles that will likely apply to your
    ideal AI dream team. We have listed the roles in order of common appearance.
  prefs: []
  type: TYPE_NORMAL
- en: AI PM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Here, we start on our journey of creating a dream team. All organizations are
    different. Some won’t hire PMs until they’re further along with building an MVP.
    Others might hire *founding* PMs. Others might already be mature organizations
    and are just ready to launch their first AI product. No matter where your organization
    lies, you will eventually need all the activities required to support an AI/ML
    product to be centralized into one person.
  prefs: []
  type: TYPE_NORMAL
- en: A product is a living breathing ecosystem in and of itself, so having a point
    person to go to that can be responsive to and responsible for the needs of various
    parts of that ecosystem will be important. Because of our own bias, we will place
    the AI PM firmly at the beginning of this list. Finding someone that’s worked
    with or specialized in AI/ML products in the past will serve as your due diligence
    for making sure your product is properly set up for success. We consider it ideal
    to hire for this role before you start hiring for other roles to maintain a cohesive
    vision across your product. Having an AI/ML PM on board before you begin the implementation
    of your product means that person is aware of the historical discussions and market
    influences to support your product best.
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML/data strategists
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This will be more of a consultative role for most companies. Ideally, this person
    would help with the acquisition of talent, along with developing methodologies
    and workflows that would support your AI/ML function/team in its entirety. This
    might be a role that you hire for at the start of your AI/ML journey to help with
    key decisions about who to hire for various roles in your AI program or product
    team, what should be included in your tech stack, and how certain workflows should
    be set up with regard to experimentation and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: This may be someone that stays on for the planning and initial phases of your
    product development (first 6-8 months) or someone that you keep on staff as a
    PM in more resourced environments. This person will also ideally be well versed
    in AI ethics principles. If you’re a start-up and you’re creating a company and
    a product from scratch, this might be your technical cofounder who is able to
    act as your technical decision-maker. This role could also be referred to as a
    data architect role.
  prefs: []
  type: TYPE_NORMAL
- en: Data engineer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have an architect for how the AI product/program team will function; now,
    we start laying down the foundations for our data pipelines with a data engineer
    based on the blueprint that’s come out of our collaboration with an AI strategist.
    If you’re setting up an AI product from scratch, look for a data engineer that
    can help support your team’s choices of data engineering philosophies.
  prefs: []
  type: TYPE_NORMAL
- en: Will you be using a data mesh, a data fabric, a data lake, or a data warehouse?
    Because you’re starting this function from the beginning for an AI/ML native product,
    you’ll want to hire someone with the confidence and experience to help guide you
    with a proper setup. Migrating and changing your data architecture can be expensive
    and time-consuming. If you get the help you need properly at the beginning, it
    will save you potential headaches later and give you a sustainable, scalable infrastructure
    to grow with confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Data analyst
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A path for many companies will be to build on an already established foundation
    of data analytics before they start expanding on those analytics with ML. The
    traditional order of operations is gaining clarity and control over your data
    by hiring amazing data analysts first that will quickly figure out what’s interesting
    and worth exploring in the data you already have. In this role, you’re looking
    for someone that’s able to quickly analyze your swathes of data with curiosity
    and exploration.
  prefs: []
  type: TYPE_NORMAL
- en: This is the person that might be your expert query maker, working in concert
    with your data engineer to feed queries through the workflows you establish to
    power your AI/ML product. These will also be the hires that will improve on the
    analytics you use internally to improve internal processes as well as the analytics
    you pass on to your customers through your product or platform’s dashboard UI/UX.
  prefs: []
  type: TYPE_NORMAL
- en: Data scientist
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have the ability to generate and move data, you’re ready to start experimenting
    with that data, and you’ll eventually need to collaborate with someone that’s
    an expert at model building. In order to be an expert at model building, you have
    to also be an expert at ML algorithms, big data, statistics, and programming.
    Most companies are coding in Python, so unless you’re serving academic circles,
    we recommend sticking with Python. This role doesn’t just need technical skills—it
    also needs soft skills because it’s a collaborative role, and it also communicates
    heavily with leadership.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you’re hiring a data scientist to execute the business goals
    you’ve established early on. This person should have a strong business acumen
    and must be able to understand the impact and purpose of their work. They should
    also have the expertise to technically and functionally realize the algorithmic
    solution that best fits your organization, data, and product. This role is inherently
    elusive to fill because finding someone with competence and experience in all
    these areas proves to be difficult for most organizations, particularly when you’re
    in the early phases of creating a start-up or a product from the beginning.
  prefs: []
  type: TYPE_NORMAL
- en: ML engineer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, you’ve got a firm handle on your strategy, your data architecture,
    the capabilities of your customer/product data, and the models you’ll be using
    in your product. Your goals and objectives have been outlined and confirmed by
    the technical stakeholders on your leadership team. Taking a cumulative approach,
    by this point you can outsource the execution of this planning-heavy part of establishing
    your AI/ML product or program. ML engineers are able to use the models and algorithms
    whipped up by your data scientists by incorporating (coding) them into the workflows
    or code repository for your product.
  prefs: []
  type: TYPE_NORMAL
- en: Again, because this is a role that will support the AI native product, this
    role will have the burden of getting in the weeds with your data and algorithms
    to see what comes out. This person can expect to do a lot of trial and error as
    they feel their way toward acceptable performance. Your ML engineer will use the
    data that’s been vetted by your data analysts and marry it with the algorithms
    your data scientists have selected in their work. Nothing really matters until
    you actually deploy something into production. The act of putting it all together
    and ultimately deploying the code that supports all the prior functions falls
    on the applied ML engineer that makes the dream team. Depending on your organization,
    you might have to make a choice between a data scientist and an ML engineer.
  prefs: []
  type: TYPE_NORMAL
- en: Frontend/backend/full stack engineers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Various manifestations of the preceding five roles exist in many capacities.
    Your particular organization might not need them all, all at once. But one thing’s
    for sure: no matter how you navigate the previous five roles, you will always
    need full stack engineering to support the AI/ML work that needs to be done before
    it’s time for deployment. ML engineers are able to add the AI/ML functions to
    your code base, but you’ll need built-out engineering teams to be supporting your
    product end to end. Your frontend, backend, and full stack engineers will collaborate
    with your ML engineers and data scientists often for the AI/ML native product.'
  prefs: []
  type: TYPE_NORMAL
- en: Structuring these teams so that they’re working intimately and have deep trust
    built between them will be important. Most of the time, any AI/ML product will
    have plenty of features and needs that don’t have anything to do with the AI/ML
    aspect of your product. You’ll need a built-out engineering team that manages
    the tasks and epics in your sprints outside of the AI/ML function. These are the
    folks that are going to get you set up with a working MVP of your product that
    you can iterate on as you continue in your product management journey. You don’t
    have a working product until you’re in this phase.
  prefs: []
  type: TYPE_NORMAL
- en: UX designers/researchers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The manifestation of your MVP is your product’s starting point. You can’t iterate
    a product that doesn’t yet exist, and reaching MVP level allows you a confident
    start. Depending on your organization and philosophy, you may already have leveraged
    UI/UX feedback during the planning phases. Perhaps you did have a product designer
    on board early on, or perhaps you worked with a UX researcher when you were doing
    your early market reconnaissance. But once you have a working product MVP, you’re
    able to establish a baseline with your users (or beta users) and get a sense of
    how they’re receiving value from your product.
  prefs: []
  type: TYPE_NORMAL
- en: UI/UX is all about how to most efficiently deliver value to your end users.
    Minimizing sources of frustration and inspiring moments of delight is the primary
    focus of this function. A good UI/UX designer or researcher will guide the visible
    changes of your product that your end users will experience. We recommend having
    this function be an ongoing engagement so that you can learn from your users as
    you build further iterations of your product that align most closely with what
    your users—and, by extension, their buyers—will approve.
  prefs: []
  type: TYPE_NORMAL
- en: Customer success
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having proper channels for listening via UI/UX design and research is important,
    but eventually, your customers will want you to talk back—and not just through
    the product itself. You might not have a huge need for a customer success team
    if you’re creating a B2C product, but if you’re selling an AI/ML product to other
    businesses, you certainly will. The customer success team exists to make sure
    your customers are properly using your product and receiving the intended value
    from it.
  prefs: []
  type: TYPE_NORMAL
- en: They’re also a great source of feedback for your data and AI/ML functions. The
    customer success team offers the feedback loop that an AI/ML product will need
    to build and improve over time. They’re also incredibly helpful at helping to
    expand on product features and collaborating with products on which potential
    new features end users might really love to see. If you’re an AI/ML PM, make sure
    you have a warm and open relationship with the customer success team because they’re
    your biggest source of knowledge on the ground. They’re the ones actually talking
    to your customers!
  prefs: []
  type: TYPE_NORMAL
- en: Marketing/sales/go-to-market team
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is another one that will likely be involved at the beginning and throughout
    your product development journey. We’re lumping in sales and marketing as **go-to-market**
    (**GTM**) because this is essentially what this function does. It communicates
    out to your market: the entire landscape of your potential customers. This is
    where you’ll combine your skill sets to optimize your product language fit or
    the message your market will see about your product. You’ll be using your GTM
    meetings to decide on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Terminology about your product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How you’re going to position it in the market
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much of your proprietary tech and algorithmic magic you’re going to allow
    your salesforce to discuss with potential customers on demos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much explainability you’re going to offer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How you’re going to communicate about technical decisions you’ve made about
    your product
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much information about your product you’re going to shield from the world
    in the spirit of competition
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you build and improve your product, your GTM team will stick with you, and
    you’ll be regularly in the flow of discussing how you’re going to communicate
    about upcoming features or releases.
  prefs: []
  type: TYPE_NORMAL
- en: Investing in your tech stack
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding the tech stack and languages that will give you the most flexibility
    is the most important part of beginning your tech stack journey. In this phase,
    you’ll work closely with your data science and data engineering teams to create
    the proper channels for delivering the relevant data to your models in a reliable
    way so that all the other stakeholders involved in building your product can trust
    the infrastructure in place.
  prefs: []
  type: TYPE_NORMAL
- en: Managing ML experimentation is a formidable undertaking in and of itself, and
    we’ve seen tools such as MLflow and Weights & Biases used for managing versions
    and experiments. You can also use tools such as Cloudera Data Science Workbench,
    Seldon, Dataiku, DataRobot, Domino, SageMaker, and TensorFlow to support your
    data scientists with a workstation for building, experimenting with, deploying,
    and training ML models.
  prefs: []
  type: TYPE_NORMAL
- en: As a PM, you’re regularly thinking about the value of building something compared
    to the cost or effort required to build it. This is why you can’t ignore your
    tech stack. It might be tempting to say, well, a CTO can decide on which tech
    stack to invest in, but it’s not so easy to outsource if this tech stack is directly
    involved with the building of your product in any way. Empowering your stakeholders
    impacts the effort and cost that goes into your AI product, so you’ll want to
    make sure you’re involved in the making of these key decisions.
  prefs: []
  type: TYPE_NORMAL
- en: The biggest consideration in your tech stack is paying attention to properly
    setting up your infrastructure to handle the scale of your data as your business
    grows. Building the right tech stack to handle the cleansing, storing, securing,
    preparing, and monitoring of your data will be the foundation for supporting your
    AI program or product team. This goes hand in hand with building your data strategy.
    Beyond this, you’ll seek to create a collaborative environment for the many roles
    in your AI program to participate in. Between the analysts, data scientists, ML
    engineers, broader engineering team, and any leaders and consultants you include
    in the formation of your AI team, you’ll want to create channels for all these
    various members to communicate and collaborate.
  prefs: []
  type: TYPE_NORMAL
- en: As is the case with many AI programs, you’ll also be looking for ways to automate
    your processes and workflows. AI/ML technologies are consistently changing and
    improving, so you’ll make a lot of traction when you invest in applying automation
    for your AI program itself. Use the brainpower of your talented staff to make
    higher-level decisions and use their complex problem-solving abilities. Anything
    that can be automated, refreshed, or standardized should be. This aligns with
    the precepts of agile and lean development. Refactoring and making elegant improvements
    in your code should be done proactively, so make sure to plan this into your springs
    responsibly and use the advantages of your tech stack in your favor to set your
    team up for success.
  prefs: []
  type: TYPE_NORMAL
- en: Having the right process, talent, and tech stack to power your AI product is
    just the beginning. You’re bringing all the necessary elements together to create
    AI-powered outputs. Those outputs will be integrated into your product somehow
    in the form of features that your customers will experience the benefit of. The
    next section will be about understanding how to orient the outputs of your AI/ML
    program and team in a way that’s most evident to your customers.
  prefs: []
  type: TYPE_NORMAL
- en: Productizing AI-powered outputs – how AI product management is different
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be exploring the difference between product management
    for traditional products and product management for AI/ML products. At first glance,
    it may seem that AI/ML products aren’t that different from traditional products.
    We’re still creating a baseline of value, use, performance, and functionality
    and optimizing that baseline as best we can. This is true for every product as
    well as for the greater practice of product management, and this won’t change
    just because our product works with AI.
  prefs: []
  type: TYPE_NORMAL
- en: The true differentiator when it comes to AI products is you’re essentially productizing
    a service. Think about it for a moment. In order for AI to work, it has to learn
    from your (or your customer’s) data. Different models might work better on different
    kinds of data. Different datasets will require different hyperparameters from
    your models. This is the nature of AI/ML. In a way, this means that you could
    find yourself in a situation where the way you build and structure your product
    could even change fundamentally from one customer to another, especially at first
    when you have very few customers.
  prefs: []
  type: TYPE_NORMAL
- en: What this effectively means is you’re understanding how all your customers are
    benefiting from the AI/ML *service* you’re providing your customers and establishing
    a standard procedure for recreating that process so that all your customers are
    able to experience the highest benefit. The general advice when productizing a
    service is first to find a niche or a specific cohort of customers to reach. If
    you can understand how AI is most helping your customers through your product
    and you’re able to focus on what value means for your customers’ success, you’ve
    begun the first steps of productizing.
  prefs: []
  type: TYPE_NORMAL
- en: The main focus will then be on how to best structure your product and internal
    processes so that you’re not starting from scratch with every customer. This will
    be exploratory at first. Perhaps certain models are working better with some customers’
    data than others. Perhaps there are specific use cases that didn’t arise until
    one of your customers asked for them. The basic idea of productizing is finding
    something that has value and brainstorming to understand where else you can leverage
    a previous project, output, or process for the betterment of all. Waste not, want
    not. If you can recycle something for the benefit of your collection of customers,
    it will add to the success and collective love your product receives.
  prefs: []
  type: TYPE_NORMAL
- en: Productizing services is a familiar concept in consulting where consultants
    are working project to project and often have to create new engagements with clients
    with an almost blank slate. But given that our own minds are pattern detection
    machines, eventually, we start to see similar requests come in or similar use
    cases pop up. Creating a repeatable process for certain types of customers, verticals,
    profiles, or use cases is the very essence of productizing. This is exactly what
    we’re doing with AI/ML products. This is also a way to better anticipate how and
    why your customers are coming to you and your product specifically so that you
    know how to share successes and case studies that apply directly to them. The
    act of productizing will also immensely empower your marketing, sales, customer
    success, and broader GTM teams.
  prefs: []
  type: TYPE_NORMAL
- en: As we have seen in this section, AI/ML product integration is about finding
    the balance between the outputs of your models and the use cases or groups those
    outputs are trying to serve. Many PMs come out of the experience of building with
    AI/ML finding they may need to customize their product for certain cohorts. In
    the following section, we’re going to address the need for AI customization should
    it arise.
  prefs: []
  type: TYPE_NORMAL
- en: AI customization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Through the act of productizing, you’ll likely start to create groupings or
    cohorts for your product. You might find that certain models work best for certain
    kinds of customers and build a structure around that. The act of grouping your
    offering into use cases and communicating differently or optimally to those cohorts
    builds on the wisdom gained from productizing. Taking that a step further, you’ll
    then naturally start to verticalize.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the various considerations for business models, verticals, and
    special customer groupings will be an important part of how you go to market with
    your product. For instance, if you’re supporting a B2C or consumer product, you’ll
    want to invest more in information gathering by acquiring more of your end users’
    direct feedback for your ideation phase. Because you’ll be creating a product
    that’s going to be experienced by potentially millions of users, you will want
    a strong handle on the preferences and desires of those end users so that your
    product is most aligned with the *voice* of your customer. A product such as this
    could also benefit from experimenting and iterating fast so that you can get a
    product out and start gathering feedback on it before you’re even getting your
    desired level of performance from the AI/ML models themselves.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re supporting B2B or business-facing apps, you might spend more time
    on the ideation and deployment of that product so that you can zero in on the
    specific set of customers you’re hoping to win over. With business applications,
    you might be creating a very complex product that does a number of overlapping
    operations but for a very niche group of users. You might also have a wide variety
    of well-documented tools that offer similar solutions to your customers, so maintaining
    feature parity with the market could be more of a factor for this line of products.
  prefs: []
  type: TYPE_NORMAL
- en: The size of your business will also impact how you show up in your organization
    as an AI PM. For instance, if your organization is large enough, there might be
    a separate PM allocated to every version of the product cycles mentioned previously.
    There could also be various PMs that support various aspects of the functionality
    of your AI product. There could also be a PM that’s devoted only to the AI features
    of the product with a higher-level PM or product director overseeing the entire
    suite. In a smaller organization, there might be only one AI PM overseeing the
    entirety of the product throughout all the phases of the life cycle or ideating
    to continuously maintain that product.
  prefs: []
  type: TYPE_NORMAL
- en: Another differentiation between the sizes of companies lies in the data itself.
    Depending on how large your company is, the access or quality of the data you
    have can have varying degrees of difficulty. As a PM, making this data available
    and in a usable condition could prove more difficult and take up more of your
    time than it would at a start-up because of having to get access to siloed groupings
    of data that require administrative governance permissions. Even getting that
    data to fit together could be tough, depending on the conventions of each silo.
    Conversely, a start-up might have a hard time even amassing enough users and have
    issues with data volumes. Data availability and quality are notorious issues for
    companies big and small.
  prefs: []
  type: TYPE_NORMAL
- en: If you have a highly verticalized product, this could also impact how your work
    shows up as an AI PM. For instance, having a product that’s specialized for healthcare,
    fintech, or education might necessitate a PM that has domain knowledge and expertise
    in these different verticals. Even if it’s the same PM that’s supporting this
    product for those verticals, you’ll likely see it as three different versions
    of your product because the weights, thresholds, and performance metrics for these
    specific verticals will likely be drastically different. Depending on the type
    of product you’re offering, you might even see a hyper-specialization to the point
    where the product is customized heavily even for every customer you have! This
    might be the case for highly tailored ML products that have to be fit to your
    clients’ data.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, the work of building products and crafting them for specific audiences
    is all about creating a product that sells. We need to be able to understand our
    audience—the buyers and users of our products—in order to build something that
    will truly serve them. In the next section, we will discuss the notion of selling
    and what that means from a product management perspective.
  prefs: []
  type: TYPE_NORMAL
- en: "Selling AI – product management as a higher octave \Lof sales"
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With AI product management, you’re selling in a number of ways. There’s the
    traditional sense of selling, which is this: creating a product that your market
    wants to buy. This is inherent in any traditional PM role. Your understanding
    of your market, your product, and your salesforce is one where you’re confident
    in the solution you’re bringing to market, your solution’s performance, and your
    salesforce’s ability to articulate the value of the solution you’re building.
    Then, there’s the opportunity and challenge AI presents: the ability to sell the
    AI functionality itself.'
  prefs: []
  type: TYPE_NORMAL
- en: Earlier in this book, we mentioned the difficulty AI/ML projects have in being
    deployed into production; this happens for a number of reasons, but among the
    top reasons is the inability to sell the value of AI to the broader organization.
    This will be incredibly relevant to any PM that’s looking to work with AI products
    because you will have to develop this intuition and ability to sell your product
    to the outside market as well as to your internal stakeholders and leaders. This
    is the case whether you work at a large organization or a small start-up.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part of the work of selling AI within your organization is going to directly
    correlate with how you empower your teams. If you want to be successful in evangelizing
    your AI product, we have the following advice:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure there’s alignment on the data strategy and data architecture side.
    Remember: AI products are data products, and if you don’t have sound practices
    on the data end, you’ll have to reverse engineer your data pipelines, and that’s
    not fun. Part of this is also making sure there is a sound data strategy that
    will grow as your business and product scale to support more users and customers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure that you are not focusing so much on the technology and tech stack
    that you’re forgetting about tying the use of that technology to impact. Remind
    yourself why you want to use AI for your product. What value is it providing your
    product and, by extension, your organization and customers? No sale is successful
    without perceived value. People that work in sales understand they need to be
    successful in communicating the value of their product before you’ll open your
    wallet. You’ll have to have the same mentality if you’re working in product management.
    This isn’t just relevant for your customers but for your leadership team as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Make sure you’re embracing experimentation. As we’ve said countless times:
    AI/ML is a highly iterative process. You can’t load up your practitioners and
    the models themselves with expectations and results without first allowing them
    the space to experiment. Beautiful, miraculous things can happen with AI/ML but
    first they need to be coaxed through iteration. Flexibility and curiosity will
    also be important when you’re considering various ML models that will support
    your product as it scales as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As with other product roles, the role of an AI PM is vast and requires knowledge
    and competencies in several areas. Having an understanding of how an AI product
    is created and brainstormed allows you to meet your market’s needs with leading-edge
    technology. Knowing how to best support the data end of such a product means you
    are setting up the most integral members of your AI team for success. Allowing
    your hands-on AI practitioners the space and ownership to experiment and report
    their findings to you and your leadership creates the proper feedback loop between
    tech and leadership to see your product flourish. Finally, creating the proper
    deployment tech stack and process ensures your end users are benefiting from your
    product in the way you originally intended and gives you the perfect board with
    which to dive into the day-to-day of iterating on your product until its sunset
    days.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The work of a PM is never done. There are always more voices, perspectives,
    and considerations to take in. Coordinating all the stakeholders, technology,
    leadership, market analysis, customer feedback, and passion for a product isn’t
    an easy task. In this chapter, we covered the stages of the AI product development
    life cycle and the various roles that can make up your AI product dream team.
    We also covered the tech stack that can help that team build a product, and various
    focus areas to help that product stand out and resonate with the cohorts of groups
    that will be buying and using your product. Hopefully, this chapter has helped
    you understand what the most important factors are when you set out to build an
    AI native product.
  prefs: []
  type: TYPE_NORMAL
- en: As long as you’re hiring the right people for the roles you have open in your
    AI program, doing your due diligence to uncover the right strategy for tech stack
    adoption, structuring your product in a way that benefits your customers according
    to their verticals, and working with your leadership and greater GTM team to build
    a product that meets a need in your market, you’ll be set up for success. You’re
    likely to do better than you think.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The What Why and How of A/B Testing in Machine Learning: [https://mlops.community/the-what-why-and-how-of-a-b-testing-in-ml/#:~:text=An%20A%2FB%20test%2C%20also,guesswork](https://mlops.community/the-what-why-and-how-of-a-b-testing-in-ml/#:~:text=An%20A%2FB%20test%2C%20also,guesswork'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'TFX: [https://www.tensorflow.org/tfx](https://www.tensorflow.org/tfx'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Seldon: [https://www.seldon.io/](https://www.seldon.io/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Dataiku: [https://www.dataiku.com/](https://www.dataiku.com/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'DataRobot: [https://www.datarobot.com/](https://www.datarobot.com/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Domino Data Lab: [https://www.dominodatalab.com/](https://www.dominodatalab.com/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloudera Data Science Workbench: [https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html](https://www.cloudera.com/products/data-science-and-engineering/data-science-workbench.html'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Weights and Biases: [https://wandb.ai/site](https://wandb.ai/site'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'ML Flow: [https://mlflow.org/](https://mlflow.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
