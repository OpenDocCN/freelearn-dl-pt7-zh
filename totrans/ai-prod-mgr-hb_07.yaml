- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Productizing the ML Service
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 产品化ML服务
- en: In [*Chapter 6*](B18935_06.xhtml#_idTextAnchor175), we briefly touched upon
    the notion of productizing and what that means for AI outputs in the *Productizing
    AI-powered outputs – how AI product management is different* section. We will
    be expanding on that concept in this chapter by exploring the trials and tribulations
    that may come up when building an AI product. Rather than thinking of AI products
    as traditional software products, it helps to think of them as a service that
    you’re learning to productize. What this refers to is the ability to create a
    consistent workflow that you can rely on to deliver consistent results in the
    way traditional products demand.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B18935_06.xhtml#_idTextAnchor175)中，我们简要讨论了产品化的概念以及这对AI输出的意义，在《产品化AI驱动的输出
    – AI产品管理有何不同》一节中提到过。我们将在本章中进一步扩展这一概念，探讨在构建AI产品时可能遇到的挑战与困境。与其将AI产品视为传统的软件产品，不如将其视为一个你正在学习如何产品化的服务。这意味着能够创建一个你可以依赖的、稳定的工作流程，以像传统产品一样提供一致的结果。
- en: We will be going more in depth into product management principles and aligning
    them to the idiosyncrasies of AI/ML services.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将深入探讨产品管理原则，并将其与AI/ML服务的特性对齐。
- en: 'By the end of this chapter, we will have an understanding of the following
    topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，我们将了解以下主题：
- en: Understanding the differences between AI and traditional software products
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解AI与传统软件产品之间的差异
- en: B2B versus B2C – productizing business models
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: B2B与B2C – 产品化商业模型
- en: Consistency and AIOps/MLOps – reliance and trust
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一致性与AIOps/MLOps – 依赖与信任
- en: Performance evaluation – testing, retraining, and hyperparameter tuning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能评估 – 测试、重训练和超参数调优
- en: Feedback loop – relationship building
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 反馈循环 – 建立关系
- en: Understanding the differences between AI and traditional software products
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解AI与传统软件产品之间的差异
- en: There are a number of differences between traditional software products and
    AI/ML products. In the following subsections, we’ll first go over how they’re
    similar, and then we’ll note the differences between the two to give us a well-rounded
    sense of what to expect when you’re product managing an AI/ML product. This will
    help us establish a baseline as well as a deviation from traditional PM work.
    When you’re a PM, you’re often tasked with being the person to maintain an intuition
    about your product and how it will grow and evolve through the process of building
    and shipping the product and working with your engineering team.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 传统软件产品与AI/ML产品之间有许多不同之处。在以下小节中，我们将首先讨论它们的相似之处，然后指出它们之间的差异，从而帮助我们全面了解在进行AI/ML产品管理时应该期待什么。这将帮助我们建立一个基准，并与传统产品管理工作有所区别。当你是产品经理时，你通常需要保持对产品的直觉，理解它如何在构建、发布产品以及与工程团队合作的过程中不断发展和演变。
- en: Part of that intuition will relate to how you will market and sell your product,
    what kinds of customer needs and issues your product can anticipate, as well as
    potential problems that might arise as you start to get into the weeds with building
    and marketing your AI product. Many PMs might not be aware of the demands AI/ML
    products will place on them, and this section is primarily aimed at helping PMs
    build this intuition as they start to navigate the world of AI/ML products.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 直觉的一部分将与如何营销和销售你的产品、你的产品能够预见的客户需求和问题，以及当你开始深入构建和营销AI产品时可能出现的潜在问题有关。许多产品经理可能没有意识到AI/ML产品对他们的要求，本节主要帮助产品经理在开始接触AI/ML产品的世界时建立这种直觉。
- en: It’s also important to note that traditional software products and AI products
    are increasingly blurring together. This is because most software companies have
    already started to integrate AI/ML into their existing products or launched AI
    native products. PMs that cover a wide variety of products will want to deepen
    their knowledge of AI/ML as a way to stay competitive within their own fields,
    whether they plan to go deep into AI or not. Understanding the differences between
    traditional software and AI products isn’t so much about comparing two disparate
    groups of products. It’s helpful in this case as well, but this is a macro trend,
    and the biggest reason for understanding the two is to anticipate how all products
    will evolve with AI. Let’s begin by checking out how traditional software products
    are similar to AI.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意的是，传统软件产品和 AI 产品正变得越来越难以区分。这是因为大多数软件公司已经开始将 AI/ML 集成到现有产品中，或者推出了原生的 AI
    产品。覆盖多种产品的产品经理（PM）将希望深入了解 AI/ML，以便在自己的领域保持竞争力，无论他们是否打算深入 AI。如果想了解传统软件和 AI 产品之间的差异，重点不在于比较这两类截然不同的产品，而是要认识到这是一个宏观趋势，理解这两者的主要原因是预测所有产品如何随着
    AI 的发展而演变。我们先来看看传统软件产品是如何与 AI 相似的。
- en: How are they similar?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它们有哪些相似之处？
- en: There are a number of similarities between traditional software products and
    AI products because, fundamentally, AI products are traditional software products
    with a productized AI/ML service built in. For this reason, the similarities we
    will outline here involve agile product development as well as data. Native AI
    products, along with the outputs from the AI pipelines that support them, follow
    the same building process most traditional software products use. They are also
    built with a heavy focus on the data that powers them. This is still true for
    traditional software products.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 传统软件产品和 AI 产品之间有许多相似之处，因为从根本上讲，AI 产品是内置了产品化 AI/ML 服务的传统软件产品。因此，我们在这里概述的相似性涉及敏捷产品开发以及数据。原生
    AI 产品及其支持的 AI 流程输出遵循与大多数传统软件产品相同的构建过程。它们的构建也高度关注驱动它们的数据。这一点对于传统软件产品同样适用。
- en: Agile development
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 敏捷开发
- en: In traditional software development, you’re going to follow some methodology
    to ideate, keep track of your work, and stay consistent with some framework or
    schedule. Most software companies these days don’t use waterfall methodology anymore
    and have instead opted to use some version of agile, scrum, or lean methodology.
    This means most software companies are using an iterative and experimental approach
    to building and shipping products. They’re taking large overarching business goals
    and translating those goals into specific tasks that will then amount to deliverables
    by the end of any given sprint. Once they have these deliverables done, they undergo
    a process of evaluation to make sure they meet varying expectations through testing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的软件开发中，你将遵循某种方法论来进行创意构思、跟踪工作进展，并保持与某种框架或计划的一致性。如今，大多数软件公司不再使用瀑布式方法，而是选择了敏捷、Scrum
    或精益方法的某个版本。这意味着大多数软件公司都在采用迭代和实验性的方式来构建和发布产品。它们将宏观的商业目标转化为具体的任务，这些任务将在任何一个 sprint
    结束时形成交付成果。一旦这些交付成果完成，它们会经过评估过程，确保通过测试满足不同的期望。
- en: 'The heart of this approach is agility. When you’re building out features of
    your product over time, you have time to test those features both functionally
    and conceptually. This is an economical way of spending time, energy, and resources
    on a product or a feature to then see how it’s received by your customer base
    and greater market. The agility this offers is what allows tech companies to be
    successful: they are able to make changes and adjustments as they build if they’re
    seeing that their product or feature isn’t resonating with their audience of users.
    This will be true whether or not your product supports AI/ML features.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的核心是敏捷性。当你在一段时间内构建产品的功能时，你有时间对这些功能进行功能性和概念性的测试。这是一种经济的方式，通过花费时间、精力和资源在一个产品或功能上，看看它是如何被你的客户群体和更广泛市场接受的。正是这种敏捷性使得科技公司能够取得成功：它们能够在构建过程中做出更改和调整，如果发现产品或功能没有与用户群体产生共鸣。这一点无论产品是否支持
    AI/ML 特性，都是成立的。
- en: We’d even go a step beyond this and say AI/ML takes the heart of this agility
    to the next level. Because AI/ML products are consistently building from prior
    manifestations, they’re constantly evolving and adapting to new demands on performance,
    accuracy, or speed. You can’t build an AI product in a vacuum. Over time, AI products
    will have many transformations, and because of this, they’re always in a state
    of being updated or upgraded to meet the expectations of their outputs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至可以进一步说，AI/ML将这种敏捷性提升到了一个新的高度。由于AI/ML产品始终在以先前的版本为基础进行构建，它们不断地进化并适应新的性能、准确性或速度需求。你不能在真空中构建AI产品。随着时间的推移，AI产品会经历多次转变，因此它们总处于更新或升级的状态，以满足其输出的期望。
- en: Data
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据
- en: Then there’s the similarity of data. Even if certain software products aren’t
    heavily dealing with your personal data, they are often built as data products
    in the sense that they are leveraging and storing some data about you or the entire
    user base to some degree to make certain determinations. Traditional software
    development will have some feedback loop to a database or be built upon a data
    pipeline of some kind that is passing information back and forth from its UI to
    some centralized (or decentralized) repository of some kind.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是数据的相似性。即使某些软件产品并未大量处理你的个人数据，它们通常也被视为数据产品，因为它们在某种程度上利用并存储关于你或整个用户群的数据，以做出某些判断。传统的软件开发通常会有某种反馈循环，连接到数据库，或者建立在某种数据管道之上，将信息从UI传输到某种集中式（或去中心化）存储库中。
- en: This means that software engineers are working with massive volumes of data
    in addition to working with source code. We’ve discussed the data demands AI/ML
    products have at length over the course of this book, but it’s important to note
    that this is inherently true of most software products out there. Software products
    are consistently using and accounting for data, whether or not it’s a “data” or
    an “AI/ML” product. Acquiring this data from your initial customers if you’re
    launching a new product is going to be true whether or not you’re building an
    applied AI product. Now that we have looked at how the two are similar, let’s
    check out what differentiates traditional software products from AI.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，软件工程师除了处理源代码外，还需要处理大量的数据。我们在本书中已经详细讨论了AI/ML产品的数据需求，但需要注意的是，大多数软件产品也是如此。软件产品始终在使用和考虑数据，无论它是否是“数据”产品或“AI/ML”产品。如果你正在推出新产品，从初始客户那里获取数据无论你是否在构建应用AI产品，都是必须的。现在我们已经了解了这两者的相似之处，让我们来看一下传统软件产品与AI之间的区别。
- en: How are they different?
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 它们有什么不同？
- en: While AI products are built on a foundation of traditional software development
    for the most part, they do have a number of key differences you should be aware
    of as a PM. AI is able to evolve a traditional software product, and you’ll hear
    this referred to as *applied AI* in product circles. What this means is applications
    of AI outside of a research setting or lab that are used in the building of tech
    products. Essentially, the concept of putting AI/ML to use, testing and optimizing
    the models for accuracy and precision, and evolving it over time through feedback
    loops is what constitutes applied AI.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管AI产品在很大程度上建立在传统软件开发的基础上，但作为PM，你需要了解它们存在一些关键的区别。AI能够推动传统软件产品的发展，你会在产品圈中听到这个被称为*应用AI*。这意味着，AI在非研究环境或实验室中的应用，用于技术产品的构建。简单来说，应用AI的概念就是将AI/ML付诸实践，测试和优化模型的准确性和精度，并通过反馈循环不断演化。
- en: The following sections will cover the biggest differences between traditional
    software products and AI products, which surround scalability, profit margins,
    and uncertainty.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下章节将讨论传统软件产品和AI产品之间的最大差异，主要围绕可扩展性、利润率和不确定性。
- en: Scalability
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可扩展性
- en: One of the major differences between applied AI products and traditional software
    products is in the area of scalability. Because AI is so specific and sensitive
    to the quality and peccadilloes of the training data, you’re likely going to have
    issues with scaling this kind of product because you’re likely to encounter so
    many edge cases that you have to go back to the drawing board or start to create
    cohorts within your user base. This has led to what *AI Forum* ([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/))
    refers to as a **collective AI fatigue** from people that are working directly
    on developing AI but also with leadership and the market at large itself that
    all stems from the issue of scalability when applied for commercial uses.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 应用AI产品和传统软件产品之间的一个主要区别是在可扩展性方面。由于AI对训练数据的质量和偏差非常敏感，因此你很可能会遇到扩展这类产品的问题，因为你可能会遇到如此多的边缘情况，以至于你不得不重新开始设计，或者开始在用户群体中创建不同的群体。这导致了*AI论坛*
    ([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/))
    所称的**集体AI疲劳**，这来源于直接从事AI开发的人员，也包括领导层和整个市场，所有问题都源于应用于商业用途时的可扩展性问题。
- en: This issue lies not just in the challenge AI poses with accuracy; indeed, you
    need a lot of data for advanced ML and DL models to work well and give you good
    performance, but you also need those models to be robust enough to work with a
    generalized population of users, situations, contexts, and locations. In traditional
    software products, you might not need this level of granularity to see success,
    but with applied AI products you might get the sense that in a perfect world,
    you might need a highly personalized model for every user or use case.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题不仅仅在于AI在准确性上的挑战；实际上，你需要大量数据才能让高级机器学习和深度学习模型运作良好并提供良好性能，但你还需要这些模型足够强大，能够适应一个广泛的用户群体、不同的情境、环境和地区。在传统的软件产品中，你可能不需要这种精细度就能看到成功，但在应用AI产品中，你可能会有一种感觉，在一个理想的世界里，你可能需要为每个用户或使用案例制定一个高度个性化的模型。
- en: This sense might not be that far off from an optimal reality. What this also
    means is that AI is particularly sensitive to the idea of edge cases, and the
    threshold for what even constitutes an edge case might be lower for AI products
    compared to their traditional software counterparts. While edge cases impact all
    software products, traditional software companies do have an inherent advantage
    in that they’re iterative, so once you build and ship a product, you’re able to
    sell it to virtually all your customers without having to do a lot of customization.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这种感觉可能并不远离理想的现实。这也意味着AI特别敏感于边缘情况的概念，甚至定义边缘情况的阈值，可能比传统软件产品的阈值要低。虽然边缘情况会影响所有软件产品，但传统软件公司具有固有的优势，因为它们是迭代的，所以一旦构建并发布产品，你就可以将其销售给几乎所有客户，而不需要做太多定制化。
- en: We will go over the differences in business models later on in this chapter,
    but this issue of scalability is doubly affected by your choice of business model.
    For instance, if you’re a B2B company, your AI product might behave wildly differently
    when compared to other customers because their training data differences might
    be too great. If we contrast this with a B2C company, you might be training your
    models on really representative and diverse data, but then the way your individual
    consumers interact with your product might vary wildly.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后续讨论商业模型的差异，但可扩展性问题是由你选择的商业模型双重影响的。例如，如果你是一家B2B公司，你的AI产品在与其他客户的比较中可能表现得截然不同，因为他们的训练数据差异可能太大。如果我们与B2C公司进行对比，你可能会在非常具有代表性和多样化的数据上训练模型，但然后，你的单个消费者与产品的互动方式可能会有很大的差异。
- en: 'Whether an issue with the training data or the way end users work with your
    product, the issue is the same: you’re having to account for so many perspectives
    and demands on your product from outside influences that it makes the scaling
    of the models used almost impossible while keeping with one consistent product
    build. Even the issue of agreeing on an acceptable level of product performance
    will likely be time, cost, and energy inefficient, let alone actually acquiring
    those levels of accuracy you’ll need to end up with a product that’s consistent
    enough to sell as an MVP.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是训练数据的问题，还是最终用户与产品互动的方式，问题都是一样的：你必须考虑到来自外部影响对产品的各种视角和需求，这使得在保持一致的产品构建的同时，几乎不可能对模型进行扩展。即便是达成对产品性能可接受水平的共识，也可能是时间、成本和精力上的低效，更不用说实际达成你所需要的准确性，以便最终能获得一个足够一致的MVP产品来出售。
- en: Getting to a level of trust where your earliest customers will see the value
    in your product enough to consistently use it will require a lot of initial work,
    and you don’t have guarantees that this intensive customer acquisition will necessarily
    dissipate as it might with traditional software products. With applied AI products,
    the process of acquiring and keeping your customers may stay at a consistently
    grueling pace, which further contributes to this issue of scalability up to a
    certain point. Strides are being made, however, to build and discover ways to
    improve models that are less reliant on massive hoards of data.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 达到一个信任水平，使得你的首批客户能够看到产品的价值并持续使用它，将需要大量的初期工作，并且你不能保证这种密集的客户获取过程会像传统软件产品那样逐渐消失。对于应用人工智能产品来说，获取并留住客户的过程可能会保持在一个持续而艰难的节奏上，这进一步加剧了在一定程度上产品可扩展性的问题。然而，已有进展在于构建和发现不那么依赖于海量数据的模型优化方法。
- en: 'According to *AI Forum* ([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/)):
    “*Data can be expensive to collect, requiring annotation and labelling (by clinicians
    in healthcare), cleaning, and preparation which can contribute 50% of AI training
    costs. Consent from data owners (e.g. patients) is needed to use their private
    data, and additional incentives are sometimes required for data custodians to
    share the data. Data privacy and security laws can introduce barriers to sharing,
    storing, accessing and handling* *the data.*”'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 根据*AI论坛*([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/))的说法：“*收集数据可能很昂贵，需要注释和标签（如在医疗保健领域由临床医生完成）、清理和准备，这些过程可能占AI训练成本的50%。需要获得数据所有者（例如患者）的同意，才能使用他们的私人数据，有时数据管理者需要额外的激励来分享数据。数据隐私和安全法律可能会对数据的共享、存储、访问和处理构成障碍。*”
- en: This reinforces the idea that the quantity of data itself is secondary to the
    commercial success of scalable AI products compared to the quality and diversity
    of the training data. It doesn’t just need to be standardized in a way that’s
    uniform across your data sample, it also needs to have enough representative data
    points that encompass the diversity of users as well—the idea being that the more
    diverse your data is, the more it will be able to anticipate the needs and uses
    of the general users that will experience it once it is deployed to the greater
    public.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这强化了一个观点：与训练数据的质量和多样性相比，数据的数量本身对于可扩展AI产品的商业成功来说是次要的。数据不仅需要在你的数据样本中以统一的方式进行标准化，它还需要有足够的代表性数据点，涵盖用户的多样性——这个理念是：你的数据越多样化，它就越能够预测将来部署到更广泛公众中的一般用户的需求和使用方式。
- en: 'Access to clean data is easier said than done. Most real-world datasets are
    riddled with data hygiene issues. Tableau ([https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled](https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled))
    offers a great summary of how to solve this: “*Data cleaning is the process of
    fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or
    incomplete data within a dataset. When combining multiple data sources, there
    are many opportunities for data to be duplicated or mislabeled. If data is incorrect,
    outcomes and algorithms are unreliable, even though they may look correct. There
    is no one absolute way to prescribe the exact steps in the data cleaning process
    because the processes will vary from dataset* *to dataset.*”'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 获取清洁数据说起来容易，做起来难。大多数现实世界的数据集都存在数据清理问题。Tableau ([https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled](https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled))
    提供了如何解决这一问题的极好总结：“*数据清理是修复或删除数据集中错误、损坏、格式不正确、重复或不完整数据的过程。当合并多个数据源时，数据可能会被重复或标注错误。如果数据不正确，即使看起来正确，结果和算法也是不可靠的。没有一种绝对的方式可以规定数据清理过程中的确切步骤，因为这些过程会根据不同的数据集而有所不同*。”
- en: AI/ML products are particularly sensitive to the quality of data, and this is
    further exacerbated by the issue of deliberate tampering or data poisoning in
    which end users attack AI/ML systems to intentionally manipulate the training
    data that powers them.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能/机器学习产品对数据质量特别敏感，而这一问题在故意篡改或数据投毒的情况下更加严重，其中终端用户攻击 AI/ML 系统，故意操控其训练数据。
- en: Profit margins
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利润率
- en: We’ve discussed the costs associated with building out an AI organization, which
    you’ll have to do if you’re building applied AI products. These costs are some
    of the biggest differentiators between traditional software products and applied
    AI products. Because these costs can be so high, they will impact your margins.
    KeyBanc Capital Markets’ 2021 survey of 354 private SaaS companies found that
    the profit margins for most companies were seeing gross profit margins of 80%,
    and those margins fell to between 68% and 75% when accounting for customer support/success
    ([https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25](https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25)).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过构建 AI 组织的成本，如果你在构建应用 AI 产品，你必须承担这些成本。这些成本是传统软件产品和应用 AI 产品之间的最大差异之一。由于这些成本可能非常高，它们会影响你的利润率。KeyBanc
    Capital Markets 2021 年对 354 家私人 SaaS 公司的调查发现，大多数公司的毛利润率为 80%，而在考虑到客户支持/成功时，毛利润率降至
    68% 至 75% 之间 ([https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25](https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25))。
- en: This number falls dramatically for AI products even in the best of circumstances,
    when companies are running optimally. To paint a picture of what can go wrong,
    the best example we were able to find came from *Harvard Business Review* ([https://hbr.org/2022/03/how-to-scale-ai-in-your-organization](https://hbr.org/2022/03/how-to-scale-ai-in-your-organization)),
    which mentioned “*…one financial company lost $20,000 in 10 minutes because one
    of its machine learning models began to misbehave. With no visibility into the
    root issue — and no way to even identify which of its models was malfunctioning
    — the company was left with no choice but to pull the plug. All models were rolled
    back to much earlier iterations, which severely degraded performance and erased
    weeks of effort.*” Imagine losing that much money in such a short time and still
    not being able to know where the problem was!
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数字在最佳情况下，即使公司运行得最好，对AI产品也会大幅下降。为了描绘出可能出现的问题，我们找到的最好例子来自*哈佛商业评论* ([https://hbr.org/2022/03/how-to-scale-ai-in-your-organization](https://hbr.org/2022/03/how-to-scale-ai-in-your-organization))，提到：“*…某家金融公司因为其一个机器学习模型开始出现问题而在10分钟内损失了$20,000。由于无法查看根本问题，甚至无法确定哪个模型出现故障，公司别无选择只能停止使用。所有模型都被回滚到较早版本，严重降低了性能并抹去了数周的努力。*”
    想象一下，在如此短的时间内损失那么多钱，却仍然无法找出问题所在！
- en: With that said, there are aspects of applied AI that are more profitable than
    others. According to *Forbes* ([https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4](https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4)),
    the area where we see the fastest return on applied AI is when it supports customer
    behavior, which makes sense because it directly impacts sales and is one of the
    highest revenue drivers. This would be use cases of applied AI such as product
    recommendations, scaled pricing algorithms, or advertising personalization/optimization
    that are bringing in more traffic to your website or helping customers with choosing
    more products based on their specific spending and purchasing habits, cost consciousness,
    or tastes and preferences.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，应用AI的某些方面比其他方面更具盈利性。根据*福布斯* ([https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4](https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4))，应用AI最快见效的领域是支持客户行为，这是有道理的，因为它直接影响销售并且是最高的收入驱动因素之一。这包括应用AI的使用案例，例如产品推荐、规模化定价算法或广告个性化/优化，这些都可以增加您网站的流量或帮助客户基于他们的特定消费和购买习惯、成本意识或品味偏好选择更多产品。
- en: The more medium-term payoff of applied AI is when AI is used to improve a product
    or make a user’s experience better in some way. This could look like product automation
    that boosts users’ productivity. For most of this book, we’ve been talking about
    these applications of AI because they directly impact an individual product and
    its performance. As a PM, this is likely the primary area you are focused on when
    it comes to applied AI and where the best place for it to fit is as far as your
    product’s performance and standing with customers and with your greater market
    is concerned. Because this essentially poses a medium-term payoff, and because
    your AI costs will be front-loaded for the most part, you’ll have to manage expectations
    with your engineering, leadership, and customer-facing teams from both a revenue
    and performance perspective.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 长期来看，应用AI的更中期回报是当AI被用来改进产品或在某种方式上提升用户体验。这可能看起来像是提升用户生产力的产品自动化。在本书的大部分内容中，我们一直在讨论这些应用的AI，因为它们直接影响个别产品及其表现。作为产品经理，这很可能是您在应用AI时关注的主要领域，它在产品的表现和市场地位方面的最佳位置。由于这基本上提出了中期回报，并且由于大部分AI成本将会前期加载，您需要从收入和性能角度管理与您的工程、领导和面向客户的团队的期望。
- en: Finally, the most long-term payoff of applied AI is when it affects the reputation
    of the company. This means AI is applied in a way that boosts a company’s trust
    reputationally, particularly when compared to its competitors and peers in the
    same space. But acquiring this level of AI supremacy is time intensive, and it
    sheds light on the double-edged sword of AI. Eventually, your competitors will
    catch on and will pay to play in your arena as well. This is the nature of competition,
    and as PMs, we understand that our products are scrutinized in the market, and
    rightly so.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，应用人工智能的最长期回报是在它影响公司声誉时产生的。这意味着人工智能的应用方式能够提升公司在信誉上的信任，特别是在与竞争对手和同行相比时。但获得这种人工智能的优势需要时间，并且它也揭示了人工智能的双刃剑本质。最终，你的竞争对手也会意识到这一点，并且会支付费用参与到你的领域中。这就是竞争的本质，作为产品经理，我们理解我们的产品会在市场上受到审视，这也是理所应当的。
- en: That being said, these areas of profitability aren’t exactly siloed. The short-term
    advantages of AI that we just discussed can also bleed into this area if your
    product specializes in marketing, recommendation systems, or advertising, for
    instance. The long-term advantages of AI that we discussed next can also apply
    to integrating applied AI into your product if what the premium AI offers your
    product is so great that it impacts your reputational standing in your chosen
    market or vertical. As a PM, technologist, or entrepreneur, you’re going to have
    to grapple with the costs AI poses as well as its advantages and create a plan
    for how you want to start leveraging applied AI.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这些盈利领域并不是完全隔离的。我们刚刚讨论的人工智能的短期优势也可以渗透到这一领域，特别是如果你的产品专注于市场营销、推荐系统或广告等领域。我们接下来讨论的人工智能的长期优势，也可以应用于将人工智能整合到你的产品中，前提是人工智能所能为你的产品带来的价值如此之大，以至于它影响了你在选定市场或垂直领域中的声誉地位。作为产品经理、技术专家或企业家，你将不得不应对人工智能所带来的成本以及它的优势，并制定一个计划，决定如何开始利用应用人工智能。
- en: As you’re getting started, one of the best ways to do this is to first understand
    the benefits AI can offer your product and company at large and then draft your
    own version of this plan and pitch it to your leadership. Communicating the effectiveness
    of AI and your understanding of how it will impact profitability will help you
    gain credibility in your own organization, and it will offer an avenue for your
    stakeholders to be able to understand the challenges and opportunities and ultimately
    contribute to the plan.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在你刚开始的时候，最好的做法之一是首先理解人工智能能够为你的产品和公司整体带来的好处，然后草拟你自己的计划版本并向领导层进行展示。传达人工智能的有效性以及你对它如何影响盈利能力的理解，将帮助你在自己组织中赢得信誉，同时也为你的利益相关者提供一个途径，让他们理解挑战与机会，并最终为计划做出贡献。
- en: Once you have this plan, you can start keeping track of the relative profitability
    of the various areas AI is applied to and have champions/supporters within your
    organization that help keep visibility of AI. If you can all agree on a specific
    appetite for AI spending and margin threshold tolerance, it will be easier to
    navigate the AI waters as you continue down your applied AI journey because it
    will force you to invest in AI in cases where there’s data, economic returns,
    and excitement to keep it going. And it will keep your finance team happy.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了这个计划，你可以开始跟踪人工智能应用在各个领域的相对盈利能力，并且在你的组织内部拥有支持者/倡导者，帮助保持人工智能的可见度。如果你们都能就人工智能支出的具体需求和利润阈值容忍度达成一致，那么在你继续进行应用人工智能的过程中，导航人工智能的道路将变得更加容易，因为这将迫使你在数据、经济回报和激动人心的因素上进行人工智能的投资。并且它将让你的财务团队保持满意。
- en: Uncertainty
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 不确定性
- en: The last big difference is conceptual. AI introduces a whole lot of uncertainty
    to the work of product management. With traditional software products, the deterministic
    qualities of a product are hardcoded. Algorithms still exist, but they’re not
    improving or learning over time. They are static. With AI products, these qualities
    are more fluid. There’s a level of expectation setting and performance that has
    to be agreed upon, expressly or intuitively, by the builders and users. If that
    level of performance doesn’t happen because the models aren’t trained enough,
    they have to be trained more. If performance doesn’t come no matter how much training
    you throw at it, you might not have a product to sell at the end of the day! This
    level of uncertainty is cushioned in traditional software because your performance
    goals aren’t quite the moving target they are when you’re building an AI product.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Where ML is concerned, you’re bound to have some level of error because, as
    we know, no model is going to be perfect. You will always need more data to get
    better performance. Collectively with your leadership, customers, and engineering
    team, you will come to understand where the threshold of accuracy needs to lie.
    It will be different for every product and every use case. The output from one
    model based on a certain training dataset might be great one day, but if you diversify
    the training set and retrain, it’s probable you won’t get the results you’re expecting.
    It’s very hard to exactly recreate and test these products, and keeping an experimental
    attitude when it comes to managing how you are testing, deploying, and maintaining
    versions will be essential. It’s also hard to know whether your models will most
    improve because of the type of model you’ve chosen, the training data selected,
    or the features you’ve selected.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: 'You also don’t know how much time, how many resources, and how much data you
    need, which makes it really difficult to actually plan your roadmap and keep a
    sense of time in the way you might be used to if you’ve worked with traditional
    software products. If you’ve been a PM before, that last sentence might raise
    some eyebrows. Yes, indeed: AI products are even more difficult to forecast! Finding
    the right balance of factors might take days, weeks, or months. With AI, it might
    not be until you’re well within the weeds of building that you start to grasp
    the complexity of your scope. This poses a great challenge to your leadership
    team, which might be interested in more concrete answers about the length of time
    you need. AI introduces so many factors of uncertainty to keep track of, which
    is why it’s so important to find a leadership team that gets this and supports
    you because the journey is riddled with doubt.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: All in all, AI is here to stay, and it’s going to be a surrounding theme as
    we head into the 2030s. The promise and opportunity of AI continue to grow as
    we see companies applying AI in new and innovative ways, and our guess is as the
    decade continues, we will see more inspired ways for companies to benefit from
    AI adoption. Companies investing in and building AI native products today will
    be setting themselves up for success for decades to come if they survive. The
    key is surviving.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: We bring up the differences between AI products and traditional software products
    here because we want everyone that has the investment and will to create AI products
    to be set up for success. If you can anticipate potential hurdles as you’re building
    a novel product, you can better prepare your teams for surmounting them as well.
    PMs will always be tasked with managing product stakeholders, mapping problems
    to solutions in their products, scrutinizing their data analytics and insights,
    communicating, and deciding on acceptance criteria that will hold their products’
    performance, as well as the accountability, explainability, and ethics of their
    products. These areas need to be nurtured whether you are supporting an AI product
    or not, and it’s all part of your evangelism work as a PM.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve discussed some of the similarities and differences between traditional
    software products and AI products, let’s turn our attention to how AI/ML products
    are positioned and built according to their business models. Creating products
    for a B2B business model is different from creating products for a B2C business
    model. Let’s get into some of those differences in the following section.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: B2B versus B2C – productizing business models
  id: totrans-53
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to building and shipping products, some of the biggest differences
    between B2B and B2C business models include domain knowledge and the degree of
    experimentation. In this section, we’ll be focusing on those two areas because
    they have the biggest impact on what productizing looks like for AI/ML products
    between these two business models. If we expand on the notion that AI/ML products
    behave more like services, the desired end result of both these business models
    will be different because they serve different kinds of customers and different
    overall needs.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: With B2B products, there’s a strong need for these products to demonstrate a
    high degree of domain knowledge and a focus on that. Since B2B products are often
    serving a proven business niche, they must often prove they have expertise in
    this niche and have studied it thoroughly enough to be able to deliver on a need.
    With B2C products, we see a focus on experimentation because rather than tapping
    into a business need that already exists, these products are looking to tap into
    a more collective need that their own customer base may not yet be aware they
    have. This requires a high degree of experimentation. In the following sections,
    we will build on these ideas further.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: Domain knowledge – understanding the needs of your market
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For starters, in B2B products, domain knowledge reigns supreme. This is because
    the use cases are incredibly specific, and the products themselves solve niche
    business problems that are specific to certain industries and domains. In order
    for a PM to be effective in the B2B space, they need to be intimately connected
    to their customers’ needs, workflows, and major pain points because their products
    solve very specific use cases. This isn’t to say PMs in this space have to come
    from the specific industry they’re serving, but they do need to invest a significant
    amount of time in building empathy with their user base in order to be effective.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: 'This time-intensive process can look like a number of things: conducting customer
    interviews, keeping up with industry trends, and understanding the competitive
    landscape and the benefits and features their competitors are serving their own
    customers are all part of this work toward building credibility in the space their
    product is competing in. This is all preliminary work of understanding the various
    types of users their product will serve as well. You’re setting yourself up for
    success if you’re a PM in this space and you’re spending time on establishing
    clear buyer and user personas and making sure you have a handle on what their
    individual needs, problems, and “jobs to be done” are.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: The expectation threshold of B2B customers is high because this space is likely
    riddled with a large number of competing products to choose from. In many cases,
    these customers are undergoing various rounds of **Requests for Proposals** (**RFPs**)
    and in-depth **Proof-of-Concept** (**PoC**) processes to make sure they are purchasing
    the right product for their use case. For an AI/ML product, these PoCs can be
    costly for your organization because you’ll need to acquire a large enough sample
    from your customers, use that data to train your models, and present your product
    and its capabilities to them once its performance is at an acceptable level to
    be able to show to your prospective customers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: This means there are often many eyes on these products, and each of those pairs
    of eyes may come with its own set of expectations and objections to your product,
    so you really need to be aware of multiple perspectives when building B2B products.
    This also means that as you build, you’re planning your release schedules with
    the idea that every release may include features that could impact your customers’
    individual workflows, so you often have to be mindful of how often and how loaded
    your release rollouts into production are.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: This domain knowledge is then built up to the point where you as a PM and your
    broader organization as a whole then become thought leaders in the space they’re
    serving. Because the professional landscape is a small world, once a product—along
    with its leadership team—does make a splash, it will trickle across the professional
    world. Building credibility internally and externally is foundationally proportional
    to the level of industry expertise that’s acquired.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: This further reinforces that the expectations of an AI/ML B2B product are quite
    high. Your users and buyers will scrutinize you on the tech stack that’s supporting
    your AI product as well as its performance and accuracy and will want to have
    evidence of explainability and why your product works. This will all be happening
    in conjunction with them testing and trialing other AI/ML solutions that are out
    there to compare them. This also means that you will have to be incredibly intentional
    about your releases to make sure there aren’t any lags in performance when you
    do make your push to production, with the full knowledge that other businesses
    are relying on your product.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Expectations are to be managed at every stage of the customer journey. B2B products
    exist in a massive ecosystem, and companies that use one product might pass outputs
    from that product to other workflows or to their own customers. This places a
    premium on B2B companies to maintain their company’s and product’s reputation
    and be more transparent about their marketing efforts, and introduces a lot more
    strain on AI/ML product teams to shy away from black-box algorithms and sell products
    that can stand by their determinants. B2B company customers have a tremendous
    amount of leverage because the stakes are high all around, and B2B products benefit
    from having engaged customers that want to see a certain level of performance
    from their products.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Experimentation – discover the needs of your collective
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With B2C products, because there isn’t such a hyperfocus on the domain you’re
    serving, the pressure on the market you’re serving is a bit more relaxed, but
    this creates another kind of pressure: the pressure to build a product that appeals
    to a much wider audience universally. Casting a wider net brings other areas into
    focus. As a PM building in a B2C environment, you’re going to approach your product
    and the market it serves more experimentally and derive insights about what’s
    most useful to your customers by tracking how they use your product. You can conduct
    focus groups, nurture beta testers, or interview your customers through in-product
    surveys, but because you can’t conduct customer interviews in the way you might
    for a B2B product, you’re left with understanding your customers’ impressions
    of your product through their in-product behaviors.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: This business model also consolidates all your user and buyer personas in one
    because, typically, the person that’s using your product is also the person buying
    it. Understanding the main drivers, desires, hopes, and dreams of your customer
    base becomes a very nebulous task because what you’re trying to capture are underlying
    needs, pain points, and moments of delight that will apply to all your users at
    once. This complicates a PM’s ability to empathize with their end users. Because
    most of these users aren’t signing the kind of year-long contracts you see with
    B2B products, the pressure to keep these consumers charmed is constant because
    they can leave at any point. This puts pressure on product, leadership, and development
    teams to consistently be providing their customer base reasons to stay and choose
    them.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: Because of the bird’s-eye view B2C products enforce on their builders, this
    means PMs have to be very discerning with their data analytics and metrics. Investing
    in understanding their customer lifetime value and customer acquisition costs
    and tracking those metrics is an important part of staying profitable and sustainable
    in the B2C landscape. B2C offers PMs an easy outlet for applying AI/ML toward
    the acquisition and retention of customers since they have such few touchpoints
    with the end users of their product. PMs in the consumer space also need to hone
    in on the demographic and individualistic qualities of their consumers to better
    understand what to build. If you see that it’s mostly people within a geographic
    area, gender, generation, or subgenre that appeals most to your product, you might
    start to build future features and releases in your roadmap with them in mind.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: We’ve mentioned many times that AI/ML products are experimental in nature because
    you want to leverage AI/ML in ways that will impact your product most obviously
    for it to be worth the top-heavy investment it requires. This is doubly true for
    B2C products because you’re building and using AI to deliver something that saves
    your consumers money or delights them, as well as using the data your product
    produces to decide on how to pivot your product. B2C PMs are reliant on data and
    analytics to make global decisions about their products on a regular basis. Although
    this is changing for the most part, traditionally in the B2B space, your marketing
    efforts are most oriented toward your buyers because they’re the ultimate decision-makers.
    This is sharply contrasted in the B2C space because your marketing efforts are
    directly linked to collective information you can derive and infer from your data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Experimentation is fun to a point, but at the end of the day, it has to deliver.
    By far the greatest pressure this places on AI/ML consumer products is the pressure
    to perform well, maintain their enormous user base, and keep their consumers happy.
    This means that consumers want to use an app that does what it says it’s going
    to do in a way that’s visually appealing. Because they aren’t as concerned with
    the downstream risks of using your product as B2B customers are, consumers don’t
    particularly care why it’s working, just that it does work. This means that the
    issue of explainability is minimized in the B2C space, and the use of black-box
    or DL algorithms is less scrutinized.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: B2B and B2C business models come with their own blend of challenges, but at
    the end of the day, players in both business models must understand their customers
    enough to create products that actually bring them value. Once you’ve built something
    of value for your customers, you enter a new phase. This next phase is about delivering
    that value consistently enough to not only win customers but keep them in the
    long run. In the following section, we will take a look under the hood to understand
    the necessary elements of delivering value consistently with the help of **ML
    operations** (**MLOps**) or **AI operations** (**AIOps**). Both will be used interchangeably
    in this book.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Consistency and AIOps/MLOps – reliance and trust
  id: totrans-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Maintaining trust, reliance, and consistency within your internal product teams
    as well as with your customer base is an act of committing to a specific ritual.
    Ritualizing the acquisition of clean data, tracking the flow through your infrastructure,
    tracking your model training, versions, and experiments, setting up a deployment
    schedule, and monitoring pipelines that get pushed to production are all part
    of the necessary work that needs to be done to make sure there’s a handle on the
    comings and goings of your AI/ML pipeline. This ritualizing is what’s referred
    to as MLOps or AIOps. In this section, we will explore the benefits of AIOps/MLOps
    and how they help you stay consistent.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: If you’re managing an ML pipeline, you will need to learn how to depend on an
    MLOps team and set up your team for success. You don’t want to get caught losing
    $20,000 in 10 minutes (as we saw in our *Profit margins* section earlier in this
    chapter) and have no leads for where the problem is stemming from. At the very
    least, you should have some idea where the problem is stemming from. MLOps is
    able to help with creating and managing the ML pipelines themselves, scaling those
    pipelines, and moving sensitive data at scale. Ultimately, the risks of compromising
    your customers’ reliance on and trust in your product are great. MLOps’ greatest
    contribution to your business is maintaining the consistency needed to build an
    AI/ML product that lasts.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: We’ve spoken at length in this chapter about productizing and what that looks
    like in different contexts of AI product management, but MLOps is actually where
    the productizing functionally happens. Taking a service and splitting that service
    apart into smaller pieces that are managed and standardized into reproducible
    and regulated segments is the work of “productizing,’’ and in that vein, MLOps
    is really the vehicle we use to truly productize AI/ML. In order to build the
    consistency and credibility customers can expect from your product, the ritual
    of MLOps needs to be cemented into your process. You never know when you'll need
    to revert to a specific version of your models or zero in on an experiment that
    had the right mix of factors. MLOps creates the organization and focus your team
    needs to have in order to have a handle on such a wide variety of experiments.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered some of the benefits of creating an MLOps organization
    to help keep track of your AI/ML pipeline, let’s explore how to build on that
    pipeline and evaluate the state of the models used. In the following section,
    we will reiterate some concepts around testing, retraining, and hyperparameter
    tuning to ensure your AI/ML pipelines are routinely being refreshed and optimized
    for performance.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Performance evaluation – testing, retraining, and hyperparameter tuning
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLOps helps us with accentuating the importance of retraining and hyperparameter
    tuning our models to deliver performance. Without having a built-out AI/ML pipeline
    that validates, trains, and retrains regularly, you won’t have a great handle
    on your product’s performance. Your MLOps team will essentially be made up of
    data scientists and ML and DL engineers that will be tasked with making adjustments
    to the hyperparameters of your model builds, testing those models, and retraining
    them when needed. This will need to be done in conjunction with managing the data
    needed to feed this testing, along with the code base for your product’s interface
    as well.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: In addition to testing and validating the models and working to clean and explore
    the data, MLOps team members also traditionally do software testing such as code
    tests, unit testing, and integration testing. In many cases, your AI products
    will effectively be traditional software products that incorporate AI/ML features
    in a subset of a greater ecosystem that’s in line with traditional software development.
    This means that MLOps may, in many cases, ensure your greater product is working
    functionally along with the AI/ML deliverables and outputs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: Another major area MLOps is well suited to minimize the risk of is the concept
    of data drift and system degradation. We covered a few different types of drift
    in earlier chapters of this book, but we’d like to reiterate here that this is
    a risk that can sneak up on you. Model degradation can happen for a number of
    reasons. Perhaps there are differences between assumptions that are made with
    the data in training and in production. Perhaps there’s been a change to the data
    itself. Perhaps there are unseen biases in your training data that were never
    picked up on. Whatever the reason, continuous monitoring of models in production
    by MLOps will be your best defense in picking up on these nuances and changes
    in AI/ML outputs so that the risks from any number of issues within the ML pipeline
    are minimized as much as possible.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapters 1* and *2* of this book, we covered the concept of continuous maintenance,
    which consists of **Continuous Integration** (**CI**), **Continuous Deployment**
    (**CD**), and **Continuous Testing** (**CT**). These basic areas of MLOps are
    mirrored in DevOps, which is common to traditional software development. The main
    differences are that in MLOps, CI isn’t just about testing and validating code—it’s
    also about validating and testing the models, data schemas, and the data samples
    themselves. Another difference is that CD isn’t just about deploying a software
    package but about nurturing an automated ML pipeline deployment process that’s
    optimized for deploying the model prediction service or for automatically scaling
    back to an earlier version if there is trouble ahead. Finally, CT isn’t just about
    testing software packages themselves but about retraining and testing the models
    that are actively being relied upon.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ve built on the idea of building consistency in how we manage
    our AI/ML pipelines and reinforced the importance of maintaining high standards
    in the performance of our AI/ML pipelines. This shouldn’t be viewed as a nice-to-have
    but rather a need-to-have. The performance and quality of AI/ML models can suffer
    for many reasons, so this consistent practice of scrutinizing performance is meant
    to ensure your product’s performance doesn’t come at the risk of the trust you’ve
    built with your developers and customers. In the following section, we’ll be discussing
    the importance of maintaining strong relationships, whether they’re internal or
    external.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Feedback loop – relationship building
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuously monitoring and reinforcing the legitimacy of a complicated system
    such as an AI/ML pipeline is all in service of the ultimate goal of building relationships
    that last. Relationships between your company and customers, your development
    team and your sales team, and your MLOps team and your leadership team are all
    forged through this work of building and going to market with your AI/ML native
    product. In AI/ML products, the feedback loop is everything. Nurturing a strong
    relationship with the builders of these products and the customers they serve
    is the underlying work of the PM. **Productizing** is the process of taking a
    service, process, skill, or idea and finding a way to present that to the greater
    market. Many layers of work go into accomplishing this well, but at its most basic
    level, this work is really just an elaborate feedback loop.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: We haven’t discussed marketing much in this chapter, but this will also be an
    integral part of maintaining this feedback loop. Finding the right words to use
    to describe your product and reach your audience (also known as product language
    fit) will be a big part of productizing. You will have to create marketing collateral,
    advertisements, and sales scripts that will all convey the value the product you’re
    building with AI/ML will have for your customers and end users. Building product
    collateral and expressing that through your various marketing and sales channels
    will go a long way toward level-setting expectations with your customers.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve seen earlier in this section, customers come with expectations, whether
    they’re business users or consumers, and it’s the task of the AI/ML PM to take
    those expectations and deliver something that aligns with them. Understanding
    the risk and promise of AI/ML and how it compares and contrasts to traditional
    software development, understanding the challenges and opportunities in your business
    model, translating all that to reproducible, repeatable tasks internally, and
    demonstrating consistency with your product’s performance in a way that aligns
    with your customers’ expectations is the work of productizing the AI native product.
    You’ll know you’ve successfully done this when you have a loyal customer base
    that wouldn’t dream of parting with you.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The act of productizing involves taking a concept, a service, or a piece of
    technology and developing it into a commercial product that’s suitable for the
    customers you’re looking to attract. As we’ve seen throughout this chapter, this
    work isn’t just a matter of getting your product up and running and creating a
    landing page for your potential customers to magically find. Productizing involves
    critically understanding the business model you’re working in and the ultimate
    audience you’re building for. Remember that AI products can be thought of as AI/ML
    services that are being built into traditional software products. This means that
    another big part of productizing for AI products involves the standardization
    and ritualization of the AI/ML service in a way that’s repeatable and predictable
    for the internal operations teams as well as the customers that will come to rely
    on your product.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: If you’re able to understand your market, build internal structures to make
    sure there’s consistency with the outputs of your AI/ML pipelines, and communicate
    that consistency through your marketing efforts, as well as the ongoing performance
    of your product, you’ve successfully productized. But productizing may not be
    enough. Depending on the specifics of the market you’re serving, you might have
    to customize your product even further for specific use cases, verticals, customer
    segments, and other peer groups. Because AI/ML model performance is so dependent
    on training data, there might be collections of data that perform differently
    when run against one model. Further specialization might be in order. If you find
    this applies to your product and market, read on to [*Chapter 8*](B18935_08.xhtml#_idTextAnchor246),
    where we will build on the concept of customization.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Past The AI Hype: When Is AI Actually Profitable?: [https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4](https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How to Scale AI in Your Organization: [https://hbr.org/2022/03/how-to-scale-ai-in-your-organization](https://hbr.org/2022/03/how-to-scale-ai-in-your-organization)'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What are the net profit margins of a SaaS company/startup?: [https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25](https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean
    Your Data: [https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled](https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled)'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Why Commercial Artificial Intelligence Products Do Not Scale: [https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
