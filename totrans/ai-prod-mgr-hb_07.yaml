- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Productizing the ML Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B18935_06.xhtml#_idTextAnchor175), we briefly touched upon
    the notion of productizing and what that means for AI outputs in the *Productizing
    AI-powered outputs – how AI product management is different* section. We will
    be expanding on that concept in this chapter by exploring the trials and tribulations
    that may come up when building an AI product. Rather than thinking of AI products
    as traditional software products, it helps to think of them as a service that
    you’re learning to productize. What this refers to is the ability to create a
    consistent workflow that you can rely on to deliver consistent results in the
    way traditional products demand.
  prefs: []
  type: TYPE_NORMAL
- en: We will be going more in depth into product management principles and aligning
    them to the idiosyncrasies of AI/ML services.
  prefs: []
  type: TYPE_NORMAL
- en: 'By the end of this chapter, we will have an understanding of the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the differences between AI and traditional software products
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: B2B versus B2C – productizing business models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consistency and AIOps/MLOps – reliance and trust
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance evaluation – testing, retraining, and hyperparameter tuning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feedback loop – relationship building
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the differences between AI and traditional software products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of differences between traditional software products and
    AI/ML products. In the following subsections, we’ll first go over how they’re
    similar, and then we’ll note the differences between the two to give us a well-rounded
    sense of what to expect when you’re product managing an AI/ML product. This will
    help us establish a baseline as well as a deviation from traditional PM work.
    When you’re a PM, you’re often tasked with being the person to maintain an intuition
    about your product and how it will grow and evolve through the process of building
    and shipping the product and working with your engineering team.
  prefs: []
  type: TYPE_NORMAL
- en: Part of that intuition will relate to how you will market and sell your product,
    what kinds of customer needs and issues your product can anticipate, as well as
    potential problems that might arise as you start to get into the weeds with building
    and marketing your AI product. Many PMs might not be aware of the demands AI/ML
    products will place on them, and this section is primarily aimed at helping PMs
    build this intuition as they start to navigate the world of AI/ML products.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to note that traditional software products and AI products
    are increasingly blurring together. This is because most software companies have
    already started to integrate AI/ML into their existing products or launched AI
    native products. PMs that cover a wide variety of products will want to deepen
    their knowledge of AI/ML as a way to stay competitive within their own fields,
    whether they plan to go deep into AI or not. Understanding the differences between
    traditional software and AI products isn’t so much about comparing two disparate
    groups of products. It’s helpful in this case as well, but this is a macro trend,
    and the biggest reason for understanding the two is to anticipate how all products
    will evolve with AI. Let’s begin by checking out how traditional software products
    are similar to AI.
  prefs: []
  type: TYPE_NORMAL
- en: How are they similar?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are a number of similarities between traditional software products and
    AI products because, fundamentally, AI products are traditional software products
    with a productized AI/ML service built in. For this reason, the similarities we
    will outline here involve agile product development as well as data. Native AI
    products, along with the outputs from the AI pipelines that support them, follow
    the same building process most traditional software products use. They are also
    built with a heavy focus on the data that powers them. This is still true for
    traditional software products.
  prefs: []
  type: TYPE_NORMAL
- en: Agile development
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In traditional software development, you’re going to follow some methodology
    to ideate, keep track of your work, and stay consistent with some framework or
    schedule. Most software companies these days don’t use waterfall methodology anymore
    and have instead opted to use some version of agile, scrum, or lean methodology.
    This means most software companies are using an iterative and experimental approach
    to building and shipping products. They’re taking large overarching business goals
    and translating those goals into specific tasks that will then amount to deliverables
    by the end of any given sprint. Once they have these deliverables done, they undergo
    a process of evaluation to make sure they meet varying expectations through testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The heart of this approach is agility. When you’re building out features of
    your product over time, you have time to test those features both functionally
    and conceptually. This is an economical way of spending time, energy, and resources
    on a product or a feature to then see how it’s received by your customer base
    and greater market. The agility this offers is what allows tech companies to be
    successful: they are able to make changes and adjustments as they build if they’re
    seeing that their product or feature isn’t resonating with their audience of users.
    This will be true whether or not your product supports AI/ML features.'
  prefs: []
  type: TYPE_NORMAL
- en: We’d even go a step beyond this and say AI/ML takes the heart of this agility
    to the next level. Because AI/ML products are consistently building from prior
    manifestations, they’re constantly evolving and adapting to new demands on performance,
    accuracy, or speed. You can’t build an AI product in a vacuum. Over time, AI products
    will have many transformations, and because of this, they’re always in a state
    of being updated or upgraded to meet the expectations of their outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Then there’s the similarity of data. Even if certain software products aren’t
    heavily dealing with your personal data, they are often built as data products
    in the sense that they are leveraging and storing some data about you or the entire
    user base to some degree to make certain determinations. Traditional software
    development will have some feedback loop to a database or be built upon a data
    pipeline of some kind that is passing information back and forth from its UI to
    some centralized (or decentralized) repository of some kind.
  prefs: []
  type: TYPE_NORMAL
- en: This means that software engineers are working with massive volumes of data
    in addition to working with source code. We’ve discussed the data demands AI/ML
    products have at length over the course of this book, but it’s important to note
    that this is inherently true of most software products out there. Software products
    are consistently using and accounting for data, whether or not it’s a “data” or
    an “AI/ML” product. Acquiring this data from your initial customers if you’re
    launching a new product is going to be true whether or not you’re building an
    applied AI product. Now that we have looked at how the two are similar, let’s
    check out what differentiates traditional software products from AI.
  prefs: []
  type: TYPE_NORMAL
- en: How are they different?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While AI products are built on a foundation of traditional software development
    for the most part, they do have a number of key differences you should be aware
    of as a PM. AI is able to evolve a traditional software product, and you’ll hear
    this referred to as *applied AI* in product circles. What this means is applications
    of AI outside of a research setting or lab that are used in the building of tech
    products. Essentially, the concept of putting AI/ML to use, testing and optimizing
    the models for accuracy and precision, and evolving it over time through feedback
    loops is what constitutes applied AI.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will cover the biggest differences between traditional
    software products and AI products, which surround scalability, profit margins,
    and uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the major differences between applied AI products and traditional software
    products is in the area of scalability. Because AI is so specific and sensitive
    to the quality and peccadilloes of the training data, you’re likely going to have
    issues with scaling this kind of product because you’re likely to encounter so
    many edge cases that you have to go back to the drawing board or start to create
    cohorts within your user base. This has led to what *AI Forum* ([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/))
    refers to as a **collective AI fatigue** from people that are working directly
    on developing AI but also with leadership and the market at large itself that
    all stems from the issue of scalability when applied for commercial uses.
  prefs: []
  type: TYPE_NORMAL
- en: This issue lies not just in the challenge AI poses with accuracy; indeed, you
    need a lot of data for advanced ML and DL models to work well and give you good
    performance, but you also need those models to be robust enough to work with a
    generalized population of users, situations, contexts, and locations. In traditional
    software products, you might not need this level of granularity to see success,
    but with applied AI products you might get the sense that in a perfect world,
    you might need a highly personalized model for every user or use case.
  prefs: []
  type: TYPE_NORMAL
- en: This sense might not be that far off from an optimal reality. What this also
    means is that AI is particularly sensitive to the idea of edge cases, and the
    threshold for what even constitutes an edge case might be lower for AI products
    compared to their traditional software counterparts. While edge cases impact all
    software products, traditional software companies do have an inherent advantage
    in that they’re iterative, so once you build and ship a product, you’re able to
    sell it to virtually all your customers without having to do a lot of customization.
  prefs: []
  type: TYPE_NORMAL
- en: We will go over the differences in business models later on in this chapter,
    but this issue of scalability is doubly affected by your choice of business model.
    For instance, if you’re a B2B company, your AI product might behave wildly differently
    when compared to other customers because their training data differences might
    be too great. If we contrast this with a B2C company, you might be training your
    models on really representative and diverse data, but then the way your individual
    consumers interact with your product might vary wildly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Whether an issue with the training data or the way end users work with your
    product, the issue is the same: you’re having to account for so many perspectives
    and demands on your product from outside influences that it makes the scaling
    of the models used almost impossible while keeping with one consistent product
    build. Even the issue of agreeing on an acceptable level of product performance
    will likely be time, cost, and energy inefficient, let alone actually acquiring
    those levels of accuracy you’ll need to end up with a product that’s consistent
    enough to sell as an MVP.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting to a level of trust where your earliest customers will see the value
    in your product enough to consistently use it will require a lot of initial work,
    and you don’t have guarantees that this intensive customer acquisition will necessarily
    dissipate as it might with traditional software products. With applied AI products,
    the process of acquiring and keeping your customers may stay at a consistently
    grueling pace, which further contributes to this issue of scalability up to a
    certain point. Strides are being made, however, to build and discover ways to
    improve models that are less reliant on massive hoards of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to *AI Forum* ([https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/)):
    “*Data can be expensive to collect, requiring annotation and labelling (by clinicians
    in healthcare), cleaning, and preparation which can contribute 50% of AI training
    costs. Consent from data owners (e.g. patients) is needed to use their private
    data, and additional incentives are sometimes required for data custodians to
    share the data. Data privacy and security laws can introduce barriers to sharing,
    storing, accessing and handling* *the data.*”'
  prefs: []
  type: TYPE_NORMAL
- en: This reinforces the idea that the quantity of data itself is secondary to the
    commercial success of scalable AI products compared to the quality and diversity
    of the training data. It doesn’t just need to be standardized in a way that’s
    uniform across your data sample, it also needs to have enough representative data
    points that encompass the diversity of users as well—the idea being that the more
    diverse your data is, the more it will be able to anticipate the needs and uses
    of the general users that will experience it once it is deployed to the greater
    public.
  prefs: []
  type: TYPE_NORMAL
- en: 'Access to clean data is easier said than done. Most real-world datasets are
    riddled with data hygiene issues. Tableau ([https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled](https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled))
    offers a great summary of how to solve this: “*Data cleaning is the process of
    fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or
    incomplete data within a dataset. When combining multiple data sources, there
    are many opportunities for data to be duplicated or mislabeled. If data is incorrect,
    outcomes and algorithms are unreliable, even though they may look correct. There
    is no one absolute way to prescribe the exact steps in the data cleaning process
    because the processes will vary from dataset* *to dataset.*”'
  prefs: []
  type: TYPE_NORMAL
- en: AI/ML products are particularly sensitive to the quality of data, and this is
    further exacerbated by the issue of deliberate tampering or data poisoning in
    which end users attack AI/ML systems to intentionally manipulate the training
    data that powers them.
  prefs: []
  type: TYPE_NORMAL
- en: Profit margins
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We’ve discussed the costs associated with building out an AI organization, which
    you’ll have to do if you’re building applied AI products. These costs are some
    of the biggest differentiators between traditional software products and applied
    AI products. Because these costs can be so high, they will impact your margins.
    KeyBanc Capital Markets’ 2021 survey of 354 private SaaS companies found that
    the profit margins for most companies were seeing gross profit margins of 80%,
    and those margins fell to between 68% and 75% when accounting for customer support/success
    ([https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25](https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25)).
  prefs: []
  type: TYPE_NORMAL
- en: This number falls dramatically for AI products even in the best of circumstances,
    when companies are running optimally. To paint a picture of what can go wrong,
    the best example we were able to find came from *Harvard Business Review* ([https://hbr.org/2022/03/how-to-scale-ai-in-your-organization](https://hbr.org/2022/03/how-to-scale-ai-in-your-organization)),
    which mentioned “*…one financial company lost $20,000 in 10 minutes because one
    of its machine learning models began to misbehave. With no visibility into the
    root issue — and no way to even identify which of its models was malfunctioning
    — the company was left with no choice but to pull the plug. All models were rolled
    back to much earlier iterations, which severely degraded performance and erased
    weeks of effort.*” Imagine losing that much money in such a short time and still
    not being able to know where the problem was!
  prefs: []
  type: TYPE_NORMAL
- en: With that said, there are aspects of applied AI that are more profitable than
    others. According to *Forbes* ([https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4](https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4)),
    the area where we see the fastest return on applied AI is when it supports customer
    behavior, which makes sense because it directly impacts sales and is one of the
    highest revenue drivers. This would be use cases of applied AI such as product
    recommendations, scaled pricing algorithms, or advertising personalization/optimization
    that are bringing in more traffic to your website or helping customers with choosing
    more products based on their specific spending and purchasing habits, cost consciousness,
    or tastes and preferences.
  prefs: []
  type: TYPE_NORMAL
- en: The more medium-term payoff of applied AI is when AI is used to improve a product
    or make a user’s experience better in some way. This could look like product automation
    that boosts users’ productivity. For most of this book, we’ve been talking about
    these applications of AI because they directly impact an individual product and
    its performance. As a PM, this is likely the primary area you are focused on when
    it comes to applied AI and where the best place for it to fit is as far as your
    product’s performance and standing with customers and with your greater market
    is concerned. Because this essentially poses a medium-term payoff, and because
    your AI costs will be front-loaded for the most part, you’ll have to manage expectations
    with your engineering, leadership, and customer-facing teams from both a revenue
    and performance perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the most long-term payoff of applied AI is when it affects the reputation
    of the company. This means AI is applied in a way that boosts a company’s trust
    reputationally, particularly when compared to its competitors and peers in the
    same space. But acquiring this level of AI supremacy is time intensive, and it
    sheds light on the double-edged sword of AI. Eventually, your competitors will
    catch on and will pay to play in your arena as well. This is the nature of competition,
    and as PMs, we understand that our products are scrutinized in the market, and
    rightly so.
  prefs: []
  type: TYPE_NORMAL
- en: That being said, these areas of profitability aren’t exactly siloed. The short-term
    advantages of AI that we just discussed can also bleed into this area if your
    product specializes in marketing, recommendation systems, or advertising, for
    instance. The long-term advantages of AI that we discussed next can also apply
    to integrating applied AI into your product if what the premium AI offers your
    product is so great that it impacts your reputational standing in your chosen
    market or vertical. As a PM, technologist, or entrepreneur, you’re going to have
    to grapple with the costs AI poses as well as its advantages and create a plan
    for how you want to start leveraging applied AI.
  prefs: []
  type: TYPE_NORMAL
- en: As you’re getting started, one of the best ways to do this is to first understand
    the benefits AI can offer your product and company at large and then draft your
    own version of this plan and pitch it to your leadership. Communicating the effectiveness
    of AI and your understanding of how it will impact profitability will help you
    gain credibility in your own organization, and it will offer an avenue for your
    stakeholders to be able to understand the challenges and opportunities and ultimately
    contribute to the plan.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have this plan, you can start keeping track of the relative profitability
    of the various areas AI is applied to and have champions/supporters within your
    organization that help keep visibility of AI. If you can all agree on a specific
    appetite for AI spending and margin threshold tolerance, it will be easier to
    navigate the AI waters as you continue down your applied AI journey because it
    will force you to invest in AI in cases where there’s data, economic returns,
    and excitement to keep it going. And it will keep your finance team happy.
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The last big difference is conceptual. AI introduces a whole lot of uncertainty
    to the work of product management. With traditional software products, the deterministic
    qualities of a product are hardcoded. Algorithms still exist, but they’re not
    improving or learning over time. They are static. With AI products, these qualities
    are more fluid. There’s a level of expectation setting and performance that has
    to be agreed upon, expressly or intuitively, by the builders and users. If that
    level of performance doesn’t happen because the models aren’t trained enough,
    they have to be trained more. If performance doesn’t come no matter how much training
    you throw at it, you might not have a product to sell at the end of the day! This
    level of uncertainty is cushioned in traditional software because your performance
    goals aren’t quite the moving target they are when you’re building an AI product.
  prefs: []
  type: TYPE_NORMAL
- en: Where ML is concerned, you’re bound to have some level of error because, as
    we know, no model is going to be perfect. You will always need more data to get
    better performance. Collectively with your leadership, customers, and engineering
    team, you will come to understand where the threshold of accuracy needs to lie.
    It will be different for every product and every use case. The output from one
    model based on a certain training dataset might be great one day, but if you diversify
    the training set and retrain, it’s probable you won’t get the results you’re expecting.
    It’s very hard to exactly recreate and test these products, and keeping an experimental
    attitude when it comes to managing how you are testing, deploying, and maintaining
    versions will be essential. It’s also hard to know whether your models will most
    improve because of the type of model you’ve chosen, the training data selected,
    or the features you’ve selected.
  prefs: []
  type: TYPE_NORMAL
- en: 'You also don’t know how much time, how many resources, and how much data you
    need, which makes it really difficult to actually plan your roadmap and keep a
    sense of time in the way you might be used to if you’ve worked with traditional
    software products. If you’ve been a PM before, that last sentence might raise
    some eyebrows. Yes, indeed: AI products are even more difficult to forecast! Finding
    the right balance of factors might take days, weeks, or months. With AI, it might
    not be until you’re well within the weeds of building that you start to grasp
    the complexity of your scope. This poses a great challenge to your leadership
    team, which might be interested in more concrete answers about the length of time
    you need. AI introduces so many factors of uncertainty to keep track of, which
    is why it’s so important to find a leadership team that gets this and supports
    you because the journey is riddled with doubt.'
  prefs: []
  type: TYPE_NORMAL
- en: All in all, AI is here to stay, and it’s going to be a surrounding theme as
    we head into the 2030s. The promise and opportunity of AI continue to grow as
    we see companies applying AI in new and innovative ways, and our guess is as the
    decade continues, we will see more inspired ways for companies to benefit from
    AI adoption. Companies investing in and building AI native products today will
    be setting themselves up for success for decades to come if they survive. The
    key is surviving.
  prefs: []
  type: TYPE_NORMAL
- en: We bring up the differences between AI products and traditional software products
    here because we want everyone that has the investment and will to create AI products
    to be set up for success. If you can anticipate potential hurdles as you’re building
    a novel product, you can better prepare your teams for surmounting them as well.
    PMs will always be tasked with managing product stakeholders, mapping problems
    to solutions in their products, scrutinizing their data analytics and insights,
    communicating, and deciding on acceptance criteria that will hold their products’
    performance, as well as the accountability, explainability, and ethics of their
    products. These areas need to be nurtured whether you are supporting an AI product
    or not, and it’s all part of your evangelism work as a PM.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve discussed some of the similarities and differences between traditional
    software products and AI products, let’s turn our attention to how AI/ML products
    are positioned and built according to their business models. Creating products
    for a B2B business model is different from creating products for a B2C business
    model. Let’s get into some of those differences in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: B2B versus B2C – productizing business models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to building and shipping products, some of the biggest differences
    between B2B and B2C business models include domain knowledge and the degree of
    experimentation. In this section, we’ll be focusing on those two areas because
    they have the biggest impact on what productizing looks like for AI/ML products
    between these two business models. If we expand on the notion that AI/ML products
    behave more like services, the desired end result of both these business models
    will be different because they serve different kinds of customers and different
    overall needs.
  prefs: []
  type: TYPE_NORMAL
- en: With B2B products, there’s a strong need for these products to demonstrate a
    high degree of domain knowledge and a focus on that. Since B2B products are often
    serving a proven business niche, they must often prove they have expertise in
    this niche and have studied it thoroughly enough to be able to deliver on a need.
    With B2C products, we see a focus on experimentation because rather than tapping
    into a business need that already exists, these products are looking to tap into
    a more collective need that their own customer base may not yet be aware they
    have. This requires a high degree of experimentation. In the following sections,
    we will build on these ideas further.
  prefs: []
  type: TYPE_NORMAL
- en: Domain knowledge – understanding the needs of your market
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For starters, in B2B products, domain knowledge reigns supreme. This is because
    the use cases are incredibly specific, and the products themselves solve niche
    business problems that are specific to certain industries and domains. In order
    for a PM to be effective in the B2B space, they need to be intimately connected
    to their customers’ needs, workflows, and major pain points because their products
    solve very specific use cases. This isn’t to say PMs in this space have to come
    from the specific industry they’re serving, but they do need to invest a significant
    amount of time in building empathy with their user base in order to be effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'This time-intensive process can look like a number of things: conducting customer
    interviews, keeping up with industry trends, and understanding the competitive
    landscape and the benefits and features their competitors are serving their own
    customers are all part of this work toward building credibility in the space their
    product is competing in. This is all preliminary work of understanding the various
    types of users their product will serve as well. You’re setting yourself up for
    success if you’re a PM in this space and you’re spending time on establishing
    clear buyer and user personas and making sure you have a handle on what their
    individual needs, problems, and “jobs to be done” are.'
  prefs: []
  type: TYPE_NORMAL
- en: The expectation threshold of B2B customers is high because this space is likely
    riddled with a large number of competing products to choose from. In many cases,
    these customers are undergoing various rounds of **Requests for Proposals** (**RFPs**)
    and in-depth **Proof-of-Concept** (**PoC**) processes to make sure they are purchasing
    the right product for their use case. For an AI/ML product, these PoCs can be
    costly for your organization because you’ll need to acquire a large enough sample
    from your customers, use that data to train your models, and present your product
    and its capabilities to them once its performance is at an acceptable level to
    be able to show to your prospective customers.
  prefs: []
  type: TYPE_NORMAL
- en: This means there are often many eyes on these products, and each of those pairs
    of eyes may come with its own set of expectations and objections to your product,
    so you really need to be aware of multiple perspectives when building B2B products.
    This also means that as you build, you’re planning your release schedules with
    the idea that every release may include features that could impact your customers’
    individual workflows, so you often have to be mindful of how often and how loaded
    your release rollouts into production are.
  prefs: []
  type: TYPE_NORMAL
- en: This domain knowledge is then built up to the point where you as a PM and your
    broader organization as a whole then become thought leaders in the space they’re
    serving. Because the professional landscape is a small world, once a product—along
    with its leadership team—does make a splash, it will trickle across the professional
    world. Building credibility internally and externally is foundationally proportional
    to the level of industry expertise that’s acquired.
  prefs: []
  type: TYPE_NORMAL
- en: This further reinforces that the expectations of an AI/ML B2B product are quite
    high. Your users and buyers will scrutinize you on the tech stack that’s supporting
    your AI product as well as its performance and accuracy and will want to have
    evidence of explainability and why your product works. This will all be happening
    in conjunction with them testing and trialing other AI/ML solutions that are out
    there to compare them. This also means that you will have to be incredibly intentional
    about your releases to make sure there aren’t any lags in performance when you
    do make your push to production, with the full knowledge that other businesses
    are relying on your product.
  prefs: []
  type: TYPE_NORMAL
- en: Expectations are to be managed at every stage of the customer journey. B2B products
    exist in a massive ecosystem, and companies that use one product might pass outputs
    from that product to other workflows or to their own customers. This places a
    premium on B2B companies to maintain their company’s and product’s reputation
    and be more transparent about their marketing efforts, and introduces a lot more
    strain on AI/ML product teams to shy away from black-box algorithms and sell products
    that can stand by their determinants. B2B company customers have a tremendous
    amount of leverage because the stakes are high all around, and B2B products benefit
    from having engaged customers that want to see a certain level of performance
    from their products.
  prefs: []
  type: TYPE_NORMAL
- en: Experimentation – discover the needs of your collective
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With B2C products, because there isn’t such a hyperfocus on the domain you’re
    serving, the pressure on the market you’re serving is a bit more relaxed, but
    this creates another kind of pressure: the pressure to build a product that appeals
    to a much wider audience universally. Casting a wider net brings other areas into
    focus. As a PM building in a B2C environment, you’re going to approach your product
    and the market it serves more experimentally and derive insights about what’s
    most useful to your customers by tracking how they use your product. You can conduct
    focus groups, nurture beta testers, or interview your customers through in-product
    surveys, but because you can’t conduct customer interviews in the way you might
    for a B2B product, you’re left with understanding your customers’ impressions
    of your product through their in-product behaviors.'
  prefs: []
  type: TYPE_NORMAL
- en: This business model also consolidates all your user and buyer personas in one
    because, typically, the person that’s using your product is also the person buying
    it. Understanding the main drivers, desires, hopes, and dreams of your customer
    base becomes a very nebulous task because what you’re trying to capture are underlying
    needs, pain points, and moments of delight that will apply to all your users at
    once. This complicates a PM’s ability to empathize with their end users. Because
    most of these users aren’t signing the kind of year-long contracts you see with
    B2B products, the pressure to keep these consumers charmed is constant because
    they can leave at any point. This puts pressure on product, leadership, and development
    teams to consistently be providing their customer base reasons to stay and choose
    them.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the bird’s-eye view B2C products enforce on their builders, this
    means PMs have to be very discerning with their data analytics and metrics. Investing
    in understanding their customer lifetime value and customer acquisition costs
    and tracking those metrics is an important part of staying profitable and sustainable
    in the B2C landscape. B2C offers PMs an easy outlet for applying AI/ML toward
    the acquisition and retention of customers since they have such few touchpoints
    with the end users of their product. PMs in the consumer space also need to hone
    in on the demographic and individualistic qualities of their consumers to better
    understand what to build. If you see that it’s mostly people within a geographic
    area, gender, generation, or subgenre that appeals most to your product, you might
    start to build future features and releases in your roadmap with them in mind.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve mentioned many times that AI/ML products are experimental in nature because
    you want to leverage AI/ML in ways that will impact your product most obviously
    for it to be worth the top-heavy investment it requires. This is doubly true for
    B2C products because you’re building and using AI to deliver something that saves
    your consumers money or delights them, as well as using the data your product
    produces to decide on how to pivot your product. B2C PMs are reliant on data and
    analytics to make global decisions about their products on a regular basis. Although
    this is changing for the most part, traditionally in the B2B space, your marketing
    efforts are most oriented toward your buyers because they’re the ultimate decision-makers.
    This is sharply contrasted in the B2C space because your marketing efforts are
    directly linked to collective information you can derive and infer from your data.
  prefs: []
  type: TYPE_NORMAL
- en: Experimentation is fun to a point, but at the end of the day, it has to deliver.
    By far the greatest pressure this places on AI/ML consumer products is the pressure
    to perform well, maintain their enormous user base, and keep their consumers happy.
    This means that consumers want to use an app that does what it says it’s going
    to do in a way that’s visually appealing. Because they aren’t as concerned with
    the downstream risks of using your product as B2B customers are, consumers don’t
    particularly care why it’s working, just that it does work. This means that the
    issue of explainability is minimized in the B2C space, and the use of black-box
    or DL algorithms is less scrutinized.
  prefs: []
  type: TYPE_NORMAL
- en: B2B and B2C business models come with their own blend of challenges, but at
    the end of the day, players in both business models must understand their customers
    enough to create products that actually bring them value. Once you’ve built something
    of value for your customers, you enter a new phase. This next phase is about delivering
    that value consistently enough to not only win customers but keep them in the
    long run. In the following section, we will take a look under the hood to understand
    the necessary elements of delivering value consistently with the help of **ML
    operations** (**MLOps**) or **AI operations** (**AIOps**). Both will be used interchangeably
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Consistency and AIOps/MLOps – reliance and trust
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Maintaining trust, reliance, and consistency within your internal product teams
    as well as with your customer base is an act of committing to a specific ritual.
    Ritualizing the acquisition of clean data, tracking the flow through your infrastructure,
    tracking your model training, versions, and experiments, setting up a deployment
    schedule, and monitoring pipelines that get pushed to production are all part
    of the necessary work that needs to be done to make sure there’s a handle on the
    comings and goings of your AI/ML pipeline. This ritualizing is what’s referred
    to as MLOps or AIOps. In this section, we will explore the benefits of AIOps/MLOps
    and how they help you stay consistent.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re managing an ML pipeline, you will need to learn how to depend on an
    MLOps team and set up your team for success. You don’t want to get caught losing
    $20,000 in 10 minutes (as we saw in our *Profit margins* section earlier in this
    chapter) and have no leads for where the problem is stemming from. At the very
    least, you should have some idea where the problem is stemming from. MLOps is
    able to help with creating and managing the ML pipelines themselves, scaling those
    pipelines, and moving sensitive data at scale. Ultimately, the risks of compromising
    your customers’ reliance on and trust in your product are great. MLOps’ greatest
    contribution to your business is maintaining the consistency needed to build an
    AI/ML product that lasts.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve spoken at length in this chapter about productizing and what that looks
    like in different contexts of AI product management, but MLOps is actually where
    the productizing functionally happens. Taking a service and splitting that service
    apart into smaller pieces that are managed and standardized into reproducible
    and regulated segments is the work of “productizing,’’ and in that vein, MLOps
    is really the vehicle we use to truly productize AI/ML. In order to build the
    consistency and credibility customers can expect from your product, the ritual
    of MLOps needs to be cemented into your process. You never know when you'll need
    to revert to a specific version of your models or zero in on an experiment that
    had the right mix of factors. MLOps creates the organization and focus your team
    needs to have in order to have a handle on such a wide variety of experiments.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered some of the benefits of creating an MLOps organization
    to help keep track of your AI/ML pipeline, let’s explore how to build on that
    pipeline and evaluate the state of the models used. In the following section,
    we will reiterate some concepts around testing, retraining, and hyperparameter
    tuning to ensure your AI/ML pipelines are routinely being refreshed and optimized
    for performance.
  prefs: []
  type: TYPE_NORMAL
- en: Performance evaluation – testing, retraining, and hyperparameter tuning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MLOps helps us with accentuating the importance of retraining and hyperparameter
    tuning our models to deliver performance. Without having a built-out AI/ML pipeline
    that validates, trains, and retrains regularly, you won’t have a great handle
    on your product’s performance. Your MLOps team will essentially be made up of
    data scientists and ML and DL engineers that will be tasked with making adjustments
    to the hyperparameters of your model builds, testing those models, and retraining
    them when needed. This will need to be done in conjunction with managing the data
    needed to feed this testing, along with the code base for your product’s interface
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to testing and validating the models and working to clean and explore
    the data, MLOps team members also traditionally do software testing such as code
    tests, unit testing, and integration testing. In many cases, your AI products
    will effectively be traditional software products that incorporate AI/ML features
    in a subset of a greater ecosystem that’s in line with traditional software development.
    This means that MLOps may, in many cases, ensure your greater product is working
    functionally along with the AI/ML deliverables and outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Another major area MLOps is well suited to minimize the risk of is the concept
    of data drift and system degradation. We covered a few different types of drift
    in earlier chapters of this book, but we’d like to reiterate here that this is
    a risk that can sneak up on you. Model degradation can happen for a number of
    reasons. Perhaps there are differences between assumptions that are made with
    the data in training and in production. Perhaps there’s been a change to the data
    itself. Perhaps there are unseen biases in your training data that were never
    picked up on. Whatever the reason, continuous monitoring of models in production
    by MLOps will be your best defense in picking up on these nuances and changes
    in AI/ML outputs so that the risks from any number of issues within the ML pipeline
    are minimized as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapters 1* and *2* of this book, we covered the concept of continuous maintenance,
    which consists of **Continuous Integration** (**CI**), **Continuous Deployment**
    (**CD**), and **Continuous Testing** (**CT**). These basic areas of MLOps are
    mirrored in DevOps, which is common to traditional software development. The main
    differences are that in MLOps, CI isn’t just about testing and validating code—it’s
    also about validating and testing the models, data schemas, and the data samples
    themselves. Another difference is that CD isn’t just about deploying a software
    package but about nurturing an automated ML pipeline deployment process that’s
    optimized for deploying the model prediction service or for automatically scaling
    back to an earlier version if there is trouble ahead. Finally, CT isn’t just about
    testing software packages themselves but about retraining and testing the models
    that are actively being relied upon.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ve built on the idea of building consistency in how we manage
    our AI/ML pipelines and reinforced the importance of maintaining high standards
    in the performance of our AI/ML pipelines. This shouldn’t be viewed as a nice-to-have
    but rather a need-to-have. The performance and quality of AI/ML models can suffer
    for many reasons, so this consistent practice of scrutinizing performance is meant
    to ensure your product’s performance doesn’t come at the risk of the trust you’ve
    built with your developers and customers. In the following section, we’ll be discussing
    the importance of maintaining strong relationships, whether they’re internal or
    external.
  prefs: []
  type: TYPE_NORMAL
- en: Feedback loop – relationship building
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Continuously monitoring and reinforcing the legitimacy of a complicated system
    such as an AI/ML pipeline is all in service of the ultimate goal of building relationships
    that last. Relationships between your company and customers, your development
    team and your sales team, and your MLOps team and your leadership team are all
    forged through this work of building and going to market with your AI/ML native
    product. In AI/ML products, the feedback loop is everything. Nurturing a strong
    relationship with the builders of these products and the customers they serve
    is the underlying work of the PM. **Productizing** is the process of taking a
    service, process, skill, or idea and finding a way to present that to the greater
    market. Many layers of work go into accomplishing this well, but at its most basic
    level, this work is really just an elaborate feedback loop.
  prefs: []
  type: TYPE_NORMAL
- en: We haven’t discussed marketing much in this chapter, but this will also be an
    integral part of maintaining this feedback loop. Finding the right words to use
    to describe your product and reach your audience (also known as product language
    fit) will be a big part of productizing. You will have to create marketing collateral,
    advertisements, and sales scripts that will all convey the value the product you’re
    building with AI/ML will have for your customers and end users. Building product
    collateral and expressing that through your various marketing and sales channels
    will go a long way toward level-setting expectations with your customers.
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve seen earlier in this section, customers come with expectations, whether
    they’re business users or consumers, and it’s the task of the AI/ML PM to take
    those expectations and deliver something that aligns with them. Understanding
    the risk and promise of AI/ML and how it compares and contrasts to traditional
    software development, understanding the challenges and opportunities in your business
    model, translating all that to reproducible, repeatable tasks internally, and
    demonstrating consistency with your product’s performance in a way that aligns
    with your customers’ expectations is the work of productizing the AI native product.
    You’ll know you’ve successfully done this when you have a loyal customer base
    that wouldn’t dream of parting with you.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The act of productizing involves taking a concept, a service, or a piece of
    technology and developing it into a commercial product that’s suitable for the
    customers you’re looking to attract. As we’ve seen throughout this chapter, this
    work isn’t just a matter of getting your product up and running and creating a
    landing page for your potential customers to magically find. Productizing involves
    critically understanding the business model you’re working in and the ultimate
    audience you’re building for. Remember that AI products can be thought of as AI/ML
    services that are being built into traditional software products. This means that
    another big part of productizing for AI products involves the standardization
    and ritualization of the AI/ML service in a way that’s repeatable and predictable
    for the internal operations teams as well as the customers that will come to rely
    on your product.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re able to understand your market, build internal structures to make
    sure there’s consistency with the outputs of your AI/ML pipelines, and communicate
    that consistency through your marketing efforts, as well as the ongoing performance
    of your product, you’ve successfully productized. But productizing may not be
    enough. Depending on the specifics of the market you’re serving, you might have
    to customize your product even further for specific use cases, verticals, customer
    segments, and other peer groups. Because AI/ML model performance is so dependent
    on training data, there might be collections of data that perform differently
    when run against one model. Further specialization might be in order. If you find
    this applies to your product and market, read on to [*Chapter 8*](B18935_08.xhtml#_idTextAnchor246),
    where we will build on the concept of customization.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Past The AI Hype: When Is AI Actually Profitable?: [https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4](https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How to Scale AI in Your Organization: [https://hbr.org/2022/03/how-to-scale-ai-in-your-organization](https://hbr.org/2022/03/how-to-scale-ai-in-your-organization)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What are the net profit margins of a SaaS company/startup?: [https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25](https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean
    Your Data: [https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled](https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Why Commercial Artificial Intelligence Products Do Not Scale: [https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/](https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
