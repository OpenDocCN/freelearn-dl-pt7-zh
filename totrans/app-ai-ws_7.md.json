["```py\n    def all_moves_from_board_list(board_list, sign):\n        move_list = []\n        for board in board_list:\n            move_list.extend(all_moves_from_board(board, sign))\n        return move_list\n    ```", "```py\n    board = EMPTY_SIGN * 9\n    all_moves = all_moves_from_board(board, AI_SIGN )\n    all_moves\n    ```", "```py\n    ['X........',\n     '.X.......',\n     '..X......',\n     '...X.....',\n     '....X....',\n     '.....X...',\n     '......X..',\n     '.......X.',\n     '........X']\n    ```", "```py\n    def filter_wins(move_list, ai_wins, opponent_wins):\n        for board in move_list:\n            won_by = game_won_by(board)\n            if won_by == AI_SIGN:\n                ai_wins.append(board)\n                move_list.remove(board)\n            elif won_by == OPPONENT_SIGN:\n                opponent_wins.append(board)\n                move_list.remove(board)\n    ```", "```py\n    def count_possibilities():\n        board = EMPTY_SIGN * 9\n        move_list = [board]\n        ai_wins = []\n        opponent_wins = []\n        for i in range(9):\n            print('step ' + str(i) + '. Moves: ' \\\n                  + str(len(move_list)))\n            sign = AI_SIGN if \\\n                   i % 2 == 0 else OPPONENT_SIGN\n            move_list = all_moves_from_board_list\\\n                        (move_list, sign)\n            filter_wins(move_list, ai_wins, \\\n                        opponent_wins)\n        print('First player wins: ' + str(len(ai_wins)))\n        print('Second player wins: ' + str(len(opponent_wins)))\n        print('Draw', str(len(move_list)))\n        print('Total', str(len(ai_wins) \\\n              + len(opponent_wins) + len(move_list)))\n        return len(ai_wins), len(opponent_wins), \\\n               len(move_list), len(ai_wins) \\\n               + len(opponent_wins) + len(move_list)\n    ```", "```py\n    first_player, second_player, \\\n    draw, total = count_possibilities()\n    ```", "```py\n    step 0\\. Moves: 1\n    step 1\\. Moves: 9\n    step 2\\. Moves: 72\n    step 3\\. Moves: 504\n    step 4\\. Moves: 3024\n    step 5\\. Moves: 13680\n    step 6\\. Moves: 49402\n    step 7\\. Moves: 111109\n    step 8\\. Moves: 156775\n    First player wins: 106279\n    Second player wins: 68644\n    Draw 91150\n    Total 266073\n    ```", "```py\n    def player_can_win(board, sign):\n        next_moves = all_moves_from_board(board, sign)\n        for next_move in next_moves:\n            if game_won_by(next_move) == sign:\n                return True\n        return False\n    ```", "```py\n    def ai_move(board):\n        new_boards = all_moves_from_board(board, AI_SIGN)\n        for new_board in new_boards:\n            if game_won_by(new_board) == AI_SIGN:\n                return new_board\n        safe_moves = []\n        for new_board in new_boards:\n            if not player_can_win(new_board, OPPONENT_SIGN):\n                safe_moves.append(new_board)\n        return choice(safe_moves) \\\n        if len(safe_moves) > 0 else new_boards[0]\n    ```", "```py\n    def all_moves_from_board(board, sign):\n        move_list = []\n        for i, v in enumerate(board):\n            if v == EMPTY_SIGN:\n                new_board = board[:i] + sign + board[i+1:]\n                move_list.append(new_board)\n                if game_won_by(new_board) == AI_SIGN:\n                    return [new_board]\n        if sign == AI_SIGN:\n            safe_moves = []\n            for move in move_list:\n                if not player_can_win(move, OPPONENT_SIGN):\n                    safe_moves.append(move)\n            return safe_moves if len(safe_moves) > 0 else move_list[0:1]\n        else:\n            return move_list\n    ```", "```py\n    first_player, second_player, \\\n    draw, total = count_possibilities()\n    ```", "```py\n    step 0\\. Moves: 1\n    step 1\\. Moves: 9\n    step 2\\. Moves: 72\n    step 3\\. Moves: 504\n    step 4\\. Moves: 3024\n    step 5\\. Moves: 5197\n    step 6\\. Moves: 18606\n    step 7\\. Moves: 19592\n    step 8\\. Moves: 30936\n    First player wins: 20843\n    Second player wins: 962\n    Draw 20243\n    Total 42048\n    ```", "```py\n    def all_moves_from_board(board, sign):\n        if sign == AI_SIGN:\n            empty_field_count = board.count(EMPTY_SIGN)\n            if empty_field_count == 9:\n                return [sign + EMPTY_SIGN * 8]\n            elif empty_field_count == 7:\n                return [board[:8] + sign if board[8] == \\\n                        EMPTY_SIGN else board[:4] + sign + board[5:]]\n        move_list = []\n        for i, v in enumerate(board):\n            if v == EMPTY_SIGN:\n                new_board = board[:i] + sign + board[i+1:]\n                move_list.append(new_board)\n                if game_won_by(new_board) == AI_SIGN:\n                    return [new_board]\n        if sign == AI_SIGN:\n            safe_moves = []\n            for move in move_list:\n                if not player_can_win(move, OPPONENT_SIGN):\n                    safe_moves.append(move)\n            return safe_moves if len(safe_moves) > 0 else move_list[0:1]\n        else:\n            return move_list\n    ```", "```py\n    first_player, second_player, draw, total = count_possibilities()\n    ```", "```py\n    step 0\\. Moves: 1\n    step 1\\. Moves: 1\n    step 2\\. Moves: 8\n    step 3\\. Moves: 8\n    step 4\\. Moves: 48\n    step 5\\. Moves: 38\n    step 6\\. Moves: 108\n    step 7\\. Moves: 76\n    step 8\\. Moves: 90\n    First player wins: 128\n    Second player wins: 0\n    Draw 60\n    Total 188\n    ```", "```py\n    from easyAI import TwoPlayersGame, Human_Player\n    class ConnectFour(TwoPlayersGame):\n        def __init__(self, players):\n            self.players = players\n            self.board = [0 for i in range(42)]\n            self.nplayer = 1  \n            def generate_winning_tuples():\n                tuples = []\n                # horizontal\n                tuples += [list(range(row*7+column, \\\n                           row*7+column+4, 1)) \\\n                           for row in range(6) \\\n                           for column in range(4)]\n                # vertical\n                tuples += [list(range(row*7+column, \\\n                           row*7+column+28, 7)) \\\n                           for row in range(3) \\\n                           for column in range(7)]\n                # diagonal forward\n                tuples += [list(range(row*7+column, \\\n                           row*7+column+32, 8)) \\\n                           for row in range(3) \\\n                           for column in range(4)]\n                # diagonal backward\n                tuples += [list(range(row*7+column, \\\n                           row*7+column+24, 6)) \\\n                           for row in range(3) \\\n                           for column in range(3, 7, 1)]\n                return tuples\n            self.tuples = generate_winning_tuples()\n    ```", "```py\n        def possible_moves(self):\n            return [column+1 \\\n                    for column in range(7) \\\n                    if any([self.board[column+row*7] == 0 \\\n                            for row in range(6)])\n                    ]\n    ```", "```py\n        def make_move(self, move):\n            column = int(move) - 1\n            for row in range(5, -1, -1):\n                index = column + row*7\n                if self.board[index] == 0:\n                    self.board[index] = self.nplayer\n                    return\n        # optional method (speeds up the AI)\n        def unmake_move(self, move):\n            column = int(move) - 1\n            for row in range(6):\n                index = column + row*7\n                if self.board[index] != 0:\n                    self.board[index] = 0\n                    return\n    ```", "```py\n        def lose(self):\n            return any([all([(self.board[c] == self.nopponent)\n                             for c in line])\n                        for line in self.tuples])\n        def is_over(self):\n            return (self.possible_moves() == []) or self.lose()\n    ```", "```py\n        def show(self):\n            print('\\n'+'\\n'.join([\n                ' '.join([['.', 'O', 'X']\\\n                          [self.board[7*row+column]] \\\n                          for column in range(7)])\n                for row in range(6)]))\n        def scoring(self):\n            return -100 if self.lose() else 0\n    if __name__ == \"__main__\":\n        from easyAI import AI_Player, Negamax\n        ai_algo = Negamax(6)\n        ConnectFour([Human_Player(), \\\n                     AI_Player(ai_algo)]).play()\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    from sklearn import preprocessing\n    from sklearn import model_selection\n    from sklearn import linear_model\n    from sklearn.preprocessing import PolynomialFeatures\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop/'\\\n               'master/Datasets/boston_house_price.csv'\n    df = pd.read_csv(file_url)\n    ```", "```py\n    features = np.array(df.drop('MEDV', 1))\n    label = np.array(df['MEDV'])\n    scaled_features = preprocessing.scale(features)\n    ```", "```py\n    array([[-0.41978194,  0.28482986, -1.2879095 , ..., \n            -0.66660821, -1.45900038, -1.0755623 ],\n           [-0.41733926, -0.48772236, -0.59338101, ..., \n            -0.98732948, -0.30309415, -0.49243937],\n           [-0.41734159, -0.48772236, -0.59338101, ..., \n            -0.98732948, -0.30309415, -1.2087274 ],\n           ...,\n           [-0.41344658, -0.48772236,  0.11573841, ..., \n            -0.80321172,  1.17646583, -0.98304761],\n           [-0.40776407, -0.48772236,  0.11573841, ..., \n            -0.80321172,  1.17646583, -0.86530163],\n           [-0.41500016, -0.48772236,  0.11573841, ..., \n            -0.80321172,  1.17646583, -0.66905833]])\n    ```", "```py\n    poly_1_scaled_features = PolynomialFeatures(degree=1)\\\n                             .fit_transform(scaled_features)\n    poly_2_scaled_features = PolynomialFeatures(degree=2)\\\n                             .fit_transform(scaled_features)\n    poly_3_scaled_features = PolynomialFeatures(degree=3)\\\n                             .fit_transform(scaled_features)\n    ```", "```py\n    array([[ 1\\.        , -0.41978194,  0.28482986, ..., -0.66660821,\n            -1.45900038, -1.0755623 ],\n           [ 1\\.        , -0.41733926, -0.48772236, ..., -0.98732948,\n            -0.30309415, -0.49243937],\n           [ 1\\.        , -0.41734159, -0.48772236, ..., -0.98732948,\n            -0.30309415, -1.2087274 ],\n           ...,\n           [ 1\\.        , -0.41344658, -0.48772236, ..., -0.80321172,\n             1.17646583, -0.98304761],\n           [ 1\\.        , -0.40776407, -0.48772236, ..., -0.80321172,\n             1.17646583, -0.86530163],\n           [ 1\\.        , -0.41500016, -0.48772236, ..., -0.80321172,\n             1.17646583, -0.66905833]])\n    ```", "```py\n    array([[ 1\\.        , -0.41978194,  0.28482986, ..., -2.28953024,\n            -1.68782164, -1.24424733],\n           [ 1\\.        , -0.41733926, -0.48772236, ..., -0.04523847,\n            -0.07349928, -0.11941484],\n           [ 1\\.        , -0.41734159, -0.48772236, ..., -0.11104103,\n            -0.4428272 , -1.76597723],\n           ...,\n           [ 1\\.        , -0.41344658, -0.48772236, ..., -1.36060852,\n             1.13691611, -0.9500001 ],\n           [ 1\\.        , -0.40776407, -0.48772236, ..., -1.19763962,\n             0.88087515, -0.64789192],\n           [ 1\\.        , -0.41500016, -0.48772236, ..., -0.9260248 ,\n             0.52663205, -0.29949664]])\n    ```", "```py\n    (poly_1_features_train, poly_1_features_test, \\\n    poly_label_train, poly_label_test) = \\\n    model_selection.train_test_split(poly_1_scaled_features, \\\n                                     label, \\\n                                     test_size=0.1, \\\n                                     random_state=8)\n    (poly_2_features_train, poly_2_features_test, \\\n    poly_label_train, poly_label_test) = \\\n    model_selection.train_test_split(poly_2_scaled_features, \\\n                                     label, \\\n                                     test_size=0.1, \\\n                                     random_state=8)\n    (poly_3_features_train, poly_3_features_test, \\\n    poly_label_train, poly_label_test) = \\\n    model_selection.train_test_split(poly_3_scaled_features, \\\n                                     label, \\\n                                     test_size=0.1, \\\n                                     random_state=8)\n    ```", "```py\n    model_1 = linear_model.LinearRegression()\n    model_1.fit(poly_1_features_train, poly_label_train)\n    model_1_score_train = model_1.score(poly_1_features_train, \\\n                                        poly_label_train)\n    model_1_score_test = model_1.score(poly_1_features_test, \\\n                                       poly_label_test)\n    ```", "```py\n    0.7406006443486721\n    ```", "```py\n    0.6772229017901507\n    ```", "```py\n    model_2 = linear_model.LinearRegression()\n    model_2.fit(poly_2_features_train, poly_label_train)\n    model_2_score_train = model_2.score(poly_2_features_train, \\\n                                        poly_label_train)\n    model_2_score_test = model_2.score(poly_2_features_test, \\\n                                       poly_label_test)\n    ```", "```py\n    0.9251199698832675\n    ```", "```py\n    0.8253870684280571\n    ```", "```py\n    model_3 = linear_model.LinearRegression()\n    model_3.fit(poly_3_features_train, poly_label_train)\n    model_3_score_train = model_3.score(poly_3_features_train, \\\n                                        poly_label_train)\n    model_3_score_test = model_3.score(poly_3_features_test, \\\n                                       poly_label_test)\n    ```", "```py\n    0.9910498071894897\n    ```", "```py\n    -8430.781888645262\n    ```", "```py\n    model_1_prediction = model_1.predict(poly_1_features_test)\n    model_2_prediction = model_2.predict(poly_2_features_test)\n    model_3_prediction = model_3.predict(poly_3_features_test)\n    df_prediction = pd.DataFrame(poly_label_test)\n    df_prediction.rename(columns = {0:'label'}, inplace = True)\n    df_prediction['model_1_prediction'] = \\\n    pd.DataFrame(model_1_prediction)\n    df_prediction['model_2_prediction'] = \\\n    pd.DataFrame(model_2_prediction)\n    df_prediction['model_3_prediction'] = \\\n    pd.DataFrame(model_3_prediction)\n    ```", "```py\n    from sklearn import neighbors\n    ```", "```py\n    def fit_knn(k, p, features_train, label_train, \\\n                features_test, label_test):\n        classifier = neighbors.KNeighborsClassifier(n_neighbors=k, p=p)\n        classifier.fit(features_train, label_train)\n        return classifier.score(features_train, label_train), \\\n               classifier.score(features_test, label_test)\n    ```", "```py\n    acc_train_1, acc_test_1 = fit_knn(5, 2, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_1, acc_test_1\n    ```", "```py\n    (0.78625, 0.75)\n    ```", "```py\n    acc_train_2, acc_test_2 = fit_knn(10, 2, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_2, acc_test_2\n    ```", "```py\n    (0.775, 0.785)\n    ```", "```py\n    acc_train_3, acc_test_3 = fit_knn(15, 2, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_3, acc_test_3\n    ```", "```py\n    (0.76625, 0.79)\n    ```", "```py\n    acc_train_4, acc_test_4 = fit_knn(25, 2, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_4, acc_test_4\n    ```", "```py\n    (0.7375, 0.77)\n    ```", "```py\n    acc_train_5, acc_test_5 = fit_knn(50, 2, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_5, acc_test_5\n    ```", "```py\n    (0.70625, 0.775)\n    ```", "```py\n    acc_train_6, acc_test_6 = fit_knn(5, 1, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_6, acc_test_6\n    ```", "```py\n    (0.8, 0.735)\n    ```", "```py\n    acc_train_7, acc_test_7 = fit_knn(10, 1, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_7, acc_test_7\n    ```", "```py\n    (0.77, 0.785)\n    ```", "```py\n    acc_train_8, acc_test_8 = fit_knn(15, 1, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_8, acc_test_8\n    ```", "```py\n    (0.7575, 0.775)\n    ```", "```py\n    acc_train_9, acc_test_9 = fit_knn(25, 1, features_train, \\\n                                      label_train, \\\n                                      features_test, label_test)\n    acc_train_9, acc_test_9\n    ```", "```py\n    (0.745, 0.8)\n    ```", "```py\n    acc_train_10, acc_test_10 = fit_knn(50, 1, features_train, \\\n                                        label_train, \\\n                                        features_test, label_test)\n    acc_train_10, acc_test_10\n    ```", "```py\n    (0.70875, 0.78)\n    ```", "```py\n    from sklearn import svm\n    ```", "```py\n    def fit_svm(features_train, label_train, \\\n                features_test, label_test, \\\n                kernel=\"linear\", C=1, \\\n                degree=3, gamma='scale'):\n        classifier = svm.SVC(kernel=kernel, C=C, \\\n                             degree=degree, gamma=gamma)\n        classifier.fit(features_train, label_train)\n        return classifier.score(features_train, label_train), \\\n               classifier.score(features_test, label_test)\n    ```", "```py\n    acc_train_1, \\\n    acc_test_1 =  fit_svm(features_train, \\\n                          label_train, \\\n                          features_test, \\\n                          label_test)\n    acc_train_1,  acc_test_1\n    ```", "```py\n    (0.71625, 0.75)\n    ```", "```py\n    acc_train_2, \\\n    acc_test_2 = fit_svm(features_train, label_train, \\\n                         features_test, label_test, \\\n                         kernel=\"poly\",  C=1, \\\n                         degree=4, gamma=0.05)\n    acc_train_2,  acc_test_2\n    ```", "```py\n    (0.68875, 0.745)\n    ```", "```py\n    acc_train_3, \\\n    acc_test_3 = fit_svm(features_train, \\\n                         label_train, features_test, \\\n                         label_test, kernel=\"poly\",  \\\n                         C=2, degree=4, gamma=0.05)\n    acc_train_3,  acc_test_3\n    ```", "```py\n    (0.68875, 0.745)\n    ```", "```py\n    acc_train_4, \\\n    acc_test_4 = fit_svm(features_train, \\\n                         label_train, features_test, \\\n                         label_test, kernel=\"poly\",  \\\n                         C=1, degree=4, gamma=0.25)\n    acc_train_4,  acc_test_4\n    ```", "```py\n    (0.84625, 0.775)\n    ```", "```py\n    acc_train_5, \\\n    acc_test_5 = fit_svm(features_train, \\\n                         label_train, features_test, \\\n                         label_test, kernel=\"poly\",  \\\n                         C=1, degree=4, gamma=0.5)\n    acc_train_5,  acc_test_5\n    ```", "```py\n    (0.9575, 0.73)\n    ```", "```py\n    acc_train_6, \\\n    acc_test_6 = fit_svm(features_train, label_train, \\\n                         features_test, label_test, \\\n                         kernel=\"poly\",  C=1, \\\n                         degree=4, gamma=0.16)\n    acc_train_6,  acc_test_6\n    ```", "```py\n    (0.76375, 0.785)\n    ```", "```py\n    acc_train_7, \\\n    acc_test_7 = fit_svm(features_train, label_train, \\\n                         features_test, label_test, \\\n                         kernel=\"sigmoid\")\n    acc_train_7,  acc_test_7\n    ```", "```py\n    (0.635, 0.66)\n    ```", "```py\n    acc_train_8, \\\n    acc_test_8 = fit_svm(features_train, \\\n                         label_train, features_test, \\\n                         label_test, kernel=\"rbf\", \\\n                         gamma=0.15)\n    acc_train_8,  acc_test_8\n    ```", "```py\n    (0.7175, 0.765)\n    ```", "```py\n    acc_train_9, \\\n    acc_test_9 = fit_svm(features_train, \\\n                         label_train, features_test, \\\n                         label_test, kernel=\"rbf\", \\\n                         gamma=0.25)\n    acc_train_9,  acc_test_9\n    ```", "```py\n    (0.74, 0.765)\n    ```", "```py\n    acc_train_10, \\\n    acc_test_10 = fit_svm(features_train, label_train, \\\n                          features_test, label_test, \\\n                          kernel=\"rbf\", gamma=0.35)\n    acc_train_10, acc_test_10\n    ```", "```py\n    (0.78125, 0.775)\n    ```", "```py\n    import pandas as pd\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop/'\\\n               'master/Datasets/car.csv'\n    ```", "```py\n    df = pd.read_csv(file_url) \n    ```", "```py\n    df.head()\n    ```", "```py\n    from sklearn import preprocessing\n    ```", "```py\n    def encode(data_frame, column):\n        label_encoder = preprocessing.LabelEncoder()\n        label_encoder.fit(data_frame[column].unique())\n        return label_encoder.transform(data_frame[column])\n    ```", "```py\n    for column in df.columns:\n        df[column] = encode(df, column)\n    ```", "```py\n    df.head()\n    ```", "```py\n    label = df.pop('class')\n    ```", "```py\n    from sklearn import model_selection\n    ```", "```py\n    features_train, features_test, label_train, label_test = \\\n    model_selection.train_test_split(df, label, \\\n                                     test_size=0.1, \\\n                                     random_state=88)\n    ```", "```py\n    from sklearn.tree import DecisionTreeClassifier\n    ```", "```py\n    decision_tree = DecisionTreeClassifier()\n    ```", "```py\n    decision_tree.fit(features_train, label_train)\n    ```", "```py\n    decision_tree.score( features_test, label_test )\n    ```", "```py\n    0.953757225433526\n    ```", "```py\n    from sklearn.metrics import classification_report\n    ```", "```py\n    print(classification_report(label_test, \\\n          decision_tree.predict(features_test)))\n    ```", "```py\n    from sklearn.ensemble import RandomForestClassifier\n    ```", "```py\n    random_forest_classifier = \\\n    RandomForestClassifier(n_estimators=100, \\\n                           max_depth=6, random_state=168)\n    ```", "```py\n    random_forest_classifier.fit(features_train, label_train)\n    ```", "```py\n    rf_preds_test = random_forest_classifier.fit(features_train, \\\n                                                 label_train)\n    rf_preds_test\n    ```", "```py\n    from sklearn.metrics import classification_report\n    ```", "```py\n    print(classification_report(label_test, rf_preds_test))\n    ```", "```py\n    from sklearn.metrics import confusion_matrix\n    ```", "```py\n    confusion_matrix(label_test, rf_preds_test)\n    ```", "```py\n    array([[ 32, 0, 10, 0], \n          [ 8, 0, 0, 1], \n          [ 5, 0, 109, 0], \n          [ 3, 0, 0, 5]])\n    ```", "```py\n    rf_varimp = random_forest_classifier.feature_importances_\n    rf_varimp\n    ```", "```py\n    array([0.12676384, 0.10366314, 0.02119621, 0.35266673, \n           0.05915769, 0.33655239])\n    ```", "```py\n    from sklearn.ensemble import ExtraTreesClassifier\n    ```", "```py\n    extra_trees_classifier = \\\n    ExtraTreesClassifier(n_estimators=100, \\\n                         max_depth=6, random_state=168)\n    ```", "```py\n    extra_trees_classifier.fit(features_train, label_train)\n    ```", "```py\n    et_preds_test = extra_trees_classifier.predict(features_test)\n    et_preds_test\n    ```", "```py\n    print(classification_report(label_test, \\\n          extra_trees_classifier.predict(features_test)))\n    ```", "```py\n    confusion_matrix(label_test, et_preds_test)\n    ```", "```py\n    array([[ 28,   0,  14,   0],\n           [  9,   0,   0,   0],\n           [  2,   0, 112,   0],\n           [  7,   0,   0,   1]])\n    ```", "```py\n    et_varimp = extra_trees_classifier.feature_importances_\n    et_varimp\n    ```", "```py\n    array([0.08844544, 0.0702334 , 0.01440408, 0.37662014, 0.05965896,\n           0.39063797])\n    ```", "```py\n    import pandas as pd\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop/'\\\n               'master/Datasets/'\\\n               'Sales_Transactions_Dataset_Weekly.csv'\n    df = pd.read_csv(file_url)\n    df\n    ```", "```py\n    df2 = df.drop(df.iloc[:, 0:55], inplace = False, axis = 1)\n    ```", "```py\n    drop function of the pandas DataFrame in order to remove the first 55 columns. We also set the inplace parameter to False in order to not remove the column of our original df DataFrame. As a result, we should only have the normalized columns from 0 to 51 in df2 and df should still be unchanged.\n    ```", "```py\n    from sklearn.cluster import KMeans\n    k_means_model = KMeans(n_clusters=8, random_state=8)\n    k_means_model.fit(df2)\n    ```", "```py\n    labels = k_means_model.labels_\n    labels\n    ```", "```py\n    df.drop(df.iloc[:, 53:], inplace = True, axis = 1)\n    df.drop('Product_Code', inplace = True, axis = 1)\n    df['label'] = labels\n    df\n    ```", "```py\n    df_agg = df.groupby('label').sum()\n    df_final = df[['label','W0']].groupby('label').count()\n    df_final=df_final.rename(columns = {'W0':'count_product'})\n    df_final['total_sales'] = df_agg.sum(axis = 1)\n    df_final['yearly_average_sales']= \\\n    df_final['total_sales'] / df_final['count_product']\n    df_final.sort_values(by='yearly_average_sales', \\\n                         ascending=False, inplace = True)\n    df_final\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    from sklearn import preprocessing\n    from sklearn.cluster import MeanShift\n    from sklearn.cluster import AgglomerativeClustering\n    from scipy.cluster.hierarchy import dendrogram\n    import scipy.cluster.hierarchy as sch\n    from sklearn import metrics\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop/'\\\n               'master/Datasets/winequality-red.csv'\n    df = pd.read_csv(file_url,sep=';')\n    df\n    ```", "```py\n    features = df.drop('quality', 1)\n    label = df['quality']\n    scaled_features = preprocessing.scale(features)\n    ```", "```py\n    mean_shift_model = MeanShift()\n    mean_shift_model.fit(scaled_features)\n    n_cluster_mean_shift = len(mean_shift_model.cluster_centers_)\n    label_mean_shift = mean_shift_model.labels_\n    n_cluster_mean_shift\n    ```", "```py\n    10\n    ```", "```py\n    dendrogram = sch.dendrogram(sch.linkage(scaled_features, \\\n                                method='ward'))\n    agglomerative_model = \\\n    AgglomerativeClustering(n_clusters=7, \\\n                            affinity='euclidean', \\\n                            linkage='ward')\n    agglomerative_model.fit(scaled_features)\n    label_agglomerative = agglomerative_model.labels_\n    ```", "```py\n    ARI_mean=metrics.adjusted_rand_score(label, label_mean_shift)\n    ARI_agg=metrics.adjusted_rand_score(label, label_agglomerative)\n    ARI_mean\n    ```", "```py\n    0.0006771608724007207\n    ```", "```py\n    ARI_agg\n    ```", "```py\n    0.05358047852603172\n    ```", "```py\n    AMI_mean = metrics.adjusted_mutual_info_score(label, \\\n                                                  label_mean_shift)\n    AMI_agg = metrics.adjusted_mutual_info_score(label, \\\n                                                 label_agglomerative)\n    AMI_mean\n    ```", "```py\n    0.004837187596124968\n    ```", "```py\n    AMI_agg\n    ```", "```py\n    0.05993098663692826\n    ```", "```py\n    0.021907254751144124\n    ```", "```py\n    V_agg\n    ```", "```py\n    0.07549735446050691\n    ```", "```py\n    0.5721233634622408\n    ```", "```py\n    FM_agg\n    ```", "```py\n    0.3300681478007641\n    ```", "```py\n    Sil_mean = metrics.silhouette_score(scaled_features, \\\n                                        label_mean_shift)\n    Sil_agg = metrics.silhouette_score(scaled_features, \\\n                                       label_agglomerative)\n    Sil_mean\n    ```", "```py\n    0.32769323700400077\n    ```", "```py\n    Sil_agg\n    ```", "```py\n    0.1591882574407987\n    ```", "```py\n    44.62091774102674\n    ```", "```py\n    CH_agg\n    ```", "```py\n    223.5171774491095\n    ```", "```py\n    DB_mean = metrics.davies_bouldin_score(scaled_features, \\\n                                           label_mean_shift)\n    DB_agg = metrics.davies_bouldin_score(scaled_features, \\\n                                          label_agglomerative)\n    DB_mean\n    ```", "```py\n    0.8106334674570222\n    ```", "```py\n    DB_agg\n    ```", "```py\n    1.4975443816135114\n    ```", "```py\n    import tensorflow.keras.datasets.mnist as mnist\n    ```", "```py\n    (features_train, label_train), \\\n    (features_test, label_test) = mnist.load_data()\n    ```", "```py\n    label_train\n    ```", "```py\n    array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\n    ```", "```py\n    features_train.shape\n    ```", "```py\n    (60000, 28, 28)\n    ```", "```py\n    features_test.shape\n    ```", "```py\n    (10000, 28, 28)\n    ```", "```py\n    features_train = features_train / 255.0\n    features_test = features_test / 255.0\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    input_layer = layers.Flatten(input_shape=(28,28))\n    ```", "```py\n    layer1 = layers.Dense(128, activation='relu')\n    ```", "```py\n    final_layer = layers.Dense(10, activation='softmax')\n    ```", "```py\n    model.add(input_layer)\n    model.add(layer1)\n    model.add(layers.Dropout(0.25))\n    model.add(final_layer)\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, \\\n                  metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \\\n                                                patience=5)\n    ```", "```py\n    model.fit(features_train, label_train, epochs=10, \\\n              validation_split = 0.2, \\\n              callbacks=[callback], verbose=2)\n    ```", "```py\n    import tensorflow.keras.datasets.fashion_mnist as fashion_mnist\n    ```", "```py\n    (features_train, label_train), \\\n    (features_test, label_test) = fashion_mnist.load_data()\n    ```", "```py\n    features_train.shape\n    ```", "```py\n    (60000, 28, 28)\n    ```", "```py\n    features_test.shape\n    ```", "```py\n    (10000, 28, 28)\n    ```", "```py\n    features_train = features_train.reshape(60000, 28, 28, 1)\n    features_test = features_test.reshape(10000, 28, 28, 1)\n    ```", "```py\n    features_train = features_train / 255.0\n    features_test = features_test / 255.0\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    conv_layer1 = layers.Conv2D(64, (3,3), \\\n                  activation='relu', input_shape=(28, 28, 1))\n    ```", "```py\n    conv_layer2 = layers.Conv2D(64, (3,3), activation='relu')\n    ```", "```py\n    fc_layer1 = layers.Dense(128, activation='relu')\n    ```", "```py\n    fc_layer2 = layers.Dense(10, activation='softmax')\n    ```", "```py\n    model.add(conv_layer1)\n    model.add(layers.MaxPooling2D(2, 2))\n    model.add(conv_layer2)\n    model.add(layers.MaxPooling2D(2, 2))\n    model.add(layers.Flatten())\n    model.add(fc_layer1)\n    model.add(fc_layer2)\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='sparse_categorical_crossentropy', \\\n                  optimizer=optimizer, metrics=['accuracy'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(features_train, label_train, \\\n              epochs=5, validation_split = 0.2, verbose=2)\n    ```", "```py\n    model.evaluate(features_test, label_test)\n    ```", "```py\n    10000/10000 [==============================] - 1s 108us/sample - loss: 0.2746 - accuracy: 0.8976\n    [0.27461639745235444, 0.8976]\n    ```", "```py\n    import pandas as pd\n    import numpy as np\n    ```", "```py\n    file_url = 'https://raw.githubusercontent.com/'\\\n               'PacktWorkshops/'\\\n               'The-Applied-Artificial-Intelligence-Workshop/'\\\n               'master/Datasets/yahoo_spx.csv'\n    ```", "```py\n    df = pd.read_csv(file_url)\n    ```", "```py\n    stock_data = df.iloc[:, 1:2].values\n    ```", "```py\n    from sklearn.preprocessing import MinMaxScaler\n    ```", "```py\n    sc = MinMaxScaler()\n    ```", "```py\n    stock_data_scaled = sc.fit_transform(stock_data)\n    ```", "```py\n    X_data = []\n    y_data = []\n    ```", "```py\n    window = 30\n    ```", "```py\n    for i in range(window, len(df)):\n        X_data.append(stock_data_scaled[i - window:i, 0])\n        y_data.append(stock_data_scaled[i, 0])\n    ```", "```py\n    X_data = np.array(X_data)\n    y_data = np.array(y_data)\n    ```", "```py\n    X_data = np.reshape(X_data, (X_data.shape[0], \\\n                        X_data.shape[1], 1))\n    ```", "```py\n    features_train = X_data[:1000]\n    label_train = y_data[:1000]\n    ```", "```py\n    features_test = X_data[:1000]\n    label_test = y_data[:1000]\n    ```", "```py\n    import numpy as np\n    import tensorflow as tf\n    from tensorflow.keras import layers\n    ```", "```py\n    np.random.seed(8)\n    tf.random.set_seed(8)\n    ```", "```py\n    model = tf.keras.Sequential()\n    ```", "```py\n    lstm_layer1 = layers.LSTM(units=50,return_sequences=True,\\\n                              input_shape=(features_train.shape[1], 1))\n    ```", "```py\n    lstm_layer2 = layers.LSTM(units=50,return_sequences=True)\n    ```", "```py\n    lstm_layer3 = layers.LSTM(units=50,return_sequences=True)\n    ```", "```py\n    lstm_layer4 = layers.LSTM(units=50)\n    ```", "```py\n    fc_layer = layers.Dense(1)\n    ```", "```py\n    model.add(lstm_layer1)\n    model.add(layers.Dropout(0.2))\n    model.add(lstm_layer2)\n    model.add(layers.Dropout(0.2))\n    model.add(lstm_layer3)\n    model.add(layers.Dropout(0.2))\n    model.add(lstm_layer4)\n    model.add(layers.Dropout(0.2))\n    model.add(fc_layer)\n    ```", "```py\n    optimizer = tf.keras.optimizers.Adam(0.001)\n    ```", "```py\n    model.compile(loss='mean_squared_error', \\\n                  optimizer=optimizer, metrics=['mse'])\n    ```", "```py\n    model.summary()\n    ```", "```py\n    model.fit(features_train, label_train, epochs=10, \\\n              validation_split = 0.2, verbose=2)\n    ```", "```py\n    model.evaluate(features_test, label_test)\n    ```", "```py\n    1000/1000 [==============================] - 0s 279us/sample - loss: 0.0016 - mse: 0.0016\n    [0.00158528157370165, 0.0015852816]\n    ```"]