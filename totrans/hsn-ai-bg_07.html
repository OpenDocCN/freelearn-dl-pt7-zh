<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Generative Models</h1>
                </header>
            
            <article>
                
<p>Generative models are the most promising push toward enabling computers to have an understanding of the world. They are true unsupervised models, and are able to perform those tasks that many today consider to be at the cutting edge of <strong>artificial intelligence </strong>(<strong>AI</strong>). Generative models are different for precisely the reason as it sounds: they generate data. Centered mostly around computer vision tasks, this class of network has the power to create new faces, new handwriting, or even paintings. </p>
<p>In this section, we'll introduce generative models and their foundations, focusing <span>specifically </span>on the two most popular types of model, the <strong>variational autoencoder </strong>(<strong>VAE</strong>), and the <strong>generative adversarial network</strong> (<strong>GAN</strong>), where you'll learn ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>In this chapter, we will be utilizing Python 3. You'll need the following packages to be installed:</p>
<ul>
<li>NumPy</li>
<li>TensorFlow</li>
<li>PyTorch</li>
</ul>
<p>It will be helpful if your machine is GPU enabled, as discussed in <a href="69346214-320e-487f-b4cf-bd5c469dc75e.xhtml" target="_blank">Chapter 3</a>, <em>Platforms and Other Essentials</em>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Getting to AI – generative models</h1>
                </header>
            
            <article>
                
<p>Generative models are a class of neural networks that are wholly different from what we have discussed thus far. The networks that we've discussed hitherto are feedforward networks. CNNs and RNNs are all discriminatory networks, in that they try to classify data. Given a specific input, they can predict classes or other labels. Generative models, on the other hand, try to predict features given a certain label. They do this by having a parameter set that is much smaller than the amount of data they are learning, which forces them to comprehend the general essence of the data in an efficient manner. </p>
<p>There are two main types of generative model, VAE and GAN. First, we'll start with the motivations for generative ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Autoencoders</h1>
                </header>
            
            <article>
                
<p>Autoencoders, and their encoder/decoder frameworks, are the inspiration behind generative models. They are a self-supervised technique for representation learning, where our network learns about its input so that it may generate new data just as input. In this section, we'll learn about their architecture and uses as an introduction to the generative networks that they inspire. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Network architecture</h1>
                </header>
            
            <article>
                
<p><span>Autoencoders work by taking an input and generating a smaller vector representation for later </span><em>reconstructing its own input</em><span>. They do this by using an encoder to impose an information bottleneck on incoming data, and then utilizing a decoder to recreate the input data based on that representation. This is based on the idea that there are <em>structures</em> within data (that is, correlations, and so on) that exist, but that are not readily apparent. Autoencoders are a means of automatically learning these relationships without explicitly doing so.</span></p>
<p>Structurally, autoencoders consist of an <strong>input layer</strong>, a <strong>hidden layer</strong>, and an <strong>output</strong> <strong>layer</strong>, as demonstrated in the following diagram: </p>

<p><span>The encoder learns to preserve as much of the relevant ...</span></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Building an autoencoder</h1>
                </header>
            
            <article>
                
<p>If you're thinking that the task of reconstructing an output doesn't appear that useful, you're not alone. What exactly do we use these networks for? Autoencoders help to extract features when there are no known labeled features at hand. To illustrate how this works, let's walk through an example using TensorFlow. We're going to reconstruct the MNIST dataset here, and, later on, we will compare the performance of the standard autoencoder against the variational autoencoder in relation to the same task. </p>
<p>Let's get started with our imports and data. MNIST is contained natively within TensorFlow, so we can easily import it:</p>
<pre>import tensorflow as tf<br/>import numpy as np<br/><br/>from tensorflow.examples.tutorials.mnist import input_data<br/>mnist = input_data.read_data_sets("/tmp/data/", one_hot=True)</pre>
<p>For ease, we can build the auto-encoder with the <kbd>tf.layers</kbd> library. We'll want our Autoencoder architecture to follow the convolutional/de-convolutional pattern, where the input layer of the decoder matches the size of the input and the subsequent layer squash the data into a smaller and smaller representation. The decoder will be the same architecture reversed, starting with the small representation and working larger.</p>
<p class="mce-root"/>
<p>All together, we want it to look something like the following: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-282 image-border" src="Images/ba95c19c-4ed2-4962-a28b-b99d4faef25e.png" style="width:5.67em;height:11.92em;" width="401" height="841"/></div>
<p>Let's start with the encoder; we'll define an initializer for the the weight and bias factors first, and then define the encoder as a function that takes and input, x. we'll then use the <kbd>tf.layers.dense</kbd> function to create standard, fully connected neural network layers. The encoder will have three layers, with the first layer size matching the input dimensions of the input data (<kbd>784</kbd>), with the subsequent layers getting continually smaller:</p>
<pre>initializer = tf.contrib.layers.xavier_initializer()<br/><br/>def encoder(x):<br/>    input_layer = tf.layers.dense(inputs=x, units=784, activation=tf.nn.relu,<br/>                                 kernel_initializer=initializer, bias_initializer=initializer <br/>                                 )<br/>    z_prime = tf.layers.dense(inputs=input_layer, units=256, activation=tf.nn.relu,<br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )<br/>    z = tf.layers.dense(inputs=z_prime, units=128, activation=tf.nn.relu,<br/>                       kernel_initializer=initializer, bias_initializer=initializer<br/>                       )<br/>    return z</pre>
<p>Next, let's let's build our decoder; it will be using the same layer type and initializer as the encoder, only now we invert the layers, so that the first layer of the decoder is the smallest and the last is the largest. </p>
<pre>def decoder(x):<br/>    x_prime_one = tf.layers.dense(inputs=x, units=128, activation=tf.nn.relu,<br/>                                 kernel_initializer=initializer, bias_initializer=initializer<br/>                                 )<br/>    x_prime_two = tf.layers.dense(inputs=x_prime_one, units=256, activation=tf.nn.relu,<br/>                                 kernel_initializer=initializer, bias_initializer=initializer<br/>                                 )<br/>    output_layer = tf.layers.dense(inputs=x_prime_two, units=784, activation=tf.nn.relu,<br/>                                  kernel_initializer=initializer, bias_initializer=initializer<br/>                                  )<br/>    return output_layer</pre>
<p>Before we get to training, let's define some hyper-parameters that will be needed during the training cycle. We'll define the size of our input, the learning rate, number of training steps, the batch size for the training cycle, as well as how often we want to display information about our training progress. </p>
<pre>input_dim = 784 <br/>learning_rate = 0.001<br/>num_steps = 1000<br/>batch_size = 256<br/>display = 1</pre>
<p>We'll then define the placeholder for our input data so that we can compile the model:</p>
<pre>x = tf.placeholder("float", [None, input_dim])</pre>
<p>And subsequently, we compile the model and the optimizer as you've seen before in previous chapter:</p>
<pre># Construct the full autoencoder<br/>z = encoder(x)<br/><br/>## x_prime represents our predicted distribution<br/>x_prime = decoder(z) <br/><br/># Define the loss function and the optimizer<br/>loss = tf.reduce_mean(tf.pow(x - x_prime, 2))<br/>optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)</pre>
<p>Lastly, we'll code up the training cycle. By this point, most of this should be fairly familiar to you; start a TensorFlow session, and iterate over the epochs/batches, computing the loss and accuracy at each point:</p>
<pre>with tf.Session() as sess:<br/>    sess.run(tf.global_variables_initializer())<br/><br/>    ## Training Loop<br/>    for i in range(1, num_steps+1):<br/>    <br/>        ## Feed Batches of MNIST Data<br/>        batch_x, _ = mnist.train.next_batch(batch_size)<br/><br/>        ## Run the Optimization Process<br/>        _, l = sess.run([optimizer, loss], feed_dict={x: batch_x})<br/><br/>        ## Display the loss at every 1000 out of 30,000 steps<br/>        if i % display == 0 or i == 1:<br/>            print('Step %i: Loss: %f' % (i, l))</pre>
<p>For this particular example, we'll add in a little something more to this process; a way to plot the reconstructed images alongside their original versions. Keep in mind that this code is still contained within the training session, just outside of the training loop:</p>
<pre>    n = 4<br/>    canvas_orig = np.empty((28 * n, 28 * n))<br/>    canvas_recon = np.empty((28 * n, 28 * n))<br/><br/>    for i in range(n):<br/><br/>        batch_x, _ = mnist.test.next_batch(n)<br/><br/>        # Encode and decode each individual written digit<br/>        g = sess.run(decoder, feed_dict={x: batch_x})<br/><br/>        # Display original images<br/>        for j in range(n):<br/><br/>            # Draw the original digits<br/>            canvas_orig[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = batch_x[j].reshape([28, 28])<br/><br/>        # Display reconstructed images<br/>        for j in range(n):<br/><br/>            # Draw the reconstructed digits<br/>            canvas_recon[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])<br/><br/>    # Plot the original image vs the reconstructed images. <br/>    print("Original Images")<br/>    plt.figure(figsize=(n, n))<br/>    plt.imshow(canvas_orig, origin="upper", cmap="gray")<br/>    plt.show()<br/><br/>    print("Reconstructed Images")<br/>    plt.figure(figsize=(n, n))<br/>    plt.imshow(canvas_recon, origin="upper", cmap="gray")<br/>    plt.show()</pre>
<p>After training, you should end up with a result along the lines of the following, with the actual digits on the left, and the reconstructed digits on the right: </p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="alignnone size-full wp-image-281 image-border" src="Images/9a2dfa95-fd49-4543-90a7-ed79f9de4aab.png" style="width:32.50em;height:19.25em;" width="664" height="321"/></div>
<p>So what have we done here? By training the autoencoder on unlabeled digits, we've done the following: </p>
<ul>
<li>Learned the latent features of the dataset without having explicit labels</li>
<li>Successfully learned the distribution of the data and reconstructed the image from scratch, from that distribution</li>
</ul>
<p>Now, let's say that we wanted to take this further and generate or classify new digits that we haven't seen yet. To do this, we could remove the decoder and attach a classifier or generator network: </p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="alignnone size-full wp-image-283 image-border" src="Images/58fbd830-412a-4784-b3b7-08eb64a140ee.png" style="width:15.25em;height:19.92em;" width="424" height="553"/></div>
<p>The encoder therefore becomes a means of initializing a supervised training model. Standard autoencoders have been used in a variety of tasks. In the supplementary code for this chapter, we'll walk through an example where we utilize autoencoders for visual anomaly detection.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Variational autoencoders</h1>
                </header>
            
            <article>
                
<p><strong>Variational autoencoders</strong> (<strong>VAEs</strong>) are built on the idea of the standard autoencoder, and are powerful generative models and one of the most popular means of learning a complicated distribution in an unsupervised fashion. VAEs are <strong>probabilistic models </strong>rooted in Bayesian inference. A probabilistic model is exactly as it sounds:</p>
<p><em>Probabilistic models incorporate random variables and probability distributions into the model of an event or phenomenon.</em></p>
<p><span>VAEs, and other generative models, are probabilistic in that they seek to learn a distribution that they utilize for subsequent sampling. While all generative models are probabilistic models, not all probabilistic models are generative models.</span></p>
<p><span>The probabilistic structure of ...</span></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Structure</h1>
                </header>
            
            <article>
                
<p>Like standard autoencoders, VAEs utilize the same encoder/decoder framework, but, that aside, they are mathematically different from their namesake. VAEs take a probabilistic perspective in terms of guiding the network:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-large wp-image-277 image-border" src="Images/763b5004-ecd3-4102-99ab-f55907db8e60.png" style="width:34.33em;height:23.33em;" width="800" height="544"/></div>
<p>Both our <strong>encoder</strong> and <strong>decoder</strong> networks are generating distributions from their input data. The encoder generates a distribution from its training data, <strong>Z</strong>, which then becomes the input distribution for the decoder. The decoder takes this distribution, <strong>Z</strong>, and tries to replicate the original distribution, <strong>X</strong>, from it.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Encoder</h1>
                </header>
            
            <article>
                
<p>The encoder generates its distribution by first defining its prior as a standard normal distribution. Then, during training, this distribution becomes updated, and the decoder can easily sample from this distribution later on. Both the encoder and the decoder are unique in terms of VAEs in that they output two vectors instead of one: a <span>vector of means, <em>μ</em>, and another vector of standard deviation, <em>σ</em></span><span>.</span> <span>These help to define the limits for our generated distributions. Intuitively, the mean vector controls where the encoding of an input should be centered, while the standard deviation controls the extent to which the encoding may vary from the mean. This constraint on the encoder forces the network to learn a distribution, thereby taking ...</span></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Decoder</h1>
                </header>
            
            <article>
                
<p>Like the standard autoencoder, the decoder in the VAE is a backward convolutional network, or a deconvolutional network. In processing the decoding, data is sampled from the generation stochastically (randomly), making the VAE one of the few models that can directly sample a probability distribution without a Markov chain Monte Carlo method. <span>As a result of the stochastic generation process, the encoding that we generate from each pass will be a different representation of the data, all while maintaining the same mean and standard deviation. This helps with the decoder's sampling technique; because all encodings are generated from the same distribution, the decoder learns that a latent data point and its surrounding points are all members of the same class. This allows the decoder to learn how to generate from similar, but slightly varying, encodings. </span></p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Training and optimizing VAEs</h1>
                </header>
            
            <article>
                
<p>VAEs utilize a negative log-likelihood loss as their reconstruction loss to measure how much information is lost during the reconstruction phase of the decoder. If the decoder does not reconstruct the input satisfactorily, it will incur a large reconstruction loss. VAEs also introduce something called <strong>Kullback</strong>–<strong>Leibler</strong> (<strong>KL</strong>) divergence into their loss functions. KL divergence simply measures how much two probability distributions diverge; in other words, how different they are from one another. We want to minimize the KL distance between the mean and standard deviation of the target distribution and that of a standard normal. It is properly minimized when the mean is zero and the standard deviation is one. The log-likelihood ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Utilizing a VAE</h1>
                </header>
            
            <article>
                
<p>We can construct a variational autoencoder in TensorFlow to see how it compares to it's simpler, standard autoencoder cousin. In this section, we'll be using the same MNIST dataset so that we can standardize our comparison across methods. Let's walk through how to construct a VAE by utilizing it to generate handwriting based on the <kbd>MNIST</kbd> dataset. Think of <em>x</em> as being the individual written characters and <em>z</em> as the latent features in each of the individual characters that we are trying to learn.</p>
<p>First, let's start with our imports:</p>
<pre>import numpy as np<br/>import tensorflow as tf<br/>from tensorflow.examples.tutorials.mnist import input_data</pre>
<p>As before, we can import the <kbd>'MNIST_data'</kbd> directly from the TensorFlow library:</p>
<pre class="mce-root">mnist = input_data.read_data_sets('MNIST_data', one_hot=True)</pre>
<p>Next, we can start to build the encoder. We're going to be utilizing the same <kbd>tf.layers</kbd> package as we did before. Here, our encoder will look fairly similar to how it did in the previous example, our layers will take in an input and gradually compress that input until we generate a latent distribution, <em>z</em>:</p>
<pre>def encoder(x):<br/>    <br/>    input_layer = tf.layers.dense(inputs=x, units=784, activation=tf.nn.elu,<br/>                                 kernel_initializer=initializer, bias_initializer=initializer,<br/>                                 name='input_layer'<br/>                                 )<br/>    <br/>    hidden_1 = tf.layers.dense(inputs=input_layer, units=256, activation=tf.nn.elu,<br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )<br/>    <br/>    hidden_2 = tf.layers.dense(inputs=hidden_1, units=128, activation=tf.nn.elu,<br/>                       kernel_initializer=initializer, bias_initializer=initializer<br/>                       )</pre>
<p>Here's where we start to diverge from the standard autoencoder, however. While the last layer in the encoder will give us the potential z-distribution that represents our data, we'll need to calculate the values of <img class="fm-editor-equation" src="Images/f91f9b49-ee69-4ac5-b432-07f3b201f54f.png" style="width:0.92em;height:1.25em;" width="110" height="150"/> and <img class="fm-editor-equation" src="Images/0a07d995-2583-4465-b9a0-78b667741e97.png" style="width:0.92em;height:0.92em;" width="110" height="110"/> that will help define that distribution. We can do that by creating two new layers that take in the potential distribution z, and output out values of <kbd>mu</kbd> and <kbd>sigma</kbd>:</p>
<pre>mu = tf.layers.dense(inputs=z, units=10, activation=None)<br/>sigma = tf.layers.dense(inputs=z, units=10, activation=None)</pre>
<p>Next, we'll use these values to go ahead and calculate the KL divergence for the encoder, which will eventually go into constructing our final loss function:</p>
<pre>kl_div = -0.5 * tf.reduce_sum( 1 + sigma - tf.square(mu) - tf.exp(sigma), axis=1)<br/><br/>kl_div = tf.reduce_mean(latent_loss)</pre>
<p>Let's go ahead and create the decoder portion of the variational autoencoder now; we'll create a deconvolutional pattern that reverses the dimensions of the encoder. All of this will be contained under a function called <kbd>decoder(z)</kbd>:</p>
<pre>def decoder(z, initializer):<br/>    layer_1 = fully_connected(z, 256, scope='dec_l1', activation_fn=tf.nn.elu, <br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )<br/>    layer_2 = fully_connected(layer_1, 384, scope='dec_l2', activation_fn=tf.nn.elu,<br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )<br/>    layer_3 = fully_connected(layer_2, 512, scope='dec_l3', activation_fn=tf.nn.elu,<br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )<br/>    dec_out = fully_connected(layer_3, input_dim, scope='dec_l4', activation_fn=tf.sigmoid,<br/>                             kernel_initializer=initializer, bias_initializer=initializer<br/>                             )</pre>
<p>Also under the decoder function, we'll use the decoder output to calculate the reconstruction loss:</p>
<pre>epsilon = 1e-10<br/><br/>rec_loss = -tf.reduce_sum(x * tf.log(epsilon + dec_out) + (1 - x) * tf.log(epsilon + 1 - dec_out), axis=1)<br/><br/>rec_loss = tf.reduce_mean(rec_loss)</pre>
<p>As usual, we'll prepare our training parameters before we start initializing the model. We'll define a learning rate, batch size for our training, the number of training epochs, dimension of the input, and the size of our total training sample:</p>
<pre>learning_rate = 1e-4<br/>batch_size = 100<br/>epochs = 100<br/>input_dim = 784 <br/>num_sample = 55000<br/>n_z = 10</pre>
<p>We'll also define the placeholder for our input data, <kbd>x</kbd>:</p>
<pre>x = tf.placeholder(name='x', dtype='float', shape=[None, input_dim])</pre>
<p>Before we start training, we'll initialize the model, loss, and <kbd>optimizer</kbd>:</p>
<pre>## initialize the models<br/>z, kl_div = encoder(x)<br/>dec_out, rec_loss = decoder(x)<br/><br/>## Calculate the overall model loss term<br/>loss = tf.reduce_mean(rec_loss + kl_div)<br/><br/>## Create the optimizer<br/>optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)<br/><br/>## Create the weight initializer<br/>initializer = tf.contrib.layers.xavier_initializer()</pre>
<p>Finally, we can run the actual training process. This we be similar to the training processes that we've already built and experienced:</p>
<pre>with tf.Session() as sess:<br/>    sess.run(tf.global_variables_initializer())<br/>    <br/>    for epoch in range(epochs):<br/>        for iter in range(num_sample // batch_size):<br/> <br/>            batch_x = mnist.train.next_batch(batch_size)<br/>    <br/>            _, l, rl, ll = sess.run([optimizer, loss, rec_loss, kl_div], feed_dict={x: batch_x[0]})<br/><br/>        if epoch % 5 == 0:<br/>            print('[Epoch {}] Total Loss: {}, Reconstruction Loss: {}, Latent Loss: {}'.format(epoch, l, rl, ll))</pre>
<p>Lastly, we can use the bit of code following code to generate new samples from our newly trained model:</p>
<pre>z = np.random.normal(size=[batch_size, n_z])<br/>x_generated = x_hat = self.sess.run(dec_out, feed_dict={z: z})<br/><br/>n = np.sqrt(batch_size).astype(np.int32)<br/>I_generated = np.empty((h*n, w*n))<br/>for i in range(n):<br/>    for j in range(n):<br/>        I_generated[i*h:(i+1)*h, j*w:(j+1)*w] = x_generated[i*n+j, :].reshape(28, 28)<br/><br/>plt.figure(figsize=(8, 8))<br/>plt.imshow(I_generated, cmap='gray')</pre>
<p>Ultimately, you should end up with an image such as the following, with the original digits on the left and the generated digits on the right: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1409 image-border" src="Images/c0587722-c356-4abe-afbd-5d0f2a9e727c.png" style="width:40.67em;height:19.75em;" width="680" height="331"/></div>
<p>Observe how much clearer the digits are compared to the original autoencoder: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1408 image-border" src="Images/3867cf5a-5047-4f9a-8f3f-ca2c310363ac.png" style="width:40.00em;height:19.17em;" width="659" height="315"/></div>
<p>Now, let's see how we can take this further with GANs. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Generative adversarial networks</h1>
                </header>
            
            <article>
                
<p>Generative adversarial networks (<strong>GANs</strong>) are a class of networks that were introduced by Ian Goodfellow in 2014. In GANs, two neural networks play off against one another as adversaries in an <strong>actor</strong>-<strong>critic model</strong>, where one is the creator and the other is the scrutinizer. The creator, referred to as the <strong>generator network</strong>, tries to create samples that will fool the scrutinizer, the discriminator network. These two increasingly play off against one another, with the generator network creating increasingly believable samples and the discriminator network getting increasingly good at spotting the samples. In summary:</p>
<ul>
<li class="mce-root">The generator tries to maximize the probability of the discriminator passing its outputs as real, ...</li></ul></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Discriminator network</h1>
                </header>
            
            <article>
                
<p>The discriminator network in image-related GANs is a standard convolutional neural network. It takes in an image and outputs a single number that tells us whether the image is <em>real</em> or <em>fake</em>. The discriminator takes in an image, and learns the attributes of that image so that it may be a good <em>judge</em> vis-à-vis the outputs of the generator. In TensorFlow, we can create the <kbd>discriminator</kbd> as a function that we will then run in a TensorFlow session later on. This framework is more or less the same as you've seen in the previous sections with autoencoder and variational autoencoders; we'll use the higher level <kbd>tf.layers</kbd> api to create three main network layers and an output layer. After each of the main network layers, we'll add a dropout layer for regularization. The last layer will be slightly different, as we'll want to squash the output. For this, we'll use a sigmoid activation function that will give us a final output saying if an image is believed to be fake or not:</p>
<pre>def discriminator(x, initializer, dropout_rate):<br/>    <br/>    layer_1 = tf.layers.dense(x, units=1024, activation=tf.nn.relu, kernel_initializer=initializer,<br/>                              bias_initializer=initializer, name='input_layer')<br/>    dropout_1 = tf.layers.dropout(inputs=layer_1, rate=dropout_rate, training=True)<br/><br/>    <br/>    layer_2 = tf.layers.dense(dropout_1, units=512, activation=tf.nn.relu, kernel_initializer=initializer,<br/>                              bias_initializer=initializer, name='disc_layer_1')<br/>    dropout_2 = tf.layers.dropout(inputs=layer_2, rate=dropout_rate, training=True)<br/>    <br/>    <br/>    layer_3 = tf.layers.dense(dropout_2, units=256, activation=tf.nn.relu, kernel_initializer=initializer,<br/>                              bias_initializer=initializer, name='disc_layer_2')<br/>    dropout_3 = tf.layers.dropout(inputs=layer_3, rate=dropout_rate, training=True)<br/>    <br/>    <br/>    output_layer = tf.layers.dense(dropout_3, units=1, activation=tf.sigmoid, kernel_initializer=initializer,<br/>                              bias_initializer=initializer, name='disc_output')<br/>    <br/>    return output_layer</pre>
<p>Now that we have this discriminator defined, let's go ahead and move on to the generator. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Generator network</h1>
                </header>
            
            <article>
                
<p>You can think of the <kbd>generator</kbd> portion of the GAN as a reverse convolutional neural network. Like a VAE, it uses generic normal distribution, the only difference being that it up samples the distribution to form an image. This distribution represents our prior, and is updated during training as the GAN improves at producing images that the discriminator is unable to determine whether they are fake.</p>
<p>In between each layer, we utilize a <kbd>ReLu</kbd> activation function and <kbd>batch _normalization</kbd> to stabilize each layer's outputs. As the discriminator starts inspecting the outputs of <kbd>generator</kbd>, <kbd>generator</kbd> will continually adjust the distribution from which it's drawing to closely match the target distribution. The code will look fairly ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Training GANs</h1>
                </header>
            
            <article>
                
<p><span>GANs are easy to train, but difficult to optimize due to a number of unstable dynamics in their training processes. </span>To train a GAN, we train the generator on sub samples of a high-dimensional training distribution; since this does not innately exist, we initially sample from a standard normal (Gaussian) distribution.</p>
<p>Both the generator and the discriminator are trained jointly in a minimax game using an objective function, also referred to as the <kbd>minimax</kbd> function:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/6d9f4c89-a4aa-4edb-81d3-d11a43fa60c9.png" style="width:34.25em;height:3.50em;" width="4700" height="480"/></div>
<p>Let's break this down a bit. The function is telling us what happens where. Let's look at the initial bit of the first expression:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/08265ab7-a501-4899-b033-57c9e012c274.png" style="width:3.75em;height:1.75em;" width="450" height="210"/></div>
<p>The <img class="fm-editor-equation" src="Images/c45f3372-9119-4fb7-a267-37a3a3ba0936.png" style="width:1.00em;height:1.33em;" width="120" height="160"/> notation means expectation, so we are saying that the expected output, <em>x</em>, of the discriminator for real images drawn from the actual distribution of will be:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/e2652248-ec02-47e7-9085-72afbd140ce5.png" style="width:5.42em;height:1.50em;" width="820" height="220"/></div>
<p>Likewise, here's the second expression:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/cc93119c-59d1-4f43-902c-1d724c5f3745.png" style="width:4.50em;height:1.83em;" width="540" height="220"/></div>
<p>It's telling us that the expected value of the output of the discriminator for fake images drawn from the generated distribution will be as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/db7c7441-db5a-49a5-ac30-b18d81adc99d.png" style="width:9.58em;height:1.33em;" width="1660" height="220"/></div>
<p><span>The discriminator wants to maximize (<img class="fm-editor-equation" src="Images/92648cd3-1ae5-41ef-92ba-1dc9222594bd.png" style="width:3.08em;height:1.00em;" width="370" height="120"/>) the objective so that its output for real data <em>D(x)</em> is as close to one as possible, while its output for fake data <em>D(G(z))</em> is as close to zero as possible. Meanwhile, the generator seeks the opposite, to minimize (<img class="fm-editor-equation" src="Images/6f3a5e8a-ee08-497c-b37c-5fd1625f0352.png" style="width:2.83em;height:1.33em;" width="340" height="160"/>) the objective function so that <em>D(x)</em> is as close to zero as possible, while </span><em>D(G(z))</em> <span>is as close to one as possible. Mathematically, this is how the generator and the discriminator play off against one another.</span></p>
<p>When training GANs, we train to minimize the objective function so that the generator can win. We want the generator to be able to create examples that are realistic enough to fool the discriminator. To do this, we train and optimize the discriminator and the generator in parallel using gradient ascent. <span>For each iteration of training, we are going to train the discriminator network in small batches, and then train the generator network in small batches, alternating between the two paradigms. Gradient ascent for the discriminator computes the following: </span></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/f8919266-0d1b-42b1-ba3d-135b54ea748f.png" style="width:33.67em;height:3.75em;" width="4320" height="480"/></div>
<p><span>Training both the discriminator and the generator jointly can be challenging. If we tried to actually minimize the loss function for the generator, as follows, we would run into some issues:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/958a783f-cfb4-4b21-9153-0e600f597d17.png" style="width:14.83em;height:3.17em;" width="2230" height="480"/></div>
<p> <span>If we look at a plot of the <kbd>minimax</kbd> function, we can see why this is:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/1c65fc91-c973-4cdf-bb15-e4ba4455e415.png" style="width:28.92em;height:14.08em;" width="964" height="470"/></div>
<p>Optimization procedures look for gradient signals, which more or less tell gradient descent which way to go. In the <kbd>minimax</kbd> function, the biggest signals for gradient descent are to the right, but we actually want to to learn values to the left of the function, where it's minimized to zero and the generator is fooling the discriminator. However, as the generator optimizes, it will move away from its optimal point, taking us away from where it should be. To solve this, we can flip the paradigm of the generator. Instead of focusing on what it did right, we can make it focus on what it did wrong:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/efaa5ce7-54a4-4f9d-a6c6-0a45966a7db8.png" style="width:14.92em;height:3.17em;" width="2260" height="480"/></div>
<p>By taking the maximum of the generator's objective, we're maximizing the likelihood of being wrong. This parallelized training process can still be unstable, however, and stabilizing GANs is a very active area of research at the moment.</p>
<p>Let's get back to the TensorFlow process. We'll start by defining our network's training parameters:</p>
<pre><span class="k">learning_rate = 0.0002<br/>batch_size = 100<br/>epochs = 100<br/>dropout_rate=0.5<br/></span></pre>
<p>We then need to define our placeholders, both for the input <kbd>x</kbd>, as well as the <kbd>z</kbd> distribution which the generator will generate from:</p>
<pre>z = tf.placeholder(tf.float32, shape=(None, 100))<br/>x = tf.placeholder(tf.float32, shape=(None, 784))</pre>
<p>Like before, we'll create a Glorot <kbd>Initializer</kbd> that will initialize our weight and bias values for us:</p>
<pre>initializer = tf.contrib.layers.xavier_initializer()</pre>
<p>Once we have all of this, we can go ahead and actually define our network pieces. You'll notice that for the discriminator, we're using something called a scope. Scopes allow us to reuse items from the TensorFlow graph without generating an error - in this case, we want to use the variables from the discriminator function twice in a row, so we use the <kbd>tf.variable_scope</kbd> function that TensorFlow provides us. Between the two, we simply use the <kbd>scope.reuse_variables()</kbd> function to tell TensorFlow what we're doing:</p>
<pre>G = generator(z, initializer)<br/><br/>with tf.variable_scope('discriminator_scope') as scope:<br/>    disc_real = discriminator(x, initializer, 0.5)<br/>    scope.reuse_variables()<br/>    disc_fake = discriminator(G, initializer, 0.5)</pre>
<p>Lastly, we'll define the loss functions for both the generator and discriminator, and set the optimizer:</p>
<pre>epsilon = 1e-2<br/>disc_loss = tf.reduce_mean(-tf.log(disc_real + epsilon) - tf.log(1 - disc_fake + epsilon))<br/>gen_loss = tf.reduce_mean(-tf.log(disc_fake + epsilon))<br/><br/>disc_optim = tf.train.AdamOptimizer(lr).minimize(disc_loss)<br/>gen_optim = tf.train.AdamOptimizer(lr).minimize(gen_loss)</pre>
<p>We can the run the training cycle just as we have in the previous two examples. The only two differences you'll see here is that we run two optimization processes, one for the generator and one for the discriminator:</p>
<pre>with tf.Session() as sess:<br/>    sess.run(tf.global_variables_initializer()) <br/>    for epoch in range(epochs):<br/>        <br/>        ## Define the loss to update as a list<br/>        gen_loss = []<br/>        disc_loss = []<br/>        <br/>        ## Run the training iteration<br/>        for iter in range(training_data.shape[0] // batch_size):<br/>            <br/>            ## Batch the input for the discriminator<br/>            x_prime = training_data[iter*batch_size:(iter+1)*batch_size]<br/>            z_prime = np.random.normal(0, 1, (batch_size, 100))<br/><br/>            ## Run the discriminator session<br/>            _, DLoss = sess.run([disc_optim, disc_loss], {x: x_prime, z: z_prime, drop_out: 0.3})<br/>            disc_loss.append(DLoss)<br/><br/>            ## Run the generator session <br/>            z_prime = np.random.normal(0, 1, (batch_size, 100))<br/>            _, GLoss = sess.run([gen_optim, gen_loss], {z: z_prime, drop_out: 0.3})<br/>            gen_loss.append(GLoss)<br/>            <br/>        if epoch % 5 == 0:<br/>            print('[%d/%d] - loss_d: %.3f, loss_g: %.3f' % ((epoch + 1), epochs, np.mean(D_losses), np.mean(G_losses)))</pre>
<p>GANs are fairly computational expensive, so training this network may take a while unless you scale with a web services platform. </p>
<p>As you can see, all of the models that we've run thus far have built upon each other. Even with advanced generative models like GANs, we can use certain recipes to create powerful neural networks, and larger AI applications, quickly and efficiently. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Other forms of generative models</h1>
                </header>
            
            <article>
                
<p>While we've only covered two types of generative model, there are many different types that you may encounter in the literature. The following chart is not exhaustive, but does provide a general overview of the types of generative models out there:</p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/37d3c00a-b73f-4f97-a532-4a468b6f1171.png" style="width:48.92em;height:27.58em;" width="969" height="547"/></div>
<p>Let's break this down: </p>
<ul>
<li><strong>Explicit density models</strong>: Model our data directly from a probability distribution. We explicitly define the probability and solve for it</li>
<li><strong>Implicit density models</strong>: Learn to sample from a probability distribution without defining what that distribution is</li>
</ul>
<p>Within explicit density models, we have <strong>tractable density</strong> models and <strong>approximate density ...</strong></p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Fully visible belief nets</h1>
                </header>
            
            <article>
                
<p>Fully visible belief networks are a class of explicit density models <span>and a form of </span>deep belief network.<span> They use </span>the chain rule to decompose a probability distribution <img class="fm-editor-equation" src="Images/f74fdadd-39f8-4b3b-a292-aea743773a22.png" style="width:2.92em;height:1.83em;" width="350" height="220"/> over a vector, into a product over each of the members of the vector, represented between by <img class="fm-editor-equation" src="Images/1b1c3bcf-cf33-4ca8-88e2-8be9f01139e0.png" style="width:8.25em;height:1.83em;" width="990" height="220"/>. All together, it's formula is:</p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/44925bb5-891f-4ab8-afb4-8f1a68efef10.png" style="width:20.92em;height:4.50em;" width="2520" height="540"/></div>
<p class="graf graf--p graf-after--figure">The most popular model in this family is PixelCNN, an <strong>autoregressive</strong> generative model. Pixels approach image generation problems by turning them into a sequence modeling problem, where the next pixel value is determined by all the previously generated pixel values. <span>The network scans an image one pixel at a time, and predicts conditional distributions over the possible pixel values. We want to assign a probability to every pixel image based on the last pixels that the network saw. For instance, if we're looking at the same horse images as in the previous example, we would be consistently predicting what the next anticipated pixel looks such as follows:</span></p>
<div class="CDPAlignCenter CDPAlign"><img src="Images/ea5df82a-188b-4d1d-8600-342f9995cee1.png" style="width:21.67em;height:14.58em;" width="521" height="352"/></div>
<p>Based on the features that we've seen, will the next pixel still contain the horse's ear, or will it be background? While their training cycles are more stable than GANs, the biggest issue with the networks is that they generate new samples extremely slowly; the model must be run again fully in order to generate a new sample. They also block the execution, meaning that their processes cannot be run in parallel.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Hidden Markov models</h1>
                </header>
            
            <article>
                
<p>A hidden Markov model is a type of <strong>Markov model</strong>, which is itself a subclass of <strong>Dynamic Bayesian Networks</strong>.<strong> </strong>Markov models are used to model randomly changing systems called <strong>Markov processes</strong> also called <strong>Markov chains</strong>. Simply put, a Markov <span><span>process</span></span> is a sequence of events where the probability of an event happening solely depends on the previous event.</p>
<p>Markov chains appear as follows:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1350 image-border" src="Images/747b092b-e6c7-4ffd-8b43-bcb1d522d7fc.png" style="width:31.83em;height:18.92em;" width="661" height="393"/></div>
<p>In this simple chain, there are three states, represented by the circles. We then have probabilities for transitioning to another state, as well as probabilities of staying in a current state. The classic example of a Markov chain is that of the ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Boltzmann machines</h1>
                </header>
            
            <article>
                
<p>Boltzmann machines are a general class of models that contain take binary vectors as input and units that assign a probability distribution to each of those binary vectors. As you can see in the following diagram, each unit is dependent on every other unit:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1351 image-border" src="Images/7692c3f7-5955-49d3-afe4-bc5d0595b3cf.png" style="width:11.92em;height:14.33em;" width="628" height="756"/></div>
<p><span>A Boltzmann machine uses something called an <strong>energy function</strong>, which is similar to a loss function. For any given vector, </span><span>the probability of a particular state is proportional to each of the energy function values. To convert this to an actual probability distribution, it's necessary to renormalize the distribution, but this problem becomes another intractable problem. Monte Carlo methods are again used here for sampling as a workaround, hence making Boltzmann machines a Monte Carlo-based method.</span></p>
<p>Let's say we have documents that are represented by binary features. A Boltzmann machine can help us determine whether a particular word or phrase came from a particular document. We can also use Boltzmann machines for anomaly detection in large, complex systems. They work well up to a point, although this method does not work well in high dimensional spaces. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned about some of the most exciting networks in AI, variational autoencoders and GANs. Each of these relies on the same fundamental concepts of condensing data, and then generating from again from that condensed form of data. <span>You will recall that both of these networks are probabilistic models, meaning that they rely on inference from probability distributions in order to generate data. We worked through examples of both of these networks, and showed how we can use them to generate new images. </span></p>
<p>In addition to learning about these exciting new techniques, most importantly you learned that the building blocks of advanced networks can be broken down into smaller, simpler, and repetitive parts. When you think about ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">References</h1>
                </header>
            
            <article>
                
<ol>
<li><a href="http://www.statisticshowto.com/">statisticshowto.com</a></li>
<li>Figure adapted from Ian Goodfellow, Tutorial on GANs, 2017</li>
</ol>


            </article>

            
        </section>
    </div>



  </body></html>