<html><head></head><body>
		<div id="_idContainer008">
			<h1 id="_idParaDest-13" class="chapter-number"><a id="_idTextAnchor012"/>1<a id="_idTextAnchor013"/></h1>
			<h1 id="_idParaDest-14"><a id="_idTextAnchor014"/>Understanding the Infrastructure and Tools for Building AI Products</h1>
			<p>Laying a solid foundation is an essential part of understanding anything, and the frontier of <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>) products seems a lot like our universe: ever-expanding. That rate of <a id="_idIndexMarker000"/>expansion is increasing with every passing year as we go deeper into a new way to conceptualize products, organizations, and the industries we’re all a part of. Virtually every aspect of our lives will be impacted in some way by AI and we hope those reading will come out of this experience more confident about what AI adoption will look like for the products they support or hope to <span class="No-Break">build someday.</span></p>
			<p><em class="italic">Part 1</em> of this book will serve as an overview of the lay of the land. We will cover terms, infrastructure, types of AI algorithms, and products done well, and by the end of this section, you will understand the various considerations when attempting to build an AI strategy, whether you’re looking to create a native-AI product or add AI features to an <span class="No-Break">existing product.</span></p>
			<p>Managing AI products is a highly iterative process, and the work of a product manager is to help your organization discover what the best combination of infrastructure, training, and deployment workflow is to maximize success in your target market. The performance and success of AI products lie in understanding the infrastructure needed for managing AI pipelines, the outputs of which will then be integrated into a product. In this chapter, we will cover everything from databases to workbenches to deployment strategies to tools you can use to manage your AI projects, as well as how to gauge your <span class="No-Break">product’s efficacy.</span></p>
			<p>This chapter will serve as a high-level overview of the subsequent chapters in <em class="italic">Part 1</em> but it will foremost allow for a definition of terms, which are quite hard to come by in today’s marketing-heavy AI competitive landscape. These days, it feels like every product is an AI product, and marketing departments are trigger-happy with sprinkling that term around, rendering it almost useless as a descriptor. We suspect this won’t be changing anytime soon, but the more fluency consumers and customers alike have with the capabilities and specifics of AI, machine learning (ML), and data science, the more we should see clarity about how products are built and optimized. Understanding the context of AI is important for anyone considering building or supporting an <span class="No-Break">AI product.</span></p>
			<p>In this chapter, we will cover the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Definitions – what is and is <span class="No-Break">not AI</span></li>
				<li>ML versus DL – understanding <span class="No-Break">the difference</span></li>
				<li>Learning types <span class="No-Break">in ML</span></li>
				<li>The order – what is the optimal flow and where does every part of the <span class="No-Break">process live?</span></li>
				<li>DB 101 – databases, warehouses, data lakes, <span class="No-Break">and lakehouses</span></li>
				<li>Managing projects – <span class="No-Break">IaaS</span></li>
				<li>Deployment strategies – what do we do with <span class="No-Break">these outputs?</span></li>
				<li>Succeeding in AI – how well-managed AI companies do <span class="No-Break">infrastructure right</span></li>
				<li>The promise of AI – where is AI <span class="No-Break">taking us?</span><a id="_idTextAnchor015"/></li>
			</ul>
			<h1 id="_idParaDest-15"><a id="_idTextAnchor016"/>Definitions – what is and is not AI</h1>
			<p>In 1950, a mathematician and world war II war hero Alan Turing asked a simple question in his paper <em class="italic">Computing Machinery and Intelligence</em> – <em class="italic">Can machines think?</em>. Today, we’re still grappling with that same question. Depending on who you ask, AI can be many things. Many maps exist out there on the internet, from expert systems used in healthcare <a id="_idIndexMarker001"/>and finance to facial recognition to natural language processing to regression models. As we continue with this chapter, we will cover many of the facets of AI that apply to products emerging in <span class="No-Break">the market.</span></p>
			<p>For the purposes of applied AI in products across industries, in this book, we will focus primarily on ML and deep learning (DL) models used in various capacities because these are often used in production anywhere AI is referenced in any marketing capacity. We will use AI/ML as a blanket term covering a span of ML applications and we will cover the major areas most people would consider ML, such as DL, computer vision, natural language processing, and facial recognition. These are the methods of applied AI that most people will come across in the industry, and familiarity with these applications will serve any product manager looking to break into AI. If anything, we’d like to help anyone who’s looking to expand into the field from another product management background to choose which area of AI appeals to <span class="No-Break">them most.</span></p>
			<p>We’d also like to cover what is and what isn’t ML. The best way for us to express it as simply as we can is: if a machine is learning from some past behavior and if its success rate is improving as a result of this learning, it is ML! <em class="italic">Learning is the active element</em>. No models are perfect but we do learn a lot from employing models. Every model will have some <a id="_idIndexMarker002"/>element of hyperparameter tuning, and the use of each model will yield certain results in performance. Data scientists and ML engineers working with these models will be able to benchmark performance and see how performance is improving. If there are fixed, hardcoded rules that don’t change, it’s <span class="No-Break">not ML.</span></p>
			<p>AI is a subset of computer science, and all programmers are effectively doing just that: giving computers a set of instructions to fire away on. If your current program doesn’t learn from the past in any way, if it simply executes on directives it was hardcoded with, we can’t call this ML. You may have heard the terms <em class="italic">rules-based engine</em> or <em class="italic">expert system</em> thrown around in other programs. They are considered forms of AI, but they're not ML because although they are a form of AI, the rules are effectively replicating the work of a person, and the system itself is not learning or changing on <span class="No-Break">its own.</span></p>
			<p>We find ourselves in a tricky time in AI adoption where it can be very difficult to find information online about what makes a product <em class="italic">AI</em>. Marketing is eager to add the AI label to their products but there still isn’t a baseline of explainability with what that means out in the market. This further confuses the term AI for consumers and technologists alike. If you’re confused by the terms, particularly when they’re applied to products you see promoted online, you’re very much <span class="No-Break">not alone.</span></p>
			<p>Another area of confusion is the general term that is AI. For most people, the concept of AI brings to mind the <em class="italic">Terminator</em> franchise from the 1980s and other futurist depictions of inescapable technological destruction. While there certainly can be a lot of harm to come from AI, this <a id="_idIndexMarker003"/>depiction represents what’s referred to as <em class="italic">strong AI</em> or <strong class="bold">artificial general intelligence</strong> (<strong class="bold">AGI</strong>). We still have ways to go for <a id="_idIndexMarker004"/>something such as AGI but we’ve got plenty of what’s referred to as <strong class="bold">artificial narrow intelligence </strong>or <strong class="bold">narrow </strong><span class="No-Break"><strong class="bold">AI</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">ANI</strong></span><span class="No-Break">).</span></p>
			<p>ANI is also commonly expressed as <em class="italic">weak AI</em> and is what’s generally meant when you see AI plastered all over products you find online. ANI is exactly what it sounds like: a narrow application of AI. Maybe it’s good at talking to you, at predicting some future value, or at organizing things; maybe it’s an expert at that, but its expertise won’t bleed into other areas. If it could, it would stop being ANI. These major areas of AI are referred to as strong and weak in comparison to human intelligence. Even the most convincing conversational AIs out there, and they are quite convincing, are demonstrating an illusionary intelligence. Effectively, all AI that exists at the moment is weak or ANI. Our <em class="italic">Terminator</em> days are still firmly in our future, perhaps never to <span class="No-Break">be realized.</span></p>
			<p>For every person out there that’s come across Reddit threads about AI being sentient or somehow having ill will toward us, we want to make the following statement very clear. AGI does not exist and there is no such thing as sentient AI. This does not mean AI doesn’t actively <a id="_idIndexMarker005"/>and routinely cause humans harm, even in its current form. The major caveat here is that unethical, haphazard applications of AI already actively cause us both minor inconveniences and major upsets. Building AI ethically and responsibly is still a work in progress. While AI systems may not be sentiently plotting the downfall of humanity, when they’re left untested, improperly managed, and inadequately vetted for bias, the applications of ANI that are deployed already have the capacity to do real damage in <span class="No-Break">our lives.</span></p>
			<p>For now, can machines think like us? No, they don’t think like us. Will they someday? We hope not. It’s my personal opinion that the insufferable aspects of the human condition end with us. But we do very much believe that we will experience some of our greatest ails, as well as our wildest curiosities, to be impacted considerably by the benevolence of AI <span class="No-Break">and<a id="_idTextAnchor017"/> ML.</span></p>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor018"/>ML versus DL – understanding the difference</h1>
			<p>As a product manager, you’re going to need to build a lot of trust with your technical counterparts <a id="_idIndexMarker006"/>so that, together, you can <a id="_idIndexMarker007"/>build an amazing product that works as well as it can technically. If you’re reading this book, you’ve likely come across the phrase ML and DL. We will use the following sections titled <em class="italic">ML</em> and <em class="italic">DL</em> to go over some of the basics but keep in mind that we will be elaborating on these concepts further down in <a href="B18935_03.xhtml#_idTextAnchor101"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-17"><a id="_idTextAnchor019"/>ML</h2>
			<p>In its basic form, <strong class="bold">ML</strong> is made up of two essential components: <em class="italic">the models used</em> and <em class="italic">the training data it’s learning from</em>. These data are historical data points that effectively teach machines a baseline foundation from which to learn, and every time you retrain <a id="_idIndexMarker008"/>the models, the models are theoretically improving. How the models are chosen, built, tuned, and maintained for optimized performance is the work of data scientists and ML engineers. Using this knowledge of performance toward the optimization of the product experience itself is the work of product managers. If you’re working in the field of AI product management, you’re working incredibly closely with your data science and <span class="No-Break">ML teams.</span></p>
			<p>We’d like to also make a distinction about the folks you’ll be working with as an AI product manager. Depending on your organization, you’re either working with data scientists and developers to deploy ML or you’re working with ML engineers who can both train and upkeep the models as well as deploy them into production. We highly suggest maintaining strong relationships with any and all of these impacted teams, along <span class="No-Break">with DevOps.</span></p>
			<p>All ML models can be grouped into the following four major <span class="No-Break">learning categories:</span></p>
			<ul>
				<li><span class="No-Break">Supervised learning</span></li>
				<li><span class="No-Break">Unsupervised learning</span></li>
				<li><span class="No-Break">Semi-supervised learning</span></li>
				<li><span class="No-Break">Reinforcement learning</span></li>
			</ul>
			<p>These are the four major areas of ML and each area is going to have its particular models and algorithms that are used in each specialization. The learning type has to do with whether or not you’re labeling the data and the method you’re using to reward the models you’ve used for good performance. These learning types are relevant whether your product is using a DL model or not, so they’re inclusive of all ML models. We will be covering the learning types in more depth in the following section titled <em class="italic">Learning type<a id="_idTextAnchor020"/>s </em><span class="No-Break"><em class="italic">in ML</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-18"><a id="_idTextAnchor021"/>DL</h2>
			<p><strong class="bold">DL</strong> is a subset <a id="_idIndexMarker009"/>of ML, but the terms are often used colloquially as almost separate expressions. The reason for this is DL is based on neural network algorithms and ML can be thought of as… the rest of the algorithms. In the preceding section covering ML, we looked at the process of taking data, using it to train our models, and using that trained model to predict new future data points. Every time you use the model, you see how <em class="italic">off</em> it was from the correct answer by getting some understanding of the rate of error so you can iterate back and forth until you have a model that works well enough. Every time, you are creating a model based on data that has certain patterns <span class="No-Break">or </span><span class="No-Break"><em class="italic">features</em></span><span class="No-Break">.</span></p>
			<p>This process is the same in DL, but one of the key differences of DL is that patterns or features in <a id="_idIndexMarker010"/>your data <a id="_idIndexMarker011"/>are largely picked up by the DL algorithm through what’s referred to as <strong class="bold">feature learning</strong> or <strong class="bold">feature engineering</strong> through a hierarchical layered system. We will go into the various algorithms that are used in the following section because there are a few nuances between each, but as you continue developing your understanding of the types of ML out there, you’ll also start to group the various models that make up these major areas of AI (ML and DL). For marketing purposes, you will for the most part see terms such as <em class="italic">ML</em>, <em class="italic">DL/neural networks</em>, or just the general umbrella term of <em class="italic">AI</em> referenced where DL algorithms <span class="No-Break">are used.</span></p>
			<p>It’s important to know the difference between what these terms mean in practice and at the model level and how they’re communicated by non-technical stakeholders. As product managers, we are toeing the line between the two worlds: what engineering is building and what marketing is communicating. Anytime you’ve heard the term <strong class="bold">black box model</strong>, it’s referring <a id="_idIndexMarker012"/>to a neural network model, which is DL. The reason for this is DL engineers often can’t determine how their models are arriving at certain conclusions that are creating an opaque view of what the model is doing. This opacity is double-sided, both for the engineers and technologists themselves, as well as for the customers and users downstream who are experiencing the effects of these models without knowing how they make certain determinations. The DL neural networks are mimicking the structure of the way humans are able to think using a variety of layers of <span class="No-Break">neural networks.</span></p>
			<p>For product managers, DL poses a concern for explainability because there’s very little we can understand about how and why a model is arriving at conclusions, and, depending on the context of your product, the importance of explainability could vary. Another inherent challenge is these models essentially learn autonomously because they aren’t waiting for their engineer to choose the features that are most relevant in the data for them; the neural networks themselves do the feature selection. It learns with very little <a id="_idIndexMarker013"/>input from an engineer. Think of the models as the <em class="italic">what</em> and the following section of learning types as the <em class="italic">how</em>. A quick reminder that as we move on to cover the learning styles (whether a model is used in a supervised, unsupervised, semi-supervised, or reinforcement learning capacity), these learning styles apply to both DL and tradition<a id="_idTextAnchor022"/>al <span class="No-Break">ML models.</span></p>
			<p>Let’s look at the different learning<a id="_idTextAnchor023"/> types <span class="No-Break">in ML.</span></p>
			<h1 id="_idParaDest-19"><a id="_idTextAnchor024"/>Learning types in ML</h1>
			<p>In this section, we will cover the differences between supervised, unsupervised, semi-supervised, and reinforcement learning and how all these learning types can be applied. Again, the <a id="_idIndexMarker014"/>learning type has to do with whether or not you’re labeling the data and the method you’re using to reward the models you’ve used for good performance. The ultimate objective is to understand what kind of learning model gets you the kind of performance and explainability you’re going to need when considering whether or not to use it in <span class="No-Break">y<a id="_idTextAnchor025"/>our product.</span></p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor026"/>Supervised learning</h2>
			<p>If humans are labeling the data and the machine is looking to also correctly label current or future data points, it’s supervised learning. Because we humans know the answer the machines are trying to arrive at, we can see how off they are from finding the correct answer, and <a id="_idIndexMarker015"/>we continue this process <a id="_idIndexMarker016"/>of training the models and retraining them until we find a level of accuracy that we’re <span class="No-Break">happy with.</span></p>
			<p>Applications of supervised learning models include classification models that are looking to categorize data in the way spam filters do or regression models that are looking for relationships between variables in order to predict future events and find trends. Keep in mind that all models will only work to a certain point, which is why they require constant training and updating and AI teams are often using ensemble modeling or will try various models and choose the best-performing one. It won’t be perfect either way, but with enough hand-holding, it will take you closer and closer to <span class="No-Break">the truth.</span></p>
			<p>The following is a list of common supervised learning models/algorithms you’ll likely use in production for <span class="No-Break">various products:</span></p>
			<ul>
				<li><strong class="bold">Naive Bayes classifier</strong>: This algorithm <em class="italic">naively</em> considers every feature in your <a id="_idIndexMarker017"/>dataset as its own independent <a id="_idIndexMarker018"/>variable. So, it’s essentially trying to find associations probabilistically without having any assumptions about the data. It’s one of the simpler algorithms out there and its simplicity actually is what makes it so successful with classification. It’s commonly used for binary values such as trying to decipher whether or not something <span class="No-Break">is spam.</span></li>
				<li><strong class="bold">Support vector machine</strong> (<strong class="bold">SVM</strong>): This algorithm is also largely used for classification problems and will essentially try to split your dataset into two classes <a id="_idIndexMarker019"/>so that you can use <a id="_idIndexMarker020"/>it to group your data and try to predict where future data points will land along these major splits. If you’re not seeing compelling groups between the data, SVMs allow you to add more dimensions to be able to see <span class="No-Break">groupings easier.</span></li>
				<li><strong class="bold">Linear regression models</strong>: These have been around since the 1950s and they’re the simplest <a id="_idIndexMarker021"/>models we have for regression <a id="_idIndexMarker022"/>problems such as predicting future data points. They essentially use one or more variables in your dataset to predict your dependent variable. The <em class="italic">linear</em> part of this model is trying to find the best line to fit your data, and this line is what dictates how it predicts. Here, we once again see a relatively simple model also being heavily used because of how versatile and dependable <span class="No-Break">it is.</span></li>
				<li><strong class="bold">Logistic regression</strong>: This model works a lot like linear regression in that you have <a id="_idIndexMarker023"/>independent and dependent variables, but it’s <a id="_idIndexMarker024"/>not predicting a numerical value; it’s predicting a future binary categorical state such as whether or not someone might default on a loan in the future, <span class="No-Break">for instance.</span></li>
				<li><strong class="bold">Decision trees</strong>: This <a id="_idIndexMarker025"/>algorithm works well <a id="_idIndexMarker026"/>with both predicting something categorical as well as something numerical, so it’s used for both kinds of ML problems, such as predicting a future state or a future price. This is less common so decision trees are used often for both kinds of problems, which has contributed to its popularity. Its comparison to a tree comes <a id="_idIndexMarker027"/>from the nodes and branches <a id="_idIndexMarker028"/>that effectively function like a flow chart. The model learns from the flow of past data to predict <span class="No-Break">future values.</span></li>
				<li><strong class="bold">Random forest</strong>: This algorithm builds from the previous decision trees and is also used for both categorical and numerical problems. The way it works is it splits the <a id="_idIndexMarker029"/>data into different <em class="italic">random</em>”samples, creates decision trees for each sample, and then takes an average or <a id="_idIndexMarker030"/>majority vote for its predictions (depending on whether you’re using it for categorical or numerical predictions). It’s hard to understand how a random forest comes to conclusions, so if interpretability isn’t super high on the list of concerns, you can <span class="No-Break">use it.</span></li>
				<li><strong class="bold">K-nearest neighbors</strong> (<strong class="bold">KNNs</strong>): This algorithm exclusively works on categorical <a id="_idIndexMarker031"/>as well as numerical <a id="_idIndexMarker032"/>predictions, so it’s looking for a future state and it offers results in groups. The number of data points in the group is set by the engineer/data scientist, and the way the model works is by grouping the data and determining characteristics the data shares with its neighbors and giving its best guess based on those neighbors for <span class="No-Break">future values.</span></li>
			</ul>
			<p>Now that we’ve covered supervised learning, let’s dis<a id="_idTextAnchor027"/>cuss unsupervised <span class="No-Break">learning next.</span></p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor028"/>Unsupervised learning</h2>
			<p>If the data <a id="_idIndexMarker033"/>is unlabeled and we’re using machines to label the data <a id="_idIndexMarker034"/>and find patterns we don’t yet know of, it’s unsupervised. Effectively, we humans either know the right answer or we don’t, and that’s how we decipher which camp the ML algorithms belong to. As you might imagine, we take the results of unsupervised learning models with some hesitancy because it may be finding an organization that isn’t actually helpful or accurate. Unsupervised learning models also require large amounts of data to train on because the results can be wildly inaccurate if it’s trying to find patterns out of a small data sample. As it ingests more and more data, its performance will improve and become more refined over time, but once again, there is no <span class="No-Break"><em class="italic">correct</em></span><span class="No-Break"> answer.</span></p>
			<p>Applications of unsupervised learning models include clustering and dimensionality reduction. Clustering models segment or group data into certain areas. These can be used for <a id="_idIndexMarker035"/>things such as looking for patterns in medical trials or drug discovery, for instance, because you’re looking for <a id="_idIndexMarker036"/>connections and groups of data where there might not already be obvious answers. Dimensionality reduction essentially removes the features in your dataset that contribute less to the performance you’re looking for and will simplify your data so that your most important features will best improve your performance to separate real signals from <span class="No-Break">the noise.</span></p>
			<p>The following is a list of common unsupervised learning models/algorithms you’ll likely use in production for <span class="No-Break">various products:</span></p>
			<ul>
				<li><strong class="bold">K-means clustering</strong>: This algorithm will group data points together to better see patterns (or clusters), but it’s looking for some optimal number of clusters as well. This <a id="_idIndexMarker037"/>is unsupervised learning, so the <a id="_idIndexMarker038"/>model is looking to find patterns that it can learn from because it’s not given any information (or supervision) to go off from the engineer that’s using it. Also, the number of clusters assigned is a hyperparameter and you will need to choose what number of clusters <span class="No-Break">is optimal.</span></li>
				<li><strong class="bold">Principal component analysis</strong> (<strong class="bold">PCA</strong>): Often, the largest problem with using unsupervised <a id="_idIndexMarker039"/>ML on very large datasets is there’s actually too much uncorrelated data to find meaningful <a id="_idIndexMarker040"/>patterns. This is why PCA is used so often because it’s a great way to reduce dimension without actually losing or discarding information. This is especially useful for massive datasets such as finding patterns in genome sequencing or drug <span class="No-Break">discovery trials.</span></li>
			</ul>
			<p>Next, l<a id="_idTextAnchor029"/>et’s jump into <span class="No-Break">semi-supervised learning.</span></p>
			<h2 id="_idParaDest-22"><a id="_idTextAnchor030"/>Semi-supervised learning</h2>
			<p>In a perfect world, we’d have massive well-labeled datasets with which to create optimal <a id="_idIndexMarker041"/>models that <a id="_idIndexMarker042"/>don’t overfit. <strong class="bold">Overfitting</strong> is when you create and tune a model to the dataset you have but it fits a bit too <a id="_idIndexMarker043"/>well, which means it’s optimized for that particular dataset and doesn’t work well with more diverse data. This is a common problem in data science. We live in an imperfect world and we can find ourselves in situations where we don’t have enough labeled data or enough data at all. This is where semi-supervised learning comes in handy. We give some labeled datasets and also include a dataset that is unlabeled to essentially give the model nudges in the right direction as it tries to come up with its own semblance of <span class="No-Break">finding patterns.</span></p>
			<p>It doesn’t quite have the same level of absolute truth associated with supervised learning, but it does offer the models some helpful clues with which to organize its results so that it can find an easier path to the <span class="No-Break">right answer.</span></p>
			<p>For instance, let’s say you’re looking for a model that works well with detecting patterns in photos or speech. You might label a few of them and then see how the performance improves over time with the examples you don’t label. You can use multiple models in semi-supervised learning. The process would be a lot like supervised learning, which learns with labeled datasets so that it knows exactly how off it is from being correct. The main difference between supervised learning and semi-supervised learning is that you’re predicting a portion of the new unlabeled data and then, essentially, checking its accuracy against the labeled data. You’re adding unlabeled new data points into the training set so that it’s <em class="italic">training</em> on the data it’s <span class="No-Break">gotten correct.</span></p>
			<p>Finally, to wrap up this section, let’s t<a id="_idTextAnchor031"/>ake a brief look at <span class="No-Break">reinforcement learning.</span></p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor032"/>Reinforcement learning</h2>
			<p>This area of ML effectively learns with trial and error, so it’s learning from past behavior and <a id="_idIndexMarker044"/>adapting its approach to finding <a id="_idIndexMarker045"/>the best performance by itself. There’s a sequence to reinforcement learning and it’s really a system based on weights and rewards to reinforce correct results. Eventually, the model tries to optimize for these rewards and gets better with time. We see reinforcement learning used a lot with robotics, for instance, where robots are trained to understand how to operate and adjust to the parameters of the real world with all <span class="No-Break">its unpredictability.</span></p>
			<p>Now that we’ve discussed and understood the different ML types, let’s move on and u<a id="_idTextAnchor033"/>nderstand the optimal flow of the <span class="No-Break">ML process.</span></p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor034"/>The order – what is the optimal flow and where does every part of the process live?</h1>
			<p>Companies interested in creating value with AI/ML have a lot to gain compared to their more hesitant competitors. According to McKinsey Global Institute, “<em class="italic">Companies that fully absorb AI in their value-producing workflows by 2025 will dominate the 2030 world economy with +120% cash flow growth.</em>” The undertaking of embracing AI and productionizing it – whether in your product or for internal purposes – is complex, technical debt-heavy, and expensive. Once your models and use cases are chosen, making that <a id="_idIndexMarker046"/>happen in production becomes a difficult program to manage and this is a process many companies will struggle with as we see companies in industries other than tech starting to take on the challenge of embracing AI. Operationalizing the process, updating the models, keeping the data fresh and clean, and organizing experiments, as well as validating, testing, and the storage associated with it, are the <span class="No-Break">complicated parts.</span></p>
			<p>In an effort to make this entire process more digestible, we’re going to present this as a step-by-step process because there are varying layers of complexity but the basic components will be the same. Once you have gotten through the easy bit and you’ve settled on the models and algorithms you feel are optimal for your use case, you can begin to ref<a id="_idTextAnchor035"/>ine your process for managing your <span class="No-Break">AI system.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor036"/>Step 1 – Data availability and centralization</h2>
			<p>Essentially, you’ll need a central place to store the data that your AI/ML models and algorithms <a id="_idIndexMarker047"/>will be learning from. Depending on the databases you invest in or legacy systems you’re using, you might have a need for an ETL pipeline and data engineering to make the layers of data and metadata available for your productionized AI/ML models to ingest and offer insights from. Think of this as creating the pipeline needed to feed your <span class="No-Break">AI/ML system.</span></p>
			<p>AI feeds on data, and if your system of delivering data is clunky or slow, you’ll run into issues in production later. Choosing your preferred way of storing data is tricky in and of itself. You don’t know how your tech stack will evolve as you scale, so choosing a cost-effective <a id="_idIndexMarker048"/>and reliable solution is a mission in and of itself. For example, as we started to add more and more customers at a cybersecurity company we were previously working for, we noticed the load time for certain customer-facing dashboards was lagging behind. Part of the issue was the number of customers, and their metadata was too large to<a id="_idTextAnchor037"/> support the pipelines we already had <span class="No-Break">in place.</span></p>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor038"/>Step 2 – Continuous maintenance</h2>
			<p>At this point, you have your models and algorithms and you’ve chosen a system for delivering <a id="_idIndexMarker049"/>data to them. Now, you’re going <a id="_idIndexMarker050"/>to be in the flow of constantly maintaining this system. In <a id="_idIndexMarker051"/>DevOps, this is referred to as <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>)/<strong class="bold">continuous delivery</strong> (<strong class="bold">CD</strong>). In the later chapters, we will cover the concept of <strong class="bold">AI Operations</strong> (<strong class="bold">AIOps</strong>) but for <a id="_idIndexMarker052"/>now, the following is a list of the stages tailored for the continuous maintenance of AI pipelines. The following are the four major components of the continuous <span class="No-Break">maintenance process:</span></p>
			<ul>
				<li><strong class="bold">CI</strong>: Testing/validating <a id="_idIndexMarker053"/>code and components, along with data, data schemas, <span class="No-Break">and models</span></li>
				<li><strong class="bold">CD</strong>: Code changes <a id="_idIndexMarker054"/>or updates to your model are passed on continuously so that once you’ve made changes, they are slated to appear in the testing environment before going to production <span class="No-Break">without pauses</span></li>
				<li><strong class="bold">CT</strong>: We’ve <a id="_idIndexMarker055"/>mentioned the idea of continuous learning being important for ML, and <strong class="bold">continuous training</strong> productionizes this process so that as your data feeds are refreshed, your models are consistently training and learning from that <span class="No-Break">new data</span></li>
				<li><strong class="bold">CM</strong>: We <a id="_idIndexMarker056"/>can’t have ML/AI models continuously running without also <strong class="bold">continuously monitoring</strong> them to make sure something isn’t going <span class="No-Break">horribly wrong</span></li>
			</ul>
			<p>You can’t responsibly manage an AI program if you aren’t iterating your process constantly. Your models and hyperparameters will become stale. Your data will become stale and when an iterative process like this stagnates, it will stop being effective. Performance is something you’ll constantly be staying up to date on because the lack of performance <a id="_idIndexMarker057"/>will be self-evident, whether it is client-facing or not. With that said, things can also go wrong. For example, lags in performance or in the frequency of the model updating can lead to people losing their jobs, not getting a competitive rate on a mortgage, or getting an unfair prison sentence. Major consequences can arise from downstream effects due to improper model maintenance. We recommend exploring the <em class="italic">Additional resources</em> section at the end of this chapter for more examples and information on how stagnan<a id="_idTextAnchor039"/>t AI systems can wreak havoc on environments <span class="No-Break">and people.</span></p>
			<p>B 101 – databases, warehouses, data lakes, <span class="No-Break">and lakehouses</span></p>
			<p>AI/ML products run on data. Where and how you store your data is a big consideration that impacts your AI/ML performance, and in this section, we will be going through some of the most popular storage vehicles for your data. Figuring out the optimal way to store and access and train your data is a specialization in and of itself, but if you’re in the business of AI product management, eventually, you’re going to need to understand the basic building blocks of what makes your AI product work. In a few words, <span class="No-Break">data does.</span></p>
			<p>Because AI requires big data, this is going to be a significant strategic decision for your product and business. If you don’t have a well-oiled machine, pun intended, you’re going to run into snags that will impair the performance of your models and, by extension, your product itself. Having a good grasp of the most cost-effective and performance-driven solution for your particular product, and finding the balance within these various facets, is going to help your success as a product manager. Yes, you will depend on your technical executives for a lot of these decisions, but you’ll be at the table helping make these decisions, so some familiarity is <span class="No-Break">needed here.</span></p>
			<p>Let’s look at some o<a id="_idTextAnchor040"/>f the different options to store data for <span class="No-Break">AI/ML products.</span></p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor041"/>Database</h2>
			<p>Depending on your organization’s goals and budget, you’ll be centralizing your data somehow <a id="_idIndexMarker058"/>between a data lake, a database, and a data warehouse, and you might even be considering a new option: the data lakehouse. If you’re just getting your feet wet, you’re likely just storing your data in a relational database so that you can access it and query it easily. Databases are a great way to do this if you have a relatively simple setup. With a relational database, there’s a particular schema you’re operating under if you wanted to combine this data with data that’s in another database; you would run into problems aligning these <span class="No-Break">schemas later.</span></p>
			<p>If your primary use of the database is querying to access data and use only a certain subset of your company’s data for general trends, a relational database might be enough. If you’re looking to combine various datasets from disparate areas of your business and you’re looking to accomplish more advanced analytic<a id="_idTextAnchor042"/>s, dashboards, or AI/ML functions, you’ll need to <span class="No-Break">read on.</span></p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor043"/>Data warehouse</h2>
			<p>If you’re looking to combine data into a location where you can centralize it somewhere and you’ve <a id="_idIndexMarker059"/>got lots of structured data coming in, you’re more likely going to use a data warehouse. This is really the first step toward maturity because it will allow you to leverage insights and trends across your various business units quickly. If you’re looking to leverage AI/ML in various ways, rather than one specific specialized way, this will serve <span class="No-Break">you well.</span></p>
			<p>Let’s say, for example, that you want to add AI features to your existing product as well as within your HR function. You’d be leveraging your customer data to offer trends or predictions to your customers based on the performance of others in their peer group, as well as using AI/ML to make predictions or optimizations for your internal employees. Both these use cases would be well served with a <span class="No-Break">data warehouse.</span></p>
			<p>Data warehouses do, however, require some upfront investment to create a plan and design your data structures. They also require a costly investment as well because they make data available for analysis on demand, so you’re paying a premium for keeping that data readily available. Depending on how advanced your internal users are, you could opt for cheaper options, but this option would be optimal for organizations where most of your business users are looking for easily digestible ways to analyze data. Either way, a data warehouse will allow you to create<a id="_idTextAnchor044"/> dashboards for your internal users and <span class="No-Break">stakeholder teams.</span></p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor045"/>Data lake (and lakehouse)</h2>
			<p>If you’re sitting on lots of raw, unstructured data, and you want to have a more cost-effective place to store it, you’d be looking at a data lake. Here, you can store unstructured, semi-structured, as well as structured data that can be easily accessed by your more tech-savvy internal users. For instance, data scientists and ML engineers would be able <a id="_idIndexMarker060"/>to work with this data because they would be creating their own data models to transform and analyze the data on the fly, but this isn’t the case at <span class="No-Break">most companies.</span></p>
			<p>Keeping your data in a data lake would be cheap if you’ve got lots of data your business users don’t need immediately, but you won’t ever really be able to replace a warehouse or a database with one. It’s more of a “nice to have.’’ If you’re sitting on a massive data lake of historical data you want to use in the future for analytics, you’ll need to consider another way to store it to get <span class="No-Break">those insights.</span></p>
			<p>You might also come <a id="_idIndexMarker061"/>across the term <strong class="bold">lakehouse</strong>. There are many databases, data warehouses, and data lakes out there. However, the only lakehouse we’re aware of has been popularized by a company called Databricks, which offers something like a data lake but with some of the capabilities you get with data warehouses, namely, the ability to showcase data, make it available and ingestible for non-technical internal users, and create dashboards with it. The biggest advantage here is that you’re storing it and paying for the data to be stored upfr<a id="_idTextAnchor046"/>ont with the ability to access and manipulate <span class="No-Break">it downstream.</span></p>
			<h2 id="_idParaDest-30"><a id="_idTextAnchor047"/>Data pipelines</h2>
			<p>Regardless of the tech you use to maintain and store your data, you’re still going to need to put <a id="_idIndexMarker062"/>up pipelines to make sure your data is moving, that your dashboards are refreshing as readily as your business requires, and that data is flowing the way it needs to. There are also multiple ways of processing and passing data. You might be doing it in batches (batch processing) for large amounts of data being moved at various intervals, or in real-time pipelines for getting data in real time as soon as it’s generated. If you’re looking to leverage predictive analytics, enable reporting, or have a system in place to move, process, and store data, a data pipeline will likely be enough. However, depending on what your data is doing and how much transformation is required, you’ll likely be using both data pipelines and perhaps, more specifically, <span class="No-Break">ETL pipelines.</span></p>
			<p><strong class="bold">ETL</strong> stands for <strong class="bold">extract, transform, and load</strong>, so your data engineers are going to be creating <a id="_idIndexMarker063"/>specific pipelines for more advanced systems such as centralizing all your data into one place, adding data or data enrichment, connecting your data with <strong class="bold">CRM</strong> (<strong class="bold">customer relationship management</strong>) tools, or even transforming the data and adding structure to it between systems. The reason for this is that it’s a necessary step when using a data warehouse or database. If you’re exclusively using a data lake, you’ll have all the metadata you need to be able to analyze it and get your insights as you like. In most cases, if you’re working with an AI/ML product, you’re going to be working with a data engineer who will power the data flow needed to <a id="_idIndexMarker064"/>make your product a success because you’re likely using a relational database as well as a data warehouse. The analytics required to enable AI/ML features will most likely need to be powered by a data engineer who will focus on the <span class="No-Break">ETL pipeline.</span></p>
			<p>Managing and maintaining this system will also be the work of your data engineer, and we encourage every product manager to have a close relationship with the data engineer(s) that supports their products. One key difference between the two is that ETL pipelines are generally updated in batches and not in real time. If you’re using an ETL pipeline, for instance, to update historical daily information about how your customers are using your product to offer client-facing insights in your platform, it might be optimal to keep this batch updating twice daily. If you need insights to come in real time for a dashboard that’s being used by your internal business users and they rely on that data to make daily decisions, however, you likely will need to resort to a data pipeline that’s <span class="No-Break">updated continuously.</span></p>
			<p>Now, that we understand the different available options to store data and how to choose the right op<a id="_idTextAnchor048"/>tion for the business, let’s discuss how to manage <span class="No-Break">our projects.</span></p>
			<h1 id="_idParaDest-31"><a id="_idTextAnchor049"/>Managing projects – IaaS</h1>
			<p>If you’re looking to create an AI/ML system in your organization, you’ll have to think about it as <a id="_idIndexMarker065"/>its own ecosystem that you’ll need to constantly maintain. This is why you see MLOps and AIOps working in conjunction with DevOps teams. Increasingly so, we will start to see managed services and <strong class="bold">infrastructure-as-a-service</strong> (<strong class="bold">IaaS</strong>) offerings coming out more and more. There has been a shift in the industry toward companies such as Determined AI and Google’s AI platform pipeline tools to meet the needs of the market. At the heart of this need is <a id="_idIndexMarker066"/>the desire to ease some of the burdens from companies left scratching their heads as they begin to take on the mammoth task of getting started with an <span class="No-Break">AI system.</span></p>
			<p>Just as DevOps teams became popular with at-scale software development, the result of decades of mistakes, we will see something similar with MLOps and AIOps. Developing a solution and putting it into operation are two different key areas that need to work together. This is doubly true for AI/ML systems. The trend now is on IaaS. This is an important concept to understand because companies just approaching AI often don’t have an understanding of the cost, storage, compute power, and investment required to do AI properly, particularly for DL AI projects that require massive amounts of data to <span class="No-Break">train on.</span></p>
			<p>At this point, most companies haven’t been running AI/ML programs for decades and don’t have dedicated teams. Tech companies such as MAANG (Meta, Amazon, Apple, Netflix, Google) are leading the cultural norms with managing AI/ML, but most companies that will need to embrace AI are not in tech and <a id="_idIndexMarker067"/>are largely unprepared for the technical debt AI adoption will pose for their engineering teams <span class="No-Break">to manage.</span></p>
			<p>Shortcuts taken to get AI initiatives off the ground will require code refactoring or changing how your data is stored and managed, which is why strategizing and planning for AI adoption is so crucial. This is why so many of these IaaS services are popping up to help keep engineering teams nimble should they require changes in the future as well. The infrastructure needed to keep AI teams up and running is going to change as time goes on, and the advantage of using an IaaS provider is that you can run all your projects and only pay for th<a id="_idTextAnchor050"/>e time your AI developers are actually using data to <span class="No-Break">train models.</span></p>
			<h1 id="_idParaDest-32"><a id="_idTextAnchor051"/>Deployment strategies – what do we do with these outputs?</h1>
			<p>Once you’re <a id="_idIndexMarker068"/>happy with the models you’ve chosen (including their performance and error rate), you’ve got a good level of infrastructure to support your product and chosen AI model’s use case; you’re ready to go to the last step of the process and deploy this code into production. Keeping up with a deployment strategy that works for your product and organization will be part of the continuous maintenance we’ve outlined in the previous section. You’ll need to think about things such as how often you’ll need to retrain your models and refresh your training data to prevent model decay and data drift. You’ll also need a system for continuously monitoring your model’s performance so this process will be really specific to your product and business, particularly because these periods of retraining will require some downtime for <span class="No-Break">your system.</span></p>
			<p>Deployment is <a id="_idIndexMarker069"/>going to be a dynamic process because your models are trying to effectively make predictions of real-world data for the most part, so depending on what’s going on in the world of your data, you might have to give deployment more or less of your attention. For instance, when we were working for an ML property-tech company, we were updating, retraining, and redeploying our models almost daily because we worked with real estate data that was experiencing a huge skew due to rapid changes in migration data and housing price data due to the pandemic. If those models were left unchecked and there weren’t engineers and business leaders on both sides of this product, on the client’s end and internally, we might not have caught some of the egregious liberties the models were making on behalf of <span class="No-Break">under-representative data.</span></p>
			<p>There are also a number of well-known deployment strategies you s<a id="_idTextAnchor052"/>hould be aware of. We will discuss them in the <span class="No-Break">following subsections.</span></p>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor053"/>Shadow deployment strategy</h2>
			<p>In this deployment strategy (often <a id="_idIndexMarker070"/>referred to as <strong class="bold">shadow mode</strong>), you’re deploying a new model with new features along with a model that already <a id="_idIndexMarker071"/>exists so that the new model that’s deployed is only experienced as a <em class="italic">shadow</em> of the model that’s currently in production. This also means that the new model is handling all the requests it’s getting just as the existing model does but it’s not showing the results of that model. This strategy allows you to see whether the shadow model is performing better on the same real-world data it’s getting without interrupting the model that’s actually live in production. Once it’s confirmed that the new model is performing better and that it has no issues running, it will then become the predominant mode<a id="_idTextAnchor054"/>l fully deployed in production and the original model will <span class="No-Break">be retired.</span></p>
			<h2 id="_idParaDest-34"><a id="_idTextAnchor055"/>A/B testing model deployment strategy</h2>
			<p>With this strategy, we’re actually seeing two slightly different models with different features <a id="_idIndexMarker072"/>to get a sense of how it’s working in the live environment concurrently. The two models are set up at <a id="_idIndexMarker073"/>the same time and the performance is optimized to reward conversion. This is effectively like an experiment where you’re looking at the results of one model over another and you’re starting with some hypothesis or expectation of how one is performing better than another, and then you’re testing that hypothesis to see whether you were right. The differences in your models do, however, have to be slight because if there’s too much variety between the features of the two,<a id="_idTextAnchor056"/> you actually won’t understand what’s creating the most success <span class="No-Break">for you.</span></p>
			<h2 id="_idParaDest-35"><a id="_idTextAnchor057"/>Canary deployment strategy</h2>
			<p>Here, we see a more gradual approach to deployment where you actually create subsets of users <a id="_idIndexMarker074"/>that will then experience your new model deployment. Here, we’re seeing the number of users that are subjected to your new model gradually increasing over time. This means that you can have <a id="_idIndexMarker075"/>a buffer time between groups of users to understand how they’re reacting and interacting with this new model. Essentially, you’re using varying groups of your own users as testers before you release to a new batch so you can catch bugs more gradually as well. It’s a slow but rewarding process if you have the patience <span class="No-Break">and courage.</span></p>
			<p>There are more strategies to choose from but keep in mind that the selection of these strategies will depend on the nature of your product, and what’s most important to your customers and users is your budget, your metrics and performance monitoring, your technical capacity and knowledge, and the timeline you have. Beyond your deployment, you’re going to have to help your business understand how often they should be doing code refactoring and branching <span class="No-Break">as well.</span></p>
			<p>Now that we’ve discussed the<a id="_idTextAnchor058"/> different deployment strategies, let’s see what it takes to succeed <span class="No-Break">in AI.</span></p>
			<h1 id="_idParaDest-36"><a id="_idTextAnchor059"/>Succeeding in AI – how well-managed AI companies do infrastructure right</h1>
			<p>It’s indicative <a id="_idIndexMarker076"/>of the complexity of ML systems that many large technology companies that depend heavily on ML have dedicated teams and platforms that focus on building, training, deploying, and maintaining ML models. The following are a few examples of options you can take when building an <span class="No-Break">ML/AI program:</span></p>
			<ul>
				<li><strong class="bold">Databricks has MLflow</strong>: MLflow is an <a id="_idIndexMarker077"/>open source platform developed by Databricks to help manage the complete ML life cycle for enterprises. It allows you to run experiences and work with any library, framework, or language. The main benefits are experiment tracking (so you can see how your models are doing between experiments), model management (to manage all versions of your model between teammates), and model deployment (to have a quick view of deployment in view in <span class="No-Break">the tool).</span></li>
				<li><strong class="bold">Google has TensorFlow Extended (TFX)</strong>: This is Google’s newest product built on TensorFlow and it’s an end-to-end platform for deploying production-level ML pipelines. It allows you to collaborate within and between teams and offers robust capabilities for scalable, <span class="No-Break">high-performance environments.</span></li>
				<li><strong class="bold">Uber has Michelangelo</strong>: Uber is a great example of a company creating their own ML management tool in-house for collaboration and deployment. Earlier, they were using disparate languages, models, and algorithms and had teams that were siloed. After they implemented Michelangelo, they were able to bring in varying skill sets and capabilities under one system. They needed one place for a reliable, recreatable, and standardized pipeline to create, manage, predict, and deploy their data <span class="No-Break">at scale.</span></li>
				<li><strong class="bold">Meta has FBLearner Flow</strong>: Meta also created its own system for managing its numerous AI projects. Since ML is such a foundational part of their product, Meta needed a platform that would allow <span class="No-Break">the following:</span><ul><li>Every ML algorithm that was implemented once to have the ability to be reusable by someone else at a <span class="No-Break">later date</span></li><li>Every engineer to have the ability to write a training pipeline that can <span class="No-Break">be reused</span></li><li>Make model training easy <span class="No-Break">and automated</span></li><li>Everybody to have the ability to search past projects and <span class="No-Break">experiments easily</span></li></ul></li>
			</ul>
			<p>Effectively, Facebook created an easy-to-use knowledge base and workflow to centralize all their <span class="No-Break">ML ops.</span></p>
			<ul>
				<li><strong class="bold">Amazon has SageMaker</strong>: This is Amazon’s product that allows you to build, train, and deploy your ML models and programs with their own collection of fully managed infrastructure tools and workflows. The idea of this product is to meet their <a id="_idIndexMarker078"/>customers where they are and offer low-code or no-code UIs, whether you employ ML engineers or business analysts. The ability to use their infrastructure is also great if you’re already using Amazon services for your cloud infrastructure so that you can take it a step further to automate and standardize your ML/AI program and operations <span class="No-Break">at scale.</span></li>
				<li><strong class="bold">Airbnb has Bighead</strong>: Airbnb created its own ML infrastructure in an effort to create standardization and centralization between their AI/ML organizations. They used a collection of tools such as Zipline, Redspot, and DeepThought to orchestrate their ML platform in an effort to do the same as Facebook and Uber: to mitigate errors and discrepancies and minimize <span class="No-Break">repeatable work.</span></li>
			</ul>
			<p>As we can see, there are multiple platforms that can be used to create, tra<a id="_idTextAnchor060"/>in, and deploy ML models. Finally, let’s see what the future of AI <span class="No-Break">looks like.</span></p>
			<h1 id="_idParaDest-37"><a id="_idTextAnchor061"/>The promise of AI – where is AI taking us?</h1>
			<p>So, where is <a id="_idIndexMarker079"/>this era of AI implementation headed and what does it mean for all industries? At this point, we’re looking at an industry of geopolitical influence, a technologically obvious decision that comes with a lot of responsibility, cost, and opportunity. As long as companies and product managers are aware of the risks, costs, and level of investment needed to properly care for an AI program, use it as a source of curiosity, and apply AI/ML to projects that create success early on and build from that knowledge, those that invest in AI will find themselves experiencing AI’s promise. This promise is rooted in quantifying prediction and optimization. For example, Highmark Inc. saved more than $260M in 2019 by using ML for fraud detection, GE helped its customers save over $1.6B with their predictive maintenance, and 35% of Amazon’s sales come from their <span class="No-Break">recommendation engine.</span></p>
			<p>When a third of your revenues are coming from an AI algorithm, there’s virtually no argument. Whatever investment you make in AI/ML, make sure you’re leveraging it to its maximum <a id="_idIndexMarker080"/>capacity by properly planning and strategizing, finding capable talent that’s aware of the space and potential dangers, and choosing the right scalable infrastructure to limit <span class="No-Break">your refactoring.</span></p>
			<p>As long as your AI/ML projects are directly married to outcomes that impact cost savings or revenue, you’ll likely experience success within your own career if you’re overseeing these projects. The recommendation of starting small, applying it to a clear business goal, tracking that goal, and showing off its effectiveness is a smart strategy because this chapter details the many areas of maintaining an AI program, as well as potential areas where it might experience hurdles. Justifying the time, investment in headcount, and infrastructure expenses will be challenging if you’re not able to communicate the strength and capabilities of AI to even your most <span class="No-Break">hesitant executive.</span></p>
			<p>This will also be important for your technical resources (data scientists, data engineers, and ML engineers) as well as for your business stakeholders. It’s one thing to know more about the ML algorithms you’ll be using or to get a few recommendations about how to best store your data, but you really won’t have the intimacy and fluency needed to truly be an agent of change within your organization if you don’t iterate with your own projects and grow your knowledge and intuition about what works best from there. We learn through iteration and we build confidence the more we complete a task successfully. This will be the case for you as a product manager <span class="No-Break">as well.</span></p>
			<p>In the previous example, GE offered cost savings to its customers, Highmark prevented future bottlenecks by predicting fraud, and Amazon grew its revenues through ML. When we think about the promise of AI and where it’s taking us, these examples drive the idea that this is the home of the latest industrial revolution. It’s not just something that will offer benefits to companies but to everyone all at once. The distribution of the benefits may not be completely equal because, ultimately, it’s the companies that are investing in <a id="_idIndexMarker081"/>this tech and they will look to experience the highest return on this investment first, but the point<a id="_idTextAnchor062"/> stands that consumers, as well as businesses, will experience benefits <span class="No-Break">from AI.</span></p>
			<h1 id="_idParaDest-38"><a id="_idTextAnchor063"/>Summary</h1>
			<p>We’ve covered a lot in this chapter, but keep in mind that a lot of the concepts present here will be returned to in subsequent chapters for further discussion. It’s almost impossible to overstate the infrastructure AI/ML will need to be successful because so much of the performance is dependent on how we deliver data and how we manage deployments. We covered the basic definitions of ML and DL, as well as the learning types that both can employ. We also covered some of the basics of setting up and maintaining an AI pipeline and included a few examples of how other companies manage this kind <span class="No-Break">of operation.</span></p>
			<p>Building products that leverage AI/ML is an ambitious endeavor, and this first chapter was meant to provide enough of a foundation for the process of setting up an AI program overall, so that we can build on the various aspects of that process in the following chapters without having to introduce too many new concepts so late in the book. If you’re feeling overwhelmed, it only means you’re grasping the scale necessary for building with AI. That’s a great sign! In <a href="B18935_02.xhtml#_idTextAnchor067"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, we will get into the specifics of <a id="_idTextAnchor064"/>using and maintaining the ML models we briefly introduced earlier in <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-39"><a id="_idTextAnchor065"/>Additional resources</h1>
			<p>For additional information, you can refer to the <span class="No-Break">following resources:</span></p>
			<ul>
				<li><em class="italic">Weapons of Math Destruction</em> by Cathy <span class="No-Break">O’Neil: </span><a href="https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815&#13;"><span class="No-Break">https://www.amazon.com/Weapons-Math-Destruction-Increases-Inequality/dp/0553418815</span></a></li>
				<li><em class="italic">Invisible Women: Exposing Data Bias in a World Designed for Men</em> by Caroline Criado <span class="No-Break">Perez: </span><a href="https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419735217/ref=sr_1_1?keywords=invisible+women&amp;qid=1673296808&amp;sr=8-1"><span class="No-Break">https://www.amazon.com/Invisible-Women-Data-World-Designed/dp/1419735217/ref=sr_1_1?keywords=invisible+women&amp;qid=1673296808&amp;sr=8-1</span></a></li>
				<li><em class="italic">The Ethical Algorithm: The Science of Socially Aware Algorithm Design</em> by Michael Kearns, Aaron <span class="No-Break">Roth: </span><a href="https://www.amazon.com/Ethical-Algorithm-Science-Socially-Design/dp/0190948205/&#13;"><span class="No-Break">https://www.amazon.com/Ethical-Algorithm-Science-Socially-Design/dp/0190948205/</span></a></li>
				<li><em class="italic">Artificial Unintelligence: How Computers Misunderstand the World</em> by Meredith <span class="No-Break">Broussard: </span><a href="https://www.amazon.com/Artificial-Unintelligence-Computers-Misunderstand-World/dp/026253701X/&#13;"><span class="No-Break">https://www.amazon.com/Artificial-Unintelligence-Computers-Misunderstand-World/dp/026253701X/</span></a></li>
				<li><em class="italic">Algorithms of Oppression: How Search Engines Reinforce Racism</em> by Safiya Umoja <span class="No-Break">Noble: </span><a href="https://www.amazon.com/Algorithms-Oppression-Search-Engines-Reinforce/dp/1479837245/&#13;"><span class="No-Break">https://www.amazon.com/Algorithms-Oppression-Search-Engines-Reinforce/dp/1479837245/</span></a></li>
				<li><em class="italic">Race After Technology: Abolitionist Tools for the New Jim Code</em> by Ruha <span class="No-Break">Benjamin: </span><a href="https://www.amazon.com/Race-After-Technology-Abolitionist-Tools/dp/1509526404/&#13;"><span class="No-Break">https://www.amazon.com/Race-After-Technology-Abolitionist-Tools/dp/1509526404/</span></a></li>
				<li><em class="italic">The Age of Surveillance Capitalism: The Fight for a Human Future at the New Frontier of Power</em> by Shoshana Zuboff : <a href="https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1541758005/&#13;"><span class="No-Break">https://www.amazon.com/Age-Surveillance-Capitalism-Future-Frontier/dp/1541758005/</span></a></li>
				<li><em class="italic">Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor</em> by Virginia <span class="No-Break">Eubanks: </span><a href="https://www.amazon.com/Automating-Inequality-High-Tech-Profile-Police/dp/1250074312/&#13;"><span class="No-Break">https://www.amazon.com/Automating-Inequality-High-Tech-Profile-Police/dp/1250074312/</span></a></li>
				<li><em class="italic">Data Feminism</em> by Catherine <span class="No-Break">D’Ignazio: </span><a href="https://www.amazon.com/Feminism-Strong-Ideas-Catherine-DIgnazio/dp/0262044005/&#13;"><span class="No-Break">https://www.amazon.com/Feminism-Strong-Ideas-Catherine-DIgnazio/dp/0262044005/</span></a></li>
			</ul>
			<h1 id="_idParaDest-40"><a id="_idTextAnchor066"/>References</h1>
			<ul>
				<li><a href="https://www.canva.com/careers/topic/machine-learning/&#13;"><span class="No-Break">https://www.canva.com/careers/topic/machine-learning/</span></a></li>
				<li><em class="italic">Model Deployment </em><span class="No-Break"><em class="italic">Strategies</em></span><span class="No-Break">: </span><a href="https://neptune.ai/blog/model-deployment-strategies&#13;"><span class="No-Break">https://neptune.ai/blog/model-deployment-strategies</span></a></li>
				<li><em class="italic">AI Helps DuoLingo Personalize Language </em><span class="No-Break"><em class="italic">Learning</em></span><span class="No-Break">: </span><a href="https://www.wired.com/brandlab/2018/12/ai-helps-duolingo-personalize-language-learning/#:~:text=The%20learning%20behind%20the%20lingo,data%20and%20make%20intelligent%20predictions"><span class="No-Break">https://www.wired.com/brandlab/2018/12/ai-helps-duolingo-personalize-language-learning/#:~:text=The%20learning%20behind%20the%20lingo,data%20and%20make%20intelligent%20predictions</span></a></li>
				<li><a href="https://www.crunchbase.com/organization/ggwp-65c2"><span class="No-Break">https://www.crunchbase.com/organization/ggwp-65c2</span></a></li>
				<li><a href="https://www.cbinsights.com/company/anon-ai"><span class="No-Break">https://www.cbinsights.com/company/anon-ai</span></a></li>
				<li><em class="italic">AI-50 America’s Most Promising Artificial Intelligence </em><span class="No-Break"><em class="italic">Companies</em></span><span class="No-Break">: </span><a href="https://www.forbes.com/sites/alanohnsman/2021/04/26/ai-50-americas-most-promising-artificial-intelligence-companies/?sh=3b5e27ef77cf"><span class="No-Break">https://www.forbes.com/sites/alanohnsman/2021/04/26/ai-50-americas-most-promising-artificial-intelligence-companies/?sh=3b5e27ef77cf</span></a></li>
				<li><a href="https://www.lacework.com/labs/"><span class="No-Break">https://www.lacework.com/labs/</span></a></li>
				<li><a href="https://www.crunchbase.com/organization/lacework/company_financials"><span class="No-Break">https://www.crunchbase.com/organization/lacework/company_financials</span></a></li>
				<li><em class="italic">SHEIN’s AI Program Matches Local Demand at </em><span class="No-Break"><em class="italic">Scale</em></span><span class="No-Break">: </span><a href="https://www.psfk.com/2022/06/sheins-consumer-to-manufacturer-ai-program-matches-local-demand-at-scale.html#:~:text=Shein’s%20AI%20engine%20can%20quickly,brand%20much%20cheaper%20operating%20costs&#13;"><span class="No-Break">https://www.psfk.com/2022/06/sheins-consumer-to-manufacturer-ai-program-matches-local-demand-at-scale.html#:~:text=Shein’s%20AI%20engine%20can%20quickly,brand%20much%20cheaper%20operating%20costs</span></a></li>
				<li><em class="italic">Product Led Growth, </em><span class="No-Break"><em class="italic">Wes Bush</em></span></li>
				<li><em class="italic">Mind the Gap – It’s Not AI/ML Unless It’s in Production: Data Strategy Series Part </em><span class="No-Break"><em class="italic">4</em></span><span class="No-Break">: </span><a href="https://www.credera.com/insights/mind-gap-not-ai-ml-unless-production-data-strategy-series-part-4&#13;"><span class="No-Break">https://www.credera.com/insights/mind-gap-not-ai-ml-unless-production-data-strategy-series-part-4</span></a></li>
				<li><em class="italic">Airbnb’s End-to-End ML </em><span class="No-Break"><em class="italic">Platform</em></span><span class="No-Break">: </span><a href="https://medium.com/acing-ai/airbnbs-end-to-end-ml-platform-8f9cb8ba71d8&#13;"><span class="No-Break">https://medium.com/acing-ai/airbnbs-end-to-end-ml-platform-8f9cb8ba71d8</span></a></li>
				<li><em class="italic">Amazon </em><span class="No-Break"><em class="italic">SageMaker</em></span><span class="No-Break">: </span><a href="https://aws.amazon.com/sagemaker/"><span class="No-Break">https://aws.amazon.com/sagemaker/</span></a></li>
				<li><em class="italic">Introducing FBLearner Flow: Facebook’s AI </em><span class="No-Break"><em class="italic">backbone</em></span><span class="No-Break">: </span><a href="https://engineering.fb.com/2016/05/09/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/&#13;"><span class="No-Break">https://engineering.fb.com/2016/05/09/core-data/introducing-fblearner-flow-facebook-s-ai-backbone/</span></a></li>
				<li><em class="italic">Meet Michelangelo: Uber’s Machine Learning </em><span class="No-Break"><em class="italic">Platform</em></span><span class="No-Break">: </span><a href="https://www.uber.com/blog/michelangelo-machine-learning-platform/&#13;"><span class="No-Break">https://www.uber.com/blog/michelangelo-machine-learning-platform/</span></a></li>
				<li><em class="italic">TFX is an end-to-end platform for deploying production ML </em><span class="No-Break"><em class="italic">pipelines</em></span><span class="No-Break">: </span><a href="https://www.tensorflow.org/tfx&#13;"><span class="No-Break">https://www.tensorflow.org/tfx</span></a></li>
				<li><em class="italic">Managed MLflow Managing the complete machine learning </em><span class="No-Break"><em class="italic">lifecycle</em></span><span class="No-Break">: </span><a href="https://www.databricks.com/product/managed-mlflow&#13;"><span class="No-Break">https://www.databricks.com/product/managed-mlflow</span></a></li>
				<li><em class="italic">Discover </em><span class="No-Break"><em class="italic">Lakehouse</em></span><span class="No-Break">: </span><a href="https://www.databricks.com/discoverlakehouse?utm_medium=paid+search&amp;utm_source=google&amp;utm_campaign=13039235745&amp;utm_adgroup=125064728314&amp;utm_content=product+page&amp;utm_offer=discoverlakehouse&amp;utm_ad=576656880219&amp;utm_term=what%20is%20a%20lakehouse&amp;gclid=CjwKCAjwx7GYBhB7EiwA0d8oe_HabROASQAaw7XYRq-VinQLswPqDyh8iPCT4032m8UN7H0B0uNyVBoCZ-QQAvD_BwE&#13;"><span class="No-Break">https://www.databricks.com/discoverlakehouse?utm_medium=paid+search&amp;utm_source=google&amp;utm_campaign=13039235745&amp;utm_adgroup=125064728314&amp;utm_content=product+page&amp;utm_offer=discoverlakehouse&amp;utm_ad=576656880219&amp;utm_term=what%20is%20a%20lakehouse&amp;gclid=CjwKCAjwx7GYBhB7EiwA0d8oe_HabROASQAaw7XYRq-VinQLswPqDyh8iPCT4032m8UN7H0B0uNyVBoCZ-QQAvD_BwE</span></a></li>
				<li><em class="italic">Computing Machinery and </em><span class="No-Break"><em class="italic">Intelligence</em></span><span class="No-Break">: </span><a href="https://phil415.pbworks.com/f/TuringComputing.pdf&#13;"><span class="No-Break">https://phil415.pbworks.com/f/TuringComputing.pdf</span></a></li>
				<li><em class="italic">Key requirements for an MLOps </em><span class="No-Break"><em class="italic">foundation</em></span><span class="No-Break">: </span><a href="https://cloud.google.com/blog/products/ai-machine-learning/key-requirements-for-an-mlops-foundation&#13;"><span class="No-Break">https://cloud.google.com/blog/products/ai-machine-learning/key-requirements-for-an-mlops-foundation</span></a></li>
				<li><em class="italic">How does TikTok use machine </em><span class="No-Break"><em class="italic">learning?</em></span><span class="No-Break">: </span><a href="https://dev.to/mage_ai/how-does-tiktok-use-machine-learning-5b7i"><span class="No-Break">https://dev.to/mage_ai/how-does-tiktok-use-machine-learning-5b7i</span></a></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer009">
			</div>
		</div>
	</body></html>