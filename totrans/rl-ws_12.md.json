["```py\n    import tensorflow as tf\n    ```", "```py\n    def funct(x,y):\n        return x**2-8*x+y**2+3*y\n    ```", "```py\n    def initialize():\n        x = tf.Variable(5.0)\n        y = tf.Variable(10.0)\n        return x, y\n    x, y= initialize()\n    ```", "```py\n    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1)\n    ```", "```py\n    for i in range(100):\n        with tf.GradientTape() as tape:\n            # Calculate loss function using x and y values\n            loss= funct(x,y)\n            # Get gradient values\n            gradients = tape.gradient(loss, [x, y])\n            # Save gradients in array without altering them\n            p_gradients = [grad for grad in gradients]\n    ```", "```py\n            ag = zip(p_gradients, [x,y])\n    ```", "```py\n            print('Step={:.1f} , z ={:.1f},x={:.1f},y={:.1f}'\\\n                  .format(i, loss.numpy(), x.numpy(), y.numpy()))\n    ```", "```py\n            optimizer.apply_gradients(ag)\n    ```", "```py\n    import tensorflow as tf\n    import tensorflow_probability as tfp\n    ```", "```py\n    def funct(x,y):\n        return x**2-8*x+y**2+3*y\n    ```", "```py\n    initial_position = (tf.Variable(5.0), tf.Variable(10.0))\n    ```", "```py\n    optimizer1 = tfp.optimizer.differential_evolution_minimize\\\n                 (funct, initial_position = initial_position, \\\n                  population_size = 100, \\\n                  population_stddev = 1.5, seed = 879879)\n    ```", "```py\n    print('Final solution: z={:.1f}, x={:.1f}, y={:.1f}'\\\n          .format(optimizer1.objective_value.numpy(),\\\n          optimizer1.position[0].numpy(), \\\n          optimizer1.position[1].numpy()))\n    ```", "```py\n    Final solution: z=-18.2, x=4.0, y=-1.5\n    ```", "```py\n    import random\n    ```", "```py\n    size = 100\n    initial_population = (tf.random.uniform([size]), \\\n                          tf.random.uniform([size]))\n    ```", "```py\n    optimizer2 = tfp.optimizer.differential_evolution_minimize\\\n                 (funct, initial_population= initial_population,\\\n                  seed=879879)\n    ```", "```py\n    print('Final solution: z={:.1f}, x={:.1f}, y={:.1f}'\\\n          .format(optimizer2.objective_value.numpy(),\\\n          optimizer2.position[0].numpy(),\\\n          optimizer2.position[1].numpy()))\n    ```", "```py\n    Final solution: z=-18.2, x=4.0, y=-1.5\n    ```", "```py\n    population =  np.zeros((no_chromosomes, no_genes))\n    for i in range(no_chromosomes):\n        ones = random.randint(0, no_genes)\n        population[i, 0:ones] = 1\n        np.random.shuffle(population[i])\n```", "```py\nidentical_to_target = population == target\n```", "```py\n    import random\n    import numpy as np\n    ```", "```py\n    # create function for random population\n    def original_population(chromosomes, genes):\n        #initialize the population with zeroes\n        population =  np.zeros((chromosomes, genes))\n        #loop through each chromosome\n        for i in range(chromosomes):\n            #get random no. of ones to be created\n            ones = random.randint(0, genes)\n            #change zeroes to ones\n            population[i, 0:ones] = 1\n            #shuffle rows\n            np.random.shuffle(population[i])\n        return population\n    ```", "```py\n    def create_target_solution(gene):\n        #assume that there is an equal number of ones and zeroes\n        counting_ones = int(gene/2)\n        # build array with equal no. of ones and zeros\n        target = np.zeros(gene)\n        target[0:counting_ones] = 1\n        # shuffle the array to mix zeroes and ones\n        np.random.shuffle(target)\n        return target\n    ```", "```py\n    def fitness_function(target,population):\n        #create an array of true/false compared to the reference\n        identical_to_target = population == target\n        #sum no. of genes that are identical\n        fitness_weights = identical_to_target.sum(axis = 1)\n        return fitness_weights\n    ```", "```py\n    #population of 5 chromosomes, each having 8 genes\n    population = original_population(5,8)\n    target = create_target_solution(8)\n    weights = fitness_function(target,population)\n    ```", "```py\n    print('\\n target:', target)\n    for i in range(len(population)):\n        print('Index:', i, '\\n chromosome:', population[i],\\\n              '\\n similarity to target:', weights[i])\n    ```", "```py\n    target: [0\\. 0\\. 1\\. 1\\. 1\\. 0\\. 0\\. 1.]\n    Index: 0 \n     chromosome: [1\\. 1\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.] \n     similarity to target: 5\n    Index: 1 \n     chromosome: [1\\. 0\\. 1\\. 1\\. 1\\. 0\\. 0\\. 0.] \n     similarity to target: 6\n    Index: 2 \n     chromosome: [1\\. 0\\. 0\\. 0\\. 0\\. 0\\. 0\\. 0.] \n     similarity to target: 3\n    Index: 3 \n     chromosome: [0\\. 0\\. 0\\. 1\\. 1\\. 0\\. 1\\. 0.] \n     similarity to target: 5\n    Index: 4 \n     chromosome: [1\\. 0\\. 0\\. 1\\. 1\\. 1\\. 0\\. 1.] \n     similarity to target: 5\n    ```", "```py\n    import random\n    import numpy as np\n    ```", "```py\n    # create  function for random population\n    def original_population(chromosomes, genes):\n        #initialize the population with zeroes\n        population =  np.zeros((chromosomes, genes))\n        #loop through each chromosome\n        for i in range(chromosomes):\n            #get random no. of ones to be created\n            ones = random.randint(0, genes)\n            #change zeroes to ones\n            population[i, 0:ones] = 1\n            #shuffle rows\n            np.random.shuffle(population[i])\n        return population\n    ```", "```py\n    def create_target_solution(gene):\n        #assume that there is an equal number of ones and zeroes\n        counting_ones = int(gene/2)\n        # build array with equal no. of ones and zeros\n        target = np.zeros(gene)\n        target[0:counting_ones] = 1\n        # shuffle the array to mix zeroes and ones\n        np.random.shuffle(target)\n        return target\n    ```", "```py\n    def fitness_function(target,population):\n        #create an array of true/false compared to the reference\n        identical_to_target = population == target\n        #sum no. of genes that are identical\n        fitness_weights = identical_to_target.sum(axis = 1)\n        return fitness_weights\n    ```", "```py\n    # select the best parents\n    def select_parents(population, weights):\n        #identify the parent with the highest weight\n        parent1 = population[np.argmax(weights)]\n        #replace weight with the minimum number\n        weights[np.argmax(weights)] = 0\n        #identify the parent with the second-highest weight\n        parent2 = population[np.argmax(weights)]\n        return parent1, parent2\n    ```", "```py\n    def choice_by_roulette(sorted_population, fitness):\n        normalised_fitness_sum = 0\n        #get a random draw probability\n        draw = random.uniform(0,1)\n        prob = []\n    ```", "```py\n        for i in range(len(fitness)):\n            normalised_fitness_sum += fitness[i]\n    ```", "```py\n        ma = 0\n        n = 0\n    # calculate the probability of the fitness selection\n        for i in range(len(sorted_population)):\n               probability = fitness[i]/normalised_fitness_sum\n               #compare fitness to the maximum fitness and track it\n               prob_max = fitness[i]/np.argmax(fitness)\n               prob.append(probability)\n                if ma < prob_max:\n                    ma = prob_max\n                    n = i\n    ```", "```py\n          for i in range(len(sorted_population)):\n                if draw <= prob[i]:\n                    fitness[i] = 0\n                    return sorted_population[i], fitness\n                else:\n                    fitness[n] = 0\n                    return sorted_population[n], fitness\n    ```", "```py\n    population = original_population(5,8)\n    target = create_target_solution(8)\n    weights = fitness_function(target,population)\n    print(weights)\n    print('\\n target:', target)\n    ```", "```py\n    [5 1 5 3 4]\n    ```", "```py\n    print('\\n target:', target)\n    parents = select_parents(population,weights)\n    print('Parent 1:', parents[0],'\\nParent 2:', parents[1])\n    print(weights)\n    ```", "```py\n    target: [0\\. 1\\. 1\\. 1\\. 1\\. 0\\. 0\\. 0.]\n    Parent 1: [1\\. 1\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.] \n    Parent 2: [1\\. 1\\. 1\\. 1\\. 1\\. 1\\. 1\\. 0.]\n    [0 1 5 3 4]\n    ```", "```py\n    parent3, weights = choice_by_roulette(population, weights)\n    print('Parent 3:', parent3, 'Weights:', weights)\n    parent4, weights = choice_by_roulette(population, weights)\n    print('Parent 4:', parent4,'Weights:', weights)\n    ```", "```py\n    0.8568696148662779\n    [0.0, 0.07692307692307693, 0.38461538461538464, \n     0.23076923076923078, 0.3076923076923077]\n    Parent 3: [1\\. 1\\. 1\\. 1\\. 1\\. 1\\. 1\\. 0.] Weights: [0 1 0 3 4]\n    0.4710306341255527\n    [0.0, 0.125, 0.0, 0.375, 0.5]\n    Parent 4: [0\\. 0\\. 1\\. 0\\. 1\\. 1\\. 1\\. 0.] Weights: [0 1 0 3 0]\n    ```", "```py\nchild1 = np.hstack((parent1[0:p],parent2[p:]))\nchild2 = np.hstack((parent2[0:p], parent1[p:]))\n```", "```py\ndef crossover_reproduction(parents, population):\n    #define parents separately\n    parent1 = parents[0]\n    parent2 = parents[1]\n    #randomly assign a point for cross-over\n    p = random.randrange(0, len(population))\n    print(\"Crossover point:\", p)\n    #create children by joining the parents at the cross-over point\n    child1 = np.hstack((parent1[0:p],parent2[p:]))\n    child2 = np.hstack((parent2[0:p], parent1[p:]))\n    return child1, child2\n```", "```py\n    import random\n    import numpy as np\n    ```", "```py\n    def original_population(chromosomes, genes):\n        #initialize the population with zeroes\n        population =  np.zeros((chromosomes, genes))\n        #loop through each chromosome\n        for i in range(chromosomes):\n            #get random no. of ones to be created\n            ones = random.randint(0, genes)\n            #change zeroes to ones\n            population[i, 0:ones] = 1\n            #shuffle rows\n            np.random.shuffle(population[i])\n        return population\n    ```", "```py\n    def create_target_solution(gene):\n        #assume that there is an equal number of ones and zeroes\n        counting_ones = int(gene/2)\n        # build array with equal no. of ones and zeros\n        target = np.zeros(gene)\n        target[0:counting_ones] = 1\n        # shuffle the array to mix zeroes and ones\n        np.random.shuffle(target)\n        return target\n    ```", "```py\n    def fitness_function(target,population):\n        #create an array of true/false compared to the reference\n        identical_to_target = population == target\n        #sum no. of genes that are identical\n        fitness_weights = identical_to_target.sum(axis = 1)\n        return fitness_weights\n    ```", "```py\n    # select the best parents\n    def select_parents(population, weights):\n        #identify the parent with the highest weight\n        parent1 = population[np.argmax(weights)]\n        #replace weight with the minimum number\n        weights[np.argmax(weights)] = 0\n        #identify the parent with the second-highest weight\n        parent2 = population[np.argmax(weights)]\n        return parent1, parent2\n    ```", "```py\n    def crossover_reproduction(parents, population):\n        #define parents separately\n        parent1 = parents[0]\n        parent2 = parents[1]\n        #randomly assign a point for cross-over\n        p = random.randrange(0, len(population))\n        print(\"Crossover point:\", p)\n        #create children by joining the parents at the cross-over point\n        child1 = np.hstack((parent1[0:p],parent2[p:]))\n        child2 = np.hstack((parent2[0:p], parent1[p:]))\n        return child1, child2\n    ```", "```py\n    population = original_population(5,8)\n    target = create_target_solution(8)\n    weights = fitness_function(target,population)\n    ```", "```py\n    print('\\n target:', target)\n    ```", "```py\n    target: [1\\. 0\\. 0\\. 1\\. 1\\. 0\\. 1\\. 0.]\n    ```", "```py\n    parents = select_parents(population,weights)\n    print('Parent 1:', parents[0],'\\nParent 2:', parents[1])\n    ```", "```py\n    Parent 1: [1\\. 0\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.] \n    Parent 2: [1\\. 0\\. 0\\. 0\\. 0\\. 0\\. 0\\. 0.]\n    ```", "```py\n    children = crossover_reproduction(parents,population)\n    print('Child 1:', children[0],'\\nChild 2:', children[1])\n    ```", "```py\n    Crossover point: 4 \n    Child 1: [1\\. 0\\. 1\\. 1\\. 0\\. 0\\. 0\\. 0.] \n    Child 2: [1\\. 0\\. 0\\. 0\\. 1\\. 0\\. 1\\. 1.]\n    ```", "```py\n    target: [1\\. 0\\. 1\\. 1\\. 0\\. 0\\. 1\\. 0.]\n    . . .\n    Parent 1: [1\\. 0\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.]\n    Parent 2: [0\\. 0\\. 1\\. 1\\. 0\\. 1\\. 0\\. 0.]\n    . . .\n    Crossover point: 1\n    Child 1: [1\\. 0\\. 1\\. 1\\. 0\\. 1\\. 0\\. 0.]\n    Child 2: [0\\. 0\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.]. . .\n    ```", "```py\n    import random\n    import numpy as np\n    ```", "```py\n    def original_population(chromosomes, genes):\n        #initialize the population with zeroes\n        population =  np.zeros((chromosomes, genes))\n        #loop through each chromosome\n        for i in range(chromosomes):\n            #get random no. of ones to be created\n            ones = random.randint(0, genes)\n            #change zeroes to ones\n            population[i, 0:ones] = 1\n            #shuffle rows\n            np.random.shuffle(population[i])\n        return population\n    ```", "```py\n    def create_target_solution(gene):\n        #assume that there is an equal number of ones and zeroes\n        counting_ones = int(gene/2)\n        # build array with equal no. of ones and zeros\n        target = np.zeros(gene)\n        target[0:counting_ones] = 1\n        # shuffle the array to mix zeroes and ones\n        np.random.shuffle(target)\n        return target\n    ```", "```py\n    def fitness_function(target,population):\n        #create an array of true/false compared to the reference\n        identical_to_target = population == target\n        #sum no. of genes that are identical\n        fitness_weights = identical_to_target.sum(axis = 1)\n        return fitness_weights\n    ```", "```py\n    # select the best parents\n    def select_parents(population, weights):\n        #identify the parent with the highest weight\n        parent1 = population[np.argmax(weights)]\n        #replace weight with the minimum number\n        weights[np.argmax(weights)] = 0\n        #identify the parent with the second-highest weight\n        parent2 = population[np.argmax(weights)]\n        return parent1, parent2\n    ```", "```py\n    def crossover_reproduction(parents, population):\n        #define parents separately\n        parent1 = parents[0]\n        parent2 = parents[1]\n        #randomly assign a point for cross-over\n        p = random.randrange(0, len(population))\n        print(\"Crossover point:\", p)\n        #create children by joining the parents at the cross-over point\n        child1 = np.hstack((parent1[0:p],parent2[p:]))\n        child2 = np.hstack((parent2[0:p], parent1[p:]))\n        return child1, child2\n    ```", "```py\n    def mutate_population(population, mutation_probability):\n        #create array of random mutations that uses the population\n        mutation_array = np.random.random(size = (population.shape))\n        \"\"\"\n        compare elements of the array with the probability and \n        put the results into an array\n        \"\"\"\n        mutation_boolean = mutation_array \\\n                           >= mutation_probability\n        \"\"\"\n        convert boolean into binary and store to create a new \n        array for the population\n        \"\"\"\n        population[mutation_boolean] = np.logical_not\\\n                                       (population[mutation_boolean])\n        return population\n    ```", "```py\n    population = original_population(5,8)\n    target = create_target_solution(8)\n    weights = fitness_function(target,population)\n    parents = select_parents(population,weights)\n    children = crossover_reproduction(parents,population)\n    ```", "```py\n    Crossover point: 3\n    ```", "```py\n    population_crossover = np.append(population, children, axis= 0)\n    print('\\nPopulation after the cross-over:\\n', \\\n          population_crossover)\n    ```", "```py\n    Population after the cross-over:\n     [[0\\. 1\\. 0\\. 0\\. 0\\. 0\\. 1\\. 0.]\n     [0\\. 0\\. 0\\. 0\\. 0\\. 1\\. 0\\. 0.]\n     [1\\. 1\\. 1\\. 1\\. 1\\. 0\\. 0\\. 1.]\n     [1\\. 1\\. 1\\. 0\\. 1\\. 1\\. 1\\. 1.]\n     [0\\. 1\\. 1\\. 1\\. 1\\. 0\\. 0\\. 0.]\n     [1\\. 1\\. 1\\. 1\\. 1\\. 0\\. 0\\. 1.]\n     [1\\. 1\\. 1\\. 0\\. 1\\. 1\\. 1\\. 1.]]\n    ```", "```py\n    mutation_probability = 0.05\n    new_population = mutate_population\\\n                     (population_crossover,mutation_probability)\n    print('\\nNext generation of the population:\\n',\\\n          new_population)\n    ```", "```py\n    Next generation of the population:\n     [[1\\. 0\\. 1\\. 1\\. 1\\. 1\\. 0\\. 1.]\n     [1\\. 0\\. 1\\. 1\\. 1\\. 0\\. 1\\. 1.]\n     [1\\. 0\\. 0\\. 0\\. 0\\. 1\\. 1\\. 0.]\n     [0\\. 0\\. 0\\. 1\\. 0\\. 0\\. 0\\. 0.]\n     [1\\. 0\\. 0\\. 0\\. 1\\. 1\\. 1\\. 1.]\n     [0\\. 0\\. 0\\. 0\\. 0\\. 1\\. 1\\. 0.]\n     [0\\. 0\\. 0\\. 1\\. 0\\. 1\\. 0\\. 1.]]\n    ```", "```py\n    import numpy as np\n    import pandas as pd\n    from sklearn.metrics import mean_squared_error\n    from sklearn.model_selection import train_test_split as split\n    from tensorflow.keras.layers import SimpleRNN, Input, Dense\n    from tensorflow.keras.models import Model\n    from deap import base, creator, tools, algorithms\n    from scipy.stats import bernoulli\n    from bitstring import BitArray\n    ```", "```py\n    np.random.seed(998)\n    ```", "```py\n    #read data from csv\n    data = pd.read_csv('../Dataset/train.csv')\n    #use column wp2\n    data = np.reshape(np.array(data['wp2']), (len(data['wp2']), 1))\n    data = data[0:1500]\n    ```", "```py\n    def format_dataset(data, w_size):\n        #initialize as empty array\n        X, Y = np.empty((0, w_size)), np.empty(0)\n        \"\"\"\n        depending on the window size the data is separated in \n        2 arrays containing each of the sizes\n        \"\"\"\n        for i in range(len(data)-w_size-1):\n            X = np.vstack([X,data[i:(i+w_size),0]])\n            Y = np.append(Y, data[i+w_size,0])\n        X = np.reshape(X,(len(X),w_size,1))\n        Y = np.reshape(Y,(len(Y), 1))\n        return X, Y\n    ```", "```py\n    def training_hyperparameters(ga_optimization):\n        \"\"\"\n        decode GA solution to integer window size and number of units\n        \"\"\"\n        w_size_bit = BitArray(ga_optimization[0:6])\n        n_units_bit = BitArray(ga_optimization[6:])\n        w_size = w_size_bit.uint\n        n_units = n_units_bit.uint\n        print('\\nWindow Size: ', w_size, \\\n              '\\nNumber of units: ',n_units)\n        \"\"\"\n        return fitness score of 100 if the size or the units are 0\n        \"\"\"\n        if w_size == 0 or n_units == 0:\n            return 100\n        \"\"\"\n        segment train data on the window size splitting it into \n        90 train, 10 validation\n        \"\"\"\n        X,Y = format_dataset(data, w_size)\n        X_train, X_validate, Y_train, Y_validate = \\\n        split(X, Y, test_size= 0.10, random_state= 998)\n    ```", "```py\n        input_features = Input(shape=(w_size,1))\n        x = SimpleRNN(n_units,input_shape=(w_size,1))(input_features)\n        output = Dense(1, activation='linear')(x)\n        rnnmodel = Model(inputs=input_features, outputs = output)\n        rnnmodel.compile(optimizer='adam', \\\n                         loss = 'mean_squared_error')\n        rnnmodel.fit(X_train, Y_train, epochs=5, \\\n                     batch_size=4, shuffle = True)\n        Y_predict = rnnmodel.predict(X_validate)\n        # calculate RMSE score as fitness score for GA\n        RMSE = np.sqrt(mean_squared_error(Y_validate, Y_predict))\n        print('Validation RMSE: ', RMSE, '\\n')\n        return RMSE,\n    ```", "```py\n    population_size = 4\n    generations = 5\n    gene = 10\n    ```", "```py\n    creator.create('FitnessMax', base.Fitness, weights= (-1.0,))\n    creator.create('Individual', list, fitness = creator.FitnessMax)\n    toolbox = base.Toolbox()\n    toolbox.register('bernoulli', bernoulli.rvs, 0.5)\n    toolbox.register('chromosome', tools.initRepeat, \\\n                     creator.Individual, toolbox.bernoulli, n = gene)\n    toolbox.register('population', tools.initRepeat, \\\n                     list, toolbox.chromosome)\n    toolbox.register('mate', tools.cxTwoPoint)\n    toolbox.register('mutate', tools.mutFlipBit, indpb = 0.6)\n    toolbox.register('select', tools.selRandom)\n    toolbox.register('evaluate', training_hyperparameters)\n    population = toolbox.population(n = population_size)\n    algo = algorithms.eaSimple(population,toolbox,cxpb=0.4, \\\n                               mutpb=0.1, ngen=generations, \\\n                               verbose=False)\n    ```", "```py\n    Window Size:  48 \n    Number of units:  15\n    Train on 1305 samples\n    Epoch 1/5\n    1305/1305 [==============================] - 3s 2ms/sample \n    - loss: 0.0106\n    Epoch 2/5\n    1305/1305 [==============================] - 3s 2ms/sample \n    - loss: 0.0066\n    Epoch 3/5\n    1305/1305 [==============================] - 3s 2ms/sample \n    - loss: 0.0057\n    Epoch 4/5\n    1305/1305 [==============================] - 3s 2ms/sample \n    - loss: 0.0051\n    Epoch 5/5\n    1305/1305 [==============================] - 3s 2ms/sample \n    - loss: 0.0049\n    Validation RMSE:  0.05564985152918074\n    ```", "```py\n    optimal_chromosome = tools.selBest(population, k = 1)\n    optimal_w_size = None\n    optimal_n_units = None\n    for op in optimal_chromosome:\n        w_size_bit = BitArray(op[0:6])\n        n_units_bit = BitArray(op[6:])\n        optimal_w_size = w_size_bit.uint\n        optimal_n_units = n_units_bit.uint\n        print('\\nOptimal window size:', optimal_w_size, \\\n              '\\n Optimal number of units:', optimal_n_units)\n    ```", "```py\n    Optimal window size: 48 \n    Optimal number of units: 15\n    ```", "```py\n    conda install neat\n    ```", "```py\n    from __future__ import print_function\n    import os\n    import neat\n    ```", "```py\n    xnor_inputs = [(0.0, 0.0), (0.0, 1.0), (1.0, 0.0), (1.0, 1.0)]\n    xnor_output = [(1.0,),(0.0,),(0.0,),(1.0,)]\n    ```", "```py\n     def fitness_function(chromosomes, configuration):\n        for ch_id, chromosome in chromosomes:\n            chromosome.fitness = 4.0\n            neural_net = neat.nn.FeedForwardNetwork.create\\\n                         (chromosome, configuration)\n            for xnor_i,xnor_o in zip(xnor_inputs, xnor_output):\n                output = neural_net.activate(xnor_i)\n                squared_diff = (output[0] - xnor_o[0])**2\n                chromosome.fitness -= squared_diff\n    ```", "```py\n    [NEAT]\n    fitness_criterion    = max\n    fitness_threshold    = 3.9\n    pop_size             = 200\n    reset_on_extinction   = False\n    ```", "```py\n    [DefaultGenome]\n    # activation options of the nodes\n    activation_default      = sigmoid\n    activation_mutate_rate  = 0.01\n    activation_options      = sigmoid\n    # aggregation options for the node\n    aggregation_default    = sum\n    aggregation_mutate_rate = 0.0\n    aggregation_options    = sum\n    ```", "```py\n    # bias options for the node\n    bias_init_mean          = 0.0\n    bias_init_stdev         = 0.05\n    bias_max_value          = 30.0\n    bias_min_value          = -30.0\n    bias_mutate_power       = 0.5\n    bias_mutate_rate        = 0.8\n    bias_replace_rate       = 0.1\n    ```", "```py\n    # compatibility options for the genes in the chromosome\n    compatibility_disjoint_coefficient = 1.0\n    compatibility_weight_coefficient   = 0.5\n    ```", "```py\n    # add/remove rates for connections between nodes\n    conn_add_prob           = 0.5\n    conn_delete_prob        = 0.5\n    # connection enable options\n    enabled_default         = True\n    enabled_mutate_rate     = 0.01\n    feed_forward            = True\n    initial_connection      = full\n    # add/remove rates for nodes\n    node_add_prob           = 0.2\n    node_delete_prob        = 0.2\n    ```", "```py\n    # network parameters\n    num_hidden              = 0\n    num_inputs              = 2\n    num_outputs             = 1\n    # node response options\n    response_init_mean      = 1.0\n    response_init_stdev     = 0.0\n    response_max_value      = 30.0\n    response_min_value      = -30.0\n    response_mutate_power   = 0.0\n    response_mutate_rate    = 0.0\n    response_replace_rate   = 0.0\n    # connection weight options\n    weight_init_mean        = 0.0\n    weight_init_stdev       = 1.0\n    weight_max_value        = 30\n    weight_min_value        = -30\n    weight_mutate_power     = 0.5\n    weight_mutate_rate      = 0.9\n    weight_replace_rate     = 0.15\n    ```", "```py\n    [DefaultSpeciesSet]\n    compatibility_threshold = 3.0\n    [DefaultStagnation]\n    species_fitness_func = max\n    max_stagnation       = 20\n    species_elitism      = 2\n    [DefaultReproduction]\n    Elitism            = 2\n    survival_threshold = 0.2\n    ```", "```py\n    #load configuration\n    configuration = neat.Config(neat.DefaultGenome, \\\n                                neat.DefaultReproduction, \\\n                                neat.DefaultSpeciesSet, \\\n                                neat.DefaultStagnation,\\\n                                \"../Dataset/config-feedforward-xnor\")\n    print(\"Output of file configuration:\", configuration)\n    ```", "```py\n    Output of file configuration: <neat.config.Config object at \n    0x0000017618944AC8>\n    ```", "```py\n    #load the population size\n    pop = neat.Population(configuration)\n    #add output for progress in terminal\n    pop.add_reporter(neat.StdOutReporter(True))\n    statistics = neat.StatisticsReporter()\n    pop.add_reporter(statistics)\n    pop.add_reporter(neat.Checkpointer(5))\n    ```", "```py\n    #run for 200 generations using\n    best = pop.run(fitness_function, 200)\n    #display the best chromosome\n    print('\\n Best chromosome:\\n{!s}'.format(best))\n    ```", "```py\n    ****** Running generation 0 ****** \n    Population's average fitness: 2.45675 stdev: 0.36807\n    Best fitness: 2.99412 - size: (1, 2) - species 1 - id 28\n    Average adjusted fitness: 0.585\n    Mean genetic distance 0.949, standard deviation 0.386\n    Population of 200 members in 1 species:\n       ID   age  size  fitness  adj fit  stag\n      ====  ===  ====  =======  =======  ====\n         1    0   200      3.0    0.585     0\n    Total extinctions: 0\n    Generation time: 0.030 sec\n     ****** Running generation 1 ****** \n    Population's average fitness: 2.42136 stdev: 0.28774\n    Best fitness: 2.99412 - size: (1, 2) - species 1 - id 28\n    Average adjusted fitness: 0.589\n    Mean genetic distance 1.074, standard deviation 0.462\n    Population of 200 members in 1 species:\n       ID   age  size  fitness  adj fit  stag\n      ====  ===  ====  =======  =======  ====\n         1    1   200      3.0    0.589     1\n    Total extinctions: 0\n    Generation time: 0.032 sec (0.031 average)\n    ```", "```py\n    #show output of the most fit chromosome against the data\n    print('\\n Output:')\n    best_network = neat.nn.FeedForwardNetwork.create\\\n                   (best, configuration)\n    for xnor_i, xnor_o in zip(xnor_inputs, xnor_output):\n        output = best_network.activate(xnor_i)\n        print(\"input{!r}, expected output {!r}, got: {:.1f}\"\\\n              .format(xnor_i,xnor_o,output[0]))\n    ```", "```py\n    Output:\n    input(0.0, 0.0), expected output (1.0,), got: 0.9\n    input(0.0, 1.0), expected output (0.0,), got: 0.0\n    input(1.0, 0.0), expected output (0.0,), got: 0.2\n    input(1.0, 1.0), expected output (1.0,), got: 0.9\n    ```", "```py\n    ****** Running generation 41 ******\n    Population's average fitness: 2.50036 stdev: 0.52561\n    Best fitness: 3.97351 - size: (8, 16) - species 2 - id 8095\n    Best individual in generation 41 meets fitness threshold \\\n    - complexity: (8, 16)\n    Best chromosome:\n    Key: 8095\n    Fitness: 3.9735119749933214\n    Nodes:\n        0 DefaultNodeGene(key=0, bias=-0.02623087593563278, \\\n                          response=1.0, activation=sigmoid, \\\n                          aggregation=sum)\n        107 DefaultNodeGene(key=107, bias=-1.5209385195946818, \\\n                            response=1.0, activation=sigmoid, \\\n                            aggregation=sum)[…]\n\n    Connections:\n        DefaultConnectionGene(key=(-2, 107), \\\n                              weight=1.8280370376000628, \\\n                              enabled=True)\n        DefaultConnectionGene(key=(-2, 128), \\\n                              weight=0.08641968818530771, \\\n                              enabled=True)\n        DefaultConnectionGene(key=(-2, 321), \\\n                              weight=1.2366021868005421, \\\n                              enabled=True)[…]\n    ```", "```py\n    import gym \n    import numpy as np \n    import math \n    import tensorflow as tf\n    from matplotlib import pyplot as plt\n    from random import randint\n    from statistics import median, mean\n    ```", "```py\n    Generation:1, max reward:11.0\n    Generation:2, max reward:11.0\n    Generation:3, max reward:10.0\n    Generation:4, max reward:10.0\n    Generation:5, max reward:11.0\n    Generation:6, max reward:10.0\n    Generation:7, max reward:10.0\n    Generation:8, max reward:10.0\n    Generation:9, max reward:11.0\n    Generation:10, max reward:10.0\n    Generation:11, max reward:10.0\n    Generation:12, max reward:10.0\n    Generation:13, max reward:10.0\n    Generation:14, max reward:10.0\n    Generation:15, max reward:10.0\n    Generation:16, max reward:10.0\n    Generation:17, max reward:10.0\n    Generation:18, max reward:10.0\n    Generation:19, max reward:11.0\n    Generation:20, max reward:11.0\n    ```", "```py\nTrial:486, total reward:8.0\nTrial:487, total reward:9.0\nTrial:488, total reward:10.0\nTrial:489, total reward:10.0\nTrial:490, total reward:8.0\nTrial:491, total reward:9.0\nTrial:492, total reward:9.0\nTrial:493, total reward:10.0\nTrial:494, total reward:10.0\nTrial:495, total reward:9.0\nTrial:496, total reward:10.0\nTrial:497, total reward:9.0\nTrial:498, total reward:10.0\nTrial:499, total reward:9.0\nAverage reward: 9.384\n```"]