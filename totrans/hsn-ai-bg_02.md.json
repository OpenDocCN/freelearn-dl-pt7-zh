["```py\nimport numpy as np\n## Element-wise multiplication without utilizing linear algebra techniques\n\nx = [1,2,3]\ny = [4,5,6]\n\nproduct = []\nfor i in range(len(x)):\n    product.append(x[i]*y[i])\n\n## Element-wise multiplication utilizing linear algebra techniques\n\nx = np.array([1,2,3])\ny = np.array([4,5,6])\nx * y\n```", "```py\nmy_scalar = 5\nmy_scalar = 5.098\n```", "```py\nmy_vector = np.array([5,6])\n```", "```py\nmatrix = np.array([[5,6], [6,9]])\n```", "```py\ntensor = [[[1,2,3,4]],[[2,5,6,3]],[[7,6,3,4]]] ...\n```", "```py\nvector = np.array([[1,2], [1,2]])new_vector = vector + 2\n```", "```py\nvector_one = np.array([[1,2],[3,4]])\nvector_two = np.array([[5,6],[7,8]])\n    a + b\n    ## You should see:\n        array([[ 6, 8],[10, 12]])\n        array([[ 6, 8],[10, 12]])\n     a - b\n     ## You should see:\n         array([[-4, -4], [-4, -4]])\n```", "```py\n## Dot Product\nvector_one = np.array([1,2,3])\nvector_two = np.array([2,3,4])\nnp.dot(vector_one,vector_two) ## This should give us 20\n```", "```py\nvector_one = np.array([1,2,3])\nvector_two = np.array([2,3,4])\nvector_one * vector_two\n## You should see:\narray([ 2,  6, 12])\n```", "```py\n.p_diseasePos = 0.8 ## Chance of having the disease given a positive result\np_diseaseNeg = 0.2 ## Chance of having the disease given a negative result\np_noPos = 0.096\np_noNeg = 0.904\np_FalsePos = (.80 * .01) + (.096 * .99)\np_disease_given_pos = (.80 * .01) / p_FalsePos\nprint(p_disease_given_pos)\n```", "```py\nimport pandas as pd\ndata = pd.read_csv(\"iris.csv\")\ndata.head()\n```", "```py\nfeatures = (features - features.mean()) / features.std()\n\ncorr_matrix = np.corrcoef(data.values.T)\ncorr_matrix.corr()\n```", "```py\neigen_values, eigen_vectors = np.linalg.eig(corr_matrix)\n```", "```py\n\neigenpairs = [[eigen_values[i], eigen_vectors[:,i]] for i in range(len(eigen_vectors))]\n\neigenpairs.sort(reverse=True)\n```", "```py\nprojection = np.hstack((eigenpairs[0][1].reshape(eig_vectors.shape[1],1),\n                                  eigenpairs[1][1].reshape(eig_vectors.shape[1],1)))\n```", "```py\ntransform = features.dot(projection)\n```", "```py\nfig = plt.figure(figsize=(8,8))\n\nax = fig.gca()\nax = sns.regplot(transform.iloc[:,0], transform.iloc[:,1],fit_reg=False, scatter_kws={'s':70}, ax=ax)\n\nax.set_xlabel('principal component 1', fontsize=10)\nax.set_ylabel('principal component 2', fontsize=10)\n\nfor tick in ax.xaxis.get_major_ticks():\n    tick.label.set_fontsize(12) \n\nfor tick in ax.yaxis.get_major_ticks():\n    tick.label.set_fontsize(12) \n\nax.set_title('Pricipal Component 1 vs Principal Component 2\\n', fontsize=15)\n\nplt.show()\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {\n 'n_estimators': [100, 500, 1000],\n 'max_features': [2, 3, 4],\n 'max_depth': [90, 100, 110, 120],\n 'min_samples_split': [6, 10, 14],\n 'min_samples_leaf': [2, 4, 6], \n}\n```", "```py\nsearch = GridSearchCV(estimator = rf_classifier, param_grid = parameters, cv = 3)\n```", "```py\nsearch.fit(x_train, y_train)\nsearch.best_params_\n```", "```py\nbest = search.best_estimator_\naccuracy = evaluate(best, x_test, y_test)\n```"]