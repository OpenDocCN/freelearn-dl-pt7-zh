- en: What's Next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We did it! We have created six different neural network projects, each with
    their own unique architecture. In this final chapter, let's recap on what we have
    accomplished. We will also look at some of the recent advancements in neural networks
    and deep learning that were not covered in previous chapters. Finally, we will
    peer ahead and see what the future holds for neural networks and AI in general.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, these are the topics that we''ll cover in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A recap of the different neural networks that we used in this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A recap of key neural network concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cutting edge advancements in neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The limitations of neural networks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The future of AI and machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping up with machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Favorite machine learning tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What will you create?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have accomplished a lot in this book. Let's do a quick recap of the projects
    that we have built in each chapter, as well as the neural network architecture
    enabling them. This section also serves as a quick refresher for the key neural
    network concepts that we have covered in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning and Neural Networks 101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](1068b86b-d786-48ba-b91c-35d0ff569460.xhtml), *Machine Learning
    and Neural Networks 101,* we started off by building the simplest, one-layer neural
    network, known as the **perceptron**. At its core, the perceptron is simply a
    mathematical function that takes in a set of input, performs some mathematical
    computation, and outputs the result of the computation. For the perceptron, the
    mathematical computation is simply the multiplication of the weights with the
    inputs.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the right set of weights dictates how well our neural network performs.
    At the start, the weights of the neural network are initialized randomly. The
    process of tuning the weights of our neural network to maximize model performance
    is called **model training**. During training, the weights of the neural network
    are continuously tuned to minimize the **loss function**. The loss function is
    simply a mathematical function that allows us to quantify how well our neural
    networks are doing. The algorithm that we use to adjust our weights to minimize
    the loss function is known as **gradient descent**.
  prefs: []
  type: TYPE_NORMAL
- en: We created our very first neural network from scratch, without using machine
    learning libraries such as Keras or scikit-learn. We applied our simple neural
    network on a toy example, where the neural network had to learn binary (that is,
    1 or 0) predictions. We used a sum-of-squares error as the loss function to train
    our neural network, where the error is 1 if the prediction is wrong and the error
    is 0 if the prediction is correct. We then summed up the error across each individual
    point, giving us the sum-of-squares error. We saw that our neural network was
    able to learn from the training examples, producing accurate predictions for the
    testing data.
  prefs: []
  type: TYPE_NORMAL
- en: Having understood the concepts of a neural network, we then discussed the most
    important libraries in Python for neural networks and machine learning in general.
    We saw how pandas is essential when we are working with tabular data (that is,
    from CSV files) and how it can also be used for data visualization. More importantly,
    we talked about Keras, the essential library in Python for working with neural
    networks and deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about the fundamental building blocks in Keras, which are the `layers`.
    There are several types of `layers` in Keras, but the most important ones are
    the `convolutional` and `dense` layers, which are the building blocks of all neural
    networks that we covered in the book.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting Diabetes with Multilayer Perceptrons
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml), *Predicting Diabetes
    with Multilayer Perceptrons,* we kicked off our first project by creating a neural
    network that can predict whether a patient is at risk of diabetes. Specifically,
    we used a neural network known as the MLP to perform this classification prediction.
    We used the Pima Indians Diabetes dataset for this problem. The dataset consists
    of 768 different data points, with eight measurements (that is, features) and
    one label for each data point.
  prefs: []
  type: TYPE_NORMAL
- en: As part of the machine learning workflow,we had to do data preprocessing before
    using this dataset with our neural network. We had to impute missing values, perform
    data standardization, and split our dataset into a training and testing dataset.
  prefs: []
  type: TYPE_NORMAL
- en: We also built our very first neural network using Keras in this chapter. We
    saw how we can use the `Sequential` class in Keras to construct a neural network
    layer by layer, just like stacking Lego blocks on top of one another. We also
    looked at the **ReLU** and **sigmoid activation** functions, which are the two
    commonly used activation functions.
  prefs: []
  type: TYPE_NORMAL
- en: We evaluated the performance of our neural network by using metrics such as
    the **confusion matrix** and the **ROC curve**, which are important tools to help
    us understand the performance of our neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Predicting Taxi Fares with Deep Feedforward Nets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 3](bf157365-e4d3-42ae-89f4-58c9047e6500.xhtml), *Predicting Taxi
    Fares with Deep Feedforward Nets*, we used a **deep feedforward neural network**
    in a **regression** **prediction** problem, where the task was to predict the
    dollar amount of a NYC taxi fare, based on features such as pick-up and drop-off
    locations. In this project, we had to work with a noisy dataset that included
    missing data and data anomalies. We saw how data visualization is essential to
    help us identify outliers in the dataset, and to discover important trends in
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: This project was also the first project where feature engineering was done.
    Using the existing features, we created other features that improved the accuracy
    of our neural network. Finally, we created and trained a deep feedforward neural
    network in Keras by using our dataset, which produced an impressive mean square
    error of 3.50.
  prefs: []
  type: TYPE_NORMAL
- en: Cats Versus Dogs – Image Classification Using CNNs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus Dogs –
    Image Classification Using CNNs*, we started our first neural network project
    in the domain of image recognition and computer vision. Specifically, we created
    a CNN that is able to classify images of cats and dogs.
  prefs: []
  type: TYPE_NORMAL
- en: We saw how digital images are essentially two-dimensional arrays (for grayscale
    images), with each array value representing the intensity of each pixel. CNNs are
    the go-to neural network architecture for most image recognition problems. The
    **filtering** and **convolution** operation in the CNN is used to identify important
    spatial features in the images, which makes it suitable for image recognition
    problems. CNNs have gone through several iterations and improvements over the
    years. LeNet first came to the scene in 1998, before more sophisticated neural
    networks such as the VGG16 and ResNet were developed in the 2010s.
  prefs: []
  type: TYPE_NORMAL
- en: We created our own CNN in Keras, and we used Keras's `ImageDataGenerator` and
    the `flow_from_directory` method to train a neural network when the dataset (images
    of cats and dogs) was too large to fit into memory in one go. The simple CNN that
    we created achieved an accuracy of 80%. We also used **transfer learning **to
    leverage on a pre-trained VGG16 neural network for the cats-and-dogs classification
    problem. This method showed the sophistication of the VGG16 model, achieving an accuracy
    of 90%.
  prefs: []
  type: TYPE_NORMAL
- en: Removing Noise from Images Using Autoencoders
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 5](16d0775b-23ec-456a-a57b-cba2e9da7570.xhtml), *Removing Noise
    from Images Using Autoencoders*, we looked at **autoencoders**, a special class
    of neural networks that learns a **latent representation** of the input. Autoencoders
    have an **encoder** component that compresses the input into a latent representation,
    and a **decoder** component that reconstructs the input using the latent representation.
  prefs: []
  type: TYPE_NORMAL
- en: In an autoencoder, the size of the hidden layer that's used for the latent representation
    is an important hyperparameter that needs to be tuned carefully. The size of the
    latent representation should be sufficiently small enough to represent a compressed
    representation of the input features, and also sufficiently *large* enough for
    the decoder to reconstruct the input without too much loss. We trained an autoencoder
    to compress MNIST images. We showed that by using a hidden layer size of 32 ×
    1, and we achieved a compression rate of 24.5, while ensuring that the reproduced
    images were similar to the original input images.
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at using autoencoders for **image** **denoising**. By using a
    noisy image as the input and a clean image as the output, we can train an autoencoder
    to identify features of the image that do not belong to noise. Thus, we can apply
    the autoencoder to remove noise from images. Such autoencoders are known as **denoising
    autoencoders**. We trained and applied a denoising autoencoder to the noisy office
    documents dataset, which consists of scanned images of dirty office documents.
    Using deep convolutional layers within the denoising autoencoder, we managed to
    remove noise almost entirely from the office documents.
  prefs: []
  type: TYPE_NORMAL
- en: Sentiment Analysis of Movie Reviews Using LSTM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 6](21ef7df7-5976-4e0d-bec5-d736ec571d94.xhtml), *Sentiment Analysis
    of Movie Reviews Using LSTM*, we looked at sentiment analysis, which is a sequential
    problem in the domain of **Natural Language Processing** (**NLP**).We saw that
    sentiment analysis is a challenging problem even for humans, because words convey
    different meanings in different contexts. RNNs are thought to be the best form
    of neural networks for tackling sequential problems such as sentiment analysis.
    However, conventional recurrent neural networks suffer from a long-term dependency
    problem, which makes it unsuitable for lengthy bodies of text.
  prefs: []
  type: TYPE_NORMAL
- en: A variation of recurrent neural networks, known as the LSTM network, was designed
    to overcome the long-term dependency problem. The intuition behind LSTMs is that
    because of its ability to assign weights to certain words, we can selectively
    forget words that are less important and remember words that are more important.
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at how we can represent words as vectors using word embeddings.
    Word embeddings transform words into a lower-dimensional feature space, placing
    words that are similar near to one another, while words that are dissimilar are
    placed further away.
  prefs: []
  type: TYPE_NORMAL
- en: We created and trained an LSTM network in Keras for sentiment analysis on the
    IMDB movie reviews dataset, and we looked at some of the important hyperparameters
    to tune while training an LSTM net. In particular, we saw how the optimizer makes
    a significant difference in the performance of the LSTM network. Our final LSTM
    network achieves 85% accuracy in classifying the sentiment of IMDB movie reviews.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing a Facial Recognition System with Neural Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 7](9223bc03-bd68-42df-93ff-32c5d0f7e246.xhtml), *Implementing a
    Facial Recognition System with Neural Networks*, we created a facial recognition
    system using Siamese neural networks. Siamese neural networks are a special class
    of neural networks, with a shared, conjoined component. Siamese neural networks
    accept a pair of images as input, and can be trained to output a distance that
    is inversely proportional to the similarity of the two images. This forms the
    idea behind using Siamese neural networks for facial recognition. If the two faces
    in the input pair of images belong to the same subject, then the distance output
    should be small, and vice versa. By training a Siamese neural network on positive
    pairs (faces that belong to the same subject) and negative pairs (faces that belong
    to different subjects), using contrastive loss, it will eventually learn to output
    an appropriate distance for positive and negative pairs.
  prefs: []
  type: TYPE_NORMAL
- en: We also looked at face detection, which is an important precursor to facial
    recognition. Face detection is used to isolate and extract faces from raw images,
    which is then passed to our neural network for face recognition. Face detection
    is commonly done using the Viola-Jones algorithm, which uses Haar features to
    detect facial features in images. To create our facial recognition system, we
    combined OpenCV, which uses the video stream from a computer's webcam for face
    detection, and the Siamese neural network that we trained for face recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Cutting edge advancements in neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in the previous section, we covered a lot of material in this book.
    However, the possibilities of neural networks are truly boundless. There are other
    important types of neural networks that we have not yet discussed in this book.
    For completeness, we shall discuss them in this section. As you shall see, these
    neural networks are very different than what we have seen so far, and it should
    provide you with a new perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Generative adversarial networks** (**GANs**) are a class of generative neural
    networks. To understand generative models, it''s important to contrast them against
    discriminativemodels. So far in this book, we have focused only on discriminative
    models. Discriminative models are concerned with learning the mapping of features
    to a label. For example, when we created a CNN to classify images of cats and
    dogs, the CNN is a discriminative model that learns the mapping of features (images)
    to a label (a cat or a dog).'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, generative models are concerned with generating appropriate
    features, given the label. For example, given labeled images of cats and dogs,
    a generative model would learn to create the appropriate features for each label.
    In other words, a generative model learns to synthesize images of cats and dogs!
  prefs: []
  type: TYPE_NORMAL
- en: GANs are one of the most exciting developments in AI in recent years. In fact,
    Yann LeCun called GANs *the most interesting idea in machine learning in the past
    10 years.* So, how do GANs work? Intuitively, GANs consist of two components—the
    generator and the discriminator. The role of the generator is to generate features
    (such as images), and the role of the discriminator is to evaluate how well the
    generated features represent the original features. When we train the GAN, we
    pit the generator against the discriminator (hence the term *adversarial* in GAN).
    Eventually, the generator will become so good that the discriminator can no longer
    differentiate the generated features from the original features and the GAN can
    now generate lifelike images.
  prefs: []
  type: TYPE_NORMAL
- en: 'To have a sense of how good GANs have become, check out the following paper,
    which was released by researchers from NVIDIA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org/pdf/1812.04948.pdf](https://arxiv.org/pdf/1812.04948.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Within the paper, you'll see some samples of faces generated by GANs that are
    indistinguishable from real human faces. GANs have improved at such a frightening
    pace that we can now generate hyper-realistic human faces.
  prefs: []
  type: TYPE_NORMAL
- en: GANs have been applied to several interesting use cases. For example, researchers
    have found a way to use GANs in style transfer. In style transfer, GANs learn
    the artistic style of a given image, and apply it to another image. For example,
    we can use GANs to learn the artistic style of Vincent van Gough's famous *The
    Starry Night* painting, and apply it to any arbitrary image. Check out the GitHub
    repository at [https://github.com/jcjohnson/neural-style](https://github.com/jcjohnson/neural-style) for
    examples of style transfer.
  prefs: []
  type: TYPE_NORMAL
- en: Deep reinforcement learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reinforcement learning is a branch of machine learning that learns the best
    action to take in any given state to maximize future rewards. Reinforcement learning
    has been applied to games such as chess. In chess, the position of the pieces
    on the chessboard represents the state that we are in. The role of reinforcement
    learning in this case is to learn the best action to take (that is, the pieces
    to move) in any given state.
  prefs: []
  type: TYPE_NORMAL
- en: If we think of the best action to take in any arbitrary state being represented
    by a mathematical function (call it the action-value function), then we can use
    neural networks to learn this action-value function. Once the function has been
    learned, our neural network can be used to predict the best action to take in
    any given state—essentially, our neural network becomes an unbeatable chess player!
    The application of deep neural networks to reinforcement learning is known as
    deep reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: Deep reinforcement learning has found much success in game-playing. In 2017,
    AlphaGo, an AI game-playing agent trained using deep reinforcement learning, managed
    to beat Ke Jie, one of the best Go players in the world. AlphaGo's victory sparked
    much fanfare and discussion over the future of AI.
  prefs: []
  type: TYPE_NORMAL
- en: In 2018, deep reinforcement learning took another leap when OpenAI Five (a team
    of five neural networks) managed to beat amateur human players at Dota 2\. Dota
    2 is a multiplayer online game once thought to be beyond the realm of AI, due
    to the immense complexity and dynamism of the game. Professional Dota 2 players
    are celebrities in their own right, with legions of fans admiring the speed of
    thought and lighting-fast reactions possessed by the best Dota 2 players in the
    world. Today, OpenAI Five continuously pushes the boundary of what it can do in
    Dota 2\. OpenAI Five trains itself by playing 180 years' worth of games against
    itself every day. OpenAI Five views the the state of the game as an array of 20,000
    numbers, and from there, it decides on the best action to take.
  prefs: []
  type: TYPE_NORMAL
- en: 'To learn more about OpenAI Five, as well as to try out an interactive demo,
    do visit OpenAI''s website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://blog.openai.com/openai-five/](https://blog.openai.com/openai-five/)'
  prefs: []
  type: TYPE_NORMAL
- en: Beyond game-playing, deep reinforcement learning has made important contributions
    to autonomous vehicles as well. Autonomous vehicles abstract the world around
    them using computer vision algorithms. This abstraction represents the state that
    the vehicle is in. From there, deep reinforcement learning selects the best action
    to take (for example, accelerate, brake), according to its state.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of neural networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The possibilities of a neural network may seem boundless, but there are in fact
    limitations as to what neural networks and machine learning in general can achieve.
  prefs: []
  type: TYPE_NORMAL
- en: First of all, neural networks have poor interpretability. In other words, neural
    networks often function as black-box algorithms, and it is difficult to *interpret*
    the results produced by a neural network. Take for example our project in [Chapter
    2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml), *Predicting Diabetes with Multilayer
    Perceptrons*, where we used a neural network to predict patients at risk of developing
    diabetes. The neural network takes in input, such as blood glucose level, blood
    pressure, age, and so on, and outputs a prediction of whether the patient is at
    risk of developing diabetes. Even though the neural network is able to make such
    a prediction with high accuracy, we do not actually know what are the factors
    that influence the predictions. This may be insufficient for a doctor, who may
    wish to create an intervention plan for the patient.
  prefs: []
  type: TYPE_NORMAL
- en: When applied in a real-world setting, this lack of interpretability is a real
    concern for business users, who may be uncomfortable with deploying a black-box
    algorithm. Beyond model performance, business users would also like to know why
    the model works, and what factors influence a target variable that the business
    is concerned with.
  prefs: []
  type: TYPE_NORMAL
- en: Improving the interpretability of neural networks is one of the areas that researchers
    are working on. In particular, researchers are working on producing interpretable
    results when deep neural networks are applied to computer vision problems. To
    that end, some researchers have proposed to reduce the convolutional layers of
    a CNN to a graphical model, which represents the semantic hierarchy hidden inside
    the neural network.
  prefs: []
  type: TYPE_NORMAL
- en: The second limitation of neural networks is that they can be easily fooled when
    applied to image recognition. In [Chapter 4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats
    Versus Dogs – Image Classification Using CNNs*, we achieved a high accuracy (90%)
    when CNNs were used to classify images of cats and dogs. While CNNs are considered
    state-of-the-art for image recognition, their Achilles' heel is that they can
    be easily fooled by a malicious agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'A recent study by Nguyen and others showed that because neural networks perceive
    images differently than humans, an image that is completely unrecognizable to
    humans can be used to fool neural networks, leading neural networks to produce
    erroneous predictions. For examples of these synthetic images that are unrecognizable
    to humans, but can be used to fool neural networks, check out the paper from Nguyen
    and others:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org/pdf/1412.1897.pdf](https://arxiv.org/pdf/1412.1897.pdf)'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, researchers showed that by combining these synthetic images with
    an existing image in an imperceptible way to humans, neural networks can be fooled
    to produce a wrong prediction.
  prefs: []
  type: TYPE_NORMAL
- en: This finding has a significant impact on the feasibility of using neural networks
    in computer vision based security systems. A malicious agent could possibly provide
    a carefully handcrafted input image to the neural network, fooling it, and bypassing
    the security system.
  prefs: []
  type: TYPE_NORMAL
- en: It is clear that neural networks are far from perfect, and they are certainly
    not the magic solution to all our problems. However, there are reasons to be optimistic,
    as new breakthroughs are constantly being discovered every day that improve our
    understanding of neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: The future of artificial intelligence and machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Next, let''s discuss the future of AI and machine learning in general. In my
    opinion, we will see the rise of the following key developments over the next
    few decades:'
  prefs: []
  type: TYPE_NORMAL
- en: Artificial general intelligence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Artificial general intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Artificial general intelligence** (**AGI**) is defined as *an artificial
    intelligence agent with the ability to perform any intellectual task that a human
    being can*. Some researchers have made the distinction of weak AI versus strong
    AI, with weak AI being used to describe the level of AI today. AI agents today
    are mostly concerned with performing a single task. For example, we train AI agents
    to predict whether a patient is at risk of diabetes, and another AI agent to classify
    images of cats and dogs. These AI agents are separate entities, and an AI agent
    that is trained to perform a certain task cannot be used to perform other tasks.
    This narrow view of AI is termed weak AI.'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other hand, strong AI refers to generalized AI agents that can perform
    any task. A strong AI agent could be something like a self-conscious, human-like
    AI assistant. At the moment, strong AI belongs to the realm of science fiction.
    In my opinion, the current machine learning algorithms at our disposal (for example,
    neural networks, decision trees) will not be sufficient to achieve AGI. In the
    words of Francois Chollet (the developer of Keras):'
  prefs: []
  type: TYPE_NORMAL
- en: '*"You cannot achieve general intelligence simply by scaling up today''s deep
    learning techniques."'
  prefs: []
  type: TYPE_NORMAL
- en: - Francois Chollet*
  prefs: []
  type: TYPE_NORMAL
- en: It will take a significant breakthrough to attain AGI—the kind of breakthrough
    that once saw neural networks and deep learning define the *weak AI* that we know
    today.
  prefs: []
  type: TYPE_NORMAL
- en: Automated machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though a data scientist has been termed *the sexiest job of the 21st century*,
    the reality is that most data scientists spend a disproportionate amount of time
    on time-consuming tasks such as data preprocessing and hyperparameter tuning.
    To address this issue, companies such as Google are developing tools to automate
    the machine learning process. Google has recently launched **AutoML**, a solution
    that uses neural nets to design neural nets. Google believes that AutoML can package
    the expertise that is currently possessed by data scientists and provide that
    expertise on demand as a service on the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, some data scientists have taken offense at the thought that they
    could one day be replaced by AI, and they claim that automated machine learning
    would never become a reality. My personal opinion is that the truth is somewhere
    in-between. Today, there are already libraries in Python that can help us automate
    some of the more time-consuming tasks, such as hyperparameter tuning. Such libraries
    can brute-force their way through a range of hyperparameters, selecting the set
    of hyperparameters that maximizes our results. There are even libraries in Python
    that can visualize a dataset automatically, plotting the most relevant graphs
    automatically. As such libraries become more mainstream, I believe that data scientists
    will spend less time on such time-consuming activities, and more time on other
    impactful tasks, such as model design and feature engineering.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping up with machine learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The field of machine learning and AI is constantly evolving, and new knowledge
    is constantly being discovered. How do we keep ourselves updated in this ever-changing
    field? Personally, I keep myself updated by reading books, scientific journals,
    and practicing on real datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Books
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fact that you are reading this book shows that you are committed to improving
    your knowledge! Unfortunately, we cannot cover every single topic of machine learning
    in this book. If you enjoyed this book, you may wish to refer to the catalog of
    books that Packt has. You will find that Packt has books on nearly every single
    topic in machine learning. The Packt team also ensures that the reader stays up
    to date with the latest developments by continuously publishing books on the latest
    technologies in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Packt's catalog can be found at [https://www.packtpub.com/all](https://www.packtpub.com/all).
  prefs: []
  type: TYPE_NORMAL
- en: Scientific journals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AI researchers have always believed in openness. They believe that knowledge
    should be freely shared and that the best way to grow as a community is by sharing.
    Therefore, most of the cutting-edge scientific papers in AI and machine learning
    can be found freely online. In particular, most AI researchers share their findings
    on the following website:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://arxiv.org](https://arxiv.org)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Arxiv** is an open-access depository for scientific journals. Most of the
    cutting-edge findings are shared freely on arxiv as soon as they are available.
    This results in rapid development, with ideas being built on top of one another
    iteratively.'
  prefs: []
  type: TYPE_NORMAL
- en: Practicing on real-world datasets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Lastly, as machine learning practitioners, it is important to keep our skills
    sharp by practicing often. **Kaggle** is a website that hosts data science competitions
    by using real-world datasets. There are different levels of competitions, so beginners
    and experts can find something suitable for their level of ability. The type of
    dataset also varies from tabular data, images (computer vision problems), and
    text (NLP problems).
  prefs: []
  type: TYPE_NORMAL
- en: Kernels are perhaps one of the most useful features of Kaggle. Through Kaggle
    kernels, users can share their code and methods openly. This ensures reproducible
    results, and, often, you will learn a technique that you did not know about. Kaggle
    also provides a free cloud environment to run your code, including GPU support.
    If you would like to put your skills to the test, after reading this book Kaggle
    is a great place to start.
  prefs: []
  type: TYPE_NORMAL
- en: Favorite machine learning tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this book, I have used a lot of Python and Keras. Beyond that, there are
    also several machine learning tools that I consider to be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Jupyter Notebook**:Jupyter notebooks are interactive notebooks that are often
    used during the early stages of machine learning projects. The advantage of using
    Jupyter Notebooks is that it allows us to write interactive code iteratively.
    Unlike a `.py` Python file, code can be executed in chunks, and output (for example,
    graphs) can be displayed in line with the code.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Google Colab**:Google Colab is a free cloud platform that allows us to write
    Jupyter Notebook code in the cloud. All changes are synced automatically, and
    teams can work collaboratively on the same notebook. The greatest advantage of
    Google Colab is that you can run code with GPU instances in the cloud, which are
    provided for free by Google! This means that we can train a deep neural network
    efficiently from anywhere in the world, even if we do not own a powerful GPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we did a quick recap of all the different neural networks and
    key concepts that were covered in this book. We then looked at some cutting-edge
    developments in neural networks, including generative adversarial networks and
    deep reinforcement learning. Even though the potential of neural networks may
    seem boundless at times, it is important for us to remember that there are limitations
    to what the current state of neural networks can accomplish. Next, we surveyed
    the landscape of machine learning and AI in general, and we saw what AI could
    look like in the near future. We also offered some tips to readers on keeping
    up with the constantly evolving field of machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, I would like to conclude this book by asking the following question—what
    will you create? We live in an age of highly advanced technology, where access
    to information is freely available. Whatever your current level, whether you are
    a seasoned machine learning veteran or a beginner in this field, you have all
    the resources that you need to succeed. I would like to encourage you to always
    be curious, and to always have a thirst for knowledge. Many of the discoveries
    in this field came from curious people like you and me. We can all contribute.
    What will you create?
  prefs: []
  type: TYPE_NORMAL
