<html><head></head><body>
		<div id="_idContainer004">
			<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/>Preface</h1>
			<p>So, you want to work with foundation models? That is an excellent place to begin! Many of us in the machine learning community have followed these curious creatures for years, from their earliest onset in the first days of the Transformer models, to their expansion in computer vision, to the near ubiquitous presence of text generation and interactive dialogue we see in the <span class="No-Break">world today.</span></p>
			<p>But where do foundation models come from? How do they work? What makes them tick, and when should you pretrain and fine-tune them? How can you eke out performance gains on your datasets and applications? How many accelerators do you need? What does an end-to-end application look like, and how can you use foundation models to master this new surge of interest in <span class="No-Break">generative AI?</span></p>
			<p>These pages hope to provide answers to these very important questions. As you are no doubt aware, the pace of innovation in this space is truly breathtaking, with more foundation models coming online every day from both open-source and proprietary model vendors. To grapple with this reality, I’ve tried to focus on the most important conceptual fundamentals throughout the book. This means your careful study here should pay off for at least a few more <span class="No-Break">years ahead.</span></p>
			<p>In terms of practical applications and guidance, I’ve overwhelmingly focused on cloud computing options available through AWS and especially Amazon SageMaker. I’ve spent more than the last five years very happily at AWS and enjoy sharing all of my knowledge and experience with you! Please do note that all thoughts and opinions shared in this book are my own, and do not represent those <span class="No-Break">of Amazon’s.</span></p>
			<p>The following chapters focus on concepts, not code. This is because software changes rapidly, while fundamentals change very slowly. You’ll find in the repository with the book links to my go-to resources for all of the key topics mentioned throughout these fifteen chapters, which you can use right away to get hands-on with everything you’re learning here. Starting July 1, 2023, you’ll also find in the repository a set of new pretraining and fine-tuning examples from yours truly to complete all of <span class="No-Break">the topics.</span></p>
			<p>You might find this hard to believe, but in my early twenties I wasn’t actually coding: I was exploring the life of a Buddhist monastic. I spent five years living at a meditation retreat center in Arizona, the Garchen Institute. During this time, I learned how to meditate, focus my mind, watch my emotions and develop virtuous habits. After my master’s degree at the University of Chicago years later, and now at Amazon, I can see that these traits are extremely useful in today’s world <span class="No-Break">as well!</span></p>
			<p>I mention this so that you can take heart. Machine learning, artificial intelligence, cloud computing, economics, application development, none of these topics are straightforward. But if you apply yourself, if you really stretch your mind to consider the core foundations of the topics at hand, if you keep yourself coming back to the challenge again and again, there’s truly nothing you can’t do. That is the beauty of humanity! And if a meditating yogi straight from the deep silence of a retreat hut can eventually learn what it takes to pretrain and fine-tune foundation models, then so <span class="No-Break">can you!</span></p>
			<p>With that in mind, let’s learn more about the <span class="No-Break">book itself!</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Most of the concepts mentioned here will be accompanied by scripting examples in the repository starting July 1, 2023. However, to get you started even earlier, you can find a list of resources in the repository today with links to useful hands-on examples elsewhere for demonstration.</p>
			<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/>Who is this book for?</h1>
			<p>If you’re a machine learning researcher or enthusiast who wants to start a foundation modelling project, this book is for you. Applied scientists, data scientists, machine learning engineers, solution architects, product managers, and students will all benefit from this book. Intermediate Python is a must, along with introductory concepts of cloud computing. A strong understanding of deep learning fundamentals is needed, while advanced topics will be explained. The content covers advanced machine learning and cloud techniques, explaining them in an actionable, <span class="No-Break">easy-to-understand way.</span></p>
			<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/>What this book covers</h1>
			<p><a href="B18942_01.xhtml#_idTextAnchor016"><span class="No-Break"><em class="italic">Chapter 1</em></span></a><em class="italic">, An Introduction to Pretraining Foundation Models</em> In this chapter you’ll be introduced to foundation models, the backbone of many artificial intelligence and machine learning systems today. We will dive into their creation process, also called pretraining, and understand where it’s competitive to improve the accuracy of your models. We will discuss the core transformer architecture underpinning state of the art models like Stable Diffusion, BERT, Vision Transformers, CLIP, Flan-T5 and more. You will learn about the encoder and decoder frameworks that work to solve a variety of <span class="No-Break">use cases.</span></p>
			<p><a href="B18942_02.xhtml#_idTextAnchor034"><span class="No-Break"><em class="italic">Chapter 2</em></span></a><em class="italic">, Dataset Preparation: Part One</em> In this chapter, we begin to discuss what you’ll need in your dataset to start a meaningful pretraining project. This is the first of two parts on dataset preparation. It opens with some business guidance on finding a good use case for foundation modeling, where the data become instrumental. Then, focusing on the content of your dataset, we use qualitative and quantitative measures to compare it with datasets used in pretraining other top models. You’ll learn how to use the scaling laws to determine if your datasets are “large enough” and “good enough” to boost accuracy while pretraining. We discuss bias identification and mitigation, along with multilingual and <span class="No-Break">multimodal solutions.</span></p>
			<p><a href="B18942_03.xhtml#_idTextAnchor050"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><em class="italic">, Model Preparation</em> In this chapter you’ll learn how to pick which model will be most useful to serve as a basis for your pretraining regime. You’ll learn how to think about the size of the model in parameters, along with the key loss functions and how they determine performance in production. You’ll combine the scaling laws with your expected dataset size to select ceiling and basement model sizes, which you’ll use to guide <span class="No-Break">your experiments.</span></p>
			<p><a href="B18942_04.xhtml#_idTextAnchor066"><span class="No-Break"><em class="italic">Chapter 4</em></span></a><em class="italic">, Containers and Accelerators on the Cloud </em>In this chapter, you’ll learn how to containerize your scripts and optimize them for accelerators on the cloud. We’ll learn about a range of accelerators for foundation models, including tradeoffs around cost and performance across the entire machine learning lifecycle. You’ll learn key aspects of Amazon SageMaker and AWS to train models on accelerators, optimize performance, and troubleshoot common issues. If you’re already familiar with using accelerators on AWS, feel free to skip <span class="No-Break">this chapter.</span></p>
			<p><a href="B18942_05.xhtml#_idTextAnchor085"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><em class="italic">, Distribution Fundamentals</em> In this chapter, you’ll learn conceptual fundamentals for the distribution techniques you need to employ for large scale pretraining and fine-tuning. First, you’ll master top distribution concepts for machine learning, notably model and data parallel. Then, you’ll learn how Amazon SageMaker integrates with distribution software to run your job on as many GPUs as you need. You’ll learn how to optimize model and data parallel for large-scale training especially with techniques like sharded data parallelism. Then, you’ll learn how to reduce your memory consumption with advanced techniques like optimizer state sharding, activation checkpointing, compilation, and more. Lastly, we’ll look at a few examples across language, vision, and more to bring all of these <span class="No-Break">concepts together.</span></p>
			<p><a href="B18942_06.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><em class="italic">, Dataset Preparation: Part Two, the Data Loader</em> In this chapter, you’ll learn how to prepare your dataset to immediately use with your chosen models. You’ll master the concept of a data loader, knowing why it’s a common source of error in training large models. You’ll learn about creating embeddings, using tokenizers and other methods to featurize your raw data for your preferred neural network. Following these steps, you’ll be able to prepare your entire dataset, using methods for both vision and language. Finally, you’ll learn about data optimizations on AWS and Amazon SageMaker to efficiently send datasets large and small to your training cluster. Throughout this chapter we’ll work backwards from the training loop; giving you incrementally all the steps you need to have functional deep neural networks training at scale. You’ll also follow a case study from how I trained on 10TB for Stable Diffusion <span class="No-Break">on SageMaker!</span></p>
			<p><a href="B18942_07.xhtml#_idTextAnchor116"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><em class="italic">, Finding the Right Hyperparameters</em> In this chapter, you’ll dive into the key hyperparameters that govern performance for top vision and language models, such as batch size, learning rate, and more. First, we’ll start with a quick overview of hyperparameter tuning for those who are new or new a light refresh, including key examples in vision and language. Then we’ll explore hyperparameter tuning in foundation models, both what is possible today and where trends might emerge. Finally, we’ll learn how to do this on Amazon SageMaker, taking incremental steps in a cluster size and changing each hyperparameter as <span class="No-Break">we do.</span></p>
			<p><a href="B18942_08.xhtml#_idTextAnchor127"><span class="No-Break"><em class="italic">Chapter 8</em></span></a><em class="italic">, Large-Scale Training on SageMaker </em>In this chapter, we cover key features and functionality available with Amazon SageMaker for running highly optimized distributed training. You’ll learn how to optimize your script for SageMaker training, along with key usability features. You’ll also learn about backend optimizations for distributed training with SageMaker, like GPU health checks, resilient training, checkpointing, script mode, <span class="No-Break">and more.</span></p>
			<p><a href="B18942_09.xhtml#_idTextAnchor138"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><em class="italic">, Advanced Training Concepts</em> In this chapter, we will cover advanced training concepts at scale, like evaluating throughput, calculating model TFLOPS per device, compilation, and using the scaling laws to determine the right length of training time. In the last chapter you learned about how to do large-scale training on SageMaker generally speaking. In this chapter you’ll learn about particularly complex and sophisticated techniques you can use to drive down the overall cost of your job. This lower cost directly translates to higher model performance, because it means you can train for longer on the <span class="No-Break">same budget.</span></p>
			<p><a href="B18942_10.xhtml#_idTextAnchor152"><span class="No-Break"><em class="italic">Chapter 10</em></span></a><em class="italic">, Fine-Tuning and Evaluating </em>In this chapter, you’ll learn how to fine-tune your model on use case-specific datasets, comparing its performance to that of off-the-shelf public models. You should be able to see quantitative and qualitative boost from your pretraining regime. You’ll dive into some examples from language, text, and everything in-between. You’ll also learn how to think about and design a human-in-the-loop evaluation system, including the same RLHF that makes ChatGPT tick! This chapter focuses on <em class="italic">updating the trainable weights of the model</em>. For techniques that mimic learning but don’t update the weights, such as prompt tuning and standard retrieval augmented generation, see <a href="B18942_13.xhtml#_idTextAnchor198"><span class="No-Break"><em class="italic">Chapter 13</em></span></a> on prompt engineering or <a href="B18942_15.xhtml#_idTextAnchor229"><span class="No-Break"><em class="italic">Chapter 15</em></span></a> on <span class="No-Break">future trends.</span></p>
			<p><a href="B18942_11.xhtml#_idTextAnchor167"><span class="No-Break"><em class="italic">Chapter 11</em></span></a><em class="italic">, Detecting, Mitigating, and Monitoring Bias</em> In this chapter, we’ll analyze leading bias identification and mitigation strategies for large vision, language, and multimodal models. You’ll learn about the concept of bias, both in a statistical sense and how it impacts human beings in critical ways. You’ll understand key ways to quantify and remedy this in vision and language models, eventually landing on monitoring strategies that enable you to reduce any and all forms of harm when applying your <span class="No-Break">foundation models.</span></p>
			<p><a href="B18942_12.xhtml#_idTextAnchor178"><span class="No-Break"><em class="italic">Chapter 12</em></span></a><em class="italic">, How to Deploy Your Model</em> In this chapter, we’ll introduce you to a variety of techniques for deploying your model, including real-time endpoints, serverless, batch options and more. These concepts apply to many compute environments, but we’ll focus on capabilities available on AWS within Amazon SageMaker. We’ll talk about why you should try to shrink the size of your model before deploying, along with techniques for this across vision and language. We’ll also cover distributed hosting techniques, for scenarios when you can’t or don’t need to shrink your model. Lastly, we’ll explore model serving techniques and concepts that can help you optimize the end-to-end performance of <span class="No-Break">your model.</span></p>
			<p><a href="B18942_13.xhtml#_idTextAnchor198"><span class="No-Break"><em class="italic">Chapter 13</em></span></a><em class="italic">, Prompt Engineering</em> In this chapter, we’ll dive into a special set of techniques called prompt engineering. You’ll learn about this technique at a high level, including how it is similar to and different from other learning-based topics throughout this book. We’ll explore examples across vision and language, and dive into key terms and success metrics. In particular this chapter covers all of the tips and tricks for improving performance without updating the model weights. This means we’ll be mimicking the learning process, without necessarily changing any of the model parameters. This includes some advanced techniques like prompt and <span class="No-Break">prefix tuning.</span></p>
			<p><a href="B18942_14.xhtml#_idTextAnchor217"><span class="No-Break"><em class="italic">Chapter 14</em></span></a><em class="italic">, MLOps for Vision and Language</em> In this chapter, we’ll introduce core concepts of operations and orchestration for machine learning, also known as MLOps. This includes building pipelines, continuous integration and deployment, promotion through environments, and more. We’ll explore options for monitoring and human-in-the-loop auditing of model predictions. We’ll also identify unique ways to support large vision and language models in your <span class="No-Break">MLOps pipelines.</span></p>
			<p><a href="B18942_15.xhtml#_idTextAnchor229"><span class="No-Break"><em class="italic">Chapter 15</em></span></a><em class="italic">, Future Trends in Pretraining Foundation Models</em> In this chapter, we’ll close out the book by pointing to where trends are headed for all relevant topics presented in this book. We’ll explore trends in foundation model application development, like using LangChain to build interactive dialogue applications, along with techniques like retrieval augmented generation to reduce LLM hallucination. We’ll explore ways to use generative models to solve classification tasks, human-centered design, and other generative modalities like code, music, product documentation, PowerPoints, and more! We’ll talk through AWS offerings like SageMaker JumpStart Foundation Models, Amazon Bedrock, Amazon Titan, and Amazon Code Whisperer, and top trends in the future of foundation models and <span class="No-Break">pretraining itself.</span></p>
			<h1 id="_idParaDest-10"><a id="_idTextAnchor009"/>To get the most out of this book</h1>
			<p>As mentioned earlier, you want to be very happy in Python development to absolutely maximize your time in this book. The pages don’t spend a lot of time focusing on the software, but again, everything in the GitHub repository is Python. If you’re already using a few key AWS services, like Amazon SageMaker, S3 buckets, ECR images, and FSx for Lustre, that will speed you up tremendously in applying what you’ve learned here. If you’re new to these, that’s ok, we’ll include introductions to each <span class="No-Break">of these.</span></p>
			<table id="table001" class="No-Table-Style">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">AWS Service or Open-source </strong><span class="No-Break"><strong class="bold">software framework</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">What we’re using </strong><span class="No-Break"><strong class="bold">it for</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Amazon SageMaker</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Studio, notebook instances, training jobs, <span class="No-Break">endpoints, pipelines</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">S3 buckets</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Storing objects and <span class="No-Break">retrieving metadata</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Elastic <span class="No-Break">Container Registry</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Storing <span class="No-Break">Docker images</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>FSx <span class="No-Break">for Lustre</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Storing large-scale data for model <span class="No-Break">training loops</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Python</span></p>
						</td>
						<td class="No-Table-Style">
							<p>General scripting: including managing and interacting with services, importing other packages, cleaning your data, defining your model training and evaluation <span class="No-Break">loops, etc</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>PyTorch <span class="No-Break">and TensorFlow</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Deep learning frameworks to define your <span class="No-Break">neural networks</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Hugging Face</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Hub with more than 100,000 open-source pretrained models and countless extremely useful and reliable methods for NLP and <span class="No-Break">increasingly CV</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Pandas</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Go-to library for <span class="No-Break">data analysis</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Docker</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Open-source framework for building and <span class="No-Break">managing containers</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p><strong class="bold">If you are using the digital version of this book, we advise you to access the code from the book’s GitHub repository (a link is available in the next section), step through the examples, and type the code yourself. Doing so will help you avoid any potential errors related to the copying and pasting </strong><span class="No-Break"><strong class="bold">of code.</strong></span></p>
			<h1 id="_idParaDest-11"><a id="_idTextAnchor010"/>Download the example code files</h1>
			<p>You can download the example code files for this book from GitHub at <a href="https://github.com/PacktPublishing/Pretrain-Vision-and-Large-Language-Models-in-Python">https://github.com/PacktPublishing/Pretrain-Vision-and-Large-Language-Models-in-Python</a>. If there’s an update to the code, it will be updated in the <span class="No-Break">GitHub repository.</span></p>
			<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check <span class="No-Break">them out!</span></p>
			<h1 id="_idParaDest-12"><a id="_idTextAnchor011"/>Conventions used</h1>
			<p>There are a number of text conventions used throughout <span class="No-Break">this book.</span></p>
			<p><strong class="source-inline">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: “Mount the downloaded <strong class="source-inline">WebStorm-10*.dmg</strong> disk image file as another disk in <span class="No-Break">your system.”</span></p>
			<p>A block of code is set <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
html, body, #map {
 height: 100%;
 margin: 0;
 padding: 0
}</pre>
			<p><strong class="bold">Bold</strong>: Indicates a new term, an important word, or words that you see onscreen. For instance, words in menus or dialog boxes appear in <strong class="bold">bold</strong>. Here is an example: “Select <strong class="bold">System info</strong> from the <span class="No-Break"><strong class="bold">Administration</strong></span><span class="No-Break"> panel.”</span></p>
			<p class="callout-heading">Tips or important notes</p>
			<p class="callout">Appear like this.</p>
			<h1 id="_idParaDest-13"><a id="_idTextAnchor012"/>Get in touch</h1>
			<p>Feedback from our readers is <span class="No-Break">always welcome.</span></p>
			<p><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, email us at <a href="http://customercare@packtpub.com">customercare@packtpub.com</a> and mention the book title in the subject of <span class="No-Break">your message.</span></p>
			<p><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a> and fill in <span class="No-Break">the form.</span></p>
			<p><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <a href="http://copyright@packt.com">copyright@packt.com</a> with a link to <span class="No-Break">the material.</span></p>
			<p><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please <span class="No-Break">visit </span><a href="http://authors.packtpub.com"><span class="No-Break">authors.packtpub.com</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-14"><a id="_idTextAnchor013"/>Share Your Thoughts</h1>
			<p>Once you’ve read Pretrain Vision and Large Language Models in Python, we’d love to hear your thoughts! <a href="https://packt.link/r/1-804-61825-X">Please click here to go straight to the Amazon review page for this book</a> and share <span class="No-Break">your feedback.</span></p>
			<p>Your review is important to us and the tech community and will help us make sure we’re delivering excellent <span class="No-Break">quality content.</span></p>
			<h1 id="_idParaDest-15"><a id="_idTextAnchor014"/>Download a free PDF copy of this book</h1>
			<p>Thanks for purchasing <span class="No-Break">this book!</span></p>
			<p>Do you like to read on the go but are unable to carry your print <span class="No-Break">books everywhere?</span></p>
			<p>Is your eBook purchase not compatible with the device of <span class="No-Break">your choice?</span></p>
			<p>Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at <span class="No-Break">no cost.</span></p>
			<p>Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into your application. </p>
			<p>The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your <span class="No-Break">inbox daily</span></p>
			<p>Follow these simple steps to get <span class="No-Break">the benefits:</span></p>
			<ol>
				<li>Scan the QR code or visit the link below</li>
			</ol>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer003" class="IMG---Figure">
					<img src="image/B18942_QR_Free_PDF.jpg" alt=""/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/9781804618257">https://packt.link/free-ebook/9781804618257</a></p>
			<ol>
				<li value="2">Submit your proof of purchase</li>
				<li>That’s it! We’ll send your free PDF and other benefits to your email directly</li>
			</ol>
		</div>
		<div>
			<div id="_idContainer005" class="Basic-Text-Frame">
			</div>
		</div>
	

		<div id="_idContainer006" class="Content">
			<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>Part 1: Before Pretraining</h1>
			<p>In part 1, you’ll learn how to get ready to pretrain a large vision and/or language model, including dataset and <span class="No-Break">model preparation.</span></p>
			<p>This section has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18942_01.xhtml#_idTextAnchor016"><em class="italic">Chapter 1</em></a>, <em class="italic">An Introduction to Pretraining Foundation Models</em></li>
				<li><a href="B18942_02.xhtml#_idTextAnchor034"><em class="italic">Chapter 2</em></a>, <em class="italic">Dataset Preparation: Part One</em></li>
				<li><a href="B18942_03.xhtml#_idTextAnchor050"><em class="italic">Chapter 3</em></a>, <em class="italic">Model Preparation</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer007" class="Basic-Graphics-Frame">
			</div>
		</div>
		<div>
			<div id="_idContainer008">
			</div>
		</div>
	</body></html>