["```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [ {\n      \"Action\": [\n          \"s3:GetObject\",\n          \"s3:ListBucket\",\n          \"s3:PutObject\"\n      ],\n      \"Resource\": [\"*\"],\n      \"Effect\": \"Allow\"\n          }\n      ]\n    }\n    ```", "```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [\n      { \"Effect\": \"Allow\", \n        \"Principal\": \n          { \"Service\": \n              [ \"sagemaker.amazonaws.com\", \n                \"s3.amazonaws.com\", \n                \"comprehend.amazonaws.com\" ] \n              }, \n              \"Action\": \"sts:AssumeRole\" } \n          ] \n      }\n    ```", "```py\n    bucket = '<bucket-name>'\n    prefix = 'chapter6'\n    ```", "```py\n    raw_df = pd.read_csv('topic-modeling/initial/complaints_data_initial.csv')\n    raw_df.shape\n    ```", "```py\n    raw_df = raw_df.dropna(subset=['Consumer complaint narrative'])\n    raw_df = pd.DataFrame(raw_df['Consumer complaint narrative'].copy())\n    raw_df.shape\n    ```", "```py\n    raw_df.to_csv('topic-modeling/raw/complaints_data_subset.csv', header=False, index=False)\n    ```", "```py\n    # Write the formatted sentences into a CSV file\n    import csv\n    fnfull = \"topic-modeling/input/complaints_data_formatted.csv\"\n    with open(fnfull, \"w\", encoding='utf-8') as ff:\n        csv_writer = csv.writer(ff, delimiter=',', quotechar = '\"')\n        for infile in all_files:\n            for num, sentence in enumerate(infile):\n                csv_writer.writerow([sentence])\n    # Let's store the formatted CSV into a Pandas DataFrame \n    # as we will use this to create the training dataset for our custom classifier\n    columns = ['Text']\n    form_df = pd.read_csv('topic-modeling/input/complaints_data_formatted.csv', header=None, names = columns)\n    form_df.shape\n    # Upload the CSV file to the input prefix in S3 to be used in the topic modeling job\n    s3 = boto3.client('s3')\n    s3.upload_file('topic-modeling/input/complaints_data_formatted.csv', bucket, prefix+'/topic_modeling/input/topic_input.csv')\n    ```", "```py\n    # Let's first download the results of the topic modeling job. \n    # Please copy the output data location from your topic modeling job for this step and use it below\n    directory = \"results\"\n    parent_dir = os.getcwd()+'/topic-modeling'\n    # Path\n    path = os.path.join(parent_dir, directory)\n    os.makedirs(path, exist_ok = True)\n    print(\"Directory '%s' created successfully\" %directory)\n    tpprefix = prefix+'/topic_modeling/results/custom-classification and train folders, which we need in the notebook to execute the next step, as shown in the following code block:\n\n    ```", "```py\n\n    Now, let's rearrange the columns so that we have the label as the first column. We will convert this into a CSV file and upload it into our S3 bucket. This CSV file will be the training dataset for our Amazon Comprehend Custom Classification model:\n\n    ```", "```py\n\n    ```", "```py\n    endpoint_arn = '<comprehend-custom-classifier-endpoint-arn>'\n    ```", "```py\n    test_text = 'because of your inability to accept my payments on time I now have a really bad credit score, you need to fix this now'\n    comprehend = boto3.client('comprehend')\n    response = comprehend.classify_document(Text=test_text, EndpointArn=endpoint_arn)\n    print(response)\n    ```", "```py\n    {'Classes': [{'Name': 'account', 'Score': 0.9856781363487244}, {'Name': 'credit', 'Score': 0.013113172724843025}, {'Name': 'debt', 'Score': 0.0005924980505369604}], 'ResponseMetadata': {'RequestId': 'c26c226c-3878-447e-95f5-60b4d91bb536', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'c26c226c-3878-447e-95f5-60b4d91bb536', 'content-type': 'application/x-amz-json-1.1', 'content-length': '151', 'date': 'Wed, 19 May 2021 17:35:38 GMT'}, 'RetryAttempts': 0}}\n    ```", "```py\n     cls_df = pd.DataFrame(response['Classes'])\n    max_score = cls_df['Score'].max()\n    routing_type = cls_df.query('Score == @max_score')['Name'].values[0]\n    print(\"This request should be routed to: \" + routing_type)\n    ```", "```py\n    This request should be routed to: account\n    ```", "```py\n    sent_response = comprehend.detect_sentiment(\n        Text=test_text,\n        LanguageCode='en'\n    )\n    print(\"The customer's feedback sentiment is: \" + sent_response['Sentiment'])\n    The customer's feedback sentiment is: NEGATIVE\n    ```"]