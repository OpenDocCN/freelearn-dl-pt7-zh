["```py\npip install pandas_datareader\n```", "```py\nimport datetime\nfrom pandas_datareader import DataReader\n%matplotlib inline\n\nApple = DataReader(\"AAPL\", \"yahoo\", \n        start=datetime.datetime(2010, 1, 1), \n        end=datetime.datetime(2015,12,31)) \nApple.head()\n```", "```py\nclose = Apple['Adj Close']\nplt.figure(figsize= (10,10))\nclose.plot()\nplt.ylabel(\"Apple stocj close price\")\nplt.show()\n```", "```py\nmoving_average = close.rolling(window=20).mean()\n\nplt.figure(figsize= (10,10))\nclose.plot(label='Adj Close')\nmoving_average.plot(label='Moving Average Window 20')\nplt.legend(loc='best')\nplt.show()\n```", "```py\nfod = close.diff()\nplt.figure(figsize= (10,10))\nfod.plot(label='First order difference')\nfod.rolling(window=40).mean().\\\n        plot(label='Rolling Average')\nplt.legend(loc='best')\nplt.show()\n```", "```py\n# Autocorrelation\nplt.figure(figsize= (10,10))\nfod.plot(label='First order difference')\nfod.rolling(window=40).mean().\\\n        plot(label='Rolling Average')\nfod.rolling(window=40).corr(fod.shift(5)).\\\n        plot(label='Auto correlation')\nplt.legend(loc='best')\nplt.show()\n```", "```py\n# Normalization\nfrom sklearn.preprocessing import MinMaxScaler\ndef normalize(data):\n    x = data.values.reshape(-1,1)\n    pre_process = MinMaxScaler()\n    x_normalized = pre_process.fit_transform(x)\n    return x_normalized\n\nx_norm = normalize(close)\n\nplt.figure(figsize= (10,10))\npd.DataFrame(x_norm, index = close.index).plot(label=\"Normalized Stock prices\")\nplt.legend(loc='best')\nplt.show()\n```", "```py\n# Create window from the normalized data\ndef window_transform(series, window_size):\n    X = []\n    y = []\n\n    # Generate a sequence input/output pairs from series\n    # x= <s1,s2,s3,s4,s5,... s_n> y = s_n+1 and so on\n    for i in range(len(series) - window_size):\n    X.append(series[i:i+window_size])\n    y.append(series[i+window_size])\n\n    # reshape each \n    X = np.asarray(X)\n    X.shape = (np.shape(X)[0:2])\n    y = np.asarray(y)\n    y.shape = (len(y),1)\n\n    return X,y\n\nwindow_size = 7\nX,y = window_transform(x_norm,window_size = window_size)\n```", "```py\nf = open('foundation.txt')\ntext = f.read()\nprint(text)\n```", "```py\n# clean data\nimport re\n# remove Punctuation\ntext = re.sub(r\"[^a-zA-Z0-9]\", \" \", text) \nprint(text)\n```", "```py\n# Normalize text\n# Convert to lowercase\ntext = text.lower() \nprint(text)\n```", "```py\nimport os\nimport nltk\nnltk.download('punkt') \nfrom nltk.tokenize import word_tokenize\n\n# Split text into words using NLTK\nwords_nltk = word_tokenize(text)\nprint(words_nltk)\n```", "```py\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n#Remove stop words\nwords = [w for w in words \\\n        if w not in stopwords.words(\"english\")]\n\n```", "```py\nfrom nltk.stem.porter import PorterStemmer\n\n# Reduce words to their stems\nstemmed = [PorterStemmer().stem(w) for w in words]\nprint(stemmed)\n\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\n# Reduce words to their root form\nlemmed = [WordNetLemmatizer().lemmatize(w) for w in words]\nprint(lemmed)\n```", "```py\nimport cv2 # for image reading and processsing\nimport numpy as np\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\n%matplotlib inline\n```", "```py\nimg_files = np.array(glob(\"Obama/*\"))\n```", "```py\ndef distort_image(img, rot = 50, shift_px = 40):\n    \"\"\"\n    Function to introduce random distortion: brightness, flip,\n    rotation, and shift \n    \"\"\"\n    rows, cols,_ = img.shape\n    choice = np.random.randint(5)\n    #print(choice)\n    if choice == 0: # Randomly rotate 0-50 degreee\n        rot *= np.random.random() \n        M = cv2.getRotationMatrix2D((cols/2,rows/2), rot, 1)\n        dst = cv2.warpAffine(img,M,(cols,rows))\n    elif choice == 1: # Randomly change the intensity\n        hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n        ratio = 1.0 + 0.4 * (np.random.rand() - 0.5)\n        hsv[:, :, 2] = hsv[:, :, 2] * ratio\n        dst = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n    elif choice == 2: # Randomly shift the image in horizontal and vertical direction\n        x_shift,y_shift = np.random.randint(-shift_px,shift_px,2)\n        M = np.float32([[1,0,x_shift],[0,1,y_shift]])\n        dst = cv2.warpAffine(img,M,(cols,rows))\n    elif choice == 3: # Randomly flip the image\n        dst = np.fliplr(img)\n    else:\n        dst = img\n\n    return dst\n```", "```py\n# data generator\ndef data_generator(samples, batch_size=32, validation_flag = False):\n    \"\"\"\n    Function to generate data after, it reads the image files, \n    performs random distortions and finally \n    returns a batch of training or validation data\n    \"\"\"\n    num_samples = len(samples)\n    while True: # Loop forever so the generator never terminates\n shuffle(samples)\n        for offset in range(0, num_samples, batch_size):\n            batch_samples = samples[offset:offset+batch_size]\n            images = []\n\n            for batch_sample in batch_samples:\n                if validation_flag: # The validation data consists only of center image and without distortions\n                    image = cv2.imread(batch_sample)\n                    images.append(image)\n                    continue\n                else: # In training dataset we introduce distortions to augment it and improve performance\n                    image = cv2.imread(batch_sample)\n                    # Randomly augment the training dataset to reduce overfitting\n                    image = distort_image(image)\n                    images.append(image)\n\n        # Convert the data into numpy arrays\n        X_train = np.array(images)\n\n        yield X_train \n\ntrain_generator = data_generator(img_files,  batch_size=32)\n```", "```py\nimport cv2 # for capturing videos\nimport math # for mathematical operations\nimport matplotlib.pyplot as plt # for plotting the images\n%matplotlib inline\n```", "```py\nvideoFile = \"video.avi\" # Video file with complete path\ncap = cv2.VideoCapture(videoFile) # capturing the video from the given path\nframeRate = cap.get(5) #frame rate\n```", "```py\ncount = 0\nwhile(cap.isOpened()):\n    frameId = cap.get(1) #current frame number\n    ret, frame = cap.read()\n    if (ret != True):\n        break\n    if (frameId % math.floor(frameRate) == 0):\n        filename =\"frame%d.jpg\" % count\n        count += 1\n        cv2.imwrite(filename, frame)\n\ncap.release()\nprint (\"Finished!\")\n```", "```py\nimg = plt.imread('frame5.jpg') # reading image using its name\nplt.imshow(img)\n```", "```py\npip install librosa\n```", "```py\nimport librosa\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Get the file path to the included audio example\nfilename = librosa.util.example_audio_file()\n```", "```py\ninput_length=16000*4\ndef audio_norm(data):\n    # Function to Normalize\n    max_data = np.max(data)\n    min_data = np.min(data)\n    data = (data-min_data)/(max_data-min_data) \n    return data\n\ndef load_audio_file(file_path, \n            input_length=input_length):\n    # Function to load an audio file and \n    # return a 1D numpy array \n    data, sr = librosa.load(file_path, sr=None)\n\n    max_offset = abs(len(data)-input_length)\n    offset = np.random.randint(max_offset)\n    if len(data)>input_length:\n        data = data[offset:(input_length+offset)]\n    else:\n        data = np.pad(data, (offset, \n            input_size - len(data) - offset), \n            \"constant\")    \n\n    data = audio_norm(data)\n    return data\n```", "```py\ndata_base = load_audio_file(filename)\nfig = plt.figure(figsize=(14, 8))\nplt.title('Raw wave ')\nplt.ylabel('Amplitude')\nplt.plot(np.linspace(0, 1, input_length), data_base)\nplt.show()\n```", "```py\ndef preprocess_audio_mel_T(audio, sample_rate=16000, \n        window_size=20, #log_specgram\n        step_size=10, eps=1e-10):\n\n    mel_spec = librosa.feature.melspectrogram(y=audio,\n             sr=sample_rate, n_mels= 256)\n    mel_db = (librosa.power_to_db(mel_spec,\n         ref=np.max) + 40)/40\n    return mel_db.T\n\ndef load_audio_file2(file_path,\n             input_length=input_length):\n    #Function to load the audio file  \n    data, sr = librosa.load(file_path, sr=None)\n\n    max_offset = abs(len(data)-input_length)\n    offset = np.random.randint(max_offset)\n    if len(data)>input_length:\n        data = data[offset:(input_length+offset)]\n    else:\n        data = np.pad(data, (offset, \n            input_size - len(data) - offset),\n            \"constant\")\n\n    data = preprocess_audio_mel_T(data, sr)\n    return data\n```", "```py\ndata_base = load_audio_file2(filename)\nprint(data_base.shape)\nfig = plt.figure(figsize=(14, 8))\nplt.imshow(data_base)\n```"]