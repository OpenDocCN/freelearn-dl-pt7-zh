["```py\n# Extract training and validation zipped folders to merch_data/<train/val>\n\nextract_zipfile(bucket, train_key, rel_train_path)\nextract_zipfile(bucket, val_key, rel_val_path)\n\n# Create List files (./merch_data)\ncreate_listfile(rel_train_path, listfile_train_prefix) #data path, prefix path\ncreate_listfile(rel_val_path, listfile_val_prefix)\n\n# # Create RecordIO file\n# data path --> prefix path (location of list file)\n# mxnet's im2rec.py uses ./merch_data folder to locate .lst files for train and val\n# mxnet's im2rec.py uses ./merch_data/<train/val> as data path\n# list files are used to create recordio files\n\ncreate_recordio(rel_train_path, listfile_train_prefix)\ncreate_recordio(rel_val_path, listfile_val_prefix)\n```", "```py\n# Create List file for all images present in a directory\n\ndef create_listfile(data_path, prefix_path):\n    \"\"\"\n    input: location of data -- path and prefix\n    \"\"\"\n\n    # Obtain the path of im2rec.py on the current ec2 instance\n    im2rec_path = mx.test_utils.get_im2rec_path()\n\n    with open(os.devnull, 'wb') as devnull:\n        subprocess.check_call(['python', im2rec_path, '--list', '--recursive', prefix_path, data_path], stdout=devnull) \n```", "```py\n# The algorithm supports multiple network depth (number of layers). They are 18, 34, 50, 101, 152 and 200\n# For this training, we will use 18 layers\n\nnum_layers = 18\nimage_shape = \"3,224,224\" # Number of channels for color image, Number of rows, and columns (blue, green and red)\nnum_training_samples = 302 # number of training samples in the training set\nnum_classes = 5 # specify the number of output classes\nmini_batch_size = 60 # batch size for training\nepochs = 4  # number of epochs\nlearning_rate = 0.01 #learning rate\ntop_k=2\n# Since we are using transfer learning, we set use_pretrained_model to 1 so that weights can be initialized with pre-trained weights\nuse_pretrained_model = 1\n```", "```py\n# create the Amazon SageMaker training job\nsagemaker = boto3.client(service_name='sagemaker')\nsagemaker.create_training_job(**training_params)\n\n# confirm that the training job has started\nstatus = sagemaker.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\nprint('Training job current status: {}'.format(status))\n\nOutput:\nTraining job current status: InProgress\nTraining job ended with status: Completed\n```", "```py\nTraining: Blue Line -- trn_acc[0.366667, 0.86, 0.966667, 0.986667]\n\nValidation: Orange Line -- val_acc[0.45, 0.583333, 0.583333, 0.716667] \n```", "```py\ninfo = sage.describe_training_job(TrainingJobName=job_name)\n# Get S3 location of the model artifacts\nmodel_data = info['ModelArtifacts']['S3ModelArtifacts']\nprint(model_data)\n# Get the docker image of image classification algorithm\nhosting_image = get_image_uri(boto3.Session().region_name, 'image-classification')\nprimary_container = {\n    'Image': hosting_image,\n    'ModelDataUrl': model_data,\n}\n# Create model \ncreate_model_response = sage.create_model(\n    ModelName = model_name,\n    ExecutionRoleArn = role,\n    PrimaryContainer = primary_container)\nprint(create_model_response['ModelArn'])\n```", "```py\nsagemaker = boto3.client('sagemaker')\nsagemaker.create_transform_job(**request)\n\nprint(\"Created Transform job with name: \", batch_job_name)\n\nwhile(True):\n    response = sagemaker.describe_transform_job(TransformJobName=batch_job_name)\n    status = response['TransformJobStatus']\n    if status == 'Completed':\n        print(\"Transform job ended with status: \" + status)\n        break\n    if status == 'Failed':\n        message = response['FailureReason']\n        print('Transform failed with the following error: {}'.format(message))\n        raise Exception('Transform job failed') \n    time.sleep(30) \n```", "```py\nCreated Transform job with name: merch-classification-model-2019-03-13-11-59-13\nTransform job ended with status: Completed\n```"]