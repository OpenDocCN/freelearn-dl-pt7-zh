["```py\nlibrary(keras)\n```", "```py\nMnistData <- dataset_mnist()\n```", "```py\nstr(MnistData)\n```", "```py\nList of 2\n $ train:List of 2\n ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...\n $ test :List of 2\n ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...\n ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...\n```", "```py\nXtrain <- MnistData$train$x\nYtrain <- MnistData$train$y\nXtest <- MnistData$test$x\nYtest <- MnistData$test$y\n```", "```py\ntable(Ytrain)\ntable(Ytest)\n```", "```py\nYtrain\n 0    1    2    3    4    5    6    7    8    9\n5923 6742 5958 6131 5842 5421 5918 6265 5851 5949\nYtest\n 0    1    2    3    4    5    6    7    8    9\n 980 1135 1032 1010  982  892  958 1028  974 1009\n```", "```py\nhist(Ytrain)\nhist(Ytest)\n```", "```py\ndim(Xtrain)\ndim(Xtest)\n```", "```py\n> dim(Xtrain)\n[1] 60000    28    28\n> dim(Xtest)\n[1] 10000    28    28\n```", "```py\nXtrain <- array_reshape(Xtrain, c(nrow(Xtrain), 784))\nXtest <- array_reshape(Xtest, c(nrow(Xtest), 784))\n```", "```py\ndim(Xtrain)\ndim(Xtest)\n```", "```py\n> dim(Xtrain)\n[1] 60000   784\n> dim(Xtest)\n[1] 10000   784\n```", "```py\nXtrain <- Xtrain / 255\nXtest <- Xtest / 255\n```", "```py\nYtrain <- to_categorical(Ytrain, 10)\nYtest <- to_categorical(Ytest, 10)\n```", "```py\nKerasMLPModel <- keras_model_sequential()\n```", "```py\nKerasMLPModel %>%\n  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%\n```", "```py\nlayer_dropout(rate = 0.45) %>%\n```", "```py\nlayer_dense(units = 128, activation = 'relu') %>%\n```", "```py\nlayer_dropout(rate = 0.3) %>%\n```", "```py\nlayer_dense(units = 10, activation = 'softmax')\n```", "```py\nsummary(KerasMLPModel)\n```", "```py\nKerasMLPModel %>% compile(\n  loss = 'categorical_crossentropy',\n  optimizer = optimizer_rmsprop(),\n  metrics = c('accuracy')\n)\n```", "```py\nBatchSize <- 128\nNumEpochs <- 50\n```", "```py\nModelHistory <- KerasMLPModel %>% fit(\n  Xtrain, Ytrain,\n  batch_size = BatchSize,\n  epochs = NumEpochs,\n  verbose = 1,\n  validation_split = 0.3\n)\n```", "```py\nplot(ModelHistory)\n```", "```py\nScoreValues <- KerasMLPModel %>% evaluate(\n  Xtrain, Ytrain,\n  verbose = 0\n)\n```", "```py\ncat('Loss :', ScoreValues[[1]], '\\n')\ncat('Accuracy:', ScoreValues[[2]], '\\n')\n```", "```py\nLoss: 0.04588709\nAccuracy: 0.99245\n```", "```py\ninstall.packages(\"devtools\")\n```", "```py\ndevtools::install_github(\"smilesun/rlR\")\n```", "```py\nlibrary(rlR)\n```", "```py\nCPEnv = makeGymEnv(\"CartPole-v0\")\n```", "```py\nCPEnv\n```", "```py\naction cnt: 2\nstate original dim: 4\ndiscrete action\n```", "```py\nCPEnv$step(1)\n```", "```py\n$state\n[1] -0.02800090 -0.17157109 -0.01648416  0.27999059\n$reward\n[1] 1\n$done\n[1] FALSE\n$info\nnamed list()\n```", "```py\nCPAgent = initAgent(\"AgentDQN\", CPEnv)\n```", "```py\nstr(CPAgent)\n```", "```py\nClasses 'AgentDQN', 'AgentArmed', 'Agent', 'R6' <AgentDQN>\n act_cnt: 2\n afterEpisode: function ()\n afterStep: function ()\n env: EnvGym, Environment, R6 epochs: 1\n gamma: 0.99 lr_decay: 0.999000499833375\n mem: ReplayMemUniform, ReplayMem, R6\n policy: PolicyEpsilonGreedy, Policy, R6\n replay: function (batchsize)\n sess: tensorflow.python.client.session.Session, tensorflow.python.client.session.BaseSession, tensorflow.python.client.session.SessionInterface, python.builtin.object\n state_dim: 4\n stopLearn: function ()\n```", "```py\nCPAgent$learn(500L)\n```", "```py\nEpisode: 472 finished with steps:200, rewards:200.000000 global step 44519 \nLast 100 episodes average reward 131.702970 \nEpsilon0.010000 \nrand steps:2 \nreplaymem size GB:0.0388956144452095 \nlearning rate: 0.000589783361647278 \n```", "```py\nCPAgent$plotPerf(F)\n```"]