["```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [ {\n      \"Action\": [\n          \"s3:GetObject\",\n          \"s3:ListBucket\",\n          \"s3:PutObject\"\n      ],\n      \"Resource\": [\"*\"],\n      \"Effect\": \"Allow\"\n          }\n      ]\n    }\n    ```", "```py\n    { \"Version\": \"2012-10-17\", \"Statement\": [\n      { \"Effect\": \"Allow\", \n        \"Principal\": \n          { \"Service\": \n              [ \"sagemaker.amazonaws.com\", \n                \"s3.amazonaws.com\",\n    \"transcribe.amazonaws.com\",\n                \"comprehend.amazonaws.com\" ] \n              }, \n              \"Action\": \"sts:AssumeRole\" } \n          ] \n      }\n    ```", "```py\n    bucket = '<your-s3-bucket>'\n    prefix = 'chapter8'\n    s3=boto3.client('s3')\n    ```", "```py\n    import time\n    import boto3\n    def transcribe_file(job_name, file_uri, transcribe_client):\n        transcribe_client.start_transcription_job(\n            TranscriptionJobName=job_name,\n            Media={'MediaFileUri': file_uri},\n            MediaFormat='mp4',\n            LanguageCode='en-US'\n        )\n    ```", "```py\n    job_name = 'media-monetization-transcribe'\n    transcribe_client = boto3.client('transcribe')\n    file_uri = 's3://'+bucket+'/'+prefix+'/'+'rawvideo/bank-demo-prem-ranga.mp4'\n    transcribe_file(job_name, file_uri, transcribe_client)\n    ```", "```py\n    job = transcribe_client.get_transcription_job(TranscriptionJobName=job_name)\n    job_status = job['TranscriptionJob']['TranscriptionJobStatus']\n    if job_status in ['COMPLETED', 'FAILED']:\n        print(f\"Job {job_name} is {job_status}.\")\n        if job_status == 'COMPLETED':\n            print(f\"Download the transcript from\\n\"\n                  f\"\\t{job['TranscriptionJob']['Transcript']['TranscriptFileUri']}\") \n    ```", "```py\n    raw_df = pd.read_json(job['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n    raw_df = pd.DataFrame(raw_df.at['transcripts','results'].copy())\n    raw_df.to_csv('topic-modeling/raw/transcript.csv', header=False, index=False)\n    import csv\n    folderpath = r\"topic-modeling/raw\" # make sure to put the 'r' in front and provide the folder where your files are\n    filepaths  = [os.path.join(folderpath, name) for name in os.listdir(folderpath) if not name.startswith('.')] # do not select hidden directories\n    fnfull = \"topic-modeling/job-input/transcript_formatted.csv\"\n    for path in filepaths:\n        print(path)\n        with open(path, 'r') as f:\n            content = f.read() # Read the whole file\n            lines = content.split('.') # a list of all sentences\n            with open(fnfull, \"w\", encoding='utf-8') as ff:\n                csv_writer = csv.writer(ff, delimiter=',', quotechar = '\"')\n                for num,line in enumerate(lines): # for each sentence\n                    csv_writer.writerow([line])\n    f.close()\n    s3.upload_file('topic-modeling/job-input/transcript_formatted.csv', bucket, prefix+'/topic-modeling/job-input/tm-input.csv')\n    ```", "```py\n    directory = \"results\"\n    parent_dir = os.getcwd()+'/topic-modeling'\n    path = os.path.join(parent_dir, directory)\n    os.makedirs(path, exist_ok = True)\n    print(\"Directory '%s' created successfully\" %directory)\n    tpprefix = prefix+'/'+topic terms DataFrame contains the topic number, what term corresponds to the topic, and the weightage this term contributes to the topic. Execute the code shown in the following code block to review the contents of the topic terms DataFrame:\n\n    ```", "```py\n\n    e.) We may have multiple topics on the same line, but for this solution, we are not interested in these duplicates, so we will drop them:\n\n    ```", "```py\n\n    f.) Let's now filter the topics such that we select the topic with the maximum weight distribution for the text it refers to:\n\n    ```", "```py\n\n    g.) Load these into their own DataFrame and display it:\n\n    ```", "```py\n\n    h.) We will select the `content` topic term as it has the highest weight and assign this to a variable for use in the subsequent steps:\n\n    ```", "```py\n\n    ```", "```py\n    adindex_df = pd.read_csv('media-content/ad-index.csv', header=None, index_col=0)\n    adindex_df\n    ```", "```py\n    advalue = adindex_df.loc[adtopic]\n    advalue\n    ```", "```py\n    1           cmsid=176\n    2    vid=short_tencue\n    ```", "```py\n    ad_rawurl = pd.read_csv('media-content/adserver.csv', header=None).at[0,0].split('&')\n    ad_rawurl\n    ```", "```py\n    ['https://pubads.g.doubleclick.net/gampad/ads?sz=640x480',\n     'iu=/124319096/external/ad_rule_samples',\n     'ciu_szs=300x250',\n     'ad_rule=1',\n     'impl=s',\n     'gdfp_req=1',\n     'env=vp',\n     'output=vmap',\n     'unviewed_position_start=1',\n     'cust_params=deployment%3Ddevsite%26sample_ar%3Dpremidpost',\n     cmsid and vid values highlighted in the preceding response with the values corresponding to our topic and reformat the URL:\n\n    ```", "```py\n\n    g.) We get the following response. Copy the contents of the following URL:\n\n    ```", "```py\n\n    ```"]