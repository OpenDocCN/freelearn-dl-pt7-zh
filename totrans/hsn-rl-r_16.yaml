- en: Deep Q-Learning Using Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keras is a library of high-level neural networks, written in Python and able
    to work using different support libraries. It was developed to allow rapid experimentation.
    Keras allows easy and fast prototyping using total modularity, minimalism, and
    extensibility. It supports both convolutional networks and recurrent networks
    and combinations of both. Furthermore, it supports arbitrary connectivity schemes
    and runs smoothly on CPU and GPU. In this chapter, we will learn how to approach
    reinforcement learning using Keras. We will learn to use Keras to develop a model
    that can recognize handwritten digits. Later, we will use deep Q-learning to balance
    a cart pole.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multilayer perceptron for image processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Approaching deep-Q learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this chapter, we will have explored the Keras model using TensorFlow
    as the backend engine and how to use Keras to set up a **Multilayer Perceptron**
    (**MLP**) model. Then, we will learn how to use deep reinforcement learning to
    balance a cart pole system.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Check out the following video to see the Code in Action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://bit.ly/2qMtw3I](http://bit.ly/2qMtw3I)'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keras is a Python library that provides a simple and clean way to create a range
    of deep learning models. Keras code was released under the MIT license. Keras
    has been structured based on austerity and simplicity, and it provides a no frills
    programming model that maximizes readability. It allows neural networks to be
    expressed in a very modular way, considering a model as a sequence or a single
    graph. This is a good approximation because the components of a deep learning
    model are discrete elements that can be arbitrarily combined. New components are
    easily aggregated and modifiable within the framework designed for engineers,
    to quickly test and explore new ideas. Finally, using the Python programming language
    provides constructs that allow clear programming on both a small and large scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see the Keras official home page ([https://keras.io/](https://keras.io/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c4131d3-f184-4443-a1d1-d6baaa8b0d6a.png)'
  prefs: []
  type: TYPE_IMG
- en: Its ease of use is the strong point of Keras. During the design phase, the user
    has been the focus of the attention of the developers, producing a product that
    reduces the user's work using simple and consistent APIs. In this way, the number
    of actions necessary to solve common use cases is reduced. Also, the results are
    returned clearly, making the identification of possible errors very simple.
  prefs: []
  type: TYPE_NORMAL
- en: In Keras, a model is represented by a sequence of autonomous and completely
    configurable modules that can relate to the lowest possible number of restrictions.
    Everything in Keras is a module—neural layers, cost functions, optimizers, initialization
    schemes, activation functions, and regularization schemes. These independent modules
    can be combined to create new, more complex models.
  prefs: []
  type: TYPE_NORMAL
- en: All modules available in Keras are simple to add, and so are new classes and
    functions in a programming language. Also, the modules are already available and
    are accompanied by numerous examples that explain their practical use. But Keras
    is not limited to the availability of the built-in modules. The user will be able
    to easily create new modules, making Keras an easily extensible environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `keras` library bases its technology on the levels that are used to manage
    input and output. An application in Keras can be implemented through the following
    four simple steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Prepare input and output data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the first level to manage the input data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up intermediate levels to perform the analysis.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the output level to manage the targets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Keras works as a specific high-level API for neural networks. It can act as
    a user interface and can extend the functionality of other deep learning framework
    backends on which it runs. Thanks to this feature, Keras has become a wrapper
    for migration between frameworks. Not only can algorithms and models of neural
    networks for deep learning be exchanged but also networks and preliminary weights.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapper libraries consist of a thin layer of code that translates a library's
    existing interface into a compatible interface.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, since Keras is autonomous, it can be used without having
    to interact with the backend framework on which it is running. Keras has its own
    chart data structures for defining computational charts; it is not based on the
    data structures of the underlying backend framework. This way, you will not have
    to learn how to program the backend framework.
  prefs: []
  type: TYPE_NORMAL
- en: Keras is easy to learn and use. Using Keras is like working with LEGO® blocks;
    you just have to put in sequence a series of compatible modules. It was created
    so that people can quickly perform the experimental phase of models using a highly
    modular and extensible framework. Keras focuses on defining levels for neural
    networks. You do not have to deal with tensors, but it's easy to write with less
    code.
  prefs: []
  type: TYPE_NORMAL
- en: The backend takes care of complex mathematics and, in the next section, we will
    see how the TensorFlow backend works.
  prefs: []
  type: TYPE_NORMAL
- en: The Keras backend in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Keras is a model-level library that provides high-level blocks for the development
    of deep learning models. Keras developers have focused their efforts on creating
    high-level models by neglecting low-level operations such as tensor products and
    convolutions. These operations have been entrusted to specialized and well-optimized
    tensor manipulation libraries that already exist, hence acting as a backend engine
    for Keras. Several backend engines can be connected perfectly to Keras. Actually,
    Keras has three backend implementations available—TensorFlow, Theano, and Microsoft
    **Cognitive Toolkit** (**CNTK**).
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is an open source software library for numerical calculation based
    on graph modeling (data flow graphs). A graph is defined as an abstract pipeline
    of mathematical operations operating on tensors and is known as a multidimensional
    array. Each graph consists of nodes and arcs, wherein the nodes are operations
    on the data, and the arcs represent the tensors that pass through the various
    operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the updated version of the library and all of the documentation
    supplied at the following link: [http://www.tensorflow.org](http://www.tensorflow.org).'
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow is the most commonly used library in the field of machine learning
    and neural networks. It has numerous APIs, including the lowest level, that is,
    TensorFlow Core, and allows complete control over programming. These APIs are
    those typically used in the field of machine learning since they make it possible
    to check in detail all of the elements of the model being implemented. The highest-level
    APIs are available and built from TensorFlow Core. In some cases, they can make
    some operations such as repetitive and predefined tasks faster and simpler, but
    generally preclude the possibility of going into detail, and in the implementation
    of a neural network, it is often necessary to have more precise control over operations.
    However, they can still be useful for the development of standard machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's see how we can exploit the potential offered by the `keras` library
    in the R environment.
  prefs: []
  type: TYPE_NORMAL
- en: Using Keras in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we anticipated in the *Introduction to Keras* section, Keras is written in
    Python and is, therefore, the natural development environment in which to operate.
    Despite this, as with many libraries, an interface has been built that allows
    us to operate in the R environment using the potential of Keras. This is due to
    the great simplicity of use of the `keras` library technology, which makes the
    implementation of algorithms based on machine learning really simple and immediate.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Keras in R, we can use the interface available at the following URL:
    [https://keras.rstudio.com/index.html](https://keras.rstudio.com/index.html).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following screenshot, we can see the official home page of the R interface
    to Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/22a55595-eab5-4356-8977-8acc6b03873a.png)'
  prefs: []
  type: TYPE_IMG
- en: It will be possible to retrieve all of the information needed to install the
    interface and to start using it. The simplicity with which it is possible to operate
    with the `keras` library will be confirmed in the next section, where we will
    see how to recognize handwritten digits using Keras.
  prefs: []
  type: TYPE_NORMAL
- en: Multilayer perceptron for image processing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we saw in [Chapter 11](91935d6b-70d6-4d61-b1b8-86d84470caf4.xhtml), *Exploring
    Deep Reinforcement Learning Methods*, the MLP is a feedforward artificial neural
    network. The simplest variant is the single-layer variant, which consists of a
    single layer of output nodes while the inputs are supplied directly to the units
    through a series of weights. The MLP is a type of network that provides for the
    presence of at least three levels connected to each other in feedforward—an input
    layer, a hidden layer, and output layers.
  prefs: []
  type: TYPE_NORMAL
- en: For each node, except those of the input layer, a non-linear activation function
    is used. In fact, if an MLP network has a linear activation function that maps
    the weighted inputs of each neuron into output, then even with multiple levels,
    it is considered a two-level input/output model. In the training phase, the weights
    of the connections are modified by processing the data contained in the model.
    The update is based on the amount of error present in the output compared to the
    expected result.
  prefs: []
  type: TYPE_NORMAL
- en: The error function is one that belongs to the space of the weights that measure
    how reliable the network is at solving the problem in question. The task of the
    learning algorithm is to minimize this function, therefore, to find the point
    in the space of the weights at which the function has the global minimum point,
    or in some cases, a local minimum point may suffice.
  prefs: []
  type: TYPE_NORMAL
- en: To verify the potential of Keras in image processing, we will deal with a practical
    case of handwritten digit recognition. To do this, we will use a dataset widely
    used by the developer community—the MNIST dataset.
  prefs: []
  type: TYPE_NORMAL
- en: The MNIST dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The **Modified National Institute of Standards and Technology** (**MNIST**)
    dataset is a large database of handwritten digits. It has a set of 70,000 examples
    of data. It is a subset of NIST's larger dataset. The digits are of 28x28 pixel
    resolution and are stored in a matrix of 70,000 rows and 785 columns; 784 columns
    form each pixel value from the 28x28 matrix, and one value is the actual digit.
    The digits have been size-normalized and centered in a fixed-size image.
  prefs: []
  type: TYPE_NORMAL
- en: The digit images in the MNIST set were originally selected and experimented
    with by Chris Burges and Corinna Cortes using bounding box normalization and centering.
    Yann LeCun's version uses centering by the center of mass within a larger window.
    The data is available on Yann LeCun's website at [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows a sample of images of 0-8 from the MNIST dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c1de2216-a245-435b-89a3-4fcae011755d.png)'
  prefs: []
  type: TYPE_IMG
- en: This dataset is already available in the `keras` library and contains 60,000
    28x28 grayscale images of the 10 digits for the training, along with a test set
    of 10,000 images.
  prefs: []
  type: TYPE_NORMAL
- en: To start, we preprocess the data by preparing it adequately for the next use
    in the Keras model.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will analyze the features of the MNIST dataset and we will
    learn how to prepare the data in a format compatible with Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start importing the `keras` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'To import the `mnist` dataset, we can use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at what is contained in the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Now we can see the dataset contains 60,000 observations for training and 10,000
    for the test phase. Each observation represents a 28x28 pixel (*x*) image. The
    corresponding label (*y*) is provided for each observation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will extract the four lists, and place them in four variables that
    represent our input and output data for the model we intend to process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: In *The MNIST dataset* section, we four said that the dataset contains 10 digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s verify it; we''ll also analyze the distribution of these figures in
    the dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Actually, we have 10 occurrences – the digits from 0 to 9\. Furthermore, we
    can verify that the frequencies of each digit are comparable. To confirm this,
    we can trace a histogram:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram shows the histograms of the two distributions next to
    each other (**YTrain** on the left and **YTest** on the right):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c39f2f5f-1669-4382-9a7f-ea3386cfb9ce.png)'
  prefs: []
  type: TYPE_IMG
- en: By analyzing the previous diagram, we can see that the frequencies of the presence
    of 10 digits are equally distributed in the two datasets. As we said, each sample
    image consists of a 28x28 matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'To confirm this, we will extract the dimensions of the two input vectors:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following shapes are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Hence, each observation contains the data relating to the 28x28 pixels in grayscale.
  prefs: []
  type: TYPE_NORMAL
- en: 'To reduce the dimensionality, we will flatten the 28x28 images into vectors
    of a size of `784`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: The `array_reshape()` function reshapes a multi-dimensional array, using row-major
    (C-style) reshaping semantics by default. This function gives a new shape to an
    array without changing its data. The new shape should be compatible with the original
    shape. The first dimension of the new shape is the number of observations. The
    second dimension represents the product of the last two dimensions of the starting
    data (*28 x 28 = 784*).
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand this transformation better, we print the shape of the transformed
    dataset:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have to normalize all values between 0 and 1\. The MNIST images are
    stored in pixel format, where each pixel (in total, 28x28) is stored as an 8-bit
    integer, giving a range of possible values from 0 to 255\. Typically, 0 is taken
    to be black, and 255 is taken to be white.
  prefs: []
  type: TYPE_NORMAL
- en: 'The values in between make up the different shades of gray. Now, to normalize
    all values between 0 and 1, simply divide each value by 255\. So, the pixel containing
    the value 255 will become 1, and the one containing 0 will remain as such; in
    between, lie all of the other values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: After preparing the input data, it is necessary to rearrange the output data.
    We have said that it represents the labels of the images. We have already seen
    that each image has been labeled with a number ranging from 0 to 9\. To use these
    values in a Keras model, it is necessary to modify them.
  prefs: []
  type: TYPE_NORMAL
- en: 'A method to quantify each category of a qualitative predictor involves the
    creation of a binary variable, 0-1 (called a dummy variable), which indicates
    the presence or absence of the attribute in each statistical unit. Let''s see
    how:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The `to_categorical()` function takes a vector or 1 column matrix of class
    labels and converts it into a matrix with *p* columns, one for each category.
    This is the format most commonly used in the fitting and predicting of neural
    networks. The dummy variable can take two values:'
  prefs: []
  type: TYPE_NORMAL
- en: '0: If the attribute is absent'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '1: If the attribute is present'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, each observation will be a line of 10 values in which there are all zeros
    except in the column that identifies the digit that will contain 1.
  prefs: []
  type: TYPE_NORMAL
- en: After preparing the data, it is time to use them to train a Keras model.
  prefs: []
  type: TYPE_NORMAL
- en: Keras MLP model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After adequately preprocessing the data, we can define the architecture of
    the Keras model. Keras is structured according to the object-oriented programming
    methodology. Therefore, the creation of a model is very simple: select the basic
    architecture and then add the layers necessary to create the desired model. As
    just mentioned, the sequential model lets you create a layer-by-layer model as
    a linear stack of layers. However, it is not possible to create models that share
    levels or that have multiple inputs or outputs. A sequential model is created
    by passing a list of layer instances to the constructor:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we instantiate an object from the `keras_model_sequential` class:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: All information about your network, such as weights, layers, and operations,
    will be stored in this object.
  prefs: []
  type: TYPE_NORMAL
- en: 'After instantiating our object, we will move on to adding layers:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The `layer_dense()` function adds a densely-connected NN layer to an output.
    In a densely connected layer, every input is connected to every output by a weight,
    which is generally followed by a non-linear activation function. The first argument
    contains the dimensionality of the output space (units = 256). The second argument
    contains the activation function (`activation = 'relu'`). **Rectified Linear Unit**
    (**ReLU**) is the most used activation function since 2015\. It's a simple condition
    and has advantages over the other functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, the third argument contains the input shape (`input_shape = c(784)`).
    Recall that the first layer passed to a sequential model should have a defined
    input shape. Let''s add the second layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The dropout layer applies dropout to the input. Dropout consists of randomly
    setting a fraction rate of input units to 0 at each update during training time,
    which helps to prevent overfitting. Only one argument is passed. This is the rate,
    a float between 0 and 1\. This indicates the fraction of the units to drop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, a second dense layer is added:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: In this case, the input is not present, the number of output nodes is progressively
    resized, and the activation function is always `relu`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s add another layer of dropout:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s finish with a last dense layer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code block, the output units are 10 because there are 10 figures
    that the system must classify. The softmax function is a more generalized logistic
    activation function that's used for multiclass classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we''ll analyze the overall architecture of the Keras model we have defined.
    In Keras, to summarize a model, it is possible to use the `summary()` function.
    The summary is returned in text format and includes the following information:'
  prefs: []
  type: TYPE_NORMAL
- en: The layers and their order in the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output shape of each layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of parameters (weights) in each layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of parameters (weights) in the model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To print a summary of the model, we simply type the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'The following screenshot shows the architecture of the Keras model defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/95ad0254-26bd-45c4-9917-1754c45a09ec.png)'
  prefs: []
  type: TYPE_IMG
- en: In the previous screenshot, we can clearly see the output shape and number of
    weights in each layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before training a model, you need to configure the learning process, which
    is done via the `compile()` method, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The `compile()` method configures a Keras model for training. Three arguments
    are passed, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`loss`: The `categorical_crossentropy` loss function is passed. When using
    `categorical_crossentropy`, your targets should be in categorical format. We have
    10 classes; the target for each sample must be a 10-dimensional vector that is
    all zeros except for a one at the index corresponding to the class of the sample.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`optimizer`: `optimizer_rmsprop` is passed. This optimizer divides the learning
    rate by an exponentially decaying average of squared gradients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`metrics`: The accuracy metric is passed. A metric is a function that is used
    to evaluate the performance of your model during training and testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, we can move on to the training phase. First, you need to set some parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`BatchSize` is the number of samples per gradient update. `NumEpochs` is the
    number of epochs to train the model. An epoch is an iteration over the entire
    input and output data provided.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To train the model, the `fit()` method is used, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'The following arguments are passed:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Xtrain`: This is an array of input training data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Ytrain`: This is an array of target (label) data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`epochs`: This is the number of epochs to train the model. An epoch is an iteration
    over the entire *x* and *y* data provided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`batch_size`: This is the number of samples per gradient update.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`verbose`: This is an integer, either 0, 1, or 2\. Verbosity mode would be:
    0 = silent, 1 = progress bar, and 2 = one line per epoch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`validation_split`: This is a float between 0 and 1, a fraction of the training
    data to be used as validation data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When the `fit()` function is used, the loss and the accuracy at the end of
    each training epoch are displayed, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/11594ff3-e351-44b9-9acd-37a6e8184684.png)'
  prefs: []
  type: TYPE_IMG
- en: 'To get an idea of how the loss function and the accuracy vary during the epochs,
    it can be useful to create a plot of loss and accuracy on the training and validation
    phases, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram is plotted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ea3218d3-57b5-4f45-b407-9ec1a34d1711.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see the evolution of the model for both subsets, as loss and accuracy
    vary.
  prefs: []
  type: TYPE_NORMAL
- en: 'To evaluate the performance of the model we''ve just adapted, we use the `evaluate()`
    function, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'This function returns the loss value and metrics values for the model in test
    mode. Computation is done in batches. Let''s print loss and accuracy:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: The accuracy obtained confirms that a deep neural network can classify the handwritten
    digits.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to use deep Q-learning to balance a cart
    pole.
  prefs: []
  type: TYPE_NORMAL
- en: Approaching deep Q-learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 11](91935d6b-70d6-4d61-b1b8-86d84470caf4.xhtml), *Exploring Deep
    Reinforcement Learning Methods*, we saw that deep Q-learning adopts a neural network
    as an approximation of a value function. These methods represent an evolution
    of the basic Q-learning method since the action-state table is replaced by a neural
    network, to approximate the optimal value function. Deep Q-learning only requires
    the state of the environment as an input and provides all of the status-action
    values as there are actions that can be performed in the environment. In this
    algorithm, therefore, the learning does not consist of updating the table but
    of adjusting the weights of the neurons that make up the network. This update
    takes place using the backpropagation technique.
  prefs: []
  type: TYPE_NORMAL
- en: To begin with, let's see how to install the library we will use as a first approach
    to deep Q-learning.
  prefs: []
  type: TYPE_NORMAL
- en: Deep Q-learning in R
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To approach the DQN in R, we will use the `rlR` library. To use this library,
    Keras must be installed with TensorFlow as a backend on our machine. Furthermore,
    to run the example that we will propose, the OpenAI Gym library must be installed:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we provide to install the `rlXR` library. The library is available
    on GitHub at the following URL: [https://github.com/smilesun/rlR](https://github.com/smilesun/rlR).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To install an R package available on GitHub, we can use the `install_github()`
    function available in the `devtools` package.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, we must first install the `devtools` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: The `devtools` package contains several functions for developing R packages.
    Using this library, many common tasks are greatly simplified.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can use the `install_github()` function contained in `devtools`,
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: This command will first download the package from the GitHub website and then
    install it. The function argument contains a text string that calls both the author
    and the package name.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can load the library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: As an example of the application of the method, we will use an OpenAI library
    environment, already introduced in [Chapter 8](47b30864-c93f-4e61-aa44-fa46b70508dd.xhtml),
    *Reinforcement Learning in Game Applications*. I refer to the `CartPole-v0` environment,
    which is a classic problem of reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'The system consists of a pole (which acts like an inverted pendulum) attached
    to a cart via a joint, as shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4e2a9057-b551-4190-878e-5440690171ae.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The system is controlled by applying a force of +1 or -1 to the cart. The force
    applied to the cart can be controlled, and the objective is to swing the pole
    upward and stabilize it. This must be done without the cart falling to the ground.
    The balancing procedure involves the following actions: the agent moves the pole
    to the right or the left. A reward of 1 is returned for each time the pole is
    balanced. If the pole deviates by more than 15 degrees from the vertical position,
    the procedure ends. To balance the pole and therefore solve the problem, it is
    necessary to set the push in the opposite direction to the inclination of the
    pole:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To load the `CartPole` environment using the OpenAI Gym library, simply type
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'We check what makes are available:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'The following information is returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two actions (`action cnt: 2`); this agrees with what was said before.
    The system is controlled by applying a force of +1 or -1 to the cart. These are
    the two actions available. The second piece of information, `state original dim:
    4`, tells us that the state of the system is characterized by four pieces of information,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Cart position
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cart velocity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pole angle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pole velocity at the tip
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, the third piece of information, `discrete action`, tells us that the
    space of action is defined by discrete choices. This makes the DQN the best solution
    to deal with this type of problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'The environment we initialized contains several methods. For example, we can
    use the `step()` method, which performs an action and returns the state of the
    environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The following results are returned:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The returned values have the following meaning:'
  prefs: []
  type: TYPE_NORMAL
- en: '`$state`: This is an environment-specific object representing your observation
    of the environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$reward`: This is the amount of reward achieved by the previous action. The
    scale varies between environments, but the goal is always to increase your total
    reward.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$done`: This shows whether it''s time to reset the environment again. Most
    (but not all) tasks are divided into well-defined episodes, and done being `True`
    indicates that the episode has terminated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`$info`: This is diagnostic information useful for debugging. It can sometimes
    be useful for learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'At this point, we can elaborate on the model based on deep Q-learning:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s initialize the agent:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s analyze what the object we have instantiated contains:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We are given back so much information, we have highlighted only part of it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Analyzing this information in detail, we can obtain the functions available
    for this agent. After instantiating our agent, it is time to train it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is to train the agent for 500 episodes. At the end of each episode,
    the following information is printed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can print a graph showing how the reward varies in the episodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram is printed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/bfc3ff40-8cf0-4522-a128-7145d4c72e83.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that as the agent learns, the rewards obtained from the system increase,
    meaning that the agent is implementing the best policy to achieve the desired
    result.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to tackle a deep reinforcement learning problem
    using Keras. To begin with, we explored the `keras` library and analyzed the TensorFlow
    backend. Next, we identified handwritten digits using a multilayered neural network
    using Keras. In this way, we could understand how a Keras model is structured
    with a practical example. In the final part of this chapter, we used the `rlR`
    library to apply deep reinforcement learning using the cart pole environment of
    the OpenAI Gym library.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will summarize what has been covered so far in this
    book, and what the next steps are from this point on. We will explore the next
    real-life challenges in the construction and implementation of machine learning
    models, and additional resources and technologies to learn how to improve our
    machine learning capabilities.
  prefs: []
  type: TYPE_NORMAL
