- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Dataset Preparation: Part One'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will begin to discuss what you’ll need in your dataset to
    start a meaningful pretraining project. This is the first of two parts on dataset
    preparation. It opens with some business guidance on finding a good use case for
    foundation modeling, where the data becomes instrumental. Then, focusing on the
    content of your dataset, we use qualitative and quantitative measures to compare
    it with datasets used to pretrain other top models. You’ll learn how to determine
    whether your datasets are “large enough” and “good enough” to boost accuracy while
    pretraining. We discuss bias identification and mitigation, along with multilingual
    and multimodal solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: A business-level discussion on finding datasets and use cases for foundation
    modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating your dataset by comparing it to ones available in the open source
    research community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using scaling laws to size your dataset appropriately
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bias detection and mitigation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dataset enhancements – multilingual and augmentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finding a dataset and use case for foundation modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Datasets – we love them, we struggle with them, we rely on them, and we ignore
    them, oftentimes all at once. Every transaction, every digital moment, every archive,
    and every snapshot is a candidate for inclusion in a dataset. If your organization
    has already gone through a digital transformation, or if you’re digitally native,
    odds are you are already heavily invested in some data storage solution. Whether
    it’s on-premises or in the cloud, every organization needs a secure, reliable,
    operational, and robust solution to store countless types of data. The major question
    for you right now is, how can I monetize that? How can I lean into what is most
    unique about my organization’s history and strengths, and capitalize on it to
    develop net-new capabilities that further my own competitive advantage?
  prefs: []
  type: TYPE_NORMAL
- en: For companies that already have machine learning models deployed into production
    applications, an easy way to find a candidate dataset for a foundation modeling
    project is to ask yourself, what is the single common denominator in all of my
    models? What domains, what modalities, and what signals do those models rely on,
    and what resources can I draw on to increase the overall intelligence of these
    models?
  prefs: []
  type: TYPE_NORMAL
- en: 'One common mental exercise is to consider the interactions that are core to
    your business. From search to customer support, supply chain, product development
    and maintenance, marketing, and so on, each of your lines of business involve
    decision making on a regular basis. Now, ask yourself the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What if I could improve the accuracy of this decision making by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if I could increase my marketing lead conversion by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if I could recommend better content to customers by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if I could increase my operational efficiency by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if I could answer questions more accurately by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What if I could deliver my products faster by 1%?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you’ve found a certain aspect of your business that’s most interesting
    to you or where you think the impact of your investment could be the highest,
    try to quantify this number. Will an increase in accuracy by 1% give you $50,000?
    What about $500,000? Maybe even $1,000,000? Many multiples of that? I’m stating
    the obvious here, but all things being equal, higher is clearly better. You want
    to pick an area you think will have the absolute maximum return on your investment.
  prefs: []
  type: TYPE_NORMAL
- en: Now, once you have that area of your organization identified, take 10% of the
    total estimated earnings, or some other low percentage you feel more comfortable
    with. That is your maximum compute budget. Now, don’t worry – we’re not going
    to blow through that all at once. You may not even need to spend it all. As we
    step through this book, I’ll help you figure out how to get early signals that
    your project is going to be successful, such as training on 1% of your data to
    ensure the performance is better than open source models. You want to hit key
    milestones throughout your pretraining project, and as you hit those milestones,
    you will get closer to achieving your end goal. That overall goal is also the
    same number you’ll use to figure out how much time it’s worth for you to spend
    on this project, how many people you’ll want to pull in, how many sprints to use,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have this target application in mind, along with both the estimated
    return and costs, you are ready to start bringing it to life! Start listing any
    datasets your organization already stores that are related to the application
    you want to build. Do you have relational databases with transactions relevant
    to this? Customer history? Click-stream data? Search results? What about images?
    Do you have any videos? Any audio files? Any experimental results? Push yourself
    to be creative in listing as many candidate datasets as you have. Consider taking
    a solid hour just to look around and see what your organization already has stored
    around this candidate application area. If it’s already mission-critical, then
    most likely you have quite a bit stored already.
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t already have at least a few GB of data or, even better, a few 10s
    of GB, then you might want to consider gathering a new dataset from open source
    solutions. These might include any combination of over 6,000 datasets available
    through the *Papers With Code* site *(1)*. You can also look at the 8,000 datasets
    available from the *Hugging Face Hub* *(2)*. Remember, these datasets are available
    at no cost! Open source datasets are an excellent way to start proving the concept
    of your idea. Common datasets for language pretraining are *The Pile*, *Common
    Crawl*, *Wikipedia*, *CodeParrot*, and so on *(3)*. You can also look at the OSCAR
    corpus for multimodal pretraining. The **Vision Transformer** (**ViT**) *(4)*
    model was trained from scratch on ImageNet. You have plenty of options! You can
    also use all of these open source datasets to enhance your original dataset, using
    the best of both open source and proprietary options.
  prefs: []
  type: TYPE_NORMAL
- en: Something else to remember is that *pretraining explicitly benefits from unlabeled
    data*. The best pretraining projects happen when they leverage large volumes of
    unlabeled data and smaller volumes of labeled data. This is largely why pretraining
    foundation models is popular – most data in the world isn’t labeled. However,
    when we use a pretraining objective, as we learned about in the first chapter,
    we can easily train models to learn about this. Then, we fine-tune them using
    supervised data, which is usually smaller in quantity.
  prefs: []
  type: TYPE_NORMAL
- en: So, if you find yourself in a scenario with multiple hundreds of GBs of data,
    such as images, files, records, transactions, metadata, and time-series data,
    you may want to consider that as a top candidate for custom pretraining.
  prefs: []
  type: TYPE_NORMAL
- en: Top pretraining use cases by industry
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s highlight a few top use cases to pretrain custom foundational models
    by industry. These are areas in our world where pretraining and finetuning are
    already having an impact today:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Software** **and internet**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search and discovery
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating documentation and code
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Questioning/answering
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hospitality** **and travel**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer support and service
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Booking recommendations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consumer electronics**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Design automation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Fashion design automation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Financial services**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document summarization and generation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal forecasts
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Media** **and entertainment**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creativity enhancement
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Speeding up the generation of creatives (new images, new movies, better artifacts,
    and so on)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying the best creative to move to finals (best shot, best sequence, best
    melody, and so on)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health care and** **life sciences**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Protein modeling, drug discovery, and experimental prioritization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Notes synthesis and diagnosis confirmation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Visual results confirmation and experiment result prioritization
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Scientific literature synthesis and experimental design suggestion
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manufacturing** **and agriculture**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Part defects and building error detection
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall design automation of parts and products
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Autonomous product design
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Public** **sector governance**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Policy impact analysis automation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Policy suggestion automation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Political and philosophical difference reconciliation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Budget impact assessment and analysis automation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s now move on to see how different your dataset is.
  prefs: []
  type: TYPE_NORMAL
- en: Delta – how different is your dataset?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now that you have some idea of what use case you are most interested in, and
    what datasets will give your organization the most value, it’s time to understand
    how unique your dataset is. This analysis matters because it will answer two questions:'
  prefs: []
  type: TYPE_NORMAL
- en: First, which models are already on the table for you to use, due to having been
    trained on similar data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Second, how well have those models performed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This insight will start to give you a clue toward what performance you can hope
    to achieve on your datasets as a best-case scenario. Then, we’ll plug that expected
    performance number back into our total project value and make sure we’re still
    on track. The next chapter is completely dedicated to answering those questions.
    Here, we’ll learn how to pick apart your dataset. This is a good section for those
    who are new to data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: First, it’s always a good idea to spend time really analyzing any dataset you’re
    touching. Whether you are starting from something custom in your own database,
    or working with an open source option, anticipate spending at least a few hours
    getting to know it in little detail. Probably the best phrase I’ve heard to inspire
    this process is, *a good data science team asks more questions than they answer*.
    This is because *the act of analyzing a dataset is a living process, not a finite
    state*. Getting to know a dataset is a little bit like getting to know a person;
    it’s just that the way you ask questions and make observations is totally different.
  prefs: []
  type: TYPE_NORMAL
- en: Start by verbally describing the contours of your dataset. How many rows does
    it have? How many columns? How large are the images? How many tokens does it have?
    What features does it have? Are they numeric or categorical? Is it based on time?
    What metadata does it have? Make sure you have a good picture in your mind of
    what this dataset looks like. Talk with other people on your team about it until
    you feel confident and can answer questions quickly about the basics of your dataset
    composition. Use common data analysis techniques, such as Jupyter notebooks, to
    produce summary statistics and charts, and perform exploratory data analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Critically, ask yourself, what real-world process was this dataset drawn from?
    How was this dataset acquired? We call this a sampling mechanism. If you are new
    to data analysis, and especially new to data analysis in applied settings outside
    of theoretical research, the first thing you’ll need to understand is that “not
    all sampling mechanisms are perfect.” To put it another way, you should get into
    the practice of assuming that there may be something wrong with your dataset.
    You need to critically evaluate the way your dataset was developed. Was it randomly
    collected? Or does all of the data have some underlying similarities? Any errors?
    The most important part of your data analysis process is to disabuse yourself
    of any underlying errors, inconsistencies, oddities, and faults in the raw data
    itself. You need to gain certainty that the data itself is indeed valid and reliable.
    Why? Because this certainty serves as a fundamental guarantee for everything you
    produce from this dataset. If the data isn’t reliable, your work can never be
    reliable.
  prefs: []
  type: TYPE_NORMAL
- en: When you have an idea about your dataset, before that idea is proven true by
    the results you empirically observe, it’s called a **hypothesis**. A hypothesis
    is a concept you believe may be true about your dataset, or about any real-world
    process. However, because you currently lack empirical evidence validating the
    certainty of this hypothesis, you can’t state at the current time that it is objectively
    true. That’s why we call it a hypothesis!
  prefs: []
  type: TYPE_NORMAL
- en: A core part of the scientific process, and as a corollary, your own development
    in machine learning is learning how to state this hypothesis clearly. You can
    phrase it as a simple question, something as basic as “which model solves this
    problem the best?”, “what does it mean to solve this type of problem optimally?”,
    or even, “how can we improve upon the state of the art in this area?”
  prefs: []
  type: TYPE_NORMAL
- en: Once you have a hypothesis, also called a **research objective**, clearly stated,
    you then want to learn “how to design experiments that answer this question.”
    Experimental design is a surprisingly challenging skill! This includes the work
    of evaluating current research in certain areas, considering open questions and
    results others have demonstrated, and attempting to build upon them empirically.
    At the end of your project, you want to have clear empirical results you can point
    to that validate your work. We’ll discuss this more in the following chapters
    on model evaluation, but it’s a critical topic to keep in mind.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s learn about sizing our datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Use the scaling laws to size your datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At this point, you should have identified your datasets, have a basic understanding
    of them, and be able to describe how they are similar to and different from previous
    datasets and research work in your chosen domain. It’s helpful to have at least
    a handful of papers to refer to so that you can do so when you’re stuck.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll explore how large your dataset should be in order to
    produce the expected results on a pretraining or fine-tuning project, which clearly
    validates the time and compute expenses you’ll be racking up. We’ll also discuss
    certain characteristics you’ll want this dataset to have, such as sufficient variety,
    quality, and lack of duplicates. The entirety of the next chapter is dedicated
    to picking the right model, including the size and scope, but for now, we’ll focus
    on the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: First, it’s helpful to know that there is a very large gray area between so-called
    large and small models and the corresponding size in datasets that they tend to
    run on. Under no circumstances should you think that you only need multiple terabytes
    and/or petabytes to think about pretraining, or even models that don’t fit on
    a single GPU. You can produce meaningful results with unsupervised data simply
    by continuing to pretrain your model, rather than necessarily starting pretraining
    from scratch, and still hit your business and intellectual goals. Depending on
    your project, and how niche and interesting it may be, you can easily showcase
    some useful work on just under 1 GB of data. So, don’t hesitate just because you
    aren’t sitting on the Fort Knox of all web data; just start from where you are!
  prefs: []
  type: TYPE_NORMAL
- en: Next, you’ll need to understand something called the scaling laws *(6)*. These
    are a set of theories and formulas about how large models behave at different
    scales, notably as power laws. These formulas themselves are derived from empirical
    behavior at varying scales. You can use them to determine what model and dataset
    sizes are optimal for a given compute budget, and vice versa. To some degree,
    these laws, and their updated versions as presented in *Chinchilla*, are independent
    of the model architecture itself. This implies that the biggest way to improve
    model accuracy is scaling up the size, rather than alterations in the model architecture
    itself. Kaplan originally presented scaling laws explicitly within the context
    of language models leveraging the transformer model architecture. However, given
    the 10x increase in accuracy that this validated hypothesis gave rise to in the
    GPT-3 paper, I and many others *(7)* believe there is a reason to explore this
    basic relationship outside of **large language models** (**LLMs**), including
    vision and multimodal especially.
  prefs: []
  type: TYPE_NORMAL
- en: You might be thinking, so what? Why is this such a big deal? Obviously, there’s
    some balance you’d want to achieve across your dataset, compute size, and model,
    so what gives? The reason Kaplan’s work was such a breakthrough is that *having
    a valid formula to quantify the optimal compute, data, and model values lets you
    estimate what range of loss your model might achieve*. To put it another way,
    now that we have scaling laws, we can figure out mathematically what loss we should
    expect at the end of our model training run, within a given range. And for training
    runs that can send compute costs into the hundreds of thousands of dollars, if
    not millions, this knowledge is incredibly valuable. OpenAI has validated this
    in its GPT-4 technical report, claiming to be able to accurately forecast its
    model’s loss given changes in scale.
  prefs: []
  type: TYPE_NORMAL
- en: This opens a new area of questions. What other aspects of machine learning have
    empirically observable laws? In what other ways can we be inspired by physics
    to discover formulaic patterns that rely on mathematical relationships, beyond
    the inner workings of the model itself? This matters because, today, the vast
    majority of machine learning is trial and error. We hope something works, we try
    it out, learn from our experiment, and then take another step. However, I believe
    scaling laws point to a future where machine learning is increasingly enhanced
    with simple, efficient, and fast checks, rather than long-running computational
    experiments. What if we’ve simply been thinking about this in the wrong way for
    decades?
  prefs: []
  type: TYPE_NORMAL
- en: Fundamentals – scaling laws of neural language models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you take a look at the original paper: *Scaling Laws of Neural Language
    Laws*, you’ll find out that one core concept is central to their analysis – proportionality.
    Kaplan et al here argue that changes in your dataset size or model size should
    be accompanied by proportional changes in the companion quantity. To put it another
    way, if you use a bigger dataset, you should use a bigger model, and vice versa.
    Now, exactly how strong this relationship is, what describes it, what constants
    are involved, and precisely how much scaling should be undertaken up or down is
    entirely at the heart of their paper.'
  prefs: []
  type: TYPE_NORMAL
- en: 'While it is helpful to know that a relationship is proportional, it is insufficient.
    Kaplan et al suggest and find empirically that the optimal scaling of neural language
    models follows a power law. Power laws are actually quite simple; they’re just
    about exponents at the end of the day. If two quantities follow a power law, you
    can assume that one side of the equation follows exponential change:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18942_02_001.jpg)'
  prefs: []
  type: TYPE_IMG
- en: To estimate the early-stopped test loss of a transformer-based training regime,
    given the size of both a dataset and a model, Kaplan et al suggest the following.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to unpack this in very simple terms – first, the left-hand side:'
  prefs: []
  type: TYPE_NORMAL
- en: '**L** = the final loss of your model, stopped early, on your test set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**N** = the number of trainable parameters in your model'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**D** = the size of your dataset in tokens (for language)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, you understand that the entire equation is about computing the potential
    loss of your model, which would be great to know ahead of time! The rest of the
    terms on the right-hand side are about how to get there. All four of ![](img/B18942_02_002.png),
    ![](img/B18942_02_003.png), ![](img/B18942_02_004.png), and ![](img/B18942_02_005.png)
    describe constants that must be discovered from the dataset and training regime.
    Think of these as hyperparameters; we want to find some constant terms that describe
    our specific dataset and model. In many cases, however, we can simply use the
    constants as presented in their work.
  prefs: []
  type: TYPE_NORMAL
- en: Kaplan et al found constant values for each of these in their training runs
    by fitting the loss curves with their scaling law functions. Using mathematical
    extensions of their core equations, they were able to accurately fit their learning
    curves. Making that fit helped them discover constants that proved useful throughout
    the rest of their studies.
  prefs: []
  type: TYPE_NORMAL
- en: In the real world, once you’ve performed some preliminary data analysis and
    have a good idea of what characteristics you’ll need to train an adequate model,
    most data science teams will immediately move on to training your first model.
    This is because the machine learning process is generally iterative; you’ll test
    a variety of methods, see which ones are the most promising at a given point in
    time, scale and evaluate, and then try again. For the purposes of a larger book
    on the topic, I’ll go into more detail on two key topics that can help you improve
    your dataset. These are steps you probably wouldn’t implement right at the beginning
    of your data science journey but that you should come back to over time to increase
    the overall quality of your work. The first is bias detection and mitigation,
    and the second is dataset enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: Bias detection and mitigation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The trajectory of the word “bias” is interesting in that, in the last 15 years,
    it’s come full circle. Originally, *bias* was arguably a statistical term. Formally,
    it implied that a sample size was improperly constructed, giving excessive weight
    to certain variables. Statisticians developed numerous methods to identify and
    reduce bias to evaluate studies properly, such as those used in randomized control
    trials in public health or policy evaluations in econometrics. Basic tactics include
    making sure that the treatment and control groups are roughly the same size and
    have roughly the same characteristics. Without a guarantee of that basic mathematical
    equivalence, or more realistically as close to it as the research team can get,
    it’s difficult to trust that the results of a study are truly valid. The results
    themselves are subject to bias, simply indicating the presence or absence of basic
    characteristics, rather than implying anything meaningful about the treatment
    itself.
  prefs: []
  type: TYPE_NORMAL
- en: In the last 5 years, however, numerous studies have demonstrated the inability
    of machine learning models to perform adequately for certain groups of people
    under certain scenarios. The most egregious examples include facial recognition,
    image detection, employment, judicial decision-making, and countless others. Large
    technology companies have been the first to come under fire here, with financial
    institutions and even public policy organizations also coming in tow. These accusations
    are valid. While bias in datasets has always been a big problem in machine learning,
    the impact on human lives across the world is now so obvious that it deserves
    significant dialogue, discussion, solutioning, and monitoring. If bias is present
    in any dataset, it is almost certain to creep into the model itself. Models certainly
    are not objective; they are effectively children of the datasets they were trained
    on. Bias has now come full circle, starting in statistics, resonating with human
    rights, and now driving machine learning research.
  prefs: []
  type: TYPE_NORMAL
- en: '*The word bias has now come full circle; starting in statistics, resonating
    with human rights, and now driving machine* *learning research.*'
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of developing and attempting to deploy a machine learning model,
    and especially a large one with its own pretraining regime, you need to know a
    few things. First, the most reliable way to mitigate bias is by increasing and
    decreasing the different aspects of your datasets. This is especially obvious
    in computer vision. If you add more images of certain groups – for example, African
    Americans – your model will be able to recognize them. If you don’t have those
    images in sufficient numbers, your model won’t be able to recognize them in applications.
  prefs: []
  type: TYPE_NORMAL
- en: For natural language, this question ends up being even more challenging. This
    is because most of the data in language isn’t already tabulated into different
    social categories, such as gender, race, religion, and sexuality. For all of those
    types that we care about and know we want to protect, we need to introduce our
    own methods to identify, compare, and synthesize them across our datasets. Just
    doing this alone is tough, as you can imagine.
  prefs: []
  type: TYPE_NORMAL
- en: 'Identifying bias is the first critical step in your journey toward responsible
    ML. Right at the beginning, you need to be able to answer two critical questions
    about your dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: First, what types of bias are present in my dataset currently?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, how much risk does this bias expose to my organization?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Think about risk in terms of impact on your customers, particularly the predictions
    from a biased ML model. If your model has the potential to cause harm to your
    customers, such as denying a loan, downgrading an employment submission, recommending
    harmful content, or even denying bail or other legal sentencing, then by all means
    make bias detection and mitigation your highest priority!
  prefs: []
  type: TYPE_NORMAL
- en: 'While there are a variety of frameworks concerning responsible AI, I like to
    boil these down to four key actions to take. In terms of bias in ML models trained
    on biased datasets, your four key steps are **expect**, **identify**, **mitigate**,
    and **monitor**:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Expect**: When picking ML projects and datasets, expect that every dataset
    will have some type of bias at the root. Ask yourself, what problem is my ML model
    trying to solve, and what issues will I run into if I don’t have enough of certain
    types of data?'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Identify**: Then, use a variety of techniques to identify the bias present
    in your dataset. Make sure you know right at the outset how many attributes within
    certain groups you do or do not have. Keep working on this until you can quantify
    at least a handful of different types of bias metrics. See the following note
    box for some suggestions on how to identify bias.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Mitigate**: Once you’ve identified the bias in your dataset numerically,
    take steps to mitigate the bias. Increase or decrease certain aspects of your
    dataset. Use augmentation, up- or down-sampling, and data transformations to drive
    down your bias metrics until they hit a less dangerous threshold.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Monitor**: Once you’ve deployed your ML model, the adventure continues. You
    can use the same bias detection methods you leveraged in *step 2* to monitor the
    model deployed in your application. Ensure that your application and overall system
    design include statistical monitoring and set thresholds for acceptable statistical
    levels. When the model starts to meet or exceed your thresholds, start manually
    reviewing the model predictions and initiate your training pipeline. Keeping humans
    in the loop, particularly those who are both knowledgeable and caring, is the
    best way to reduce the risk of biased predictions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How to do bias detection and monitoring
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we know bias is important, how do we find it mathematically? And once
    we’ve done that, how do we mitigate and monitor? There are many ways of doing
    this, and we can categorize these in their respective domains:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tabular**: Detecting bias in tabular data amounts to computing some statistics.
    First, you’ll need to have some ground truth label in your dataset, indicating
    the status inside or outside of a certain group. Notably, for many teams, this
    alone presents a sizeable problem. However, the logical counter to this is simple.
    Expect your data to be biased, regardless of whether or not you have a column
    labeling it as members of certain groups. Introducing this label *is the only
    way to identify bias intrinsic to your dataset and, ultimately, remove it*. Otherwise,
    try to use a proxy, although these are known to be faulty.'
  prefs: []
  type: TYPE_NORMAL
- en: Assuming you have a label, such as gender or race, then you have two types of
    metrics – pretraining and post-training metrics. One simple pretraining statistic
    is **class imbalance**. Class imbalance is simply the number of observations from
    your advantaged group, minus the number in the disadvantaged group, divided by
    your overall dataset size. If your class imbalance is too high, your dataset and
    subsequent model are certain to be biased.
  prefs: []
  type: TYPE_NORMAL
- en: One common post-training metric is disparate impact, which is defined simply
    as the number of positive predicted labels in your disadvantaged group, divided
    by the same in your advantaged group. Intuitively, this measures your model’s
    likelihood of predicting positive for different groups, which as you can imagine
    is critical in certain domains such as employment or law. There is some legal
    precedent for using 4/5, or 80%, as the lower threshold here.
  prefs: []
  type: TYPE_NORMAL
- en: '**Vision and language**: Lastly, both vision and language have different approaches.
    In language, it’s common to evaluate a language model’s learned preference to
    suggest a given category under certain conditions, such as placing “he” or “her”
    under some employment criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: With vision, you might use a pretrained text classifier to ensure that datasets
    are balanced before training. Also, you can clearly indicate a model’s poor behavior
    in detecting certain classes – for example, certain groups in image recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing your dataset – multilingual, multimodal, and augmentations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Finally, now that you’ve learned how to pick a dataset, compare it with research
    datasets, determine the right approximate size, and evaluate bias, let’s dive
    into enhancing the dataset. In particular, we’ll look at a few dimensions – **multilingual**,
    **multimodal**, and **augmentations**. All three of these typically come a bit
    later in your ML projects, especially after the first few versions of your models
    have been trained and you’re looking for the next idea to give you a boost.
  prefs: []
  type: TYPE_NORMAL
- en: Personally, I think there are few applications in the world where multilingually
    *isn’t* a strong added value. *Multilingual* just means multiple languages. While
    many of the state-of-the-art language models were originally trained on English-only
    text, researchers in the last few years have made strong efforts to increase the
    lingual diversity of these corpora. That means they’re adding support for a lot
    of languages. In 2022, Hugging Face led a massive worldwide effort to democratize
    the creation of large language models, calling their program *Big Science* *(8)*.
    This led to the creation of a novel model they named the **BigScience Open-Science
    Open-Access Multilingual Language Model** (**BLOOM**). Hugging Face hopes to improve
    upon the state of the art in multilingual use cases especially, such as zero-shot
    language translation. However, the model was shown to perform worse than GPT-3
    in many cases, leading us to believe that the best models may be single-language
    only.
  prefs: []
  type: TYPE_NORMAL
- en: Frankly, being multilingual is just good business. For any product you develop,
    any program you run, and any service you offer, you are limited in interacting
    with your potential consumer through language at the end of the day. Think of
    a language as a market. While you’re developing your product, you want to bring
    it to as many markets as you can. Ultimately, that means as many languages as
    you can. For this reason, I’m optimistic that the industry will find a better
    way to incorporate multiple languages in possibly the same model without worsening
    results. Perhaps this is as simple as formatting a dataset appropriately, as in
    the case of chain-of-thought or instruction tuning.
  prefs: []
  type: TYPE_NORMAL
- en: Briefly, let’s explore adding additional modalities. Simply put, this means
    different types of datasets, such as adding vision to text, or vice versa. I introduced
    this concept in more detail at the close of [*Chapter 1*](B18942_01.xhtml#_idTextAnchor016).
    Here, I’d like to simply point out that *if you have text with images, or images
    with your text, try to use it*. Once you’re invested in a project, with many hours
    spent on analyzing the data, training, evaluating models, deploying these, and
    so on, why would you not go the extra mile to explore adding other modalities?
    Particularly when it has the potential of raising accuracy, which it does. From
    the perspective of a model, another modality is just another type of embedding.
    You’ll most likely want to use some model pretrained elsewhere to convert a raw
    image into embeddings – that is, before adding them as another input to your model.
  prefs: []
  type: TYPE_NORMAL
- en: There are trade-offs here; increasing the size of your model will increase its
    runtime. Increasing your dataset also increases your data transformation costs.
    Adding another step in the data transformation makes hosting more complex, meaning
    you may need to revisit the system design to deploy your model. All of these trade-offs
    are worthy of discussion, and ultimately, you’ll need to prioritize the projects
    that add the most value for your teams and your customers, which could very well
    include language-only models.
  prefs: []
  type: TYPE_NORMAL
- en: The other reason I’m optimistic about multimodal projects generally, as opposed
    to language-only projects, is that the visual domain carries so much information
    to humans. Humans learn to see before they learn to speak, and so many of our
    experiences and knowledge are gathered visually. For this reason, I believe foundation
    models will continue to converge around joint vision and language tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, data augmentation is a simple and easy step to improve the accuracy
    of your models without adding a ton of extra work to get it. The core idea is
    that you’re adding some degree of variety in your dataset and slight changes in
    the provided samples, which will help your model learn the difference between
    signal and noise. Both text and vision have well-tested methods for augmentation.
    With vision, this is frequently as simple as pixel manipulations, light color
    manipulations, or image rotations.
  prefs: []
  type: TYPE_NORMAL
- en: With text, this can be substituting synonyms, sentence-level reconstruction,
    or lightweight punctuation modifications. The trick is that you don’t want to
    change the basic mechanism you are trying to learn. If you’re training an image
    detection model, don’t modify any of the images so that you can’t detect the images.
    If you’re training a text classifier, don’t alter the text so much that it moves
    into a different class.
  prefs: []
  type: TYPE_NORMAL
- en: Augmentation is usually less of an issue in large-scale pretraining, where most
    datasets are so large, as they already include more than enough noise and variation.
    It does, however, seem like a promising avenue for bias reduction especially.
    Another key technique for pretraining is reducing duplicate text. This is especially
    key in web data, where memes, comments, and threads can easily render the same
    text many hundreds of times across platforms and users.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve learned all about the early stages of preparing your data, let’s
    do a quick recap of what you just learned before we move on to preparing your
    model!
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced a wide variety of use cases for foundation modeling,
    encompassing scenarios where you can fine-tune an existing foundation model and
    where pretraining itself is competitive. We provided a simple economics framework
    to help you make the case for your pretraining project, notably by tying it to
    how much you expect your business to increase based on a more accurate model.
    After that, we talked about evaluating your dataset, comparing it to research
    datasets, and learning how to think critically about its sampling mechanism. We
    set up some basic ideas to use this critical thinking for framing experiments,
    which we’ll continue in the next chapter. We learned about the scaling laws and
    presented an open source notebook you can use to find which dataset size will
    help you hit performance levels, given fixed model and compute budgets. We talked
    about detecting and mitigating bias in your datasets, along with enhancing these
    with augmentation, modalities, and languages.
  prefs: []
  type: TYPE_NORMAL
- en: Next up is model preparation!
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Please go through the following content for more information on a few of the
    topics covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Papers With* *Code*: [https://paperswithcode.com/datasets](https://paperswithcode.com/datasets).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Hugging Face* *Hub*: [https://huggingface.co/datasets](https://huggingface.co/datasets)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Hugging* *Face*: [https://huggingface.co/datasets?task_ids=task_ids:language-modeling&sort=downloads](https://huggingface.co/datasets?task_ids=task_ids:language-modeling&sort=downloads)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT* *SCALE*:
    [https://arxiv.org/pdf/2010.11929.pdf](https://arxiv.org/pdf/2010.11929.pdf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Scaling Laws for Neural Language Models: [https://arxiv.org/pdf/2001.08361.pdf](https://arxiv.org/pdf/2001.08361.pdf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Training Compute-Optimal Large Language Models: [https://arxiv.org/pdf/2203.15556.pdf](https://arxiv.org/pdf/2203.15556.pdf)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*BigScience Episode #5 – Challenges & Perspectives in Creating Large Language*
    *Models*: [https://bigscience.huggingface.co/acl-2022](https://bigscience.huggingface.co/acl-2022)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
