["```py\n\nImport whisper\nimport torch\nmodel = whisper.load_model(\"small\")\naudio = whisper.load_audio(source_audio)\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio).to(model.device)\n# detect the spoken language\n_, probs = model.detect_language(mel)\naudio_lang = max(probs, key=probs.get)\nprint(f\"Detected language: {audio_lang}\")\n```", "```py\n\nimport re\nfrom pytube import YouTube\nvideo_url = \"<Place video URL here>\" #@param {type:\"string\"}\ndrive_folder = \"\" #@param {type:\"string\"}\nyt = YouTube(video_url)\nepisode_date = yt.publish_date.strftime('%Y%m%d-')\nsource_audio = drive_folder + episode_date + (re.sub('[^A-Za-z0-9 ]+', '', yt.title).replace(' ', '_')) + \".mp4\"\naudio_file = YouTube(video_url).streams.filter(only_audio=True).first().download(filename=source_audio)\nprint(f\"Downloaded '{source_audio}\")\n```", "```py\n\n    !pip install -q cohere openai tiktoken\n    !apt-get install ffmpeg\n    !pip install -q \"git+https://github.com/openai/whisper.git\"\n    cohere, openai, tiktoken, ffmpeg, and whisper. Here’s what the following commands are doing:*   `feedparser`: This library is specifically designed for parsing RSS and Atom feeds. It simplifies working with feed data, such as extracting podcast information. Its role in the notebook is to parse the RSS feed provided by the user, enabling the extraction of details about the podcast episodes available for download and transcription.*   `requests`: A fundamental library for making HTTP requests in Python. It’s used in the notebook to download audio files from the URLs specified in the podcast’s RSS feed. The simplicity and flexibility of requests make it a go-to choice for web scraping tasks, API interactions, and downloading files over HTTP.\n    ```", "```py\n\n    import feedparser\n    import requests\n    import os\n    import time\n    from urllib.parse import urlparse\n    import subprocess\n    import re\n    ```", "```py\n\n        def list_episodes(feed_url):\n            d = feedparser.parse(feed_url)\n            episodes = []\n            for entry in d.entries:\n                title = entry.title\n                published = time.strftime('%Y%m%d', time.gmtime(time.mktime(entry.published_parsed)))\n                url = None\n                for link in entry.links:\n                    if link.type == \"audio/mpeg\":\n                        url = link.href\n                        break\n                if url:\n                    episodes.append((title, url, published))\n            return episodes\n        ```", "```py\n        from urllib.parse import urlparse\n        def download_episode(url, filename=None):\n            # If a custom filename is provided, append the appropriate extension from the URL\n            if filename:\n                parsed_url = urlparse(url)\n                # Extract only the base path without any query parameters\n                base_path = os.path.basename(parsed_url.path)\n                ext = os.path.splitext(base_path)[1]\n                filename += ext\n            else:\n                filename = os.path.basename(parsed_url.path)\n            response = requests.get(url, stream=True)\n            response.raise_for_status()\n            with open(filename, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            return filename\n        ```", "```py\n        def download_episode_start_end(url, filename=None, start_at=0, end_at=None):\n            parsed_url = urlparse(url)\n            if filename:\n                # Ensure the filename has the correct extension\n                ext = os.path.splitext(parsed_url.path)[1]\n                filename += ext\n            else:\n                filename = os.path.basename(parsed_url.path)\n            # Download the file\n            response = requests.get(url, stream=True)\n            response.raise_for_status()\n            temp_filename = \"temp_\" + filename\n            with open(temp_filename, 'wb') as f:\n                for chunk in response.iter_content(chunk_size=8192):\n                    f.write(chunk)\n            # Use ffmpeg to trim the audio file\n            trimmed_filename = \"trimmed_\" + filename\n            command = ['ffmpeg', '-y', '-i', temp_filename, '-ss', str(start_at)]\n            if end_at is not None and end_at != 0:\n                command.extend(['-to', str(end_at)])\n            command.extend(['-c', 'copy', trimmed_filename])\n            subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n            # Remove the original downloaded file\n            os.remove(temp_filename)\n            return trimmed_filename\n        ```", "```py\n\n    # Gigantes Podcast Spanish\n    podcast = '<Place RSS URL Here>'\n    d = feedparser.parse(podcast)\n    print(f\"Podcast name:\", d.feed.title)\n    print(f\"Number of episodes:\", len(d.entries))\n    # List episodes\n    episodes = list_episodes(podcast)\n    # Print the first ten episodes\n    print(\"Episodes:\")\n    for idx, (title, url, published) in enumerate(episodes, 1):\n        print(f\"{idx}. {published}-{title}\")\n        if idx == 10:\n            break\n    ```", "```py\n\n    episode_num = 5 #@param {type:\"integer\"}\n    drive_folder = \"\" #@param {type:\"string\"}\n    start_at_seconds = 1300 #@param {type:\"integer\"}\n    end_at_seconds = 0 #@param {type:\"integer\"}\n    title, url, published = episodes[episode_num - 1]\n    custom_filename = published + '-' + (re.sub('[^A-Za-z0-9 ]+', '', title[:75]).replace(' ', '_'))\n    # Download the selected episode\n    audio_file = download_episode_start_end(url, drive_folder + custom_filename, start_at_seconds, end_at_seconds) print(f\"Downloaded '{title}' as {audio_file}.\")\n    ```", "```py\n\n    import ipywidgets as widgets\n    widgets.Audio.from_file(audio_file, autoplay=False, loop=False)\n    ```", "```py\n\n    import whisper\n    import torch\n    # NLTK helps to split the transcription sentence by sentence\n    import nltk\n    nltk.download('punkt')\n    from nltk import sent_tokenize\n    model = whisper.load_model(\"small\")\n    audio = whisper.load_audio(audio_file)\n    audio = whisper.pad_or_trim(audio)\n    # make log-Mel spectrogram and move to the same device as the model\n    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n    # detect the spoken language\n    _, probs = model.detect_language(mel)\n    audio_lang = max(probs, key=probs.get)\n    print(f\"Detected language: {audio_lang}\")\n    # decode the audio\n    options = whisper.DecodingOptions(fp16=torch.cuda.is_available(), language=audio_lang, task='transcribe')\n    result = whisper.decode(model, mel, options)\n    # print the recognized text\n    print(\"----\\nTranscription from audio:\")\n    for sent in sent_tokenize(result.text):\n      print(sent)\n    # decode the audio\n    options = whisper.DecodingOptions(fp16=torch.cuda.is_available(), language=audio_lang, task='translate')\n    result = whisper.decode(model, mel, options)\n    # print the recognized text\n    print(\"----\\nTranslation from audio:\")\n    for sent in sent_tokenize(result.text):\n      print(sent)\n    ```", "```py\n\n!wget -nv \"https://github.com/PacktPublishing/Learn-OpenAI-Whisper/raw/main/Chapter06/utils.py\" -O utils.py\n```", "```py\n\n%pip install -q cohere openai tiktoken\n%pip install -q \"openvino>=2023.1.0\"\n%pip install -q \"python-ffmpeg<=1.0.16\" moviepy transformers --extra-index-url https://download.pytorch.org/whl/cpu\n%pip install -q \"git+https://github.com/garywu007/pytube.git\"\n%pip install -q gradio\n%pip install -q \"openai-whisper==20231117\" --extra-index-url https://download.pytorch.org/whl/cpu\n```", "```py\n\nfrom whisper import _MODELS\nimport ipywidgets as widgets\nmodel_id = widgets.Dropdown(\n options=list(_MODELS),\n value='base',\n description='Model:',\n disabled=False,\n)\nmodel_id\n```", "```py\n\nimport whisper\nmodel = whisper.load_model(model_id.value, \"cpu\")\nmodel.eval()\npass\n```", "```py\n\nmel = torch.zeros((1, 80 if 'v3' not in model_id.value else 128, 3000))\naudio_features = model.encoder(mel)\nif not WHISPER_ENCODER_OV.exists():\n    encoder_model = ov.convert_model(model.encoder, example_input=mel)\n    ov.save_model(encoder_model, WHISPER_ENCODER_OV)\n```", "```py\n\ntokens = torch.ones((5, 3), dtype=torch.int64)\nlogits, kv_cache = model.decoder(tokens, audio_features, kv_cache=None)\ntokens = torch.ones((5, 1), dtype=torch.int64)\nif not WHISPER_DECODER_OV.exists():\n    decoder_model = ov.convert_model(model.decoder, example_input=(tokens, audio_features, kv_cache))\n    ov.save_model(decoder_model, WHISPER_DECODER_OV)\n```", "```py\n\ncore = ov.Core()\ndevice = widgets.Dropdown(\n options=core.available_devices + [AUTO»],\n value='AUTO',\n description='Device:',\n disabled=False,\n)\ndevice\n```", "```py\n\nfrom utils import patch_whisper_for_ov_inference, OpenVINOAudioEncoder, OpenVINOTextDecoder\npatch_whisper_for_ov_inference(model)\nmodel.encoder = OpenVINOAudioEncoder(core, WHISPER_ENCODER_OV, device=device.value)\nmodel.decoder = OpenVINOTextDecoder(core, WHISPER_DECODER_OV, device=device.value)\n```", "```py\n\nfrom pytube import YouTube\nfrom pathlib import Path\nprint(f\"Downloading video {link.value} started\")\noutput_file = Path(\"downloaded_video.mp4\")\nyt = YouTube(link.value)\nyt.streams.get_highest_resolution().download(filename=output_file)\nprint(f\"Video saved to {output_file}\")\n```", "```py\n\ntask = widgets.Select(\n options=[\"transcribe\", \"translate\"],\n value=\"translate\",\n description=\"Select task:\",\n disabled=False\n)\ntask\n```", "```py\n\ntranscription = model.transcribe(audio, task=task.value)\n```", "```py\n\nfrom utils import prepare_srt\nsrt_lines = prepare_srt(transcription, filter_duration=duration)\n# save transcription\nwith output_file.with_suffix(\".srt\").open(\"w\") as f:\n f.writelines(srt_lines)\nprint(\"\".join(srt_lines))\n```", "```py\n\nimport gradio as gr\ndef video_with_srt(t_video, t_srt):\n    return t_video, t_srt\ndemo = gr.Interface(\n    fn=video_with_srt,  # Pass the function reference\n    inputs=[\n        gr.Textbox(label=»Video File Path»),\n        gr.Textbox(label=»SRT File Path»)\n    ],\n    outputs=\"video\",\n    examples=[[‹downloaded_video.mp4›, ‹downloaded_video.srt›]],\n    allow_flagging=»never»\n)\ntry:\n    demo.launch(debug=True)\nexcept Exception as e:\n    print(e)\n    demo.launch(share=True, debug=True)\n```"]