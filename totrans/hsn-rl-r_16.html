<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Deep Q-Learning Using Keras</h1>
                </header>
            
            <article>
                
<p><span>Keras is a library of high-level neural networks, written in Python and able to work using different support libraries. It was developed to allow rapid experimentation. Keras allows easy and fast prototyping using total modularity, minimalism, and extensibility. It supports both convolutional networks and recurrent networks and combinations of both. Furthermore, it supports arbitrary connectivity schemes and runs smoothly on CPU and GPU. In this chapter, we will learn how to approach reinforcement learning using Keras. We will learn to use Keras to develop a model that can recognize handwritten digits. Later, we will use deep Q-learning to balance a cart pole.</span></p>
<p>In this chapter, we will cover the following topics:</p>
<ul>
<li>Introduction to Keras</li>
<li>Multilayer perceptron for image processing</li>
<li>Approaching deep-Q learning</li>
</ul>
<p class="mce-root">By the end of this chapter, we will have explored the Keras model using TensorFlow as the backend engine and how to use Keras to set up a <strong>Multilayer Perceptron</strong> (<strong>MLP</strong>) model. Then, we will learn how to use deep reinforcement learning to balance a cart pole system.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/2qMtw3I">http://bit.ly/2qMtw3I</a></p>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction to Keras</h1>
                </header>
            
            <article>
                
<p>Keras is a Python library that provides a simple and clean way to create a range of deep learning models. Keras code was released under the MIT license. Keras has been structured based on austerity and simplicity, and it provides a no frills programming model that maximizes readability. It allows neural networks to be expressed in a very modular way, considering a model as a sequence or a single graph. This is a good approximation because the components of a deep learning model are discrete elements that can be arbitrarily combined. New components are easily aggregated and modifiable within the framework designed for engineers, to quickly test and explore new ideas. Finally, using the Python programming language provides constructs that allow clear programming on both a small and large scale.</p>
<p>In the following screenshot, we can see the Keras official home page (<a href="https://keras.io/">https://keras.io/</a>):</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-452 image-border" src="assets/9c4131d3-f184-4443-a1d1-d6baaa8b0d6a.png" style="width:125.67em;height:77.08em;"/></p>
<p class="mce-root"/>
<p class="mce-root"/>
<p><span>Its</span> <span>ease of use is the strong point of Keras. During the design phase, the user has been the focus of the attention of the developers, producing a product that reduces the user's work using simple and consistent APIs. In this way, the number of actions necessary to solve common use cases is reduced. Also, the results are returned clearly, making the identification of possible errors very simple.</span></p>
<p>In Keras, a model is represented by a sequence of autonomous and completely configurable modules that can relate to the lowest possible number of restrictions. Everything in Keras is a module—neural layers, cost functions, optimizers, initialization schemes, activation functions, and regularization schemes. These independent modules can be combined to create new, more complex models.</p>
<p>All modules available in Keras are simple to add, and so are new classes and functions in a programming language. Also, the modules are already available and are accompanied by numerous examples that explain their practical use. But Keras is not limited to the availability of the built-in modules. The user will be able to easily create new modules, making Keras an easily extensible environment.</p>
<p>The <kbd>keras</kbd> library bases its technology on the levels that are used to manage input and output. An application in Keras can be implemented through the following four simple steps:</p>
<ol>
<li>Prepare input and output data.</li>
<li>Create the first level to manage the input data.</li>
<li>Set up intermediate levels to perform the analysis.</li>
<li>Create the output level to manage the targets.</li>
</ol>
<p>Keras works as a specific high-level API for neural networks. It can act as a user interface and can extend the functionality of other deep learning framework backends on which it runs. Thanks to this feature, Keras has become a wrapper for migration between frameworks. Not only can algorithms and models of neural networks for deep learning be exchanged but also networks and preliminary weights.</p>
<p>Wrapper libraries consist of a thin layer of code that translates a library's existing interface into a compatible interface.</p>
<p>On the other hand, since Keras is autonomous, it can be used without having to interact with the backend framework on which it is running. Keras has its own chart data structures for defining computational charts; it is not based on the data structures of the underlying backend framework. This way, you will not have to learn how to program the backend framework.</p>
<p class="mce-root"/>
<p>Keras is easy to learn and use. Using Keras is like working with LEGO® blocks; you just have to put in sequence a series of compatible modules. It was created so that people can quickly perform the experimental phase of models using a highly modular and extensible framework. Keras focuses on defining levels for neural networks. You do not have to deal with tensors, but it's easy to write with less code.</p>
<p>The backend takes care of complex mathematics and, in the next section, we will see how the TensorFlow <span>backend</span> works.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Keras backend in TensorFlow</h1>
                </header>
            
            <article>
                
<p>Keras is a model-level library that provides high-level blocks for the development of deep learning models. Keras developers have focused their efforts on creating high-level models by neglecting low-level operations such as tensor products and convolutions. These operations have been entrusted to specialized and well-optimized tensor manipulation libraries that already exist, hence acting as a backend engine for Keras. Several backend engines can be connected perfectly to Keras. Actually, Keras has three backend implementations available—TensorFlow, Theano, and Microsoft <strong>Cognitive Toolkit</strong> (<strong>CNTK</strong>).</p>
<p>TensorFlow is an open source software library for numerical calculation based on graph modeling (data flow graphs). A graph is defined as an abstract pipeline of mathematical operations operating on tensors and is known as a multidimensional array. Each graph consists of nodes and arcs, wherein the nodes are operations on the data, and the arcs represent the tensors that pass through the various operations.</p>
<p>You can find the updated version of the library and all of the documentation supplied at the following link: <a href="http://www.tensorflow.org">http://www.tensorflow.org</a>.</p>
<p>TensorFlow is the most commonly used library in the field of machine learning and neural networks. It has numerous APIs, including the lowest level, that is, TensorFlow Core, and allows complete control over programming. These APIs are those typically used in the field of machine learning since they make it possible to check in detail all of the elements of the model being implemented. The highest-level APIs are available and built from TensorFlow Core. In some cases, they can make some operations such as repetitive and predefined tasks faster and simpler, but generally preclude the possibility of going into detail, and in the implementation of a neural network, it is often necessary to have more precise control over operations. However, they can still be useful for the development of standard machine learning models.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>So, let's see how we can exploit the potential offered by the <kbd>keras</kbd> library in the R environment.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using Keras in R</h1>
                </header>
            
            <article>
                
<p>As we anticipated in the <em>Introduction to Keras</em> section, Keras is written in Python and is, therefore, the natural development environment in which to operate. Despite this, as with many libraries, an interface has been built that allows us to operate in the R environment using the potential of Keras. This is due to the great simplicity of use of the <kbd>keras</kbd> library technology, which makes the implementation of algorithms based on machine learning really simple and immediate.</p>
<p>To use Keras in R, we can use the interface available at the following URL: <a href="https://keras.rstudio.com/index.html">https://keras.rstudio.com/index.html</a>.</p>
<p>In the following screenshot, we can see the official home page of the R interface to Keras:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-453 image-border" src="assets/22a55595-eab5-4356-8977-8acc6b03873a.png" style="width:130.83em;height:66.33em;"/></p>
<p>It will be possible to retrieve all of the information needed to install the interface and to start using it. The simplicity with which it is possible to operate with the <kbd>keras</kbd> library will be confirmed in the next section, where we will see how to recognize handwritten digits using Keras.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Multilayer perceptron for image processing</h1>
                </header>
            
            <article>
                
<p>As we saw in <a href="91935d6b-70d6-4d61-b1b8-86d84470caf4.xhtml">Chapter 11</a>, <em>Exploring Deep Reinforcement Learning Methods</em>, the MLP is a feedforward artificial neural network. The simplest variant is the single-layer variant, which consists of a single layer of output nodes while the inputs are supplied directly to the units through a series of weights. The MLP is a type of network that provides for the presence of at least three levels connected to each other in feedforward—an input layer, a hidden layer, and output layers.</p>
<p>For each node, except those of the input layer, a non-linear activation function is used. In fact, if an MLP network has a linear activation function that maps the weighted inputs of each neuron into output, then even with multiple levels, it is considered a two-level input/output model. In the training phase, the weights of the connections are modified by processing the data contained in the model. The update is based on the amount of error present in the output compared to the expected result.</p>
<p>The error function is one that belongs to the space of the weights that measure how <span>reliable</span> <span>the network is at solving the problem in question. The task of the learning algorithm is to minimize this function, therefore, to find the point in the space of the weights at which the function has the global minimum point, or in some cases, a local minimum point may suffice.</span></p>
<p>To verify the potential of Keras in image processing, we will deal with a practical case of handwritten digit recognition. To do this, we will use a dataset widely used by the developer community—the MNIST dataset.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The MNIST dataset</h1>
                </header>
            
            <article>
                
<p>The <strong>Modified National Institute of Standards and Technology</strong> (<strong>MNIST</strong>) dataset is a large database of handwritten digits. It has a set of 70,000 examples of data. It is a subset of NIST's larger dataset. The digits are of 28x28 pixel resolution and are stored in a matrix of 70,000 rows and 785 columns; 784 columns form each pixel value from the 28x28 matrix, and one value is the actual digit. The digits have been size-normalized and centered in a fixed-size image.</p>
<p>The digit images in the MNIST set were originally selected and experimented with by Chris Burges and Corinna Cortes using bounding box normalization and centering. Yann LeCun's version uses centering by the center of mass within a larger window. The data is available on Yann LeCun's website at <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>.</p>
<p>The following diagram shows a sample of images of 0-8 from the MNIST dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-454 image-border" src="assets/c1de2216-a245-435b-89a3-4fcae011755d.png" style="width:32.25em;height:19.00em;"/></p>
<p>This dataset is already available in the <kbd>keras</kbd> library and contains 60,000 28x28 grayscale images of the 10 digits for the training, along with a test set of 10,000 images.</p>
<p>To start, we preprocess the data by preparing it adequately for the next use in the Keras model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Data preprocessing</h1>
                </header>
            
            <article>
                
<p>In this section, we will analyze the features of the MNIST dataset and we will learn how to prepare the data in a format compatible with Keras:</p>
<ol>
<li>Let's start importing the <kbd>keras</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">library(keras)</pre>
<ol start="2">
<li>To import the <kbd>mnist</kbd> dataset, we can use the following command:</li>
</ol>
<pre style="padding-left: 60px">MnistData &lt;- dataset_mnist()</pre>
<ol start="3">
<li>Let's take a look at what is contained in the dataset:</li>
</ol>
<pre style="padding-left: 60px">str(MnistData)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>List of 2</strong><br/><strong> $ train:List of 2</strong><br/><strong>  ..$ x: int [1:60000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</strong><br/><strong>  ..$ y: int [1:60000(1d)] 5 0 4 1 9 2 1 3 1 4 ...</strong><br/><strong> $ test :List of 2</strong><br/><strong>  ..$ x: int [1:10000, 1:28, 1:28] 0 0 0 0 0 0 0 0 0 0 ...</strong><br/><strong>  ..$ y: int [1:10000(1d)] 7 2 1 0 4 1 4 9 5 9 ...</strong></pre>
<p style="padding-left: 60px">Now we can see the dataset contains 60,000 observations for training and 10,000 for the test phase. Each observation represents a 28x28 pixel (<em>x</em>) image. The corresponding label (<em>y</em>) is provided for each observation.</p>
<ol start="4">
<li>Now, we will extract the four lists, and place them in four variables that represent our input and output data for the model we intend to process:</li>
</ol>
<pre style="padding-left: 60px">Xtrain &lt;- MnistData$train$x<br/>Ytrain &lt;- MnistData$train$y<br/>Xtest &lt;- MnistData$test$x<br/>Ytest &lt;- MnistData$test$y</pre>
<p style="padding-left: 60px">In <em>The MNIST dataset</em> section, we four said that the dataset contains 10 digits.</p>
<ol start="5">
<li>Let's verify it; we'll also analyze the distribution of these figures in the dataset:</li>
</ol>
<pre style="padding-left: 60px">table(Ytrain)<br/>table(Ytest)</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>Ytrain</strong><br/><strong>  0    1    2    3    4    5    6    7    8    9</strong><br/><strong>5923 6742 5958 6131 5842 5421 5918 6265 5851 5949</strong><br/><strong>Ytest</strong><br/><strong>   0    1    2    3    4    5    6    7    8    9</strong><br/><strong> 980 1135 1032 1010  982  892  958 1028  974 1009</strong></pre>
<ol start="6">
<li>Actually, we have 10 occurrences – the digits from 0 to 9. Furthermore, we can verify that the frequencies of each digit are comparable. To confirm this, we can trace a histogram:</li>
</ol>
<pre style="padding-left: 60px">hist(Ytrain)<br/>hist(Ytest)</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">The following diagram shows the histograms of the two distributions next to each other (<strong>YTrain</strong> on the left and <strong>YTest</strong> on the right):</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-455 image-border" src="assets/c39f2f5f-1669-4382-9a7f-ea3386cfb9ce.png" style="width:133.33em;height:46.42em;"/></p>
<p style="padding-left: 60px">By analyzing the previous diagram, we can see that the frequencies of the presence of 10 digits are equally distributed in the two datasets. As we said, each sample image consists of a 28x28 matrix.</p>
<ol start="7">
<li>To confirm this, we will extract the dimensions of the two input vectors:</li>
</ol>
<pre style="padding-left: 60px">dim(Xtrain)<br/>dim(Xtest)</pre>
<p style="padding-left: 60px">The following shapes are returned:</p>
<pre style="padding-left: 60px">&gt; dim(Xtrain)<br/><strong>[1] 60000    28    28</strong><br/>&gt; dim(Xtest)<br/><strong>[1] 10000    28    28</strong></pre>
<p style="padding-left: 60px">Hence, each observation contains the data relating to the 28x28 pixels in grayscale.</p>
<ol start="8">
<li>To reduce the dimensionality, we will flatten the 28x28 images into vectors of a size of <kbd>784</kbd>:</li>
</ol>
<pre style="padding-left: 60px">Xtrain &lt;- array_reshape(Xtrain, c(nrow(Xtrain), 784))<br/>Xtest &lt;- array_reshape(Xtest, c(nrow(Xtest), 784))</pre>
<p class="mce-root"/>
<p style="padding-left: 60px">The <kbd>array_reshape()</kbd> function reshapes a multi-dimensional array, using row-major (C-style) reshaping semantics by default. This function gives a new shape to an array without changing its data. The new shape should be compatible with the original shape. The first dimension of the new shape is the number of observations. The second dimension represents the product of the last two dimensions of the starting data (<em>28 x 28 = 784</em>).</p>
<ol start="9">
<li>To understand this transformation better, we print the shape of the transformed dataset:</li>
</ol>
<pre style="padding-left: 60px">dim(Xtrain)<br/>dim(Xtest)</pre>
<p style="padding-left: 60px">The following results are printed:</p>
<pre style="padding-left: 60px">&gt; dim(Xtrain)<br/><strong>[1] 60000   784</strong><br/>&gt; dim(Xtest)<br/><strong>[1] 10000   784</strong></pre>
<p style="padding-left: 60px">Now, we have to normalize all values between 0 and 1. The MNIST images are stored in pixel format, where each pixel (<span><span>in total,</span></span> 28x28) is stored as an 8-bit integer, giving a range of possible values from 0 to 255. Typically, 0 is taken to be black, and 255 is taken to be white.</p>
<ol start="10">
<li>The values in between make up the different shades of gray. Now, to normalize all values between 0 and 1, simply divide each value by 255. So, the pixel containing the value 255 will become 1, and the one containing 0 will remain as such; in between, lie all of the other values:</li>
</ol>
<pre style="padding-left: 60px">Xtrain &lt;- Xtrain / 255<br/>Xtest &lt;- Xtest / 255</pre>
<p style="padding-left: 60px">After preparing the input data, it is necessary to rearrange the output data. We have said that it represents the labels of the images. We have already seen that each image has been labeled with a number ranging from 0 to 9. To use these values in a Keras model, it is necessary to modify them.</p>
<ol start="11">
<li>A method to quantify each category of a qualitative predictor involves the creation of a binary variable, 0-1 (called a dummy variable), which indicates the presence or absence of the attribute in each statistical unit. Let's see how:</li>
</ol>
<pre style="padding-left: 60px">Ytrain &lt;- to_categorical(Ytrain, 10)<br/>Ytest &lt;- to_categorical(Ytest, 10)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">The <kbd>to_categorical()</kbd> function takes a vector or 1 column matrix of class labels and converts it into a matrix with <em>p</em> columns, one for each category. This is the format most commonly used in the fitting and predicting of neural networks. The dummy variable can take two values:</p>
<ul>
<li><span>0: If the attribute is absent</span></li>
<li>1: If the attribute is present</li>
</ul>
<p>Now, each observation will be a line of 10 values in which there are all zeros except in the column that identifies the digit that will contain 1.</p>
<p>After preparing the data, it is time to use them to train a Keras model.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Keras MLP model</h1>
                </header>
            
            <article>
                
<p>After adequately preprocessing the data, we can define the architecture of the Keras model. Keras is structured according to the object-oriented programming methodology. Therefore, the creation of a model is very simple: select the basic architecture and then add the layers necessary to create the desired model. As just mentioned, the sequential model lets you create a layer-by-layer model as a linear stack of layers. However, it is not possible to create models that share levels or that have multiple inputs or outputs. A sequential model is created by passing a list of layer instances to the constructor:</p>
<ol>
<li>First, we instantiate an object from the <kbd>keras_model_sequential</kbd> class:</li>
</ol>
<pre style="padding-left: 60px">KerasMLPModel &lt;- keras_model_sequential()</pre>
<p style="padding-left: 60px">All information about your network, such as weights, layers, and operations, will be stored in this object.</p>
<ol start="2">
<li>After instantiating our object, we will move on to adding layers:</li>
</ol>
<pre style="padding-left: 60px">KerasMLPModel %&gt;%<br/>  layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %&gt;%</pre>
<p style="padding-left: 60px">The <kbd>layer_dense()</kbd> function adds a densely-connected NN layer to an output. In a densely connected layer, every input is connected to every output by a weight, which is generally followed by a non-linear activation function. The first argument contains the dimensionality of the output space (units = 256). The second argument contains the activation function (<kbd>activation = 'relu'</kbd>). <strong>Rectified Linear Unit</strong> (<strong>ReLU</strong>) is the most used activation function since 2015. It's a simple condition and has advantages over the other functions.</p>
<p class="mce-root"/>
<ol start="3">
<li>Finally, the third argument contains the input shape (<kbd>input_shape = c(784)</kbd>). Recall that the first layer passed to a sequential model should have a defined input shape. Let's add the second layer:</li>
</ol>
<pre style="padding-left: 60px">layer_dropout(rate = 0.45) %&gt;%</pre>
<p style="padding-left: 60px">The dropout layer applies dropout to the input. Dropout consists of randomly setting a fraction rate of input units to 0 at each update during training time, which helps to prevent overfitting. Only one argument is passed. This is the rate, a float between 0 and 1. This indicates the fraction of the units to drop.</p>
<ol start="4">
<li>Then, a second dense layer is added:</li>
</ol>
<pre style="padding-left: 60px">layer_dense(units = 128, activation = 'relu') %&gt;%</pre>
<p style="padding-left: 60px">In this case, the input is not present, the number of output nodes is progressively resized, and the activation function is always <kbd>relu</kbd>.</p>
<ol start="5">
<li>Let's add another layer of dropout:</li>
</ol>
<pre style="padding-left: 60px">layer_dropout(rate = 0.3) %&gt;%</pre>
<ol start="6">
<li>Let's finish with a last dense layer:</li>
</ol>
<pre style="padding-left: 60px">layer_dense(units = 10, activation = 'softmax')</pre>
<p style="padding-left: 60px">In the preceding code block, the output units are 10 because there are 10 figures that the system must classify. The softmax function is a more generalized logistic activation function that's used for multiclass classification.</p>
<p style="padding-left: 60px">Now, we'll analyze the overall architecture of the Keras model we have defined. In Keras, to summarize a model, it is possible to use the <kbd>summary()</kbd> function. The summary is returned in text format and includes the following information:</p>
<ul>
<li>The layers and their order in the model</li>
<li>The output shape of each layer</li>
<li>The number of parameters (weights) in each layer</li>
<li>The total number of parameters (weights) in the model</li>
</ul>
<p style="padding-left: 60px">To print a summary of the model, we simply type the following command:</p>
<pre style="padding-left: 60px">summary(KerasMLPModel)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">The following screenshot shows the architecture of the Keras model defined:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-600 image-border" src="assets/95ad0254-26bd-45c4-9917-1754c45a09ec.png" style="width:28.25em;height:12.50em;"/></p>
<p style="padding-left: 60px">In the previous screenshot, we can clearly see the output shape and number of weights in each layer.</p>
<ol start="7">
<li>Before training a model, you need to configure the learning process, which is done via the <kbd>compile()</kbd> method, as follows:</li>
</ol>
<pre style="padding-left: 60px">KerasMLPModel %&gt;% compile(<br/>  loss = 'categorical_crossentropy',<br/>  optimizer = optimizer_rmsprop(),<br/>  metrics = c('accuracy')<br/>)</pre>
<p style="padding-left: 60px">The <kbd>compile()</kbd> method configures a Keras model for training. Three arguments are passed, as follows:</p>
<ul>
<li style="padding-left: 30px"><kbd>loss</kbd>: The <kbd>categorical_crossentropy</kbd> loss function is passed. When using <kbd>categorical_crossentropy</kbd>, your targets should be in categorical format. We have 10 classes; the target for each sample must be a 10-dimensional vector that is all zeros except for a one at the index corresponding to the class of the sample.</li>
<li style="padding-left: 30px"><kbd>optimizer</kbd>: <kbd>optimizer_rmsprop</kbd> is passed. This optimizer divides the learning rate by an exponentially decaying average of squared gradients.</li>
<li style="padding-left: 30px"><kbd>metrics</kbd>: The accuracy metric is passed. A metric is a function that is used to evaluate the performance of your model during training and testing.</li>
</ul>
<p style="padding-left: 60px">Now, we can move on to the training phase. First, you need to set some parameters:</p>
<pre style="padding-left: 60px">BatchSize &lt;- 128<br/>NumEpochs &lt;- 50</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px"><kbd>BatchSize</kbd> is the number of samples per gradient update. <kbd>NumEpochs</kbd> is the number of epochs to train the model. An epoch is an iteration over the entire input and output data provided.</p>
<ol start="8">
<li>To train the model, the <kbd>fit()</kbd> method is used, as follows:</li>
</ol>
<pre style="padding-left: 60px">ModelHistory &lt;- KerasMLPModel %&gt;% fit(<br/>  Xtrain, Ytrain,<br/>  batch_size = BatchSize,<br/>  epochs = NumEpochs,<br/>  verbose = 1,<br/>  validation_split = 0.3<br/>)</pre>
<p style="padding-left: 60px">The following arguments are passed:</p>
<ul>
<li style="padding-left: 30px"><kbd>Xtrain</kbd>: This is an array of input training data.</li>
<li style="padding-left: 30px"><kbd>Ytrain</kbd>: This is an array of target (label) data.</li>
<li style="padding-left: 30px"><kbd>epochs</kbd>: This is the number of epochs to train the model. An epoch is an iteration over the entire <em>x</em> and <em>y</em> data provided.</li>
<li style="padding-left: 30px"><kbd>batch_size</kbd>: This is the number of samples per gradient update.</li>
<li style="padding-left: 30px"><kbd>verbose</kbd>: This is an integer, either 0, 1, or 2. Verbosity mode would be: 0 = silent, 1 = progress bar, and 2 = one line per epoch.</li>
<li style="padding-left: 30px"><kbd>validation_split</kbd>: This is a float between 0 and 1, a fraction of the training data to be used as validation data.</li>
</ul>
<p style="padding-left: 60px">When the <kbd>fit()</kbd> function is used, the loss and the accuracy at the end of each training epoch are displayed, as shown in the following screenshot:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-599 image-border" src="assets/11594ff3-e351-44b9-9acd-37a6e8184684.png" style="width:53.92em;height:16.67em;"/></p>
<ol start="9">
<li>To get an idea of how the loss function and the accuracy vary during the epochs, it can be useful to create a plot of loss and accuracy on the training and validation phases, as follows:</li>
</ol>
<pre style="padding-left: 60px">plot(ModelHistory)</pre>
<p style="padding-left: 60px">The following diagram is plotted:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-457 image-border" src="assets/ea3218d3-57b5-4f45-b407-9ec1a34d1711.png" style="width:139.17em;height:102.50em;"/></p>
<p style="padding-left: 60px">We can see the evolution of the model for both subsets, as loss and accuracy vary.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="10">
<li>To evaluate the performance of the model we've just adapted, we use the <kbd>evaluate()</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">ScoreValues &lt;- KerasMLPModel %&gt;% evaluate(<br/>  Xtrain, Ytrain,<br/>  verbose = 0<br/>)</pre>
<ol start="11">
<li>This function returns the loss value and metrics values for the model in test mode. Computation is done in batches. Let's print loss and accuracy:</li>
</ol>
<pre style="padding-left: 60px">cat('Loss :', ScoreValues[[1]], '\n')<br/>cat('Accuracy:', ScoreValues[[2]], '\n')</pre>
<p style="padding-left: 60px">The following results are printed:</p>
<pre style="padding-left: 60px"><strong>Loss: 0.04588709</strong><br/><strong>Accuracy: 0.99245</strong></pre>
<p>The accuracy obtained confirms that a deep neural network can classify the handwritten digits.</p>
<p>In the next section, we will see how to use deep Q-learning to balance a cart pole.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Approaching deep Q-learning</h1>
                </header>
            
            <article>
                
<p>In <a href="91935d6b-70d6-4d61-b1b8-86d84470caf4.xhtml">Chapter 11</a>, <em>Exploring Deep Reinforcement Learning Methods</em>, we saw that deep Q-learning adopts a neural network as an approximation of a value function. These methods represent an evolution of the basic Q-learning method since the action-state table is replaced by a neural network, to approximate the optimal value function. Deep Q-learning only requires the state of the environment as an input and provides all of the status-action values as there are actions that can be performed in the environment. In this algorithm, therefore, the learning does not consist of updating the table but of adjusting the weights of the neurons that make up the network. This update takes place using the backpropagation technique.</p>
<p>To begin with, let's see how to install the library we will use as a first approach to deep Q-learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deep Q-learning in R</h1>
                </header>
            
            <article>
                
<p>To approach the DQN in R, we will use the <kbd>rlR</kbd> library. To use this library, Keras must be installed with TensorFlow as a backend on our machine. Furthermore, to run the example that we will propose, the OpenAI Gym library must be installed:</p>
<ol>
<li>To begin, we provide to install the <kbd>rlXR</kbd> library. The library is available on GitHub at the following URL: <a href="https://github.com/smilesun/rlR">https://github.com/smilesun/rlR</a>.</li>
<li>To install an R package available on GitHub, we can use the <kbd>install_github()</kbd> function available in the <kbd>devtools</kbd> package.</li>
<li>Then, we must first install the <kbd>devtools</kbd> package:</li>
</ol>
<pre style="padding-left: 60px">install.packages("devtools")</pre>
<p style="padding-left: 60px">The <kbd>devtools</kbd> package contains several functions for developing R packages. Using this library, many common tasks are greatly simplified.</p>
<ol start="4">
<li>At this point, we can use the <kbd>install_github()</kbd> function contained in <kbd>devtools</kbd>, as follows:</li>
</ol>
<pre style="padding-left: 60px">devtools::install_github("smilesun/rlR")</pre>
<p style="padding-left: 60px">This command will first download the package from the GitHub website and then install it. The function argument contains a text string that calls both the author and the package name.</p>
<ol start="5">
<li>Now, we can load the library:</li>
</ol>
<pre style="padding-left: 60px">library(rlR)</pre>
<p>As an example of the application of the method, we will use an OpenAI library environment, already introduced in <a href="47b30864-c93f-4e61-aa44-fa46b70508dd.xhtml">Chapter 8</a>, <em>Reinforcement Learning in Game Applications</em>. I refer to the <kbd>CartPole-v0</kbd> environment, which is a classic problem of reinforcement learning.</p>
<p class="mce-root"/>
<p>The system consists of a pole (which acts like an inverted pendulum) attached to a cart via a joint, as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-458 image-border" src="assets/4e2a9057-b551-4190-878e-5440690171ae.png" style="width:27.58em;height:15.58em;"/></p>
<p>The system is controlled by applying a force of +1 or -1 to the cart. The force applied to the cart can be controlled, and the objective is to swing the pole upward and stabilize it. This must be done without the cart falling to the ground. The balancing procedure involves the following actions: the agent moves the pole to the right or the left. A reward of 1 is returned for each time the pole is balanced. If the pole deviates by more than 15 degrees from the vertical position, the procedure ends. To balance the pole and therefore solve the problem, it is necessary to set the push in the opposite direction to the inclination of the pole:</p>
<ol>
<li>To load the <kbd>CartPole</kbd> environment using the OpenAI Gym library, simply type the following code:</li>
</ol>
<pre style="padding-left: 60px">CPEnv = makeGymEnv("CartPole-v0")</pre>
<ol start="2">
<li>We check what makes are available:</li>
</ol>
<pre style="padding-left: 60px">CPEnv</pre>
<p style="padding-left: 60px">The following information is returned:</p>
<pre style="padding-left: 60px"><strong>action cnt: 2</strong><br/><strong>state original dim: 4</strong><br/><strong>discrete action</strong></pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p style="padding-left: 60px">There are two actions (<kbd>action cnt: 2</kbd>); this agrees with what was said before. The system is controlled by applying a force of +1 or -1 to the cart. These are the two actions available. The second piece of information, <kbd>state original dim: 4</kbd>, tells us that the state of the system is characterized by four pieces of information, as follows:</p>
<ul>
<li>Cart position</li>
<li>Cart velocity</li>
<li>Pole angle</li>
<li>Pole velocity at the tip</li>
</ul>
<p style="padding-left: 60px">Finally, the third piece of information, <kbd>discrete action</kbd>, tells us that the space of action is defined by discrete choices. This makes the DQN the best solution to deal with this type of problem.</p>
<p style="padding-left: 60px">The environment we initialized contains several methods. For example, we can use the <kbd>step()</kbd> method, which performs an action and returns the state of the environment:</p>
<pre style="padding-left: 60px">CPEnv$step(1)</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>$state</strong><br/><strong>[1] -0.02800090 -0.17157109 -0.01648416  0.27999059</strong><br/><strong>$reward</strong><br/><strong>[1] 1</strong><br/><strong>$done</strong><br/><strong>[1] FALSE</strong><br/><strong>$info</strong><br/><strong>named list()</strong></pre>
<p>The returned values have the following meaning:</p>
<ul>
<li><kbd>$state</kbd>: This is an environment-specific object representing your observation of the environment.</li>
<li><kbd>$reward</kbd>: This is the amount of reward achieved by the previous action. The scale varies between environments, but the goal is always to increase your total reward.</li>
<li><kbd>$done</kbd>: This shows whether it's time to reset the environment again. Most (but not all) tasks are divided into well-defined episodes, and done being <kbd>True</kbd> indicates that the episode has terminated.</li>
<li><kbd>$info</kbd>: This is diagnostic information useful for debugging. It can sometimes be useful for learning.</li>
</ul>
<p> </p>
<p>At this point, we can elaborate on the model based on deep Q-learning:</p>
<p> </p>
<ol>
<li>Let's initialize the agent:</li>
</ol>
<pre style="padding-left: 60px">CPAgent = initAgent("AgentDQN", CPEnv)</pre>
<ol start="2">
<li>Let's analyze what the object we have instantiated contains:</li>
</ol>
<pre style="padding-left: 60px">str(CPAgent)</pre>
<p style="padding-left: 60px">We are given back so much information, we have highlighted only part of it:</p>
<pre style="padding-left: 60px"><strong>Classes 'AgentDQN', 'AgentArmed', 'Agent', 'R6' &lt;AgentDQN&gt;</strong><br/><strong> act_cnt: 2</strong><br/><strong> afterEpisode: function ()</strong><br/><strong> afterStep: function ()</strong><br/><strong> env: EnvGym, Environment, R6 epochs: 1</strong><br/><strong> gamma: 0.99 lr_decay: 0.999000499833375</strong><br/><strong> mem: ReplayMemUniform, ReplayMem, R6</strong><br/><strong> policy: PolicyEpsilonGreedy, Policy, R6</strong><br/><strong> replay: function (batchsize)</strong><br/><strong> sess: tensorflow.python.client.session.Session, tensorflow.python.client.session.BaseSession, tensorflow.python.client.session.SessionInterface, python.builtin.object</strong><br/><strong> state_dim: 4</strong><br/><strong> stopLearn: function ()</strong></pre>
<ol start="3">
<li>Analyzing this information in detail, we can obtain the functions available for this agent. After instantiating our agent, it is time to train it:</li>
</ol>
<pre style="padding-left: 60px">CPAgent$learn(500L)</pre>
<ol start="4">
<li><span>The next step is to train the agent for 500 episodes</span>. At the end of each episode, the following information is printed:</li>
</ol>
<pre style="padding-left: 60px"><strong>Episode: 472 finished with steps:200, rewards:200.000000 global step 44519 </strong><br/><strong>Last 100 episodes average reward 131.702970 </strong><br/><strong>Epsilon0.010000 </strong><br/><strong>rand steps:2 </strong><br/><strong>replaymem size GB:0.0388956144452095 </strong><br/><strong>learning rate: 0.000589783361647278</strong> </pre>
<ol start="5">
<li>Finally, we can print a graph showing how the reward varies in the episodes:</li>
</ol>
<pre style="padding-left: 60px">CPAgent$plotPerf(F)</pre>
<p style="padding-left: 60px">The following diagram is printed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-459 image-border" src="assets/bfc3ff40-8cf0-4522-a128-7145d4c72e83.png" style="width:141.00em;height:116.67em;"/></p>
<p>We can see that as the agent learns, the rewards obtained from the system increase, meaning that the agent is implementing the best policy to achieve the desired result.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned how to tackle a deep reinforcement learning <span>problem</span> <span>using Keras. To begin with, we explored the</span> <kbd>keras</kbd> <span>library and analyzed the TensorFlow backend. Next, we identified handwritten digits using a multilayered neural network using Keras. In this way, we could understand how a Keras model is structured with a practical example. In the final part of this chapter, we used the</span> <kbd>rlR</kbd> <span>library to apply deep reinforcement learning using the cart pole environment of the OpenAI Gym library.</span></p>
<p>In the next chapter, we will summarize what has been covered so far in this book, and what the next steps are from this point on. We will explore the next real-life challenges in the construction and implementation of machine learning models, and additional resources and technologies to learn how to improve our machine learning capabilities.</p>


            </article>

            
        </section>
    </body></html>