- en: 12\. Evolutionary Strategies for RL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will be identifying the limitations of gradient-based methods
    and the motivation for evolutionary strategies. We will break down the components
    of genetic algorithms and implement them in **Reinforcement Learning** (**RL**).
    By the end of this chapter, you will be able to combine evolutionary strategies
    with traditional machine learning methods, specifically in the selection of neural
    network hyperparameters, and also identify the limitations of these evolutionary
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we looked at various policy-based methods and their
    advantages. In this chapter, we are going to learn about gradient-free methods,
    namely genetic algorithms; develop these algorithms step by step; and use them
    to optimize neural networks and RL-based algorithms. This chapter discusses the
    limitations of gradient-based methods, such as getting stuck at local optima and
    slower convergence when dealing with noisy input. This chapter presents an alternative
    optimization solution to gradient methods through genetic algorithms, as they
    ensure global optimum convergence. You will examine and implement the structure
    of genetic algorithms and implement them through hyperparameter selection for
    neural networks and evolving network topologies, as well as using them in combination
    with RL for a cart-pole balancing activity. Hybrid neural networks that use genetic
    algorithms are used to solve complex problems, such as modeling plasma chemical
    reactors, designing fractal frequency selective surfaces, or optimizing production
    processes. In the following section, you will be examining the problems posed
    by gradient-based methods.
  prefs: []
  type: TYPE_NORMAL
- en: Problems with Gradient-Based Methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will learn about the differences between value-based and
    policy-based methods and the use of gradient-based methods in policy search algorithms.
    You will then examine the advantages and disadvantages of using gradient-based
    methods in policy-based approaches and implement stochastic gradient descent using
    TensorFlow to solve a cubic function with two unknowns.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two approaches when doing RL: value-based and policy-based. These
    approaches are used to solve complex decision problems related to **Markov Decision**
    **Processes** (**MDPs**) and **Partially Observable Markov Decision Processes**
    (**POMDPs**). Value-based approaches rely on identifying and deriving the optimal
    policy based on the identification of the optimal value function. Algorithms such
    as Q-learning or SARSA(Î») are included within this category, and for tasks involving
    lookup tables, their implementation leads to convergence on a return that is optimal,
    globally. As the algorithms rely on a known model of the environment, for partially
    observable or continuous spaces, there are no guarantees for convergence on a
    solution that is optimal using these value search methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, policy-based approaches, instead of relying on the value function
    to maximize the return, use gradient methods (stochastic optimization) to explore
    the policy space. Gradient-based methods or policy gradient methods map the parametrized
    space (environment) to the policy space using loss functions, thus enabling the
    RL agent to explore directly the entirety, or a portion, of the policy space.
    One of the most widely used methods (which is going to be implemented in this
    section) is gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'For further reading on gradient descent, please refer to the technical paper
    by *Marbach, 2001*, at the following link: https://link.springer.com/article/10.1023/A:1022145020786.'
  prefs: []
  type: TYPE_NORMAL
- en: The advantages of the gradient approaches (stochastic gradient descent or ascent)
    are that they are suitable for POMDPs or non-MDPs, especially for solving robotics
    problems with multiple constraints. However, there are several disadvantages to
    employing gradient-based methods. The most notable one is that algorithms such
    as **REINFORCE** and **DPG** determine a local optimum of the expected reward.
    As the local optimum is found, the RL agent does not expand its search globally.
    For example, a robot solving a maze problem will get stuck in a corner and will
    continuously try to move in the same location. Additionally, when dealing with
    high return variance or noisy input data, algorithm performance is affected as
    they converge slower. This happens when, for instance, a robotic arm is programmed
    to pick up and place a blue component in a tray, but the table has blue hues to
    its color, which interferes with the detection of the component through the sensors
    (such as a camera).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'For further reading on the **REINFORCE** algorithm, please refer to the technical
    paper by *Williams, 1992*, at the following link: https://link.springer.com/article/10.1007/BF00992696.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, please read about the **DPG** algorithm by *Silvester, 2014*, at
    the following link: http://proceedings.mlr.press/v32/silver14.pdf.'
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to gradient-based methods is the use of gradient-free methods,
    which rely on evolutionary algorithms to achieve a global optimum for the return.
  prefs: []
  type: TYPE_NORMAL
- en: The following exercise will enable you to understand the potential of gradient
    methods for converging on optimal solutions and the lengthy process that is undertaken
    as the method searches step by step for the optimal solution. You will be presented
    with a mathematical function (loss function) that maps the input values, ![1](img/B16182_12_00a.png),
    to an output value, ![2](img/B16182_12_00b.png). The goal is to identify the optimal
    values of the inputs that lead to the lowest value of the output; however, this
    is step-dependent and is at risk of staying at a local optimum. We will be using
    the `GradientTape()` function to calculate the gradients, which are nothing but
    differentiation solutions. This will help you understand the limitations of such
    optimization strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.01: Optimization Using Stochastic Gradient Descent'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This exercise aims to enable you to apply gradient methods, most notably **Stochastic
    Gradient Descent** (**SGD**), available in TensorFlow by following the steps required
    to converge on an optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following loss function has two unknowns, ![3](img/B16182_12_00c.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.1: Sample loss function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.1: Sample loss function'
  prefs: []
  type: TYPE_NORMAL
- en: Find the optimum values for ![4](img/B16182_12_01a.png) within 100 steps with
    a learning rate of `0.1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Jupyter Notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the `tensorflow` package as `tf`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that outputs ![5](img/B16182_12_01b.png) :'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for initializing the `x` and `y` variables and initialize
    them with the values `5` and `10`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have used decimal format for the values assigned
    to `x` and `y` to start the optimization process, as the `Variable()` constructor
    needs to have a tensor type of `float32`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Instantiate the optimizer by selecting `SGD` from `keras` in TensorFlow and
    input the learning rate of 0.1:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set a loop of `100` steps, where you calculate the loss, use the `GradientTape()`
    function for automatic differentiations, and process the gradients:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we have used `GradientTape()` from TensorFlow to calculate
    the gradients (which essentially are differentiation solutions). We created a
    loss parameter that stores the ![37](img/B16182_12_01c.png) value when calling
    the function. `GradientTape()` is activated when calling the `gradient()` method,
    which essentially is used to compute multiple gradients in a single computation.
    The gradients are stored in a `p_gradients` array.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `zip()` function to aggregate the gradients to the values:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the step and the values of ![6](img/B16182_12_01d.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the optimizer using the gradients that were processed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get the following output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.2: Step-by-step optimization using SGD'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16182_12_02.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 12.2: Step-by-step optimization using SGD'
  prefs: []
  type: TYPE_NORMAL
- en: You can observe in the output that from `Step=25` onward, the ![36](img/B16182_12_02a.png)
    values do not change; therefore, they are considered to be the optimum values
    for the respective loss function.
  prefs: []
  type: TYPE_NORMAL
- en: 'By printing the steps and values of the inputs and outputs, you can observe
    that the algorithm converges before the termination of the 100 steps to the optimal
    values of ![35](img/B16182_12_02a.png). However, you can observe that the problem
    is step-dependent: if the optimization is stopped before global optimum convergence,
    the solution would be sub-optimal.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2C10rXD](https://packt.live/2C10rXD).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2DIWSqc](https://packt.live/2DIWSqc).
  prefs: []
  type: TYPE_NORMAL
- en: This exercise helped your understanding and application of SGD when solving
    a loss function, developing your analysis skills as well as your skills in programming
    using TensorFlow. This will help you in your choice of optimization algorithm,
    giving you an understanding of the limitations of gradient-based methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we have explored the benefits and disadvantages of gradient
    methods with respect to RL algorithms, identifying the types of problems that
    they are suitable for within the context of decision-making processes. The example
    offered a simple application of gradient descent, where the optimal solution for
    two unknowns was identified using SGD optimization in TensorFlow. In the next
    section, we will be exploring an optimization alternative that is gradient-free:
    genetic algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Genetic Algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As the problem with gradient methods is that the solution can get stuck at a
    single local optimum, other methods, such as gradient-free algorithms, can be
    considered as alternatives. In this section, you will learn about gradient-free
    methods, specifically evolutionary algorithms (for example, genetic algorithms).
    This section provides an overview of the steps taken for the implementation of
    genetic algorithms and exercises on how to implement an evolutionary algorithm
    to solve the loss function given in the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: When multiple local optima exist or function optimization is required, gradient-free
    methods are recommended. These methods include evolutionary algorithms and particle
    swarm optimizations. A characteristic of these methods is that they rely on sets
    of optimization solutions that are commonly referred to as populations. The methods
    rely on iteratively searching for a good solution or a distribution that can solve
    a problem or a mathematical function. The search pattern for the optimal solution
    is modeled based on Darwin's natural selection paradigm and the biological phenomenon
    of genetic evolution. Evolutionary algorithms draw inspiration from biological
    evolution patterns such as mutation, reproduction, recombination, and selection.
    Particle swarm algorithms are inspired by group social behavior, such as a beehive
    organization or ant farms, where single solutions are termed as particles that
    can evolve over time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Natural selection stems from the premise that genetic material (the chromosome)
    encodes the survival of a species, in a certain way. The evolution of the species
    relies on how well it adapts to its external environment and the information passed
    from parents to children. In genetic material, there are variations (mutations)
    between generations that can lead to successful or unsuccessful adaptation to
    the environment (especially in dire conditions). Therefore, there are three steps
    to genetic algorithms: selection, reproduction (crossover), and mutation.'
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary algorithms go about things by creating an original population of
    solutions, selecting a sub-set, and using recombination or mutation to obtain
    different solutions. This new set of solutions can replace, partly or fully, the
    original set. For the replacement to take place, the solutions go through a selection
    process that relies on analyzing their fitness. This increases the chances of
    solutions that are more suited to being utilized to develop a new set of solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other than the development of solutions, evolutionary algorithms can be used
    for parameter adaptation, using probability distributions. A population is still
    generated; however, a fitness method is used to select the parameters of the distribution
    instead of the actual solutions. After the new parameters are identified, the
    new distribution is used to generate a new set of solutions. Some strategies of
    parameter selection include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Using natural gradient ascent after the gradients of the parameters are estimated
    from the original population, also known as **Natural Evolutionary Strategies**
    (**NESes**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting solutions with a specific parameter and using the mean of this sub-set
    to find a new distribution mean, known as **Cross-Entropy Optimization** (**CEO**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Attributing a weight to each solution based on its fitness, using the weighted
    average as a new distribution mean â **Covariance Matrix Adaptation Evolution
    Strategies** (**CMAESes**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One of the major problems identified with evolutionary strategies is that achieving
    solution fitness can be computationally expensive and noisy.
  prefs: []
  type: TYPE_NORMAL
- en: '**Genetic Algorithms** (**GAs**) keep the solution population and conduct searches
    in multiple directions (through the chromosomes), furthering the exchange of information
    in these directions. The algorithms are most notably implemented on strings, which
    are either binary or character-based. The two main operations performed are mutation
    and crossover. The selection of the progenies is based on how close the solution
    is to the target (objective function), which denotes their fitness.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an overview, GAs have the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Population creation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fitness score creation and assignment to each solution of the population.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The selection of two parents to reproduce based on the fitness scores (potentially
    the solutions with the best performance).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The creation of the two child solutions by combining and re-organizing the code
    of the two parents.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application of a random mutation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Child generation is repeated until the new population size is achieved and weights
    (fitness scores) for the population are assigned.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The process is repeated until the maximum number of generations is reached or
    the target performance is achieved.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will be looking at each of these steps in detail further in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Among the many differences between gradient-based algorithms and GAs, one difference
    is the process of development. Gradient-based algorithms rely on differentiation,
    whereas GAs use the genetic processes of selection, reproduction, and mutation.
    The following exercise will enable you to implement GAs and evaluate their performance.
    You will be using a simple genetic algorithm in TensorFlow to identify the GA
    hyperparameter optimization for finding the optimal solution for `tensorflow_probability`
    package.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.02: Implementing Fixed-Value and Uniform Distribution Optimization
    Using GAs'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, you will still need to solve the following function, as in
    the previous exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3: Sample loss function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.3: Sample loss function'
  prefs: []
  type: TYPE_NORMAL
- en: Find the optimum values for ![7](img/B16182_12_03a.png) for a population size
    of 100, starting from ![8](img/B16182_12_03b.png) initialized to 5 and 10, and
    then extending to random samples from a distribution similar to the gradient-based
    method.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal of this exercise is to enable you to analyze the differences in applying
    GAs and gradient-descent methods, by starting from a single pair of variables
    and a variety of potential solutions. The algorithm aids in optimization problems
    by applying selection, crossover, and mutation to reach an optimal or nearly optimal
    solution. Additionally, you will sample the values ![9](img/B16182_12_00c.png)
    from a uniform distribution for a population of 100\. By the end of this exercise,
    you will have evaluated the differences between starting from a fixed variable
    and sampling from a distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new Jupyter Notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the `tensorflow` package and download and import `tensorflow_probability`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function that outputs ![10](img/B16182_12_03d.png):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Identify the initial step by defining the ![11](img/B16182_12_03e.png) variables
    with values of 5 and 10:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the optimizer by selecting the `tensorflow_probability` optimizer
    named `differential_evolution_minimize`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the final values of ![34](img/B16182_12_03f.png), by using the `objective_value`
    and `position` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the application. You will get the following output. You can observe that
    the final values are identical to the `Step=25.0` value in *Figure 12.2*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this exercise, the final optimal solution will be displayed. There are no
    additional optimization steps needed to reach the same solution as the gradient-based
    method. You can see that you are using fewer lines of code and that the time taken
    for the algorithm to converge is shorter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For uniform optimization, the steps to modify the code are as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Import the `random` package:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the population size and create the initial population sampling the
    ![33](img/B16182_12_03h.png) variables from a random uniform distribution of the
    population size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the same optimizer, change the `initial_position` parameter to `initial_population`;
    use the same seed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the final values of ![12](img/B16182_12_03i.png), by using the `objective_value`
    and `position` functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will get the same result despite the variation in values. This means that
    we can randomly sample or choose a specific set of initial values, and the GA
    will still converge to the optimal solution faster, meaning we can improve our
    code by using fewer lines of code than if we'd used a gradient-based method.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2MQmlPr](https://packt.live/2MQmlPr).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2zpH6hJ](https://packt.live/2zpH6hJ).
  prefs: []
  type: TYPE_NORMAL
- en: The solution will converge to the optimal values irrespective of the initial
    starting point, whether using a fixed value for the inputs or a random sampling
    of the population of chromosomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section offered a general overview of evolutionary algorithms, explaining
    the differences between evolutionary strategies and GAs. You''ve had the opportunity
    to implement differential evolution using the `tensorflow_probabilities` package
    to optimize the solution of a loss function, analyzing the implementation of two
    different techniques: starting from fixed input values and using random sampling
    for the input values. You also had the opportunity to evaluate the implementation
    of GAs compared to gradient descent methods. GAs can use independent starting
    values and their convergence to a global optimum is faster and less prone to disturbances
    that gradient descent methods, whereas gradient descent is step-dependent and
    has higher sensitivity to the input variable.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will build on the principles of developing GAs,
    starting with a look at population creation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Components: Population Creation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you were introduced to evolutionary methods for function
    optimization. In this section, we will concentrate on population creation, fitness
    score creation, and the task of creating the genetic algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The population, ![32](img/B16182_12_03g.png), is identified as a group of individuals
    or chromosomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.4: Expression for the population'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.4: Expression for the population'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `s` represents the total number of chromosomes (population size) and `i`
    is the iteration. Each chromosome is a possible solution to the presented problem
    in an abstract form. For a binary problem, the population can be a matrix with
    randomly generated ones and zeros.
  prefs: []
  type: TYPE_NORMAL
- en: 'The chromosome is a combination of input variables (genes):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.5: Expression for the chromosome'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.5: Expression for the chromosome'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `m` is the maximum number of genes (or variables).
  prefs: []
  type: TYPE_NORMAL
- en: 'When translated to code, population creation can be demonstrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Each chromosome is then compared using a fitness function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.6: Fitness function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.6: Fitness function'
  prefs: []
  type: TYPE_NORMAL
- en: 'The fitness function can be translated to code as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: The output of the function is a score indicating how close the chromosome is
    to the target (optimal solution). The target is represented by the maximization
    of the fitness function. There cases where the optimization problem relies on
    minimizing a cost function. The function can be a mathematical one, a thermodynamic
    model, or a computer game. This can be done either by considering the chromosomes
    with low weightings (scores) or by adapting the cost function into a fitness one.
  prefs: []
  type: TYPE_NORMAL
- en: Once the fitness function is identified and defined, the evolution process can
    start. The initial population is generated. A characteristic of the initial population
    is diversity. To offer this diversity, the elements can be randomly generated.
    To make the population evolve, the iterative process starts by selecting the parents
    that offer the best fit to start the reproduction process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.03: Population Creation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will be creating an original population of binary chromosomes
    of length 5\. Each chromosome should have eight genes. We will define a target
    solution and output the similarity of each chromosome to it. This exercise aims
    to allow you to design and establish the first set of steps for a GA and find
    the binary solution that fits the target. The exercise is similar to matching
    the output of a control system with a target:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Jupyter Notebook. Import the `random` and `numpy` libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function for the random population:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for creating the target solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for calculating the fitness weighting for each chromosome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, you are comparing each chromosome of the population with
    the target and cataloging the similarity as a Boolean â `True` if similar or `False`
    if different â in the matrix called `identical_to_target`. Count all the elements
    that are true and output them as the weights.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Initialize the population with `5` chromosomes and `8` genes and calculate
    `weights`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code, we calculate `population`, `target`, and `weights` based
    on the three developed functions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Print the target solution, the index of the chromosome, the chromosome, and
    the weight using a `for` loop:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the application. You will get a similar output to this, as the population
    elements are randomized:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will notice that each chromosome is compared to the target and the similarity
    (based on the fitness function) is printed out.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2zrjadT](https://packt.live/2zrjadT).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2BSSeEG](https://packt.live/2BSSeEG).
  prefs: []
  type: TYPE_NORMAL
- en: 'This section showcased the first steps of genetic algorithm development: the
    generation of a random population, fitness score assignment for each element of
    the population (chromosome), and getting the number of elements that are the best
    fit compared to the target (in this case have the highest similarity with an optimal
    solution). The following sections will expand on the code generation that occurs
    until the optimal solution is reached. To do this, in the next section, you will
    explore the selection of the parents for the reproduction process.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Components: Parent Selection'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The previous section showcased the concepts of populations; we looked at creating
    a target solution and comparing that solution with the elements (chromosomes)
    of the population. These concepts were implemented in an exercise that will be
    continued in this section. In this section, you will explore the concept of selection
    and implement two selection strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the reproduction process (which is the quintessential part of GAs, as they
    rely on creating future generations of stronger chromosomes), there are three
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Parent selection
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Mixing the parents to create new children (crossover)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Replacing them with the children in the population
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Selection essentially consists of choosing two or more parents for the mixing
    process. Once a fitness criterion is selected, the way in which the selection
    of the parents will be performed needs to be chosen, as does how many children
    will come from the parents. Selection is a vital step in performing genetic evolution,
    as it involves determining the children with the highest fitness. The most common
    way to select the best individuals is by the "survival of the fittest." This means
    the algorithm will improve the population in a step-by-step manner. The convergence
    of the GA is dependent upon the degree to which chromosomes with higher fitness
    are chosen. Therefore, the convergence speed is highly dependent on the successful
    selection of chromosomes. If the chromosomes with the highest fitness are prioritized,
    there is a chance that a sub-optimal solution will be found; if the candidates
    have consistently low fitness, then convergence will be extremely slow.
  prefs: []
  type: TYPE_NORMAL
- en: 'The available selection methods are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Top-to-bottom pairing**: This refers to creating a list of chromosomes and
    pairing them two by two. The chromosomes with odd indexes are paired with the
    even chromosomes, thus generating mother-father couples. The chromosomes at the
    top of the list are selected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random Selection**: This involves using a uniform number generator to select
    the parents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random Weighted Selection or a Roulette Wheel**: This involves calculating
    the probability of the suitability of a chromosome compared to the entire population.
    The selection of the parent is done randomly. The probability (weight) can be
    determined either by rank or fitness. The first approach (see *Figure 12.7*) relies
    on the rank of the chromosome ![31](img/B16182_12_06a.png), which can constitute
    the index of the chromosome in the population list, and ![30](img/B16182_12_06b.png)
    represents the number of required chromosomes (parents):![Figure 12.7: Probability
    using rank'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '](img/B16182_12_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 12.7: Probability using rank'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second approach (see *Figure 12.8*) relies on the fitness of the chromosome
    (![29](img/B16182_12_07a.png)) compared to the sum of the fitness of the entire
    population ( ![28](img/B16182_12_07b.png) ):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.8: Probability using chromosome fitness'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_08.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.8: Probability using chromosome fitness'
  prefs: []
  type: TYPE_NORMAL
- en: 'As an alternative, the probability (see *Figure 12.9*) can also be calculated
    based on the fitness of the chromosome (![13](img/B16182_12_08a.png)) compared
    with the highest fitness of the population ![14](img/B16182_12_08b.png). In all
    of the cases, the probabilities are compared to the randomly selected numbers
    to identify the parents with the best weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.9: Probability using the highest fitness of the population'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_09.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.9: Probability using the highest fitness of the population'
  prefs: []
  type: TYPE_NORMAL
- en: '**Selection by Tournament**: This method is based on the random selection of
    a subset of chromosomes, out of which the chromosome with the highest fitness
    is selected as a parent. This repeats until the required number of parents is
    identified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The roulette wheel and tournament techniques are among the most popular selection
    methods implemented in GAs, as they are inspired by biological processes. The
    problem with the roulette technique is that it can be noisy, and depending on
    which type of selection is used, the convergence rate can be affected. A benefit
    of the tournament method is that it can deal with large populations, leading to
    smoother convergence. The roulette wheel method is used to include random elements
    in the population, whereas when you are aiming to identify the parents with the
    highest similarity to the target, you use the tournament method. The following
    exercise will enable you to implement the tournament and roulette wheel techniques
    and evaluate your understanding of them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.04: Implementing the Tournament and Roulette Wheel Techniques'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the exercise, you will implement the tournament and roulette wheel methods
    for the population of binary chromosomes of *Exercise 12.02, Implementing Fixed
    Value and Uniform Distribution Optimization Using GAs*. Each chromosome should
    have eight genes. We will define a target solution and print two sets of parents:
    one based on the tournament method and the other by roulette from the remaining
    population. Once each parent is chosen, set the fitness rank to the minimum:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Jupyter Notebook. Import the `random` and `numpy` libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function for the random population:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for creating the target solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for calculating the fitness weighting for each chromosome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for selecting the pair of parents with the highest weighting
    (the highest fitness score). Since the population is reduced, the chromosomes
    are competing more. This method is also known as tournament selection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function for the roulette wheel by selecting a random number from
    a uniform distribution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the function, calculate the sum of all the fitness scores:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Calculate the probability of the fitness of the chromosome compared to the
    sum of all fitness scores and compared to the chromosome with the highest fitness
    score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run through all the chromosomes and select the parent that has a higher fitness
    probability compared to the sum of fitness scores higher than the `draw`, or the
    parent with the highest probability compared to the maximum fitness score:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize `population`, calculate `target` and the fitness scores, and print
    the scores and `target`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get a similar output to this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the first selection method and print out the parents and the new scores:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will get a similar output to this for the tournament selection process:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can observe that for parent 1, the score has been replaced with `0`. For
    parent 2, the score stays the same.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the roulette function to select the next two parents and print out the
    parents and the weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will have a similar output to this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that parents 2 and 3 are the same. This time, the weight for the
    respective parent is changed to 0\. Additionally, parent 4 is selected and has
    its weighting changed to 0.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2MTsKJO](https://packt.live/2MTsKJO).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YrwMhP](https://packt.live/2YrwMhP).
  prefs: []
  type: TYPE_NORMAL
- en: With this exercise, you have implemented a tournament-like method, by selecting
    the parents with the highest scores, and the roulette wheel selection technique.
    Also, you have developed a method of avoiding the double-selection of the same
    chromosome. The first set of parents was chosen using the first method, whereas
    the second method was used in selecting the second set of parents. We have also
    identified a need for a method of replacing indexes to avoid double-selection
    of the same chromosome, which is one of the pitfalls of the selection process.
    This helped you to understand the differences between the two methods and allowed
    you to put into practice GA-related methods from population generation to selection.
  prefs: []
  type: TYPE_NORMAL
- en: 'Components: Crossover Application'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section expands on recombining the genetic code of the parents by means
    of crossover into children (that is, the creation of the two child solutions by
    combining and re-organizing the code of the two parents). Various techniques can
    be used to create new solutions for generating a new population. The binary information
    of two viable solutions in machine learning can be recombined by a process called
    crossover, which is similar to biological genetic exchange, where genetic information
    is transmitted from parents to children. Crossover ensures that the genetic material
    of a solution is transmitted to the next generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Crossover is the most common form of reproduction technique, or mating. Between
    the first and last bits of the parents (selected chromosomes), the crossover point
    represents the splitting point of the binary code that will be passed onto the
    children (offspring): the part to the left of the crossover point of the first
    parent will be inherited by the first child, and everything to the right side
    of the crossover point of the second parent will become the part of the first
    child. The left side of the second parent combined with the right side of the
    first parent results in the second child:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'There are multiple crossover techniques, as listed follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Single-point crossover (which you can see in the preceding code) involves splitting
    the genetic code of the parents at one point and passing the first part to the
    first child, and the second part to the second child. It is used by traditional
    GAs; the crossover point is identical for both chromosomes and is selected randomly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Two-point crossover involves two crossover points impacting the gene exchange
    between the two parents. The more crossover points are introduced, the more the
    performance of the GA can be reduced as the genetic makeup is lost. However, introducing
    two-point crossover can lead to a better exploration of the state or parameter
    space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-point crossover involves a number of splits. If the number of splits is
    even, then the splits are selected randomly and the sections in the chromosome
    are exchanged. If the number is odd, then the splits are alternating the exchanges
    of section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uniform crossover involves the random selection (as in a coin toss) of the parent
    that will provide an element of the chromosome (gene).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Three-parent crossover entails the comparison of each gene between two parents.
    If they have the same value, the child inherits the gene; if not, the child inherits
    the gene from the third parent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the following code example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code, we define the crossover function between two parents.
    We have defined the parents separately and then randomly assigned a certain point
    for crossover. Then, we have defined the children to be created by joining the
    parents at the defined crossover point.
  prefs: []
  type: TYPE_NORMAL
- en: In the following exercise, you will continue the process of implementing the
    components of GAs to create child chromosomes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.05: Crossover for a New Generation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will be implementing crossover between two parents, for
    a new generation. Following the steps from *Exercise 12.04, Implementing Tournament
    and Roulette Wheel*, and using the chromosomes with the highest weight, we will
    apply single-point crossover to create the first new set of children:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Jupyter Notebook. Import the `random` and `numpy` libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the function for a random population:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see in the previous code, we have created a `population` function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define a function to create the target solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for calculating the fitness weighting for each chromosome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for selecting the pair of parents with the highest weighting
    (highest fitness score). Since the population is smaller, the chromosomes are
    competing more. This method is also known as tournament selection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for crossover by using a randomly selected crossover point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the population with `5` chromosomes and `8` genes and calculate
    `weights`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Print the `target` solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the parents with the highest weight and print the final selection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the `crossover` function and print the children:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Run the application.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will get a similar output to that shown in the following snippet. As you
    can see, the population elements are randomized. Check that the elements of `Child
    1` and `Child 2` are the same as those of `Parent 1` and `Parent 2`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can check that the starting elements from the crossover point in the array
    of `Child 1` have the same array elements as `Parent 2`, and that `Child 2` has
    the same array elements as `Parent 1`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/30zHbup](https://packt.live/30zHbup).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3fueZxx](https://packt.live/3fueZxx).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we identified the various strategies for the recombination
    technique known as crossover. A basic implementation of single-point crossover,
    where the crossover point is randomly generated, was represented. In the following
    section, we will examine the last element of GA design: population mutation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Components: Population Mutation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous sections, you have implemented population generation, parent
    selection, and crossover reproduction. This section will concentrate on the application
    of random mutation and the repetition of child generations until a new population
    size is achieved and weights (fitness scores) for the population of the genetic
    algorithm are assigned. This section will include an explanation of the mutation
    technique. This will be followed by a presentation of the available mutation techniques
    as well as a discussion about population replacement. Finally, an exercise implementing
    mutation techniques will be presented.
  prefs: []
  type: TYPE_NORMAL
- en: A caveat of gradient methods is that the algorithms can stop at a local optimum
    solution. To prevent this from happening, mutations can be introduced to the population
    of solutions. Mutation generally occurs after the crossover process. Mutation
    relies on randomly assigning binary information in either a set of chromosomes
    or in the entire population. Mutation provides an avenue of problem space exploration
    by introducing a random change in the population. This technique prevents rapid
    convergence and encourages the exploration of new solutions. In the final steps
    (the last generations) or when the optimal solution is reached, mutation ceases
    to be applied.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various mutation techniques, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Single-point mutation (flipping) involves randomly selecting genes from different
    chromosomes and changing their binary values to their opposites (from 0 to 1 and
    1 to 0).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interchanging involves selecting two sections of the chromosome of one parent
    and swapping them, thus generating a new child.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also reverse a randomly selected segment within the parent or the population
    of chromosomes, and all the binary values are changed to their opposites.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The occurrence of a mutation is determined by its probability. The probability
    defines the frequency at which mutations occur within the population. If the probability
    is 0%, then after the crossover, the children are unaltered; if a mutation occurs,
    one or more parts of the chromosome or the population are changed. If the probability
    is 100%, then the entire chromosome is changed.
  prefs: []
  type: TYPE_NORMAL
- en: After the mutation process occurs, the fitness of the new children is calculated,
    and the population is altered to include them. This leads to a new generation
    of the population. Depending on the strategy used, the parents with the lowest
    fitness scores are discarded to leave room for the newly generated children.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.06: New Generation Development Using Mutation'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this exercise, we will be focusing on the development of a new generation.
    We will again create a new population, select two parent chromosomes, and use
    crossover to develop two children. We will then add the two new chromosomes to
    the population and mutate the entire population with a probability of 0.05:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Jupyter Notebook. Import the `random` and `numpy` libraries:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function for the random population:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to create the target solution:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to calculate the fitness weighting for each chromosome:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to select the pair of parents with the highest weighting
    (highest fitness score). Since the population is small, the chromosomes are competing
    more. This method is also known as tournament selection:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for crossover by using a randomly selected crossover point:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function for a mutation that uses the probability and the population
    as inputs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, the condition set for the mutation selection
    is to check that each element of the array is higher than the mutation probability
    which acts as a threshold. If the element is higher than the threshold, mutation
    is applied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Append the array of `children` to the original population, creating a new crossover
    `population`, and use the `print()` function to display it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, append `population` with `children`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The population will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the crossover population and the mutation probability of `0.05` to create
    a new population and display the mutated population:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, the threshold(mutation_probability) is 0.05\. Hence, if the
    elements are higher than this threshold, they will incur a mutation (so there
    is a 95% chance of the mutation occurring to the gene).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will get a similar output as the population elements are randomized. You
    can see that the chromosomes resulting from crossover are added to the original
    population and that after mutation, the population has the same number of chromosomes,
    but the genes are different. The crossover and mutation steps can be repeated
    until the target solution is reached by looping the functions. These cycles are
    also known as generations.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3dXaBqi](https://packt.live/3dXaBqi).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2Ysc5Cl](https://packt.live/2Ysc5Cl).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, mutation was described. The benefit of mutation is that it
    introduces random variation to chromosomes, encouraging exploration and helping
    to avoid local optima. Various mutation techniques were presented. The example
    we used showed the impact of mutation probability by implementing reverse mutation
    on a population after the crossover process was finalized.
  prefs: []
  type: TYPE_NORMAL
- en: Application to Hyperparameter Selection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will explore the use of GAs for parameter selection, especially
    when using neural networks. GAs are widely used for optimization problems in scheduling
    in both production and railway management. The solutions to these types of problems
    rely on creating a combination of neural networks and GAs as function optimizers.
  prefs: []
  type: TYPE_NORMAL
- en: The exercise in this section provides a platform for tuning hyperparameters
    for a neural network to predict wind flow patterns. You will apply a simple genetic
    algorithm to optimize the values of the hyperparameters used to train a neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: '**Artificial Neural Networks** (**ANNs**) model the biological processes and
    structures of neurons in the brain. The neurons in ANNs rely on a combination
    of input information (parameters) and weights. The product (which has an added
    bias) passes through a transfer function, which is a set of neurons arranged in
    parallel with each other to form a layer.'
  prefs: []
  type: TYPE_NORMAL
- en: For weight and bias optimization, ANNs use gradient descent methods for their
    training processes and backpropagation processes. This impacts the development
    of the neural network, as before training even commences, the neural network topology
    needs to be fully designed. Because the design is pre-set, some neurons may not
    be used in the training process, but they may still be active, therefore making
    them redundant. Additionally, neural networks using gradient methods can become
    stuck at a local optimum, and therefore need to rely on alternative methods to
    help them continue their processes, such as regularization, ridge regression,
    or lasso regression. ANNs are widely used in speech recognition, feature detection
    (whether for image, topology, or signal processing), and disease detection.
  prefs: []
  type: TYPE_NORMAL
- en: To prevent these problems and enhance the training of neural networks, GAs can
    be implemented. GAs are used for function optimization, while crossover and mutation
    techniques help with problem space exploration. Initially, GAs were used to optimize
    the weights and number of nodes of neural networks. For this, the chromosomes
    of the GA are encoded with possible variations of weights and nodes. The fitness
    function generated by the ANN relies on the mean squared error of the potential
    values and the exact values of the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: However, research has expanded to implementations of **Recurrent Neural Networks**
    (**RNNs**) and combining them with RL, aiming towards multi-processor performance.
    An RNN is a type of ANN that produces outputs that are not only a result of the
    weighting process of the input but also of a vector containing previous input
    and outputs. This enables the neural network to maintain prior knowledge of previous
    training instances.
  prefs: []
  type: TYPE_NORMAL
- en: GAs serve in expanding the topology of the neural networks beyond weighting
    adjustments. One example is EDEN, whereby encoding is done within the chromosome
    and the architecture of the network, and the learning rate achieves high accuracy
    rates on multiple TensorFlow datasets. One of the most challenging problems in
    training neural networks is the quality of the features (or input hyperparameters)
    that are fed to the network. If the parameters are not appropriate, the mapping
    of inputs and outputs will be erroneous. Therefore, GAs can act as a wrapper alternative
    to the ANNs by optimizing the selection of features.
  prefs: []
  type: TYPE_NORMAL
- en: The following exercise will teach you how to apply a simple genetic algorithm
    to identify the optimal parameters (window size and number of units) for an RNN.
    The genetic algorithm implemented is using the `deap` package, through the `eaSimple()`
    function, which enables you to create, using toolbox-based code, a simple GA that
    includes population creation, selection through the `selRandom()` function, reproduction
    through the `cxTwoPoint()` function, and mutation through the `mutFlipBit()` function.
    For comparing and hyperparameter selection, the `selBest()` function is used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.07: Implementing GA Hyperparameter Optimization for RNN Training'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Our goal in this exercise is to identify the best hyperparameters to use for
    an RNN using a simple genetic algorithm. In this exercise, we are using a dataset
    that was part of a weather forecasting challenge in 2012\. A single feature, `wp2`,
    is used in the training and validation of the parameters. The two hyperparameters
    used are the number of units and the window size. These hyperparameters represent
    the genetic material for the chromosome:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset can be found in the GitHub repository at the following link: https://packt.live/2Ajjz2F.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The original dataset can be found at the following link: https://www.kaggle.com/c/GEF2012-wind-forecasting/data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new Jupyter Notebook. Import the `pandas` and `numpy` libraries and
    functions:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: From the `sklearn` package, import `mean_squared_error` and `train_test_split`.
    Also, from the `tensorflow` and `keras` packages, import `SimpleRNN`, `Input`,
    `Dense` (from the `layers` folder), and the model (from the `Model` class). To
    create the GA, it is necessary to call from the `deap` package `base`, `creator`,
    `tools`, and `algorithms`. For statistics, we are using the Bernoulli equation;
    therefore, we will call `bernoulli` from the `scipy.stats` package. From `bitstrings`,
    we will call `BitArray`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use a random seed for model development; `998` is an initialization number
    for the seed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Load data from the `train.csv` file, use `np.reshape()` to modify the data
    into an array that only contains column `wp2`, and select the first 1,501 elements:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to split the dataset based on window size:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define a function to train the RNN to identify the optimal hyperparameters
    using a simple genetic algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The first step is identifying the sections of the chromosome pertaining to window
    size and the number of units. The next step is to return an extremely high fitness
    score, if there are no window sizes or the number of units. Split the two arrays
    into training and validation arrays with a 90:10 split.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Initialize the input features, and use the `SimpleRNN` model with the training
    dataset. For optimization, use the Adam algorithm with mean squared error as the
    loss function. To train the model, use the `fit` function with `5` for `epochs`
    and a batch size of `4`. To generate the predicted values, use the input values
    stored in `X_validate` in the `predict` function for the model. Calculate the
    `RMSE`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Instantiate the population size, the number of generations used for the genetic
    algorithm, and the length of the gene with `4`, `5`, and `10`, respectively:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use the toolbox available in the `deap` package to instantiate the genetic
    algorithm, `eaSimple()`. To do this, use the creator tool to instantiate the fitness
    function as `RMSE`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The last few lines of the output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The lower the `RMSE` value, the better the hyperparameters. The Bernoulli distribution
    serves to randomly initialize the chromosome genes. Based on the chromosome, the
    population is initialized. Within the toolbox, there are four steps for creating
    a new population: `cxTwoPoint()` refers to the parents crossing information at
    two points in a crossover), `mutFlipBit()` will only mutate one of the elements
    of the chromosome with a `0.6` probability of occurrence), `selRandom()` function),
    **evaluate** (this uses the RNN training function from *Step 6* and *Step 7*).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `selBest()` function for a single optimal solution, `k=1`, compare
    the solutions to the fitness function, and select the one with the highest similarity.
    To get the optimal window size and number of units, loop through the chromosome
    and convert the bit values to unsigned integers and print the optimal hyperparameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the application. You will get a similar output to what you see here. The
    initial values for the window size and number of units will be displayed. The
    GA will run using the RNN for the total number of epochs. At the end of each epoch,
    the `RMSE` value is displayed. Once all the epochs have executed, the optimal
    values are displayed:![Figure 12.10: Optimization of the window size and number
    of units using GA'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16182_12_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 12.10: Optimization of the window size and number of units using GA'
  prefs: []
  type: TYPE_NORMAL
- en: We started with an initial window size of `51` and `15` units; the optimal window
    size is reduced to `28`, and the number of units to `4`. The difference between
    the parameters based on `RMSE` is reduced to `0.05`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/37sgQA6](https://packt.live/37sgQA6).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/30AOKRK](https://packt.live/30AOKRK).
  prefs: []
  type: TYPE_NORMAL
- en: This section has covered combining GAs with neural networks as an alternative
    to using gradient descent methods. GAs mainly served in optimizing the number
    of neurons and weights for the neural networks, but their use can be expanded,
    through hybridization, to optimizing the structure of the network and hyperparameter
    selection. This exercise tested your ability to apply a genetic algorithm to find
    the optimal values of two features related to a weather forecasting problem. The
    features were used to train an RNN to estimate wind flow using RMSE values. In
    the following section, you will expand your knowledge of hybrid optimization techniques
    for the entire architecture of a neural network using NEAT.
  prefs: []
  type: TYPE_NORMAL
- en: NEAT and Other Formulations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Neuroevolution is a term that refers to evolving neural networks using GAs.
    This branch of machine learning is shown to outperform RL in various problems
    and can be coupled with RL, as it is a method for unsupervised learning. As mentioned
    in the previous section, neuroevolution systems concentrate on changing the weights,
    the number of neurons (in the hidden layers), and the topology of ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: '**Neuroevolution of Augmented Topologies** (**NEAT**) focuses on topology evolution
    for ANNs. It involves training a simple ANN structure, consisting of input and
    output neurons and units to represent the bias, but no hidden layers. Each ANN
    structure is encoded within a chromosome that contains node genes and connection
    genes (the mapping or link between two node genes). Each connection specifies
    the input, output, weight node, activation of the connection, and innovation number
    that serves as a link between genes for the crossover process.'
  prefs: []
  type: TYPE_NORMAL
- en: Mutations relate to the weights of the connections or the structure of the full
    system. Structural mutations can appear either by including a connection between
    two nodes that are not linked or by including a new node to a pre-existing connection,
    which causes two new connections to be built (one between the existing pair of
    nodes and one that includes the newly created node).
  prefs: []
  type: TYPE_NORMAL
- en: The crossover process entails the identification of common genes between different
    chromosomes within the population. This relies on the historical information about
    gene derivation, using a global innovation number. The genes resulting from the
    mutation receive incremented numbers from the gene they mutated, whereas through
    crossover, the genes keep their original numbers. This technique helps in solving
    the problems with gene matching that cause issues for neural network topologies.
    The genes that do not have the same innovation number are selected from the parent
    with the highest fitness. If both parents have the same fitness, the genes are
    selected randomly from each of the parents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chromosomes that have similar topologies are grouped based on how far apart
    they are ![15](img/B16182_12_10a.png); individuals are therefore evaluated based
    on the genes that are different ![16](img/B16182_12_10b.png), supplementary genes
    ![17](img/B16182_12_10c.png) , and the differences in weight ![18](img/B16182_12_10d.png)
    for the similar genes compared to the average number of genes ![20](img/B16182_12_10e.png).
    Each of the coefficients ![19](img/B16182_12_10f.png) acts as a weight that highlights
    the significance of each parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.11: Topology distance calculation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.11: Topology distance calculation'
  prefs: []
  type: TYPE_NORMAL
- en: 'To categorize the chromosomes into species, the distance ![21](img/B16182_12_11a.png)
    is compared with a threshold ![22](img/B16182_12_11b.png). If ![23](img/B16182_12_11c.png),
    then the chromosome belongs to the first species where this condition is fulfilled.
    To prevent species dominance, all the elements of the species need to have the
    same fitness level, which is calculated based on the number of members in the
    species. The evolution of the species (how many new chromosomes are included,
    ![24](img/B16182_12_11d.png) depends on the comparison between the fitness of
    the species, ![25](img/B16182_12_11e.png), and the average fitness of the population,
    ![26](img/B16182_12_11f.png):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.12: Calculation of the number of new chromosomes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.12: Calculation of the number of new chromosomes'
  prefs: []
  type: TYPE_NORMAL
- en: The advantage of NEAT is that, unlike neuroevolution algorithms that have a
    random set of topology parameters, it starts with the simplest topological form
    of a neural network and progressively evolves it to find the optimal solution,
    significantly reducing the number of used generations.
  prefs: []
  type: TYPE_NORMAL
- en: Evolving topology algorithms are categorized as **Weight Evolving Artificial
    Neural Networks** (**TWEANNs**), which include EDEN, **Cellular Encoding** (**CE**),
    **Enforced Subpopulations** (**SE**) â a fixed topology system (out of which NEAT
    outperforms the latter two on CartPole) â **Parallel Distributed Genetic Programming**
    (**PDGP**), and **Generalized Acquisition of Recurrent Links** (**GNARL**).
  prefs: []
  type: TYPE_NORMAL
- en: We will now see an exercise on applying NEAT to solve a simple XNOR gate, a
    logic gate that has a binary output. The binary inputs and output are quantified
    using a truth table, which is a representation of the sets of the functional values
    of Boolean logic expressions showcasing the combination of the logical values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 12.08: XNOR Gate Functionality Using NEAT'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the exercise, you will see the impact that NEAT has on solving a simple Boolean
    algebra problem. The problem involves implementing the NEAT algorithm to identify
    the optimal neural network topology for reproducing the binary output of an exclusive
    NOR (XNOR) gate. This is a type of logic gate where, when both inputs have the
    same signal (either 0 or 1 â equivalent to off and on, respectively), the output
    of the logic gate will be 1 (on), whereas when one of the inputs is high (1) and
    the other is low (0), the output will be 0 (off).
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following truth table for the XNOR logic gate:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.13: Truth table for the XNOR gate'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16182_12_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 12.13: Truth table for the XNOR gate'
  prefs: []
  type: TYPE_NORMAL
- en: Use the NEAT algorithm to create a feedforward neural network that can mimic
    the output of an XNOR gate.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In your Anaconda environment, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Create a new Jupyter Notebook.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import `print_function` from the `__future__` file, and import the `neat` and
    `os` packages:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Initialize the inputs and the output of the XNOR gate based on the truth table:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a fitness function that uses the squared difference between the actual
    output and the output of a feedforward neural network using NEAT:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new text file with the name `config-feedforward-xnor`. Include in
    the file the following parameters for the NEAT algorithm. For the fitness function,
    select the maximal value, with a threshold close to `4` and a population size
    of `200`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the same `config-feedforward-xnor` file, include the `sigmoid` function
    for node activation with a mutation rate of `0.01`. The aggregation options are
    mostly about adding the values, with a mutation rate of 0 for aggregation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set the `bias` parameters for the algorithm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For the bias, the minimum and maximum values are `-30` and `30`. Set the initial
    standard deviation at `0.05`, as low as possible, with a power of `0.5`, a mutation
    rate of `0.8`, and a replacement rate of `0.1`. These values are essential for
    implementing the genetic algorithm optimization.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Define the coefficients ![27](img/B16182_12_13a.png), as we are only considering
    the difference between the genes (how disjointed they are) and the difference
    in weights:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Include the information about topology, connection, and node inclusion or removal-related
    parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start with a simple network without any hidden layers and set the response
    parameters for the nodes and connections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Select the default parameters for the distance threshold, species fitness function,
    and parent selection. This is the final set of parameters to be included in the
    `config-feedforward-xnor` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, in the main code file, use the `config-feedforward-xnor` file to configure
    the NEAT formulation of the neural network and output each configuration of the
    network within `Exercise 12.08`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the population based on the configuration of the NEAT algorithm and include
    the progress to the terminal to monitor the statistical differences:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the algorithm for `200` generations and select the best solution for the
    neural network topology:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use functions to compare the output of the neural network with the desired
    output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the code and you will get a similar output to what you see here. As the
    chromosomes are populated randomly, the algorithm will converge to a nearly optimal
    solution in a different number of generations for you:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: By running this experiment, you can see that the conversion to a nearly optimal
    solution happened in less than the maximum number of generations (`200`). The
    output of the feedforward neural network is nearly optimal, as the values are
    integers. Their values are close to 1 and 0\. You can also observe that from a
    neural network with no hidden layers, the ANN has evolved to have `1149` nodes
    with various connections.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to https://packt.live/2XTBs0M.
  prefs: []
  type: TYPE_NORMAL
- en: This section does not currently have an online interactive example, and will
    need to be run locally.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, the NEAT algorithm, a neuroevolution algorithm that varies
    the topology of neural networks, was presented. What sets the NEAT algorithm apart
    from alternative TWEANNs is the way in which mutation, crossover, and selection
    take place to optimize the structure of the neural network, starting from a simple
    network with no hidden layers and evolving into a more complex one with an increased
    number of nodes and connections.
  prefs: []
  type: TYPE_NORMAL
- en: This exercise, which involved implementing NEAT to reproduce the output of an
    XNOR logic gate, enabled you to understand the structure of the NEAT algorithm
    and analyze the benefits and implications of applying neuroevolutionary techniques
    as alternatives to simple electronic problems. In the next section, you will test
    your programming abilities and your knowledge of GAs by solving the cart-pole
    problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 12.01: Cart-Pole Activity'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Automatic control is a challenge, especially when operating specific equipment
    using robotic arms or carts that are transporting equipment on a shop floor. This
    problem is often generalized as the cart-pole problem. You are going to program
    an automated cart to balance a pole. The goal is to maximize the time that the
    pole is balanced for. To solve this problem, an agent can use a neural network
    for the state-action mapping. The challenge lies in identifying the structure
    of the neural network and a solution for determining the optimal values for the
    weights, bias, and number of neurons for each layer of the neural network. We
    will use a GA to identify the best values for these parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'This activity aims to implement a GA for parameter selection for an ANN that,
    after 20 generations, can obtain a high average score for 500 trials. You will
    output the average scores for both the generations and the episodes, and you will
    monitor the convergence to an optimal policy by tuning the parameters of the neural
    network using a genetic algorithm in the form of a graph. This activity has the
    purpose of testing your programming abilities by implementing concepts from previous
    chapters and the current one. The following are the steps needed to implement
    this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Jupyter Notebook file and import the appropriate packages as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Initialize the environment and the state and action space shapes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to generate randomly selected initial network parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to generate the neural network using the set of parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to get the total reward for 300 steps when using the neural
    network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to get the fitness scores for each element of the population
    when running the initial random selection.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a mutation function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a single-point crossover function.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function for the next-generation creation by selecting the pair with
    the highest rewards.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the parameters within the function to construct the neural network that
    adds the parameters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build the neural network using the identified parameters and obtain a new reward
    based on the constructed neural network.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to output the convergence graph.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function for the genetic algorithm that outputs the parameters of the
    neural network based on the highest average reward.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function that decodes the array of parameters to each neural network
    parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Set the generations to 50, the number of trial tests to 15, and the number
    of steps and trials to 500\. You will get a similar output to this (only the first
    few lines are displayed here):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The plot of rewards against generations will be similar to the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 12.14: Rewards obtained over the generations'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16182_12_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 12.14: Rewards obtained over the generations'
  prefs: []
  type: TYPE_NORMAL
- en: 'The output for the average rewards (just the last few lines are shown here)
    will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 774.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have explored gradient-based and gradient-free methods
    of algorithm optimization, with an emphasis on the potential of evolutionary algorithms
    â in particular, GAs â to solve optimization problems, such as sub-optimal solutions,
    using a nature-inspired approach. GAs consist of specific elements, such as population
    generation, parent selection, parent reproduction or crossover, and finally mutation
    occurrence, which they use to create a binary optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: Then, the use of GAs for hyperparameter tuning and selection for neural networks
    was explored, helping us to find the most suitable window size and unit number.
    We saw implementations of state-of-the-art algorithms that combined deep neural
    networks and evolutionary strategies, such as NEAT for XNOR output estimation.
    Finally, you had a chance to implement what was studied in this chapter through
    an OpenAI Gym cart-pole simulation, where we examined the application of GAs for
    parameter tuning with action selection using a deep neural network.
  prefs: []
  type: TYPE_NORMAL
- en: The development of hybrid methods in RL systems is one of the most recent optimization
    developments. You have developed and implemented optimization methods for model-free
    RL systems. In the bonus chapter (which is available on the interactive version
    of the workshop at [courses.packtpub.com](http://courses.packtpub.com)), you will
    be exploring model-based RL methods and state-of-the-art advances in deep RL for
    control systems that can be applied in the robotics, manufacturing, and transportation
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: You are now capable of applying the concepts that you learned about in this
    book using various coding techniques and various models that can help further
    enhance your field of expertise and potentially bring new changes and advancements.
    Your journey has just begun â you have taken the first steps to deciphering the
    world of RL, and you now have the tools to enhance your Python programming skills
    for RL, all of which you can independently apply.
  prefs: []
  type: TYPE_NORMAL
