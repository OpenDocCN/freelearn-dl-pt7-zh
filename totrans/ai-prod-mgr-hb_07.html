<html><head></head><body>
		<div id="_idContainer023">
			<h1 id="_idParaDest-118" class="chapter-number"><a id="_idTextAnchor219"/>7</h1>
			<h1 id="_idParaDest-119">Productizing the ML Service<a id="_idTextAnchor220"/></h1>
			<p>In <a href="B18935_06.xhtml#_idTextAnchor175"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, we briefly touched upon the notion of productizing and what that means for AI outputs in the <em class="italic">Productizing AI-powered outputs – how AI product management is different</em> section. We will be expanding on that concept in this chapter by exploring the trials and tribulations that may come up when building an AI product. Rather than thinking of AI products as traditional software products, it helps to think of them as a service that you’re learning to productize. What this refers to is the ability to create a consistent workflow that you can rely on to deliver consistent results in the way traditional <span class="No-Break">products demand.</span></p>
			<p>We will be going more in depth into product management principles and aligning them to the idiosyncrasies of <span class="No-Break">AI/ML services.</span></p>
			<p>By the end of this chapter, we will have an understanding of the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>Understanding the differences between AI and traditional <span class="No-Break">software products</span></li>
				<li>B2B versus B2C – productizing <span class="No-Break">business models</span></li>
				<li>Consistency and AIOps/MLOps – reliance <span class="No-Break">and trust</span></li>
				<li>Performance evaluation – testing, retraining, and <span class="No-Break">hyperparameter tuning</span></li>
				<li>Feedback loop – <span class="No-Break">relationship building</span></li>
			</ul>
			<h1 id="_idParaDest-120"><a id="_idTextAnchor221"/>Understanding the differences between AI and traditional software products</h1>
			<p>There are a number of differences<a id="_idIndexMarker292"/> between traditional software<a id="_idIndexMarker293"/> products and AI/ML products. In the following subsections, we’ll first go over how they’re similar, and then we’ll note the differences between the two to give us a well-rounded sense of what to expect when you’re product managing an AI/ML product. This will help us establish a baseline as well as a deviation from traditional PM work. When you’re a PM, you’re often tasked with being the person to maintain an intuition about your product and how it will grow and evolve through the process of building and shipping the product and working with your <span class="No-Break">engineering team.</span></p>
			<p>Part of that intuition will relate to how you will market and sell your product, what kinds of customer needs and issues your product can anticipate, as well as potential problems that might arise as you start to get into the weeds with building and marketing your AI product. Many PMs might not be aware of the demands AI/ML products will place on them, and this section is primarily aimed at helping PMs build this intuition as they start to navigate the world of <span class="No-Break">AI/ML products.</span></p>
			<p>It’s also important to note that traditional software products and AI products are increasingly blurring together. This is because most software companies have already started to integrate AI/ML into their existing products or launched AI native products. PMs that cover a wide variety of products will want to deepen their knowledge of AI/ML as a way to stay competitive within their own fields, whether they plan to go deep into AI or not. Understanding the differences between traditional software and AI products isn’t so much about comparing<a id="_idIndexMarker294"/> two disparate groups<a id="_idIndexMarker295"/> of products. It’s helpful in this case as well, but this is a macro trend, and the biggest reason for understanding the two is to anticipate how all products will evolve with AI. Let’s begin by checking out how traditional software products are similar <span class="No-Break">to <a id="_idTextAnchor222"/>AI.</span></p>
			<h2 id="_idParaDest-121"><a id="_idTextAnchor223"/>How are they similar?</h2>
			<p>There are a number of similarities<a id="_idIndexMarker296"/> between traditional software products and AI products because, fundamentally, AI products are traditional software products with a productized AI/ML service built in. For this reason, the similarities we will outline here involve agile product development as well as data. Native AI products, along with the outputs from the AI pipelines that support them, follow the same building process most traditional software products use. They are also built with a heavy focus on the data that powers them. This is still true for traditional <span class="No-Break">software produc<a id="_idTextAnchor224"/>ts.</span></p>
			<h3>Agile development</h3>
			<p>In traditional software<a id="_idIndexMarker297"/> development, you’re going to follow some methodology to ideate, keep track of your work, and stay consistent with some framework or schedule. Most software companies these days don’t use waterfall methodology anymore and have instead opted to use some version of agile, scrum, or lean methodology. This means most software companies are using an iterative and experimental approach to building and shipping products. They’re taking large overarching business goals and translating those goals into specific tasks that will then amount to deliverables by the end of any given sprint. Once they have these deliverables done, they undergo a process of evaluation to make sure they meet varying expectations <span class="No-Break">through testing.</span></p>
			<p>The heart of this approach is agility. When you’re building out features of your product over time, you have time to test those features both functionally and conceptually. This is an economical way of spending time, energy, and resources on a product or a feature to then see how it’s received by your customer base and greater market. The agility this offers is what allows tech companies to be successful: they are able to make changes and adjustments as they build if they’re seeing that their product or feature isn’t resonating with their audience of users. This will be true whether or not your product supports <span class="No-Break">AI/ML features.</span></p>
			<p>We’d even go a step beyond this and say AI/ML takes the heart of this agility to the next level. Because AI/ML products are consistently building from prior manifestations, they’re constantly evolving and adapting<a id="_idIndexMarker298"/> to new demands on performance, accuracy, or speed. You can’t build an AI product in a vacuum. Over time, AI products will have many transformations, and because of this, they’re always in a state of being updated or upgraded to meet the expectations of <span class="No-Break">their out<a id="_idTextAnchor225"/>puts.</span></p>
			<h3>Data</h3>
			<p>Then there’s the similarity<a id="_idIndexMarker299"/> of data. Even if certain software products aren’t heavily dealing with your personal data, they are often built as data products in the sense that they are leveraging and storing some data about you or the entire user base to some degree to make certain determinations. Traditional software development will have some feedback loop to a database or be built upon a data pipeline of some kind that is passing information back and forth from its UI to some centralized (or decentralized) repository of <span class="No-Break">some kind.</span></p>
			<p>This means that software engineers are working with massive volumes of data in addition to working with source code. We’ve discussed the data demands AI/ML products have at length over the course of this book, but it’s important to note that this is inherently true of most software products out there. Software products are consistently using and accounting for data, whether or not it’s a “data” or an “AI/ML” product. Acquiring this data from your initial customers if you’re launching a new product is going to be true<a id="_idIndexMarker300"/> whether or not you’re building an applied AI product. Now that we have looked at how the two are similar, let’s check out what differentiates traditional software products <a id="_idTextAnchor226"/><span class="No-Break">from AI.</span></p>
			<h2 id="_idParaDest-122"><a id="_idTextAnchor227"/>How are they different?</h2>
			<p>While AI products<a id="_idIndexMarker301"/> are built on a foundation of traditional software development for the most part, they do have a number of key differences you should be aware of as a PM. AI is able to evolve a traditional software product, and<a id="_idIndexMarker302"/> you’ll hear this referred to as <em class="italic">applied AI</em> in product circles. What this means is applications of AI outside of a research setting or lab that are used in the building of tech products. Essentially, the concept of putting AI/ML to use, testing and optimizing the models for accuracy and precision, and evolving it over time through feedback loops is what constitutes <span class="No-Break">applied AI.</span></p>
			<p>The following sections will cover the biggest differences between traditional software products and AI products, which surround scalability, profit margins, <span class="No-Break">and un<a id="_idTextAnchor228"/>certainty.</span></p>
			<h3>Scalability</h3>
			<p>One of the major differences<a id="_idIndexMarker303"/> between applied AI products and traditional software products is in the area of scalability. Because AI is so specific and sensitive to the quality and peccadilloes of the training data, you’re likely going to have issues with scaling this kind of product because you’re likely to encounter so many edge cases that you have to go back to the drawing board or start to create cohorts<a id="_idIndexMarker304"/> within your user base. This has led to what <em class="italic">AI Forum</em> (<a href="https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/">https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/</a>) refers to as a <strong class="bold">collective AI fatigue</strong> from people that are working directly<a id="_idIndexMarker305"/> on developing AI but also with leadership and the market at large itself that all stems from the issue of scalability when applied for <span class="No-Break">commercial uses.</span></p>
			<p>This issue lies not just in the challenge AI poses with accuracy; indeed, you need a lot of data for advanced ML and DL models to work well and give you good performance, but you also need those models to be robust enough to work with a generalized population of users, situations, contexts, and locations. In traditional software products, you might not need this level of granularity to see success, but with applied AI products you might get the sense that in a perfect world, you might need a highly personalized model for every user or <span class="No-Break">use case.</span></p>
			<p>This sense might<a id="_idIndexMarker306"/> not be that far off from an optimal reality. What this also means is that AI is particularly sensitive to the idea of edge cases, and the threshold for what even constitutes an edge case might be lower for AI products compared to their traditional software counterparts. While edge cases impact all software products, traditional software companies do have an inherent advantage in that they’re iterative, so once you build and ship a product, you’re able to sell it to virtually all your customers without having to do a lot <span class="No-Break">of customization.</span></p>
			<p>We will go over the differences in business models later on in this chapter, but this issue of scalability is doubly affected by your choice of business model. For instance, if you’re a B2B company, your AI product might behave wildly differently when compared to other customers because their training data differences might be too great. If we contrast this with a B2C company, you might be training your models on really representative and diverse data, but then the way your individual consumers interact with your product might <span class="No-Break">vary wildly.</span></p>
			<p>Whether an issue with the training data or the way end users work with your product, the issue is the same: you’re having to account for so many perspectives and demands on your product from outside influences that it makes the scaling of the models used almost impossible while keeping with one consistent product build. Even the issue of agreeing on an acceptable level of product performance will likely be time, cost, and energy inefficient, let alone actually acquiring those levels of accuracy you’ll need to end up with a product that’s consistent enough to sell as <span class="No-Break">an MVP.</span></p>
			<p>Getting to a level of trust where your earliest customers will see the value in your product enough to consistently use it will require a lot of initial work, and you don’t have guarantees that this intensive customer acquisition will necessarily dissipate as it might with traditional software products. With applied AI products, the process of acquiring and keeping your customers may stay at a consistently grueling pace, which further contributes to this issue of scalability up to a certain point. Strides are being made, however, to build and discover ways to improve models that are less reliant on massive hoards <span class="No-Break">of data.</span></p>
			<p>According<a id="_idIndexMarker307"/> to <em class="italic">AI Forum</em> (<a href="https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/">https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/</a>): “<em class="italic">Data can be expensive to collect, requiring annotation and labelling (by clinicians in healthcare), cleaning, and preparation which can contribute 50% of AI training costs. Consent from data owners (e.g. patients) is needed to use their private data, and additional incentives are sometimes required for data custodians to share the data. Data privacy and security laws can introduce barriers to sharing, storing, accessing and handling </em><span class="No-Break"><em class="italic">the data.</em></span><span class="No-Break">”</span></p>
			<p>This reinforces the idea that the quantity of data itself is secondary to the commercial success of scalable AI products compared to the quality and diversity of the training data. It doesn’t just need to be standardized in a way that’s uniform across your data sample, it also needs to have enough representative data points that encompass the diversity of users as well—the idea being that the more diverse your data is, the more it will be able to anticipate the needs and uses of the general users that will experience it once it is deployed to the <span class="No-Break">greater public.</span></p>
			<p>Access to clean data is easier said than done. Most real-world datasets are riddled with data<a id="_idIndexMarker308"/> hygiene issues. Tableau (<a href="https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled">https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled</a>) offers a great<a id="_idIndexMarker309"/> summary of how to solve this: “<em class="italic">Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset. When combining multiple data sources, there are many opportunities for data to be duplicated or mislabeled. If data is incorrect, outcomes and algorithms are unreliable, even though they may look correct. There is no one absolute way to prescribe the exact steps in the data cleaning process because the processes will vary from dataset </em><span class="No-Break"><em class="italic">to dataset.</em></span><span class="No-Break">”</span></p>
			<p>AI/ML products are particularly<a id="_idIndexMarker310"/> sensitive to the quality of data, and this is further exacerbated by the issue of deliberate tampering or data poisoning in which end users attack AI/ML systems to intentionally manipulate the training data <a id="_idTextAnchor229"/>that <span class="No-Break">powers them.</span></p>
			<h3>Profit margins</h3>
			<p>We’ve discussed the costs associated<a id="_idIndexMarker311"/> with building out an AI organization, which you’ll have to do if you’re building applied AI products. These costs are some of the biggest differentiators between traditional software products and applied AI products. Because these costs can be so high, they will impact your margins. KeyBanc Capital Markets’ 2021 survey of 354 private SaaS companies found that the profit margins for most companies were seeing gross <a id="_idIndexMarker312"/>profit margins of 80%, and those margins fell to between 68% and 75% when accounting for customer <span class="No-Break">support/success (</span><a href="https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25"><span class="No-Break">https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25</span></a><span class="No-Break">).</span></p>
			<p>This number falls dramatically for AI products even in the best of circumstances, when companies are running optimally. To paint a picture of what can go wrong, the best example<a id="_idIndexMarker313"/> we were able to find came from <em class="italic">Harvard Business Review</em> (<a href="https://hbr.org/2022/03/how-to-scale-ai-in-your-organization">https://hbr.org/2022/03/how-to-scale-ai-in-your-organization</a>), which mentioned “<em class="italic">…one financial company lost $20,000 in 10 minutes because one of its machine learning models began to misbehave. With no visibility into the root issue — and no way to even identify which of its models was malfunctioning — the company was left with no choice but to pull the plug. All models were rolled back to much earlier iterations, which severely degraded performance and erased weeks of effort.</em>” Imagine losing that much money in such a short time and still not being able to know where the <span class="No-Break">problem was!</span></p>
			<p>With that said, there are aspects of applied AI that are more profitable than others. According to <em class="italic">Forbes</em> (<a href="https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4">https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4</a>), the area where we see the fastest return on applied AI is when it supports customer behavior, which makes sense because it directly impacts sales and is one of the highest revenue drivers. This would be use cases of applied AI such as product recommendations, scaled pricing algorithms, or advertising personalization/optimization that are bringing in more traffic to your website or helping customers with choosing more products based on their specific spending and purchasing habits, cost consciousness, or tastes <span class="No-Break">and preferences.</span></p>
			<p>The more medium-term payoff of applied AI is when AI is used to improve a product or make a user’s experience better in some way. This could look like product automation that boosts users’ productivity. For most of this book, we’ve been talking about these applications of AI because they directly impact an individual product and its performance. As a PM, this is likely the primary area you are focused on when it comes to applied AI and where the best place for it to fit is as far as your product’s performance and standing with customers and with your greater market is concerned. Because this essentially poses a medium-term payoff, and because your AI costs will be front-loaded for the most part, you’ll have to manage expectations with your engineering, leadership, and customer-facing teams from both a revenue and <span class="No-Break">performance perspective.</span></p>
			<p>Finally, the most long-term payoff of applied AI is when it affects the reputation of the company. This means AI is applied in a way that boosts a company’s trust reputationally, particularly when compared to its competitors and peers in the same space. But acquiring this level of AI supremacy is time intensive, and it sheds light on the double-edged sword of AI. Eventually, your competitors will catch on and will pay to play in your arena as well. This is the nature of competition, and as PMs, we understand that our products are scrutinized in the market, and <span class="No-Break">rightly so.</span></p>
			<p>That being said, these areas of profitability aren’t exactly siloed. The short-term advantages of AI that we just discussed can also bleed into this area if your product specializes in marketing, recommendation systems, or advertising, for instance. The long-term advantages of AI that we discussed next can also apply to integrating applied AI into your product if what the premium AI offers your product is so great that it impacts your reputational standing in your chosen market or vertical. As a PM, technologist, or entrepreneur, you’re going to have to grapple with the costs AI poses as well as its advantages and create a plan for how you want to start leveraging <span class="No-Break">applied AI.</span></p>
			<p>As you’re getting started, one of the best ways to do this is to first understand the benefits AI can offer your product and company at large and then draft your own version of this plan and pitch it to your leadership. Communicating the effectiveness of AI and your understanding of how it will impact profitability will help you gain credibility in your own organization, and it will offer an avenue for your stakeholders to be able to understand the challenges and opportunities and ultimately contribute to <span class="No-Break">the plan.</span></p>
			<p>Once you have this plan, you can start keeping<a id="_idIndexMarker314"/> track of the relative profitability of the various areas AI is applied to and have champions/supporters within your organization that help keep visibility of AI. If you can all agree on a specific appetite for AI spending and margin threshold tolerance, it will be easier to navigate the AI waters as you continue down your applied AI journey because it will force you to invest in AI in cases where there’s data, economic returns, and excitement to keep it going. And it will keep you<a id="_idTextAnchor230"/>r finance<a id="_idIndexMarker315"/> <span class="No-Break">team happy.</span></p>
			<h3>Uncertainty</h3>
			<p>The last big difference<a id="_idIndexMarker316"/> is conceptual. AI introduces a whole lot of uncertainty to the work of product management. With traditional software products, the deterministic qualities of a product are hardcoded. Algorithms still exist, but they’re not improving or learning over time. They are static. With AI products, these qualities are more fluid. There’s a level of expectation setting and performance that has to be agreed upon, expressly or intuitively, by the builders and users. If that level of performance doesn’t happen because the models aren’t trained enough, they have to be trained more. If performance doesn’t come no matter how much training you throw at it, you might not have a product to sell at the end of the day! This level of uncertainty is cushioned in traditional software because your performance goals aren’t quite the moving target they are when you’re building an <span class="No-Break">AI product.</span></p>
			<p>Where ML is concerned, you’re bound to have some level of error because, as we know, no model is going to be perfect. You will always need more data to get better performance. Collectively with your leadership, customers, and engineering team, you will come to understand where the threshold of accuracy needs to lie. It will be different for every product and every use case. The output from one model based on a certain training dataset might be great one day, but if you diversify the training set and retrain, it’s probable you won’t get the results you’re expecting. It’s very hard to exactly recreate and test these products, and keeping an experimental attitude when it comes to managing how you are testing, deploying, and maintaining versions will be essential. It’s also hard to know whether your models will most improve because of the type of model you’ve chosen, the training data selected, or the features <span class="No-Break">you’ve selected.</span></p>
			<p>You also don’t know how much time, how many resources, and how much data you need, which makes it really difficult to actually plan your roadmap and keep a sense of time in the way you might be used to if you’ve worked with traditional software products. If you’ve been a PM before, that last sentence might raise some eyebrows. Yes, indeed: AI products are even more difficult to forecast! Finding the right balance of factors might take days, weeks, or months. With AI, it might not be until you’re well within the weeds of building that you start to grasp the complexity of your scope. This poses a great challenge to your leadership team, which might be interested in more concrete answers about the length of time you need. AI introduces so many factors of uncertainty to keep track of, which is why it’s so important to find a leadership team that gets this and supports you because the journey is riddled <span class="No-Break">with doubt.</span></p>
			<p>All in all, AI is here to stay, and it’s going to be a surrounding theme as we head into the 2030s. The promise and opportunity of AI continue to grow as we see companies applying AI in new and innovative ways, and our guess is as the decade continues, we will see more inspired ways for companies to benefit from AI adoption. Companies investing in and building AI native products today will be setting themselves up for success for decades to come if they survive. The key <span class="No-Break">is surviving.</span></p>
			<p>We bring up the differences between AI products and traditional software products here because we want everyone that has the investment and will to create AI products to be set up for success. If you can anticipate potential hurdles as you’re building a novel product, you can better prepare your teams for surmounting them as well. PMs will always be tasked with managing product stakeholders, mapping problems to solutions in their products, scrutinizing their data analytics and insights, communicating, and deciding on acceptance criteria<a id="_idIndexMarker317"/> that will hold their products’ performance, as well as the accountability, explainability, and ethics of their products. These areas need to be nurtured whether you are supporting an AI product or not, and it’s all part of your evangelism work as <span class="No-Break">a PM.</span></p>
			<p>Now that we’ve discussed some of the similarities and differences between traditional software products and AI products, let’s turn our attention to how AI/ML products are positioned and built according to their business models. Creating products for a B2B business model is different from creating products for a B2C business model. Let’s get into some of those differences i<a id="_idTextAnchor231"/>n the <span class="No-Break">following section.</span></p>
			<h1 id="_idParaDest-123"><a id="_idTextAnchor232"/>B2B versus B2C – productizing business models</h1>
			<p>When it comes to building<a id="_idIndexMarker318"/> and shipping products, some of the biggest differences between B2B and B2C business models include domain knowledge and the degree of experimentation. In this section, we’ll be focusing on those two areas because they have the biggest impact on what productizing looks like for AI/ML products between these two business models. If we expand on the notion that AI/ML products behave more like services, the desired end result of both these business models will be different because they serve different kinds of customers and different <span class="No-Break">overall needs.</span></p>
			<p>With B2B products, there’s a strong need for these products to demonstrate a high degree of domain knowledge and a focus on that. Since B2B products are often serving a proven business niche, they must often prove they have expertise in this niche and have studied it thoroughly enough to be able to deliver on a need. With B2C products, we see a focus on experimentation because rather than tapping into a business need that already exists, these products are looking<a id="_idIndexMarker319"/> to tap into a more collective need that their own customer base may not yet be aware they have. This requires a high degree of experimentation. In the following sections, we will bui<a id="_idTextAnchor233"/>ld on these <span class="No-Break">ideas further.</span></p>
			<h2 id="_idParaDest-124"><a id="_idTextAnchor234"/>Domain knowledge – understanding the needs of your market</h2>
			<p>For starters, in B2B products, domain knowledge<a id="_idIndexMarker320"/> reigns supreme. This is because the use cases are incredibly specific, and the products themselves solve niche business problems that are specific to certain industries and domains. In order for a PM to be effective in the B2B space, they need to be intimately connected to their customers’ needs, workflows, and major pain points because their products solve very specific use cases. This isn’t to say PMs in this space have to come from the specific industry they’re serving, but they do need to invest a significant amount of time in building empathy with their user base in order to <span class="No-Break">be effective.</span></p>
			<p>This time-intensive process can look like a number of things: conducting customer interviews, keeping up with industry trends, and understanding the competitive landscape and the benefits and features their competitors are serving their own customers are all part of this work toward building credibility in the space their product is competing in. This is all preliminary work of understanding the various types of users their product will serve as well. You’re setting yourself up for success if you’re a PM in this space and you’re spending time on establishing clear buyer and user personas and making sure you have a handle on what their individual needs, problems, and “jobs to be <span class="No-Break">done” are.</span></p>
			<p>The expectation threshold of B2B customers is high because this space is likely riddled with a large number of competing<a id="_idIndexMarker321"/> products to choose from. In many cases, these customers<a id="_idIndexMarker322"/> are undergoing various rounds of <strong class="bold">Requests for Proposals</strong> (<strong class="bold">RFPs</strong>) and in-depth <strong class="bold">Proof-of-Concept</strong> (<strong class="bold">PoC</strong>) processes to make sure they are purchasing the right product for their use case. For an AI/ML product, these PoCs can be costly for your organization because you’ll need to acquire a large enough sample from your customers, use that data to train your models, and present your product and its capabilities to them once its performance is at an acceptable level to be able to show to your <span class="No-Break">prospective customers.</span></p>
			<p>This means there are often many eyes on these products, and each of those pairs of eyes may come with its own set of expectations and objections to your product, so you really need to be aware of multiple perspectives when building B2B products. This also means that as you build, you’re planning your release schedules with the idea that every release may include features that could impact your customers’ individual workflows, so you often have to be mindful of how often and how loaded your release rollouts into <span class="No-Break">production are.</span></p>
			<p>This domain knowledge is then built up to the point where you as a PM and your broader organization as a whole then become thought leaders in the space they’re serving. Because the professional landscape is a small world, once a product—along with its leadership team—does make a splash, it will trickle across the professional world. Building credibility internally and externally is foundationally proportional to the level of industry expertise <span class="No-Break">that’s acquired.</span></p>
			<p>This further reinforces that the expectations of an AI/ML B2B product are quite high. Your users and buyers will scrutinize you on the tech stack that’s supporting your AI product as well as its performance and accuracy and will want to have evidence of explainability and why your product works. This will all be happening in conjunction with them testing and trialing other AI/ML solutions that are out there to compare them. This also means that you will have to be incredibly intentional about your releases to make sure there aren’t any lags in performance when you do make your push to production, with the full knowledge that other businesses are relying on <span class="No-Break">your product.</span></p>
			<p>Expectations are to be managed at every stage of the customer journey. B2B products exist in a massive ecosystem, and companies that use one product might pass outputs from that product to other workflows or to their own customers. This places a premium on B2B companies to maintain<a id="_idIndexMarker323"/> their company’s and product’s reputation and be more transparent about their marketing efforts, and introduces a lot more strain on AI/ML product teams to shy away from black-box algorithms and sell products that can stand by their determinants. B2B company customers have a tremendous amount of leverage because the stakes are high all around, and B2B products benefit from having engaged customers that want to see a certain level of pe<a id="_idTextAnchor235"/>rformance from <span class="No-Break">their products.</span></p>
			<h2 id="_idParaDest-125"><a id="_idTextAnchor236"/>Experimentation – discover the needs of your collective</h2>
			<p>With B2C products, because<a id="_idIndexMarker324"/> there isn’t such a hyperfocus on the domain you’re serving, the pressure on the market you’re serving is a bit more relaxed, but this creates another kind of pressure: the pressure to build a product that appeals to a much wider audience universally. Casting a wider net brings other areas into focus. As a PM building in a B2C environment, you’re going to approach your product and the market it serves more experimentally and derive insights about what’s most useful to your customers by tracking how they use your product. You can conduct focus groups, nurture beta testers, or interview your customers through in-product surveys, but because you can’t conduct customer interviews in the way you might for a B2B product, you’re left with understanding your customers’ impressions of your product through their <span class="No-Break">in-product behaviors.</span></p>
			<p>This business model also consolidates all your user and buyer personas in one because, typically, the person that’s using your product is also the person buying it. Understanding the main drivers, desires, hopes, and dreams of your customer base becomes a very nebulous task because what you’re trying to capture are underlying needs, pain points, and moments of delight that will apply to all your users at once. This complicates a PM’s ability to empathize with their end users. Because most of these users aren’t signing the kind of year-long contracts you see with B2B products, the pressure to keep these consumers charmed is constant because they can leave at any point. This puts pressure on product, leadership, and development teams to consistently be providing their customer base reasons to stay and <span class="No-Break">choose them.</span></p>
			<p>Because of the bird’s-eye view B2C products enforce on their builders, this means PMs have to be very discerning with their data analytics and metrics. Investing in understanding their customer lifetime value and customer acquisition costs and tracking those metrics is an important part of staying profitable and sustainable in the B2C landscape. B2C offers PMs an easy outlet for applying AI/ML toward the acquisition and retention of customers since they have such few touchpoints with the end users of their product. PMs in the consumer space also need to hone in on the demographic and individualistic qualities of their consumers to better understand what to build. If you see that it’s mostly people within a geographic area, gender, generation, or subgenre that appeals most to your product, you might start to build future features and releases in your roadmap with them <span class="No-Break">in mind.</span></p>
			<p>We’ve mentioned many times that AI/ML products are experimental in nature because you want to leverage AI/ML in ways that will impact your product most obviously for it to be worth the top-heavy investment it requires. This is doubly true for B2C products because you’re building and using AI to deliver something that saves your consumers money or delights them, as well as using the data your product produces to decide on how to pivot your product. B2C PMs are reliant on data and analytics to make global decisions about their products on a regular basis. Although this is changing for the most part, traditionally in the B2B space, your marketing efforts are most oriented toward your buyers because they’re the ultimate decision-makers. This is sharply contrasted in the B2C space because your marketing efforts are directly linked to collective information you can derive and infer from <span class="No-Break">your data.</span></p>
			<p>Experimentation is fun to a point, but at the end of the day, it has to deliver. By far the greatest pressure this places on AI/ML consumer products is the pressure to perform well, maintain their enormous user base, and keep their consumers happy. This means that consumers want to use an app that does what it says it’s going to do in a way that’s visually appealing. Because they aren’t as concerned with the downstream risks of using your product as B2B customers are, consumers don’t particularly care why it’s working, just that it does work. This means that the issue of explainability is minimized in the B2C space, and the use of black-box or DL algorithms is <span class="No-Break">less scrutinized.</span></p>
			<p>B2B and B2C business models<a id="_idIndexMarker325"/> come with their own blend of challenges, but at the end of the day, players in both business models must understand their customers enough to create products that actually bring them value. Once you’ve built something of value for your customers, you enter a new phase. This next phase is about delivering that value consistently enough to not only win customers but keep them in the long run. In the following section, we will take a look under the hood to understand the necessary elements of delivering value consistently with the help of <strong class="bold">ML operations</strong> (<strong class="bold">MLOps</strong>) or <strong class="bold">AI operations</strong> (<strong class="bold">AIOps</strong>). Both will be u<a id="_idTextAnchor237"/>sed interchangeably in <span class="No-Break">this book.</span></p>
			<h1 id="_idParaDest-126"><a id="_idTextAnchor238"/>Consistency and AIOps/MLOps – reliance and trust</h1>
			<p>Maintaining trust, reliance, and consistency<a id="_idIndexMarker326"/> within your<a id="_idIndexMarker327"/> internal product<a id="_idIndexMarker328"/> teams as well as with your <a id="_idIndexMarker329"/>customer base is an act of committing to a specific ritual. Ritualizing the acquisition of clean data, tracking the flow through your infrastructure, tracking your model training, versions, and experiments, setting up a deployment schedule, and monitoring pipelines that get pushed to production are all part of the necessary work that needs to be done to make sure there’s a handle on the comings and goings of your AI/ML pipeline. This<a id="_idIndexMarker330"/> ritualizing is what’s referred<a id="_idIndexMarker331"/> to as MLOps or AIOps. In this section, we will explore the benefits of AIOps/MLOps and how they help you <span class="No-Break">stay consistent.</span></p>
			<p>If you’re managing an ML pipeline, you will need to learn how to depend on an MLOps team and set up your team for success. You don’t want to get caught losing $20,000 in 10 minutes (as we saw in our <em class="italic">Profit margins</em> section earlier in this chapter) and have no leads for where the problem is stemming from. At the very least, you should have some idea where the problem is stemming from. MLOps is able to help with creating and managing the ML pipelines themselves, scaling those pipelines, and moving sensitive data at scale. Ultimately, the risks of compromising your customers’ reliance on and trust in your product are great. MLOps’ greatest contribution to your business is maintaining the consistency needed to build an AI/ML product <span class="No-Break">that lasts.</span></p>
			<p>We’ve spoken at length in this chapter about productizing and what that looks like in different contexts of AI product management, but MLOps is actually where the productizing functionally happens. Taking a service and splitting that service apart into smaller pieces that are managed and standardized into reproducible and regulated segments is the work of “productizing,’’ and in that vein, MLOps is really the vehicle we use to truly productize AI/ML. In order to build the consistency and credibility customers can expect from your product, the ritual of MLOps needs to be cemented into your process. You never know when you'll need to revert to a specific version of your models or zero in on an experiment that had the right mix of factors. MLOps creates the organization and focus your team needs to have in order to have a handle on such a wide variety <span class="No-Break">of experiments.</span></p>
			<p>Now that we’ve covered<a id="_idIndexMarker332"/> some of the benefits of creating<a id="_idIndexMarker333"/> an MLOps organization<a id="_idIndexMarker334"/> to help keep track <a id="_idIndexMarker335"/>of your AI/ML pipeline, let’s explore how to build on that pipeline and evaluate the state of the models used. In the following section, we will reiterate some concepts around testing, retraining, and hyperparameter tuning to ensure your AI/ML pipelines are routinely bein<a id="_idTextAnchor239"/>g refreshed and optimized <span class="No-Break">for performance.</span></p>
			<h1 id="_idParaDest-127"><a id="_idTextAnchor240"/>Performance evaluation – testing, retraining, and hyperparameter tuning</h1>
			<p>MLOps helps us with accentuating<a id="_idIndexMarker336"/> the importance of retraining<a id="_idIndexMarker337"/> and hyperparameter<a id="_idIndexMarker338"/> tuning our models<a id="_idIndexMarker339"/> to deliver performance. Without having a built-out AI/ML pipeline that validates, trains, and retrains regularly, you won’t have a great handle on your product’s performance. Your MLOps team will essentially be made up of data scientists and ML and DL engineers that will be tasked with making adjustments to the hyperparameters of your model builds, testing those models, and retraining them when needed. This will need to be done in conjunction with managing the data needed to feed this testing, along with the code base for your product’s interface <span class="No-Break">as well.</span></p>
			<p>In addition to testing and validating the models and working to clean and explore the data, MLOps team members also traditionally do software testing such as code tests, unit testing, and integration testing. In many cases, your AI products will effectively be traditional software products that incorporate AI/ML features in a subset of a greater ecosystem that’s in line with traditional software development. This means that MLOps may, in many cases, ensure your greater product is working functionally along with the AI/ML deliverables <span class="No-Break">and outputs.</span></p>
			<p>Another major area MLOps is well suited to minimize the risk of is the concept of data drift and system degradation. We covered a few different types of drift in earlier chapters of this book, but we’d like to reiterate here that this is a risk that can sneak up on you. Model degradation can happen for a number of reasons. Perhaps there are differences between assumptions that are made with the data in training and in production. Perhaps there’s been a change to the data itself. Perhaps there are unseen biases in your training data that were never picked up on. Whatever the reason, continuous monitoring of models in production by MLOps will be your best defense in picking up on these nuances and changes in AI/ML outputs so that the risks from any number of issues within the ML pipeline are minimized as much <span class="No-Break">as possible.</span></p>
			<p>In <em class="italic">Chapters 1</em> and <em class="italic">2</em> of this book, we <a id="_idIndexMarker340"/>covered the concept of continuous maintenance, which consists of <strong class="bold">Continuous Integration</strong> (<strong class="bold">CI</strong>), <strong class="bold">Continuous Deployment</strong> (<strong class="bold">CD</strong>), and <strong class="bold">Continuous Testing</strong> (<strong class="bold">CT</strong>). These basic areas of MLOps are mirrored<a id="_idIndexMarker341"/> in DevOps, which is common<a id="_idIndexMarker342"/> to traditional software development. The main differences are that in MLOps, CI isn’t just about testing and validating code—it’s also about validating and testing the models, data schemas, and the data samples themselves. Another difference is that CD isn’t just about deploying a software package but about nurturing an automated ML pipeline deployment process that’s optimized for deploying the model prediction service or for automatically scaling back to an earlier version if there is trouble ahead. Finally, CT isn’t just about testing software packages themselves but about retraining and testing the models that are actively being <span class="No-Break">relied upon.</span></p>
			<p>In this section, we’ve built on the idea of building consistency in how we manage our AI/ML pipelines and reinforced the importance of maintaining high standards in the performance of our AI/ML pipelines. This shouldn’t be viewed as a nice-to-have but rather a need-to-have. The performance and quality of AI/ML models can suffer for many reasons, so this consistent practice<a id="_idIndexMarker343"/> of scrutinizing performance is meant to ensure your product’s performance<a id="_idIndexMarker344"/> doesn’t come at the risk of the<a id="_idIndexMarker345"/> trust you’ve built with your<a id="_idIndexMarker346"/> developers and customers. In the following section, we’ll be discussing the importance of maintaining strong<a id="_idTextAnchor241"/> relationships, whether they’re internal <span class="No-Break">or external.</span></p>
			<h1 id="_idParaDest-128"><a id="_idTextAnchor242"/>Feedback loop – relationship building</h1>
			<p>Continuously monitoring<a id="_idIndexMarker347"/> and reinforcing the legitimacy of a complicated system such as an AI/ML pipeline is all in service of the ultimate goal of building relationships that last. Relationships between your company and customers, your development team and your sales team, and your MLOps team and your leadership team are all forged through this work of building and going to market with your AI/ML native product. In AI/ML products, the feedback loop is everything. Nurturing a strong relationship with the builders of these products and the customers they<a id="_idIndexMarker348"/> serve is the underlying work of the PM. <strong class="bold">Productizing</strong> is the process of taking a service, process, skill, or idea and finding a way to present that to the greater market. Many layers of work go into accomplishing this well, but at its most basic level, this work is really just an elaborate <span class="No-Break">feedback loop.</span></p>
			<p>We haven’t discussed marketing much in this chapter, but this will also be an integral part of maintaining this feedback loop. Finding the right words to use to describe your product<a id="_idIndexMarker349"/> and reach your audience (also known as product language fit) will be a big part of productizing. You will have to create marketing collateral, advertisements, and sales scripts that will all convey the value the product you’re building with AI/ML will have for your customers and end users. Building product collateral and expressing that through your various marketing and sales channels will go a long way toward level-setting expectations with <span class="No-Break">your customers.</span></p>
			<p>As we’ve seen earlier in this section, customers come with expectations, whether they’re business users or consumers, and it’s the task of the AI/ML PM to take those expectations and deliver something that aligns with them. Understanding the risk and promise of AI/ML and how it compares and contrasts to traditional software development, understanding the challenges and opportunities in your business model, translating all that to reproducible, repeatable tasks internally, and demonstrating consistency with your product’s performance in a way that aligns with your customers’ expectations is the work of productizing the AI native product. You’ll know you’ve successfully done this when<a id="_idIndexMarker350"/> you have a lo<a id="_idTextAnchor243"/>yal customer base that wouldn’t dream of parting <span class="No-Break">with you.</span></p>
			<h1 id="_idParaDest-129"><a id="_idTextAnchor244"/>Summary</h1>
			<p>The act of productizing involves taking a concept, a service, or a piece of technology and developing it into a commercial product that’s suitable for the customers you’re looking to attract. As we’ve seen throughout this chapter, this work isn’t just a matter of getting your product up and running and creating a landing page for your potential customers to magically find. Productizing involves critically understanding the business model you’re working in and the ultimate audience you’re building for. Remember that AI products can be thought of as AI/ML services that are being built into traditional software products. This means that another big part of productizing for AI products involves the standardization and ritualization of the AI/ML service in a way that’s repeatable and predictable for the internal operations teams as well as the customers that will come to rely on <span class="No-Break">your product.</span></p>
			<p>If you’re able to understand your market, build internal structures to make sure there’s consistency with the outputs of your AI/ML pipelines, and communicate that consistency through your marketing efforts, as well as the ongoing performance of your product, you’ve successfully productized. But productizing may not be enough. Depending on the specifics of the market you’re serving, you might have to customize your product even further for specific use cases, verticals, customer segments, and other peer groups. Because AI/ML model performance is so dependent on training data, there might be collections of data that perform differently when run against one model. Further specialization might be in order. If you find this applies to your product and market, read on to <a href="B18935_08.xhtml#_idTextAnchor246"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, where we will build on the concept <span class="No-Break">of customization.</span></p>
			<h1 id="_idParaDest-130"><a id="_idTextAnchor245"/>References</h1>
			<ul>
				<li>Past The AI Hype: When Is AI Actually <span class="No-Break">Profitable?: </span><a href="https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4"><span class="No-Break">https://www.forbes.com/sites/forbesfinancecouncil/2020/09/01/past-the-ai-hype-when-is-ai-actually-profitable/?sh=3fdab9b81fb4</span></a></li>
				<li>How to Scale AI in Your <span class="No-Break">Organization: </span><a href="https://hbr.org/2022/03/how-to-scale-ai-in-your-organization"><span class="No-Break">https://hbr.org/2022/03/how-to-scale-ai-in-your-organization</span></a></li>
				<li>What are the net profit margins of a SaaS <span class="No-Break">company/startup?: </span><a href="https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25"><span class="No-Break">https://onplan.co/blog/what-are-the-net-profit-margins-of-a-saas-company-startup/#:~:text=Based%20on%20a%20KeyBank%20Capital,between%2068%25%20and%2075%25</span></a></li>
				<li>Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean Your <span class="No-Break">Data: </span><a href="https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled"><span class="No-Break">https://www.tableau.com/learn/articles/what-is-data-cleaning#:~:text=tools%20and%20software-,What%20is%20data%20cleaning%3F,to%20be%20duplicated%20or%20mislabeled</span></a></li>
				<li>Why Commercial Artificial Intelligence Products Do Not <span class="No-Break">Scale: </span><a href="https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/"><span class="No-Break">https://ai-forum.com/opinion/why-commercial-artificial-intelligence-products-do-not-scale/</span></a></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer024">
			</div>
		</div>
	</body></html>