["```py\n$ git clone https://github.com/PacktPublishing/Neural-Network-Projects-with-Python.git    \n```", "```py\n$ cd Neural-Network-Projects-with-Python\n```", "```py\n$ conda env create -f environment.yml\n```", "```py\n$ conda activate neural-network-projects-python\n```", "```py\n$ cd Chapter05\n```", "```py\n$ python autoencoder_image_compression.py\n```", "```py\nfrom keras.datasets import mnist\n\ntraining_set, testing_set = mnist.load_data()\nX_train, y_train = training_set\nX_test, y_test = testing_set\nmatplotlib to plot the data:\n```", "```py\nfrom matplotlib import pyplot as plt\nfig, ((ax1, ax2, ax3, ax4, ax5), (ax6, ax7, ax8, ax9, ax10)) = plt.subplots(2, 5, figsize=(10,5))\n\nfor idx, ax in enumerate([ax1,ax2,ax3,ax4,ax5, ax6,ax7,ax8,ax9,ax10]):\n    for i in range(1000):\n        if y_test[i] == idx:\n            ax.imshow(X_test[i], cmap='gray')\n            ax.grid(False)\n            ax.set_xticks([])\n            ax.set_yticks([])\n            break\nplt.tight_layout()\nplt.show()\n```", "```py\nfrom keras.models import Sequential\n\nmodel = Sequential()\n```", "```py\nfrom keras.layers import Dense\n\nhidden_layer_size = 1\nmodel.add(Dense(units=hidden_layer_size, input_shape=(784,), \n                activation='relu'))\n```", "```py\nmodel.add(Dense(units=784, activation='sigmoid'))\n```", "```py\nmodel.summary()\n```", "```py\ndef create_basic_autoencoder(hidden_layer_size):\n    model = Sequential() \n    model.add(Dense(units=hidden_layer_size, input_shape=(784,), \n                    activation='relu'))\n    model.add(Dense(units=784, activation='sigmoid'))\n    return model\n\nmodel = create_basic_autoencoder(hidden_layer_size=1)\n```", "```py\nX_train_reshaped = X_train.reshape((X_train.shape[0],\n                                    X_train.shape[1]*X_train.shape[2]))\nX_test_reshaped = X_test.reshape((X_test.shape[0],\n                                  X_test.shape[1]*X_test.shape[2]))\n```", "```py\nX_train_reshaped = X_train_reshaped/255.\nX_test_reshaped = X_test_reshaped/255.\n```", "```py\nmodel.compile(optimizer='adam', loss='mean_squared_error')\n```", "```py\nmodel.fit(X_train_reshaped, X_train_reshaped, epochs=10)\n```", "```py\noutput = model.predict(X_test_reshaped)\n```", "```py\nimport random\nfig, ((ax1, ax2, ax3, ax4, ax5),\n      (ax6, ax7, ax8, ax9, ax10)) = plt.subplots(2, 5, figsize=(20,7))\n\n# randomly select 5 images\nrandomly_selected_imgs = random.sample(range(output.shape[0]),5)\n\n# plot original images (input) on top row\nfor i, ax in enumerate([ax1,ax2,ax3,ax4,ax5]):\n    ax.imshow(X_test[randomly_selected_imgs[i]], cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"INPUT\",size=40)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# plot output images from our autoencoder on the bottom row\nfor i, ax in enumerate([ax6,ax7,ax8,ax9,ax10]):\n    ax.imshow(output[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"OUTPUT\",size=40)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```", "```py\nhiddenLayerSize_2_model = create_basic_autoencoder(hidden_layer_size=2)\nhiddenLayerSize_4_model = create_basic_autoencoder(hidden_layer_size=4)\nhiddenLayerSize_8_model = create_basic_autoencoder(hidden_layer_size=8)\nhiddenLayerSize_16_model = create_basic_autoencoder(hidden_layer_size=16)\nhiddenLayerSize_32_model = create_basic_autoencoder(hidden_layer_size=32)\n```", "```py\nhiddenLayerSize_2_model.compile(optimizer='adam',\n                                loss='mean_squared_error')\nhiddenLayerSize_2_model.fit(X_train_reshaped, X_train_reshaped, \n                            epochs=10, verbose=0)\n\nhiddenLayerSize_4_model.compile(optimizer='adam',\n                                loss='mean_squared_error')\nhiddenLayerSize_4_model.fit(X_train_reshaped, X_train_reshaped,\n                            epochs=10, verbose=0)\n\nhiddenLayerSize_8_model.compile(optimizer='adam',\n                                loss='mean_squared_error')\nhiddenLayerSize_8_model.fit(X_train_reshaped, X_train_reshaped,\n                            epochs=10, verbose=0)\n\nhiddenLayerSize_16_model.compile(optimizer='adam',\n                                 loss='mean_squared_error')\nhiddenLayerSize_16_model.fit(X_train_reshaped, X_train_reshaped, \n                             epochs=10, verbose=0)\n\nhiddenLayerSize_32_model.compile(optimizer='adam',\n                                 loss='mean_squared_error')\nhiddenLayerSize_32_model.fit(X_train_reshaped, X_train_reshaped,\n                             epochs=10, verbose=0)\n```", "```py\noutput_2_model = hiddenLayerSize_2_model.predict(X_test_reshaped)\noutput_4_model = hiddenLayerSize_4_model.predict(X_test_reshaped)\noutput_8_model = hiddenLayerSize_8_model.predict(X_test_reshaped)\noutput_16_model = hiddenLayerSize_16_model.predict(X_test_reshaped)\noutput_32_model = hiddenLayerSize_32_model.predict(X_test_reshaped)\n```", "```py\nfig, axes = plt.subplots(7, 5, figsize=(15,15))\n\nrandomly_selected_imgs = random.sample(range(output.shape[0]),5)\noutputs = [X_test, output, output_2_model, output_4_model, output_8_model,\n           output_16_model, output_32_model]\n\n# Iterate through each subplot and plot accordingly\nfor row_num, row in enumerate(axes):\n    for col_num, ax in enumerate(row):\n        ax.imshow(outputs[row_num][randomly_selected_imgs[col_num]]. \\\n                      reshape(28,28), cmap='gray')\n        ax.grid(False)\n        ax.set_xticks([])\n        ax.set_yticks([])\nplt.tight_layout()\nplt.show()\n```", "```py\nimport numpy as np\n\nX_train_noisy = X_train_reshaped + np.random.normal(0, 0.5,\n                                    size=X_train_reshaped.shape)\nX_test_noisy = X_test_reshaped + np.random.normal(0, 0.5,\n                                    size=X_test_reshaped.shape)\n```", "```py\nX_train_noisy = np.clip(X_train_noisy, a_min=0, a_max=1)\nX_test_noisy = np.clip(X_test_noisy, a_min=0, a_max=1)\n```", "```py\nbasic_denoise_autoencoder = create_basic_autoencoder(hidden_layer_size=16)\n```", "```py\nbasic_denoise_autoencoder.compile(optimizer='adam', \n                                  loss='mean_squared_error')\nbasic_denoise_autoencoder.fit(X_train_noisy, X_train_reshaped, epochs=10)\n```", "```py\noutput = basic_denoise_autoencoder.predict(X_test_noisy)\n```", "```py\nfig, ((ax1, ax2, ax3, ax4, ax5), (ax6, ax7, ax8, ax9, ax10), (ax11,ax12,ax13,ax14,ax15)) = plt.subplots(3, 5, figsize=(20,13))\nrandomly_selected_imgs = random.sample(range(output.shape[0]),5)\n\n# 1st row for original images\nfor i, ax in enumerate([ax1,ax2,ax3,ax4,ax5]):\n    ax.imshow(X_test_reshaped[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Original \\n Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# 2nd row for input with noise added\nfor i, ax in enumerate([ax6,ax7,ax8,ax9,ax10]):\n    ax.imshow(X_test_noisy[randomly_selected_imgs[i]].reshape(28,28),\n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Input With \\n Noise Added\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# 3rd row for output images from our autoencoder\nfor i, ax in enumerate([ax11,ax12,ax13,ax14,ax15]):\n    ax.imshow(output[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Denoised \\n Output\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```", "```py\nconv_autoencoder = Sequential()\n```", "```py\nfrom keras.layers import Conv2D\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3),\n                            activation='relu', padding='same', \n                            input_shape=(28,28,1)))\nconv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3),\n                            activation='relu', padding='same'))\n```", "```py\nconv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3),\n                            activation='relu', padding='same'))\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3),\n                            activation='relu', padding='same'))\n```", "```py\nconv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3),\n                            activation='sigmoid', padding='same'))\n```", "```py\nconv_autoencoder.summary()\n```", "```py\nconv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nconv_autoencoder.fit(X_train_noisy.reshape(60000,28,28,1),\n                     X_train_reshaped.reshape(60000,28,28,1),\n                     epochs=10)\n```", "```py\noutput = conv_autoencoder.predict(X_test_noisy.reshape(10000,28,28,1))\n```", "```py\nfig, ((ax1, ax2, ax3, ax4, ax5), (ax6, ax7, ax8, ax9, ax10), (ax11,ax12,ax13,ax14,ax15)) = plt.subplots(3, 5, figsize=(20,13))\nrandomly_selected_imgs = random.sample(range(output.shape[0]),5)\n\n# 1st row for original images\nfor i, ax in enumerate([ax1,ax2,ax3,ax4,ax5]):\n    ax.imshow(X_test_reshaped[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Original \\n Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# 2nd row for input with noise added\nfor i, ax in enumerate([ax6,ax7,ax8,ax9,ax10]):\n    ax.imshow(X_test_noisy[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Input With \\n Noise Added\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# 3rd row for output images from our autoencoder\nfor i, ax in enumerate([ax11,ax12,ax13,ax14,ax15]):\n    ax.imshow(output[randomly_selected_imgs[i]].reshape(28,28), \n              cmap='gray')\n    if i == 0:\n        ax.set_ylabel(\"Denoised \\n Output\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```", "```py\nnoisy_imgs_path = 'Noisy_Documents/noisy/'\nclean_imgs_path = 'Noisy_Documents/clean/'\n```", "```py\nimport os\nimport numpy as np\nfrom keras.preprocessing.image import load_img, img_to_array\n\nX_train_noisy = []\n\nfor file in sorted(os.listdir(noisy_imgs_path)):\n    img = load_img(noisy_imgs_path+file, color_mode='grayscale', \n                   target_size=(420,540))\n    img = img_to_array(img).astype('float32')/255\n    X_train_noisy.append(img)\n\n# convert to numpy array\nX_train_noisy = np.array(X_train_noisy) \n```", "```py\nprint(X_train_noisy.shape)\n```", "```py\nX_train_clean = []\n\nfor file in sorted(os.listdir(clean_imgs_path)):\n    img = load_img(clean_imgs_path+file, color_mode='grayscale', \n                   target_size=(420,540))\n    img = img_to_array(img).astype('float32')/255\n    X_train_clean.append(img) \n\n# convert to numpy array\nX_train_clean = np.array(X_train_clean)\n```", "```py\nimport random\nfig, ((ax1,ax2), (ax3,ax4), \n      (ax5,ax6)) = plt.subplots(3, 2, figsize=(10,12))\n\nrandomly_selected_imgs = random.sample(range(X_train_noisy.shape[0]),3)\n\n# plot noisy images on the left\nfor i, ax in enumerate([ax1,ax3,ax5]):\n    ax.imshow(X_train_noisy[i].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Noisy Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n# plot clean images on the right\nfor i, ax in enumerate([ax2,ax4,ax6]):\n    ax.imshow(X_train_clean[i].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Clean Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```", "```py\n# use the first 20 noisy images as testing images\nX_test_noisy = X_train_noisy[0:20,]\nX_train_noisy = X_train_noisy[21:,]\n\n# use the first 20 clean images as testing images\nX_test_clean = X_train_clean[0:20,]\nX_train_clean = X_train_clean[21:,]\n```", "```py\nbasic_conv_autoencoder = Sequential()\n```", "```py\nbasic_conv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3),\n                                  activation='relu', padding='same', \n                                  input_shape=(420,540,1)))\n```", "```py\nbasic_conv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3), \n                                  activation='relu', padding='same'))\n```", "```py\nbasic_conv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), \n                                  activation='sigmoid', padding='same'))\n```", "```py\nbasic_conv_autoencoder.summary()\n```", "```py\nbasic_conv_autoencoder.compile(optimizer='adam', \n                               loss='binary_crossentropy')\nbasic_conv_autoencoder.fit(X_train_noisy, X_train_clean, epochs=10)\n```", "```py\noutput = basic_conv_autoencoder.predict(X_test_noisy)\n```", "```py\nfig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3, figsize=(20,10))\n\nrandomly_selected_imgs = random.sample(range(X_test_noisy.shape[0]),2)\n\nfor i, ax in enumerate([ax1, ax4]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(X_test_noisy[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Noisy Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfor i, ax in enumerate([ax2, ax5]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(X_test_clean[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Clean Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfor i, ax in enumerate([ax3, ax6]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(output[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Output Denoised Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```", "```py\nconv_autoencoder = Sequential()\n```", "```py\nconv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3),\n                            input_shape=(420,540,1), \n                            activation='relu', padding='same'))\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3),\n                            activation='relu', padding='same'))\nconv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3),\n                            activation='relu', padding='same'))\n```", "```py\nconv_autoencoder.add(Conv2D(filters=8, kernel_size=(3,3), \n                            activation='relu', padding='same'))\nconv_autoencoder.add(Conv2D(filters=16, kernel_size=(3,3), \n                            activation='relu', padding='same'))\nconv_autoencoder.add(Conv2D(filters=32, kernel_size=(3,3), \n                            activation='relu', padding='same'))\n```", "```py\nconv_autoencoder.add(Conv2D(filters=1, kernel_size=(3,3), \n                            activation='sigmoid', padding='same'))\n```", "```py\nconv_autoencoder.summary()\n```", "```py\nconv_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\nconv_autoencoder.fit(X_train_noisy, X_train_clean, epochs=10)\n\noutput = conv_autoencoder.predict(X_test_noisy)\n```", "```py\nfig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3, figsize=(20,10))\n\nrandomly_selected_imgs = random.sample(range(X_test_noisy.shape[0]),2)\n\nfor i, ax in enumerate([ax1, ax4]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(X_test_noisy[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Noisy Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfor i, ax in enumerate([ax2, ax5]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(X_test_clean[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Clean Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nfor i, ax in enumerate([ax3, ax6]):\n    idx = randomly_selected_imgs[i]\n    ax.imshow(output[idx].reshape(420,540), cmap='gray')\n    if i == 0:\n        ax.set_title(\"Output Denoised Images\", size=30)\n    ax.grid(False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nplt.tight_layout()\nplt.show()\n```"]