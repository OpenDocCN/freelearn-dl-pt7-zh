- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Privacy and Security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding chapters, we’ve demonstrated the process of crafting and implementing
    practical solutions using **Azure OpenAI** (**AOAI**) in conjunction with various
    Azure AI services. In this chapter, we will focus on privacy and security considerations
    related to AOAI.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: AOAI service compliance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AOAI data privacy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content filtering
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managed identities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtual Network** (**VNet**) configuration'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Private endpoint configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Responsible AI for AOAI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AOAI service compliance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The AOAI compliance program is a set of policies and practices that Microsoft
    has established to ensure that the AOAI service is used in a responsible and ethical
    manner. The program includes the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data, privacy, and security**: Microsoft provides details on how data provided
    by customers to the AOAI service is processed, used, and stored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Responsible AI practices**: Microsoft offers technical guidance and tools
    to support customers in responsibly designing, developing, deploying, and utilizing
    AI systems that incorporate AOAI models. These recommendations align with the
    Microsoft Responsible AI Standard and encompass four key stages: Identification,
    Measurement, Mitigation, and Operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code of conduct**: Microsoft defines the requirements that all AOAI Service
    implementations must adhere to in good faith. The code of conduct covers topics
    such as acceptable use, harmful content, human interaction, attribution, and feedback.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Federal Risk and Authorization Management Program (FedRAMP) High Authorization**:
    Microsoft has obtained FedRAMP High Authorization for the AOAI service within
    the Azure Commercial environment. This means that the service meets the highest
    level of security standards required by the federal government for **cloud service**
    **providers** (**CSPs**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Health Insurance Portability and Accountability Act (HIPAA) compliance**:
    Microsoft has confirmed that the AOAI service can be used in a HIPAA-compliant
    manner. This means that customers can use the service to process **protected health
    information** (**PHI**) in accordance with the HIPPA in respect of the **Business
    Associate Agreement** (**BAA**). The BAA is a critical document for ensuring that
    PHI is handled securely and in compliance with HIPAA regulations when it is managed
    by third-party business associates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System and Organization Controls (SOC) 1, 2, 3**: SOC 1, SOC 2, and SOC 3
    are compliance standards and frameworks related to the security and integrity
    of service organizations’ systems and data. They are developed and maintained
    by the **American Institute of Certified Public Accountants** (**AICPA**). These
    standards help organizations demonstrate their commitment to protecting sensitive
    information and ensuring the reliability of their systems and services to clients
    and stakeholders. AOAI handles data for delivering its service and for keeping
    an eye out for any misuse that goes against the product terms. Your prompts (inputs)
    and completions (outputs), along with your embeddings and training data, are not
    shared with other customers, OpenAI, Microsoft, or any third-party products or
    services. AOAI models that customers fine-tuned are solely for their own use.
    Microsoft completely manages the AOAI service, hosting OpenAI models in its Azure
    environment, and the service doesn’t connect with any services run by OpenAI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AOAI service complies with various certifications and standards to ensure
    its reliability and security. These include **Cloud Security Alliance Security,
    Trust, Assurance, and Risk** (**CSA STAR**) Certification and Attestation, ISO
    20000-1:2018, ISO 22301:2019, ISO 27001:2022, ISO 27017:2015, ISO 27018:2019,
    ISO 27701:2019, ISO 9001:2015, SOC 1, 2, and 3, **Global System for Mobile Communications
    Security** **Accreditation Scheme-Subscription Management** (**GSMA SAS-SM**),
    HIPAA BAA, the **Health Information Trust Alliance** (**HITRUST**), **Payment
    Card Industry 3-D Secure** (**PCI 3DS**), the **PCI Data Security Standard** (**PCI
    DSS**), **Germany Cloud Computing Compliance Controls Catalog** (**Germany C5**),
    Singapore **Multi-Tier Cloud Security** (**MTCS**) Level 3, and Singapore **Outsourced
    Service Provider’s Audit Report** (**OSPAR**). This adherence to various compliance
    standards ensures that the AOAI service maintains high levels of security and
    reliability for its users.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Azure continually assesses the AOAI service to incorporate additional compliance
    certifications. To access the most up-to-date compliance attestation information
    for various Azure products, please visit the following link: [https://servicetrust.microsoft.com/DocumentPage/7adf2d9e-d7b5-4e71-bad8-713e6a183cf3](https://servicetrust.microsoft.com/DocumentPage/7adf2d9e-d7b5-4e71-bad8-713e6a183cf3).'
  prefs: []
  type: TYPE_NORMAL
- en: Having covered AOAI compliance, let’s now direct our attention to the subject
    of data privacy in the upcoming section.
  prefs: []
  type: TYPE_NORMAL
- en: AOAI data privacy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section provides insights into the processing, utilization, and storage
    of data you submit to the AOAI service.
  prefs: []
  type: TYPE_NORMAL
- en: AOAI models are stateless, which means that they do not store or remember any
    information from previous inputs or outputs. Instead, they solely process the
    current input and generate an output based on their model parameters, as well
    as any optional settings such as temperature or frequency penalty. This design
    choice enhances the models’ adaptability and scalability but presents challenges
    when dealing with tasks that require context or memory.
  prefs: []
  type: TYPE_NORMAL
- en: To address this limitation, you can include relevant context or historical information
    within the input or leverage external data sources to supplement the input with
    additional details. Nevertheless, such practices can introduce potential risks,
    including concerns related to data privacy and security, as well as the potential
    for misuse or abuse of the models. Consequently, Microsoft has instituted various
    safeguards to protect its models and users from these potential threats. These
    measures encompass content filtering, rate limiting, and data processing policies.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Data pertaining to prompts, completions, embeddings, and training is strictly
    confined, with no access granted to others or utilization for improving OpenAI
    or any Microsoft/third-party products. Fine-tuned AOAI models are solely accessible
    for user use, exclusively controlled by Microsoft within the AOAI service, distinct
    from services provided by OpenAI such as ChatGPT or OpenAI API.
  prefs: []
  type: TYPE_NORMAL
- en: 'AOAI handles several categories of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompts and completion data**: Users submit prompts, and the service generates
    content through operations such as completions and chat completions, as well as
    dealing with images and embeddings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Augmented data associated with prompts**: Through the On Your Data feature,
    the service accesses data from a specified data store and enhances prompts with
    this data, resulting in content that is directly connected to your dataset'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Training and validation data**: Users have the option to supply their own
    training data, consisting of pairs of prompts and completions, which can be used
    to fine-tune an OpenAI model for specific purposes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The diagram provided here outlines the AOAI data processing flow along with
    content filtering, which we will talk about in the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1: AOAI data flows for inference and fine-tuning](img/B21019_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: AOAI data flows for inference and fine-tuning'
  prefs: []
  type: TYPE_NORMAL
- en: 'This encompasses three distinct processing scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Processing prompts for content generation**: The top section illustrates
    how the AOAI service takes your prompts and generates content, including cases
    where additional data from an external source is incorporated into prompts using
    the AOAI On Your Data feature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Creating fine-tuned (custom) models**: The bottom section outlines how the
    AOAI service utilizes your training data to craft fine-tuned models, tailored
    to your specific requirements and preferences.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Content filtering by the AOAI service and Microsoft Personnel**: The diagram
    also demonstrates how the AOAI service, in conjunction with Microsoft Personnel,
    conducts an analysis of prompts, completions, and images. This analysis is designed
    to identify potentially harmful content and patterns that may indicate the misuse
    of the service, in violation of the code of conduct or other relevant product
    terms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Models, whether they are the base models or fine-tuned versions, that are deployed
    within your resource are responsible for processing the input prompts you provide
    and generating responses, which can include text, images, or embeddings. The service
    operates in a synchronous manner, evaluating the prompt and completion data in
    real time to actively monitor for potentially harmful content types. If generated
    content surpasses the thresholds configured for this purpose, the service will
    halt the generation of such content to maintain a safe and compliant environment.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s discuss the data flows for the On Your Data feature in AOAI. This feature
    involves the interaction between the AOAI service and external data sources to
    augment prompts and generate content.
  prefs: []
  type: TYPE_NORMAL
- en: The On Your Data feature in AOAI enables you to establish connections with external
    data sources, allowing the generated results to be closely tied to your specific
    data. Importantly, this data remains securely stored within the designated data
    source and location; no data is duplicated or copied into the AOAI service itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a user submits a prompt, the service dynamically retrieves pertinent data
    from the connected external data source and enhances the user’s prompt with this
    additional contextual information. Subsequently, the model processes this augmented
    prompt, and the resulting generated content is then returned; this technique is
    called **Retrieval Augmented Generation** (**RAG**). This mechanism ensures that
    the output is grounded in your data without compromising data security or privacy.
    The following diagram illustrates the entire process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2: AOAI data flows for On Your Data](img/B21019_11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: AOAI data flows for On Your Data'
  prefs: []
  type: TYPE_NORMAL
- en: In both diagrams, you may have observed that AOAI monitors abusive content asynchronously.
    Let’s delve into the upcoming section to gain a better understanding of how AOAI
    prevents abuse and the generation of harmful content.
  prefs: []
  type: TYPE_NORMAL
- en: Preventing abuse and harmful content generation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To mitigate the risk of the AOAI service being used for harmful purposes, it
    incorporates both content filtering and abuse monitoring features.
  prefs: []
  type: TYPE_NORMAL
- en: Real-time content filtering occurs as the service processes prompts to produce
    content. Prompts and generated results are not used for training, retraining,
    or improving content classifier models, nor are they stored within these models.
    Further details on content filtering will be provided in a subsequent section
    of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Abuse monitoring involves identifying and handling instances of recurring content
    and behaviors that suggest possible breaches of the code of conduct or other relevant
    product terms. In order to detect and tackle abuse, AOAI securely retains all
    prompts and generated content for a maximum period of 30 days.
  prefs: []
  type: TYPE_NORMAL
- en: The data storage system housing prompts and completions is logically separated
    by customer resource, with each request specifying the resource ID of the customer’s
    AOAI resource. In every region where the AOAI service is available, there exists
    a distinct data repository. A customer’s prompts and generated content are stored
    within the Azure region where their AOAI service resource is deployed, all within
    the predefined boundaries of the AOAI service. Human reviewers responsible for
    evaluating potential abuse can access prompt and completion data only when it
    has been flagged by the abuse monitoring system. These reviewers are authorized
    Microsoft employees who access the data through point-wise queries using request
    IDs, **Secure Access Workstations** (**SAWs**), and **Just-In-Time** (**JIT**)
    request approvals provided by team managers. In the instance of AOAI Service deployed
    in the **European Economic Area** (**EEA**), the authorized Microsoft employees
    are situated within the EEA.
  prefs: []
  type: TYPE_NORMAL
- en: 'Certain customers may require the utilization of the AOAI service for handling
    sensitive, highly confidential, or legally regulated input data, despite the minimal
    risk of generating harmful outputs or misuse. These customers may find themselves
    unable or unwilling to grant Microsoft permission to process such data for abuse
    detection, as previously explained, owing to internal policies or relevant legal
    obligations. To mitigate these concerns, Microsoft provides eligible customers,
    who meet specific Limited Access criteria and attest to particular use cases,
    with the opportunity to request adjustments to AOAI content management features.
    This can be done by completing the form available at [https://aka.ms/oai/modifiedaccess](https://aka.ms/oai/modifiedaccess).
    In this form, make sure you tick mark point *#23* to disable abuse monitoring
    as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3: Disabling abuse monitoring](img/B21019_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Disabling abuse monitoring'
  prefs: []
  type: TYPE_NORMAL
- en: Once Microsoft approves a customer’s request to modify abuse monitoring, no
    prompts and completions associated with the approved Azure subscription will be
    stored by Microsoft when abuse monitoring is configured to be inactive. In such
    cases, because there are no prompts and completions stored in the Service Results
    Store, the human review process is neither possible nor conducted.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s ensure that the required configuration is in place for deactivating
    abuse monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Verification of abuse monitoring deactivation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Customers who have been approved to disable abuse monitoring in their Azure
    subscription can confirm that data storage for abuse monitoring has been deactivated
    through two methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using the** **Azure portal**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sign in to the Azure portal
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the appropriate AOAI service resource.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the resource **Overview** page
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on the **JSON View** link in the top-right corner, as shown in the following
    screenshot:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.4: Content logging verification](img/B21019_11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.4: Content logging verification'
  prefs: []
  type: TYPE_NORMAL
- en: In the list of capabilities, you will find a value named `ContentLogging`, which
    will display as `FALSE` when abuse monitoring logging is turned off.
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure CLI or management API**: Alternatively, customers can use the Azure
    **Command-Line Interface** (**CLI**) or any management API provided by Azure to
    programmatically access and check the abuse monitoring status for their Azure
    subscription. You can execute the following command in Azure CLI to see the same
    JSON data as shown in the Azure portal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The `ContentLogging` attribute will only display a value of `false` if data
    storage for abuse monitoring has been deactivated. Otherwise, this property will
    not be visible in either the Azure portal or the output of Azure CLI.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous section, we discussed various aspects of data privacy, data
    flow, and abuse monitoring. Now, let’s shift our focus to content filtering.
  prefs: []
  type: TYPE_NORMAL
- en: Content filtering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The AOAI service integrates a content filtering mechanism that operates alongside
    its core models. This system functions by subjecting both the prompt and completion
    to a combination of classification models designed to identify and mitigate the
    generation of harmful content. It actively identifies and responds to specific
    types of potentially harmful content in both the prompts provided as input and
    the completions produced as output. It’s worth noting that the filtering behavior
    may vary depending on the specific API configurations and the design of the application.
  prefs: []
  type: TYPE_NORMAL
- en: 'The content filtering models have undergone dedicated training and testing
    in the following languages: English, German, Japanese, Spanish, French, Italian,
    Portuguese, and Chinese. The service has the capability to function in numerous
    other languages, although the performance quality might differ. In every instance,
    it is advisable to conduct your own testing to confirm its suitability for your
    particular application.'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The AOAI Whisper model doesn’t use content filtering for prompts and completions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subsequent sections offer details regarding the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Content filtering categories
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categories
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Severity levels
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Configurability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content filtering categories
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within the AOAI service, the content filtering system integrates neural multi-class
    classification models, specifically crafted to detect and filter out harmful content.
    These models cover four distinct main categories: **Hate**, **Sexual**, **Violence**,
    and **Self-harm**. Each category is classified into four severity levels: **Safe**,
    **Low**, **Medium**, and **High**. It’s crucial to emphasize that content identified
    at the **Safe** severity level is marked but is excluded from the filtering process
    and cannot be adjusted or customized. There are also optional classification models
    for the detection of jailbreak and protected material for text and code.'
  prefs: []
  type: TYPE_NORMAL
- en: Categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'These are the four main categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Hate**: Content that promotes hatred or discrimination against individuals
    or groups based on characteristics such as race, ethnicity, religion, gender,
    sexual orientation, and so on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sexual**: Material containing explicit or suggestive sexual language, imagery,
    or themes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Violence**: Content depicting or advocating physical harm, injury, or violence
    toward individuals or groups'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-harm**: Material encouraging or glorifying self-injury, suicide, eating
    disorders, or other forms of self-harm'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to the four predefined categories, customers have the option to
    create their own custom categories using the **Azure AI Content Safety** service.
    This allows them to train a personalized content classification model tailored
    to their needs. To do this, they will require training data to identify sensitive
    content, moderate user-generated content, or ensure compliance with local regulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Optional categories are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prompt shields for jailbreak attacks**: Jailbreak attacks refer to user prompts
    deliberately crafted to trigger the **generative AI** (**GenAI**) model into demonstrating
    behaviors it was trained to avoid or to violate rules established in the system
    message. These direct attacks can range from elaborate role-playing scenarios
    to subtle attempts to undermine safety protocols.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prompt shields for indirect attacks**: Indirect attacks, sometimes known
    as indirect prompt attacks or cross-domain prompt injection attacks, represent
    a potential security flaw where external entities embed harmful instructions within
    documents accessible to the GenAI system. This vulnerability necessitates embedding
    and formatting of the document, especially in RAG kind of architecture.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protected material for text**: Protected material text pertains to identifiable
    text content, such as song lyrics, articles, recipes, and selected web content,
    which may be generated by **large language** **models** (**LLMs**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protected material for code**: Protected material code denotes source code
    that matches a predefined set of code snippets from public repositories. LLMs
    may output such code without properly citing the original source repositories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Severity levels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'These are the four severity levels for each main category:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Safe**: Content may indeed involve topics associated with the **Violence**,
    **Self-harm**, **Sexual**, or **Hate** categories. However, these terms may be
    utilized in a general, journalistic, scientific, medical, or similar professional
    context that is suitable for broad audiences and does not involve harmful or offensive
    intent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low**: The content in question encompasses expressions of bias, judgment,
    or personal opinions, incorporates offensive language, employs stereotypes, involves
    explorations of fictional realms (for example, in gaming or literature), and portrays
    elements with a low level of intensity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Medium**: The content mentioned involves the utilization of offensive, derogatory,
    ridiculing, intimidating, or belittling language directed at particular identity
    groups. Additionally, it may include depictions of seeking and carrying out harmful
    instructions, fantasies, and the glorification and promotion of harm, all presented
    at a medium level of intensity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High**: The content in question showcases explicit and highly severe harmful
    instructions, actions, damage, or abuse. It also encompasses the endorsement,
    glorification, or promotion of extremely harmful acts, including those that are
    radical, illegal, or non-consensual in nature, as well as content related to power
    exchange or abuse that occurs without consent.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up until this point, we have discussed various categories of content filtering
    and their associated severity levels. Now, let’s delve into where these severity
    levels can be adjusted or configured.
  prefs: []
  type: TYPE_NORMAL
- en: Customizability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The default setup for content filtering is programmed to initiate the filtering
    process when medium-level severity is detected within any of the four defined
    categories of harmful content, applicable to both user prompts and generated responses.
    This means that when content is flagged as having medium or high severity, it
    will be subjected to filtering. Conversely, content identified as having low severity
    will not trigger the filtering mechanisms. The following tables provide detailed
    information on the customization options available for each severity level:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Severity** | **Customizable** **for prompts** | **Customizable** **for
    completions** | **Descriptions** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Low**, **Medium**, **High** | Yes | Yes | Highest filter level: Filters
    low-, medium-, and high-severity content. |'
  prefs: []
  type: TYPE_TB
- en: '| **Medium**, **High** | Yes | Yes | Default: Filters medium- and high-severity
    content; does not filter low-severity content. |'
  prefs: []
  type: TYPE_TB
- en: '| **High** | Subject to approval* | Subject to approval* | Filters only high-severity
    content. Approval is required for filtering. |'
  prefs: []
  type: TYPE_TB
- en: '| **No Filters** | Subject to approval* | Subject to approval* | No content
    is filtered, regardless of the detected severity level. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 11.1: Content filtering configurations'
  prefs: []
  type: TYPE_NORMAL
- en: 'Customers who are authorized to alter content filtering settings have full
    authority over these filters. They can opt to set filters to engage only at the
    high severity level or choose to turn off filtering altogether. If you wish to
    request access to modify content filters, please fill out the form at this link:
    [https://aka.ms/oai/modifiedaccess](https://aka.ms/oai/modifiedaccess). When filling
    out the form, please make sure to select point *#23* to activate high-severity
    content filtering. Additionally, in point *#24*, provide justification for this,
    as indicated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5: Modifying content filters](img/B21019_11_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: Modifying content filters'
  prefs: []
  type: TYPE_NORMAL
- en: So far, you have learned about different AOAI content filters and their configurations.
    Now, let’s discuss some best practices for implementing content filtering.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When the content filtering system identifies harmful content, your interaction
    with the API will yield one of the following outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Inappropriate prompts**: If the input prompt is determined to contain inappropriate
    content, you will receive an HTTP 400 error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`finish_reason` value in the response will be set to `content_filter`. In some
    rare instances with longer responses, a partial result may be returned, with an
    updated `finish_reason` value indicating the content filtering status.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Streaming completions**: For streaming completions, segments of content will
    be returned as they are generated. The service will maintain its streaming operation
    until it encounters a predetermined stop token, reaches a certain length limit,
    or identifies content that falls under a category and severity level that has
    been set for filtering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you plan your application, it’s important to incorporate the following best
    practices to ensure a positive **user experience** (**UX**) while mitigating potential
    issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Determine your approach for addressing situations where users submit prompts
    containing content classified within a filtered category and severity level or
    when they misuse your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examine the `finish_reason` value to identify whether a completion has been
    filtered or not
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Verify the absence of an error object in the `content_filter_result` value,
    which signifies that the content filters were successfully applied and did not
    encounter any issues during processing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s discuss how you can practically implement content filtering through Azure
    AI Foundry.
  prefs: []
  type: TYPE_NORMAL
- en: Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The subsequent instructions demonstrate the process of establishing a personalized
    content filtering configuration for your AOAI resource:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to Azure AI Foundry and locate the **Content filters** tab by following
    the bottom-left navigation, as indicated by the highlighted red box shown next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.6: AOAI Content filters tab](img/B21019_11_6.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.6: AOAI Content filters tab'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new customized content filtering configuration:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.7: Creating custom AOAI content filters](img/B21019_11_7.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.7: Creating custom AOAI content filters'
  prefs: []
  type: TYPE_NORMAL
- en: This brings you to the next configuration screen, where you can choose a name
    for your custom content filtering setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next screen, set thresholds for content filter categories for both text
    and image for input prompts:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.8: AOAI custom content filters’ default settings](img/B21019_11_8.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.8: AOAI custom content filters’ default settings'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the standard content moderation settings page, where content is regulated
    at a medium level across all categories. You have the flexibility to customize
    the content moderation severity level separately for prompts and completion of
    the four content categories each. There are three adjustable severity levels for
    each category: **Low**, **Medium**, and **High**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If your application requires stricter blocking for content categories such
    as **Violence**, **Hate**, **Sexual**, and **Self-harm**, set the threshold to
    **Low**. To permit content in the **Low** category while blocking **Medium** and
    **High** categories, adjust the threshold to **Medium**. Lastly, if you wish to
    allow content in both the **Low** and **Medium** categories but block the **High**
    category, set the threshold to **High**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9: AOAI custom content filters’ settings](img/B21019_11_9.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.9: AOAI custom content filters’ settings'
  prefs: []
  type: TYPE_NORMAL
- en: Follow the same step for output content from the model and set the threshold
    accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You also have the option to fully disable content filtering for both input
    and output content by toggling off the **Annotate and block** feature located
    in the bottom-left corner. Alternatively, you can turn off the content filter
    for specific categories by selecting **Off**. If you opt for **Annotate only**,
    the AOAI content filter system will merely flag the content without blocking it:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.10: Disabling AOAI custom content filters](img/B21019_11_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.10: Disabling AOAI custom content filters'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'To carry out step *#3*, it’s essential to obtain approval for modifying the
    content filter by filling out the given form: [https://ncv.microsoft.com/uEfCgnITdR](https://ncv.microsoft.com/uEfCgnITdR).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To activate a custom content filtering configuration, you need to assign it
    to one or more deployments in your resource. To accomplish this, navigate to the
    **Deployments** tab and choose **Edit deployment**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.11: Editing the AOAI model deployment](img/B21019_11_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.11: Editing the AOAI model deployment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Proceed to the **Advanced options** section and choose the appropriate content
    filter configuration for that deployment from the **Content** **Filter** dropdown:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.12: Assigning content filter to AOAI model](img/B21019_11_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.12: Assigning content filter to AOAI model'
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **Save and close** to apply the selected configuration to the deployment.
    Post that, you will observe the selected configuration applied to your chosen
    model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.13: Confirming the content filter for the AOAI model](img/B21019_11_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.13: Confirming the content filter for the AOAI model'
  prefs: []
  type: TYPE_NORMAL
- en: 'If necessary, you can also modify or delete a content filter configuration.
    To do so, go to the **Content filters** tab and choose the desired configuration.
    Please note that you can only edit or delete one filtering configuration at a
    time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: "![Figure 11.14: Editing or deleting a content filter in \uFEFFAzure AI Foundry](img/B21019_11_14.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.14: Editing or deleting a content filter in Azure AI Foundry'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To remove a content filtering configuration, it’s necessary to detach it from
    any deployment listed under the **Deployments** tab.
  prefs: []
  type: TYPE_NORMAL
- en: You have now acquired the skills to implement an AOAI content filter, which
    ensures that harmful content is neither inputted into nor outputted from the model.
    In the upcoming section, we will explore how content filtering operates in practice.
  prefs: []
  type: TYPE_NORMAL
- en: Content filtering in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the preceding step, as seen in step *#7* of the previous section, custom
    content filtering was implemented for the `gpt-35-turbo` model. Now, we will evaluate
    the content filter both from the AOAI portal and through the API.
  prefs: []
  type: TYPE_NORMAL
- en: AOAI portal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to Azure AI Foundry..
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **Chat** playground.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **gpt-4** from the **Deployment** options.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Input a user prompt; for example, something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In response to the provided user prompt, you will observe that AOAI content
    filtering has been activated and has filtered out the high-severity **Violence**
    content before it is forwarded to the actual model.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The diagram here illustrates the specifics of the steps described previously:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: "![Figure 11.15: Testing the content filter from \uFEFFAzure AI Foundry](img/B21019_11_15.jpg)"
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.15: Testing the content filter from Azure AI Foundry'
  prefs: []
  type: TYPE_NORMAL
- en: API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will guide you through the process of making your call
    to AOAI using the Python SDK to test the content filtering:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install Python version 3.7.1 or a more recent version on your machine. Alternatively,
    you can utilize an **Azure Machine Learning** (**AML**) notebook to obtain the
    Python environment. In this example, we have used Anaconda with Visual Studio
    Code as an IDE:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the OpenAI Python client library by using the following command: `pip`
    `install openai`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To effectively make a request to the AOAI service, you will require the following
    three pieces of information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`ENDPOINT`: This value corresponds to the endpoint of your AOAI resource. You
    can locate it in the `API-KEY`: This value is your API key for accessing the AOAI
    resource. You can find it in the `KEY1` or `KEY2`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DEPLOYMENT-NAME`: This value corresponds to the custom name you selected for
    your deployment during the model deployment process in the *Deploying AOAI* *models*
    section.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To get the first two values, navigate to your resource within the Azure portal.
    You can find `KEY1` or `KEY2`. The presence of two keys enables secure key rotation
    and regeneration without causing service interruptions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.16: Getting AOAI keys and endpoint information](img/B21019_11_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.16: Getting AOAI keys and endpoint information'
  prefs: []
  type: TYPE_NORMAL
- en: 'In your preferred IDE, create a Python file called `content_filtering.py` and
    execute the code shown next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the necessary Python package and define an AOAI key and deployment name:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you change the deployment name value to the custom name you provided
    while creating the deployment. Also, in a production environment, it is recommended
    to use a secure method for storing and accessing your credentials, such as Azure
    Key Vault. This ensures the highest level of security for your sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: 'Send the chat completion request to the AOAI model to get a response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: When you execute the preceding command, you will encounter an `InvalidRequestError`
    exception because the prompt is filtered out by the AOAI content filtering system
    before it reaches the actual model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is the actual output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: So far, you’ve observed that in all the examples, we’ve been utilizing an API
    key for making calls to the AOAI resource. This could pose security issues in
    many scenarios. In the following section, we will discuss how to access AOAI resources
    without the need for an API key.
  prefs: []
  type: TYPE_NORMAL
- en: Managed identities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In software development, one common challenge is the secure management of sensitive
    information such as passwords, keys, and certificates, essential for maintaining
    secure communication between different software components. Managed identities
    present a practical solution that eliminates the need for developers to manually
    juggle these sensitive credentials.
  prefs: []
  type: TYPE_NORMAL
- en: While Azure Key Vault provides a secure repository for storing secrets, services
    still require a seamless way to access this vault. Managed identities offer an
    automated solution by providing a managed identity within Microsoft’s Entra ID
    specifically tailored for applications. This identity serves as a secure conduit
    for applications to access resources that rely on Microsoft’s **Azure Active Directory**
    (**AD**) authentication. Through leveraging managed identities, applications can
    seamlessly obtain Azure AD tokens without the hassle of directly managing any
    credentials.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two primary types of managed identities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**System-assigned**: Azure services offer the option to activate a managed
    identity directly on a service instance. Activating a system-assigned managed
    identity results in the creation of an identity in Azure AD. This identity is
    closely associated with the lifespan of the specific service instance. Azure takes
    care of automatically removing this identity when the associated resource is deleted.
    Importantly, this identity is exclusively intended for use by the corresponding
    Azure resource, enabling it to request tokens from Azure AD.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-assigned**: You have the option to create a managed identity as an independent
    Azure resource. This involves creating a user-assigned managed identity, which
    can then be assigned to one or multiple Azure service instances. With user-assigned
    managed identities, the identity is administered independently from the resources
    that make use of it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we will establish a system-assigned managed identity
    for the purpose of accessing AOAI from an **Azure Machine Learning** (**AML**)
    notebook instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.17: AOAI managed identity](img/B21019_11_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.17: AOAI managed identity'
  prefs: []
  type: TYPE_NORMAL
- en: AML workspace creation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As a first step, you will create an AML workspace and attach a compute instance
    to execute the notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sign in to AML Studio: [https://ml.azure.com/](https://ml.azure.com/).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Create workspace**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Provide the following information to configure the workspace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Workspace name**: This must be a unique name.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Subscription**: Select your Azure subscription.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource Group**: Use an existing one or create a new one to hold the related
    resources.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Region**: Choose your closest Azure region.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Select **Create** to create the workspace.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After setting up your workspace, the next step is to establish a **compute
    instance** for executing your notebook and Python scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to the left-hand menu and choose **Notebooks**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Choose **Create compute** located in the center of the page:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.18: Creating an AML compute instance](img/B21019_11_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.18: Creating an AML compute instance'
  prefs: []
  type: TYPE_NORMAL
- en: Provide a name for the instance while retaining all the default settings on
    the first page and second page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the **Security** page, enable the **Assigned** **identity** option:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.19: Assigning a system-managed identity](img/B21019_11_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.19: Assigning a system-managed identity'
  prefs: []
  type: TYPE_NORMAL
- en: Keep the default values for the rest of the pages.
  prefs: []
  type: TYPE_NORMAL
- en: Select **Create**. It will take a few minutes to launch the instance.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Role assignment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After the compute instance has been launched, the next step is to assign **role-based
    access control** (**RBAC**) from AOAI to the AML compute instance:'
  prefs: []
  type: TYPE_NORMAL
- en: Proceed with the AOAI resource you previously created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the left-hand menu, choose **Access** **control (IAM)**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Click on **Add** and choose **Add** **role assignment**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.20: Adding a role to AOAI](img/B21019_11_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.20: Adding a role to AOAI'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next page, choose the **Cognitive Services OpenAI User** role for inference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.21: Assigning a role to AOAI](img/B21019_11_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.21: Assigning a role to AOAI'
  prefs: []
  type: TYPE_NORMAL
- en: 'On the next page, assign the role to the workspace compute instance that you
    created in the previous steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.22: Selecting AML workspace compute instance as a member](img/B21019_11_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.22: Selecting AML workspace compute instance as a member'
  prefs: []
  type: TYPE_NORMAL
- en: Select the workspace compute instance and proceed to **Review + assign**. This
    process will take a few minutes to assign the role.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Managed identity in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After completing the previous steps, it’s now time to test the AOAI call from
    the AML notebook using the managed identity:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to your AML notebook and select **Create** **new file**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.23: Creating a new notebook](img/B21019_11_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.23: Creating a new notebook'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select **Authenticate**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.24: Authenticating the Azure SDK](img/B21019_11_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.24: Authenticating the Azure SDK'
  prefs: []
  type: TYPE_NORMAL
- en: In the notebook, execute the commands shown next.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the necessary Python package(s), execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the next cell, configure the AOAI endpoint and version details:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve the managed identity token and refresh it before it expires:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure the AOAI model parameters:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Specify the system message:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Perform an AOAI request using the Python SDK. In the provided cell, it’s important
    to note that you are specifying the `api_type` value as `azure_ad` and not passing
    the AOAI key; instead, you are utilizing the managed identity token within the
    `api_key` parameter:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve the result:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The model will respond back as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This marks the completion of the setup for using a managed identity to access
    AOAI resources. In the next section, our attention will shift toward configuring
    VNets and private endpoints.
  prefs: []
  type: TYPE_NORMAL
- en: VNet configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AOAI offers customers a genuinely enterprise-grade service, encompassing content
    filtering as well as network-level security through VNet connectivity and support
    for private endpoints. In this section, we will delve into the configuration process
    for setting up a VNet and private endpoint for AOAI resources.
  prefs: []
  type: TYPE_NORMAL
- en: Normally, when you make a call to an AOAI resource, the traffic flows to the
    public endpoint of the AOAI resource and is accessible to all networks by default
    within your subscriptions. In essence, anyone with the API key and service endpoint
    can access the AOAI resource, posing a security concern for enterprise environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through the configuration of VNet settings, you can control and restrict the
    traffic flow originating from an Azure resource within a specific VNet to the
    AOAI public endpoint over the Azure backbone, as depicted here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.25: AOAI with VNet configurations](img/B21019_11_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.25: AOAI with VNet configurations'
  prefs: []
  type: TYPE_NORMAL
- en: To set up VNet settings for accessing the AOAI public endpoint from a **virtual
    machine** (**VM**) within a subnet, please follow the steps outlined here.
  prefs: []
  type: TYPE_NORMAL
- en: AOAI networking configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate the previously created AOAI resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the **Networking** section and choose the **Selected Network and Private**
    **Endpoints** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Within the **Virtual networks** section, select **Add new virtual network**
    or choose an existing one if you already have one set up. In this example, we
    have created a new VNet and subnet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.26: AOAI VNet assignment](img/B21019_11_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.26: AOAI VNet assignment'
  prefs: []
  type: TYPE_NORMAL
- en: In the **Firewall** section, if you wish to add your client’s IP address for
    accessing AOAI, you can check the corresponding checkbox.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, click on the **Save** button to preserve the settings.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By completing these steps, you have successfully configured the basic settings
    to allow AOAI access from a specific subnet through the service endpoint. Now,
    it’s time to test these settings to ensure that AOAI is only accessible from the
    configured subnet.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the VNet settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to Azure AI Foundry from your local machine and click on **Chat** from
    the playground.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter any prompt; for example, `Who is the CEO` `of Microsoft?`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will receive an error stating `Access denied due to Virtual` `Network/Firewall
    rules`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, perform the same test from a VM located within the designated subnet:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch a Windows VM inside the subnet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in to Azure AI Foundry from your local machine and click on **Chat** from
    the playground.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter any prompt; for example, `Who is the CEO` `of Microsoft?`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will get an answer back as `As of September 2021, the CEO of Microsoft is
    Satya Nadella. He has been serving as the CEO since February` `4, 2014.`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open Command Prompt and execute `nslookup` on your AOAI endpoint to confirm
    that the traffic is indeed traversing to the AOAI public endpoint from the specified
    subnet and is using the Azure backbone network:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.27: AOAI public endpoint – nslookup](img/B21019_11_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.27: AOAI public endpoint – nslookup'
  prefs: []
  type: TYPE_NORMAL
- en: With this confirmation, it is evident that AOAI is exclusively accessible from
    the designated subnet via a service endpoint over the Azure network. In the next
    section, we will discuss AOAI access over a private endpoint as a measure to address
    this issue.
  prefs: []
  type: TYPE_NORMAL
- en: Private endpoint configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AOAI private endpoints are a critical solution within the Azure ecosystem.
    They serve as a crucial component in enhancing the connection between your Azure
    resources and OpenAI services. Their primary function is to secure the transmission
    of data, keeping it isolated from exposure to the public internet. Through the
    establishment of a private link, AOAI private endpoints create a secure and efficient
    conduit for data transfer between your infrastructure and the OpenAI service.
    This approach helps in mitigating potential security risks typically associated
    with conventional public endpoints, as shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.28: AOAI private endpoint](img/B21019_11_28.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.28: AOAI private endpoint'
  prefs: []
  type: TYPE_NORMAL
- en: AOAI private endpoint configurations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate the previously created AOAI resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the **Networking** section and choose the **Firewalls and virtual** **networks**
    tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose the **Disabled**” option for **Allow** **access from**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go to the **Private endpoint** **connections** tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on **Private endpoint**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the private endpoint instance name, network interface name, and region,
    then continue to the next page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave the default settings unchanged on all other pages and proceed to create
    the private endpoint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the private endpoint is created, you will see a private IP and private
    DNS assigned to the AOAI endpoint:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.29: Private endpoint DNS details](img/B21019_11_29.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.29: Private endpoint DNS details'
  prefs: []
  type: TYPE_NORMAL
- en: Following these steps, you’ve effectively set up the fundamental configurations
    to permit AOAI access via a private endpoint. The next step involves testing these
    settings to confirm that AOAI is exclusively accessible through the private endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Testing the private endpoint settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to Azure AI Foundry from your local machine and click on **Chat** from
    the playground.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter any prompt; for example, `Who is the CEO` `of Microsoft?`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will receive an error stating `Access denied due to Virtual Network/Firewall
    rules`. This is because you disabled the public access completely.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, perform the same test from a VM located within the designated subnet where
    the private endpoint has been created:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch a Windows VM inside the subnet where you have created the private endpoint.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Log in to Azure AI Foundry from your local machine and click on **Chat** from
    the playground.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter any prompt; for example, `Who is the CEO` `of Microsoft?`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will get an answer back as `As of September 2021, the CEO of Microsoft is
    Satya Nadella. He has been serving as the CEO since February` `4, 2014`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open Command Prompt and execute `nslookup` on your AOAI endpoint to confirm
    that traffic is indeed traversing through the private endpoint from the specified
    subnet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.30: AOAI private endpoint – nslookup](img/B21019_11_30.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.30: AOAI private endpoint – nslookup'
  prefs: []
  type: TYPE_NORMAL
- en: This confirmation establishes that, with a private endpoint, you can access
    AOAI services without routing traffic over the public internet. This represents
    the most secure configuration for accessing AOAI resources.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming section, we will delve into AOAI service data encryption. Many
    enterprises are not only focused on securing their environments through various
    network settings but also emphasize the need to encrypt data both in transit and
    at rest. This approach not only ensures the integrity and confidentiality of data,
    meeting rigorous SOC audit standards, but also aligns with HIPAA and PCI compliance
    mandates. By safeguarding sensitive information against unauthorized access and
    breaches, enterprises can adhere to regulatory requirements and best practices,
    thereby establishing a robust security framework for their data.
  prefs: []
  type: TYPE_NORMAL
- en: Data encryption
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data encryption for Azure is a way of protecting your data from unauthorized
    access by using various methods, protocols, and algorithms. Azure encrypts your
    data both at rest and in transit, meaning that your data is secure when it is
    stored (at rest) in Azure services and when it is transferred over the network
    (in transit).
  prefs: []
  type: TYPE_NORMAL
- en: Encryption in transit
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Data encryption in transit for AOAI is managed by Microsoft’s Azure network
    infrastructure. Microsoft employs **Transport Layer Security** (**TLS**) 1.2 as
    the default security protocol for all its services, including AOAI. It also uses
    IPsec and MACsec to encrypt all Azure traffic within a region or between regions,
    utilizing the **Advanced Encryption Standard 256** (**AES-256**) block cipher
    for encryption. Importantly, this traffic remains entirely within Microsoft’s
    global network backbone and does not traverse the public internet (using a private
    endpoint). This approach guarantees that your data is safeguarded from unauthorized
    access or tampering during transmission by the AOAI service.
  prefs: []
  type: TYPE_NORMAL
- en: Encryption at rest
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Microsoft’s strategy for implementing dual layers of encryption for data at
    rest involves the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Microsoft-managed** **keys** (**MMK**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customer-managed** **keys** (**CMK**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MMK
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AOAI operates as part of the broader Azure AI services ecosystem, where data
    security is paramount. Within Azure AI services, data is safeguarded using **Federal
    Information** **Processing Standard** (FIPS) 140-2-compliant 256-bit AES encryption.
    This encryption standard ensures robust protection for your data. The encryption
    and decryption procedures are seamlessly integrated, meaning that encryption and
    access management are taken care of automatically. This setup guarantees that
    your data remains inherently secure without requiring any manual code or application
    adjustments to leverage this encryption layer.
  prefs: []
  type: TYPE_NORMAL
- en: CMK
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For those seeking enhanced control over key management, CMK, sometimes known
    as **Bring Your Own Key** (**BYOK**), offers a greater level of flexibility in
    creating, rotating, disabling, and revoking access controls. Moreover, CMK enables
    you to conduct audits on the encryption keys utilized to protect your data.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing CMK necessitates the utilization of Azure Key Vault as the designated
    storage solution for your customer-managed keys. You have the option to either
    generate your own keys and store them within a key vault or leverage the Azure
    Key Vault APIs to generate these keys.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure seamless integration between the Azure AI service resource and Azure
    Key Vault, they must reside in the same region and be linked to the same Azure
    AD tenant. Although they can belong to different subscriptions, this alignment
    is crucial for their effective functioning. To apply for authorization to employ
    CMK, kindly proceed to complete and submit the form accessible at the following
    link: [https://aka.ms/cogsvc-cmk](https://aka.ms/cogsvc-cmk). Please note that
    the approval process for your request typically takes around 3 to 5 business days.
    For activating CMK, it’s imperative to ensure that both the **Soft Delete** and
    **Do Not Purge** properties are enabled on the associated key vault. It’s important
    to note that only RSA keys with a size of 2048 are supported for encryption within
    Azure AI services.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s proceed with configuring CMK for the AOAI resource:'
  prefs: []
  type: TYPE_NORMAL
- en: Sign in to the Azure portal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the appropriate AOAI service resource.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the left, select **Encryption**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Under **Encryption type**, select **Customer** **Managed Keys**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enter the **Key URI** value or choose **Select from** **Key Vault**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Save your changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: With these settings in place, you have successfully enabled CMK to encrypt data
    at rest. You can rotate a customer-managed key within the key vault to align with
    your compliance policies. When a key rotation occurs, it’s essential to update
    the Azure AI services resource to use the new key **Uniform Resource** **Identifier**
    (**URI**).
  prefs: []
  type: TYPE_NORMAL
- en: Up to this point, we’ve discussed data privacy and security measures that can
    be implemented for the AOAI service to safeguard enterprise data. In the next
    section, we will shift our focus to one of the most crucial topics, which is model
    safety, in accordance with responsible AI practices.
  prefs: []
  type: TYPE_NORMAL
- en: Responsible AI for AOAI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recent advancements in LLMs have demonstrated significant progress in various
    sophisticated tasks such as content and code generation, summarization, and search.
    While these developments offer numerous advantages, they also present new challenges
    in ensuring responsible AI usage, including concerns regarding harmful content,
    manipulation, human-like behavior, privacy, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address these challenges, Microsoft has introduced a comprehensive set of
    technical guidelines and resources to aid users in responsibly incorporating AOAI
    models into their AI systems. These guidelines are based on the Microsoft Responsible
    AI Standard, which sets forth the policy requirements followed by Microsoft’s
    engineering teams. The standard primarily emphasizes the importance of identifying,
    measuring, and mitigating potential harms, as well as planning for the operation
    of AI systems. Consistent with these principles, the recommendations are divided
    into four key stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identify**: This stage involves identifying and prioritizing potential harms
    that may arise from your AI system. This is accomplished through iterative processes
    such as red-teaming, stress-testing, and comprehensive analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Measure**: In this stage, you quantify the frequency and severity of identified
    harms by establishing clear metrics, creating test sets for measurement, and conducting
    systematic testing. Both manual and automated testing methods are employed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mitigate**: To address these harms, you implement tools and strategies, including
    prompt engineering and the use of content filters. After implementing mitigations,
    it’s essential to repeat the measurement process to assess the effectiveness of
    these efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operate**: In the final stage, you define and execute a deployment and operational
    readiness plan to ensure that the AI system functions smoothly and responsibly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These stages closely correspond to the functions outlined in the **National
    Institute of Standards and Technology AI Risk Management Framework** (**NIST RMF**),
    enhancing the responsible and effective management of AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s delve into the specifics of each of these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Identify
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When developing AI systems, it’s crucial to identify potential harms and risks
    early on. This proactive approach enhances the effectiveness of mitigation efforts.
    To assess potential harms, consider the specific contexts in which the AI system
    will be used. This involves conducting impact assessments, iterative testing,
    and comprehensive analysis to pinpoint vulnerabilities and limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The goal is to create a prioritized list of potential harms for each scenario.
    Here’s a step-by-step approach:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Identify relevant harms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Model-specific considerations**: Recognize potential harms linked to the
    model’s capabilities and limitations, particularly when working with different
    models (for example, GPT-3.5 and GPT-4). Evaluate how these distinctions impact
    your system.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Contextualize potential harms**: Pinpoint additional harms or expanded scope
    of harm that may arise from the intended use of your system. Utilize tools such
    as Responsible AI impact assessments ([https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf))
    to identify these potential harms.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prioritize harms**: Assess risk factors such as frequency and severity. Evaluate
    the level of risk associated with each harm and gauge the likelihood of each risk
    occurring. Collaborate with experts and stakeholders to make informed prioritization
    decisions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Conduct testing**: Engage in red-team testing and stress testing, starting
    with high-priority harms, to understand how identified harms manifest in your
    specific scenario. This process also helps discover potential new harms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Share findings**: Document and share identified harms with relevant stakeholders
    through internal compliance procedures.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By the end of this process, you should have a detailed and sorted record of
    identified harms. As you uncover new instances of harms or fresh harms, refine
    and extend this list by repeating the process.
  prefs: []
  type: TYPE_NORMAL
- en: Measure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After identifying and prioritizing potential harms, the next step is to develop
    a strategy for systematic evaluation and assessment of the AI system. This can
    be done manually or automatically, with a recommended combination of both approaches,
    starting with manual measurement:'
  prefs: []
  type: TYPE_NORMAL
- en: Focus on a small set of priority issues and continuously monitor progress until
    adverse effects are mitigated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define and report metrics until an automated evaluation is reliable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conduct periodic spot checks to ensure the accuracy of automated assessment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then, proceed to automated measurement:'
  prefs: []
  type: TYPE_NORMAL
- en: Scale up measurements for broader coverage and more comprehensive results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously monitor for setbacks as the system, usage patterns, and mitigation
    strategies evolve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are specific suggestions for assessing potential harms in your AI system,
    starting with manual evaluation and defining a strategy for automation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Craft input scenarios**: Develop input scenarios likely to trigger each identified
    priority harm. Create diverse examples of targeted inputs that may lead to each
    prioritized harm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generate system outputs**: Use these examples as inputs for the AI system
    and document the corresponding outputs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Assess and** **communicate findings**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define metrics for each application, measuring the frequency and severity of
    harmful outputs.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorize outputs as detrimental or problematic within the context of your
    system and specific harm category.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Assess system outputs against defined metrics, document occurrences of detrimental
    outputs, and repeat assessments to evaluate mitigations and monitor for regression.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Share findings with relevant stakeholders through internal compliance procedures.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By the end of this measurement stage, you should have an established measurement
    strategy, an initial collection of documented outcomes, and refined metrics and
    measurement sets. Continuously update and add metrics for unforeseen harms, and
    regularly update recorded results as you implement and test mitigation strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To mitigate the potential risks linked with advanced language models such as
    AOAI, a multi-faceted approach is crucial. This involves a cyclical process of
    testing, evaluation, and adaptation. A comprehensive risk management strategy
    should encompass four layers of countermeasures to address the identified concerns.
    These layers include the following (as seen in *Figure 11**.31*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.31: AOAI model mitigation layers](img/B21019_11_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.31: AOAI model mitigation layers'
  prefs: []
  type: TYPE_NORMAL
- en: '**Model layer**: When working with AI models, it’s essential to understand
    the specific model’s capabilities and any fine-tuning measures taken by developers
    to align the model with its intended use. These fine-tuning steps help mitigate
    potential risks and harmful outcomes. For instance, some models, such as those
    developed by OpenAI, incorporate techniques such as **reinforcement learning from
    human feedback** (**RLHF**) and fine-tuning to build safety into the model. This
    approach helps prevent unwanted behaviors, as seen in models such as ChatGPT,
    GPT 4, GPT4-o, and so on. For example, ChatGPT has been fine-tuned to avoid generating
    inappropriate or harmful content by incorporating feedback loops where human reviewers
    assess outputs and guide the model toward safer and more useful interactions.
    This ensures that the model responds appropriately in a variety of contexts, reducing
    the likelihood of generating offensive or misleading information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Safety system layer**: Selecting a base model is just the first step. Relying
    solely on built-in safety measures is often insufficient, as even fine-tuned LLMs
    can make errors and are vulnerable to attacks such as jailbreaks. To address this,
    a layered **defense-in-depth** (**DiD**) strategy is employed, similar to security
    practices. An AI-driven safety system operates alongside the model, continuously
    monitoring inputs and outputs to prevent attacks and identify errors. At the platform
    level, content filters such as those from AOAI are used to block harmful input
    and output content, enhancing the overall safety and security of the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Application layer**: At the application level, prioritizing safety is crucial.
    Developers can achieve this by utilizing “guided instructions” (also referred
    to as “clear prompts” or “model guidance”) in conjunction with prompt engineering,
    a topic explored in-depth later in this book. These guided instructions involve
    providing explicit directions to the model to steer its behavior, which can significantly
    align the system’s responses with desired outcomes. Additionally, incorporating
    user-centered design principles and implementing UX mitigations are vital strategies
    to prevent AI misuse and reduce the risk of overreliance on AI systems, such as
    the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Review and edit**: Design the UX to encourage thorough review and editing
    of AI-generated content before final acceptance.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Transparency**: Inform users about potential inaccuracies in AI-generated
    content from the outset and regularly remind them during use. Highlight specific
    content types with known inaccuracies, such as numbers, to prompt verification
    and external validation.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User accountability**: Emphasize that users are responsible for the final
    content when reviewing AI-generated material. Remind developers, for instance,
    to thoroughly assess and test code suggestions before acceptance.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Citation**: Include clear citations of information sources when generating
    content derived from references provided to the model.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Length limitations**: Limit input and output length when necessary to prevent
    generating undesirable or harmful content, ensuring responsible use and minimizing
    misuse.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Input and output structuring**: Use prompt engineering to structure inputs
    and control the format or pattern of generated outputs, avoiding open-ended responses
    and enabling users to query within specific boundaries.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automated posting restrictions**: Implement controls to limit automatic posting
    of AI-generated content on social media or external sites, and consider preventing
    automated execution of generated code, to maintain responsible and intentional
    usage.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Positioning layer**: In the positioning layer, transparency is key. To empower
    users, provide clear and concise information about the system’s capabilities and
    limitations. Educational resources, such as a dedicated “learn more” section,
    can offer users a deeper understanding of the system’s functionality and boundaries.
    Additionally, promote responsible system use by sharing best practices with users
    and stakeholders. These guidelines can include effective prompt crafting, reviewing
    generated content, and other essential tips. Integrating these resources and guidelines
    into the UX ensures easy access and enhances user understanding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When implementing measures to address potential harms, it’s crucial to establish
    a systematic process for continuously evaluating their effectiveness. Regularly
    documenting and reviewing measurement results is vital for ongoing system improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Operate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once measurement and mitigation systems are in place, the next step is to establish
    and enact a deployment and operational readiness strategy. This phase encompasses
    thorough reviews of your system and mitigation strategies with relevant stakeholders,
    establishing pipelines for telemetry and feedback collection, and devising an
    **incident response** (**IR**) and rollback strategy to ensure seamless system
    operation and preparedness for any potential issues. Outlined next are recommended
    steps for deploying and operating a system leveraging the AOAI service while implementing
    precise and efficient measures to mitigate potential risks:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Collaborate with compliance teams**: Work with your organization’s compliance
    teams to determine the necessary types of reviews for your system, including legal,
    privacy, security, and accessibility assessments. This will help you identify
    potential issues and address them proactively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Phased delivery strategy**: Implement a phased delivery approach for launching
    your AOAI service. This involves introducing the system to a small group of users
    initially, collecting feedback, and addressing any issues before a wider release.
    This approach helps manage risk, identifies unanticipated failure modes, and ensures
    proactive mitigation of unforeseen concerns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IR planning**: Develop a comprehensive **IR plan** (**IRP**), including timelines
    for effective **incident management** (**IM**). This plan should outline procedures
    for addressing and managing incidents efficiently.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rollback planning**: Establish a rollback plan to quickly revert to a previous
    system state in case of an unforeseen incident. This ensures minimal disruption
    and swift recovery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swift action and mitigation**: Be prepared to take swift action in response
    to unexpected harms. Develop functionalities and procedures to identify and block
    problematic prompts and responses in near real time. In case of unanticipated
    harms, act promptly to block troublesome prompts and responses, implement suitable
    mitigations, investigate incidents thoroughly, and establish sustainable solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Misuse prevention**: Implement processes to identify and address users who
    violate content policies, such as generating hate speech or using the system for
    harmful purposes. Take appropriate measures, including blocking users who frequently
    generate blocked or flagged content. Consider incorporating an appeals process
    when applicable.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User feedback mechanisms**: Establish robust user feedback channels for stakeholders
    and the public to submit feedback and report issues related to generated content
    or system use. Document and systematically evaluate feedback to enhance the system.
    Consider incorporating user feedback buttons to categorize content as “inaccurate,”
    “harmful,” or “incomplete.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Telemetry data collection**: Collect and document telemetry data, considering
    applicable privacy laws and policies. This data should include signals reflecting
    user satisfaction and system usability. Leverage telemetry data to detect shortcomings
    and enhance the system to better meet user needs and expectations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is for informational purposes only and should not be considered
    legal advice. It’s essential to consult with a legal expert to ensure compliance
    with specific regulations and laws applicable to the AI system in your jurisdiction.
    The recommendations provided may not be universally applicable, and it’s crucial
    to recognize that they might be insufficient in certain situations. Please seek
    legal guidance if you have any doubts or concerns about the laws and regulations
    that may apply to your system.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we presented a comprehensive exploration of critical considerations
    for deploying and operating the AOAI service. The focus was on ensuring compliance
    with regulatory requirements and privacy standards, as well as implementing robust
    safeguards for responsible and secure usage. We emphasized the importance of adhering
    to compliance standards and regulations pertinent to your operating jurisdiction,
    enabling legal and ethical AI deployment. Data privacy was highlighted as a non-negotiable
    aspect of AI deployment, with key practices outlined to safeguard user data and
    respect their privacy. The implementation of content filtering mechanisms was
    also identified as crucial to ensure that generated content aligns with ethical
    and safety guidelines. Additionally, we discussed the significance of managed
    identity solutions for securing access to the AOAI service, as well as configurations
    for VNets and private endpoints to enhance network and system security. Finally,
    we explored Microsoft’s layered defense approach, highlighting the significance
    of building and using GenAI responsibly with AOAI. This approach underscores the
    need for iterative, safeguarded strategies encompassing compliance, privacy, security,
    and ethical considerations, providing a robust framework for the responsible deployment
    of GenAI applications.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming chapter, we will delve into various techniques for operationalizing
    AOAI, including critical aspects such as monitoring, cost management, quota management,
    **business continuity** (**BC**), and **disaster recovery** (**DR**). These topics
    are pivotal for ensuring the smooth and efficient operation of your AOAI services.
  prefs: []
  type: TYPE_NORMAL
