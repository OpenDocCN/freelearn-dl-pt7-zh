<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer286">
			<h1 id="_idParaDest-174"><em class="italic"><a id="_idTextAnchor178"/>Chapter 15</em>: Classifying Documents and Setting up Human in the Loop for Active Learning</h1>
			<p>In the last chapter, we covered how you can use <strong class="bold">Amazon Comprehend Custom Entity</strong> to extract business entities from your documents, and we showed you how you can use humans in the loop with Amazon Augmented AI (A2I) to augment or improve entity predictions. Lastly, we showed you how you can retrain the Comprehend custom entity model with an augmented dataset to improve accuracy using Amazon A2I.</p>
			<p>In this chapter, we will talk about how you can use <strong class="bold">Amazon Comprehend</strong> custom classification to classify documents and then how you can set up active learning feedback with your custom classification model using Amazon A2I.</p>
			<p>We will be covering the following topics in this chapter:</p>
			<ul>
				<li>Using comprehend custom classification with human in the loop for active learning</li>
				<li>Building the document classification workflow</li>
			</ul>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor179"/>Technical requirements</h1>
			<p>For this chapter, you will need access to an AWS account. Please make sure to follow the instructions specified in the <em class="italic">Technical requirements</em> section in <a href="B17528_02_Final_SB_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>,<strong class="bold"> </strong><em class="italic">Introducing Amazon Textract</em>, to create your AWS account, and log in to the AWS Management Console before trying the steps in this chapter.</p>
			<p>The Python code and sample datasets for setting up Comprehend custom classification with a human-in-the-loop solution are in the following link: <a href="https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015">https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services/tree/main/Chapter%2015</a>.</p>
			<p>Check out the following video to see the Code in Action at <a href="https://bit.ly/3BiOjKt">https://bit.ly/3BiOjKt</a>.</p>
			<p>Please use the instructions in the following sections along with the code in the repository to build the solution.</p>
			<h1 id="_idParaDest-176"><a id="_idTextAnchor180"/>Using Comprehend custom classification with human in the loop for active learning</h1>
			<p>Amazon Comprehend provides the capability to classify the data using Amazon Comprehend AutoML and bring your own custom training dataset. You can easily accomplish <a id="_idIndexMarker847"/>a lot with the Amazon Comprehend custom classification feature as it requires fewer documents to train Comprehend AutoML models. You are spending less time labeling the dataset and then worrying about setting up infrastructure or choosing the right algorithm. </p>
			<p>You can use Amazon Comprehend custom classification for a variety of use cases, such as classifying documents based on type, classifying news articles, or classifying movies based on type. </p>
			<p>The fictitious company <em class="italic">LiveRight pvt ltd</em> wants to classify the documents submitted by the customers, such as whether the document submitted is an ID or a bank statement, even before analyzing the data inside the document. Moreover, if you are using a classification model to classify the documents based on the type of submitted document, you would also want to improve the accuracy of your predicted outcome in real time, based on the confidence score predicted by the Comprehend custom classification model. This is where humans in the loop with Amazon Augmented AI is going to help.</p>
			<p>We covered Amazon A2I in <a href="B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 13</em></a>, <em class="italic">Improving the Accuracy of Document Processing Workflows</em>. In this chapter, we will walk you through some reference architecture on how you can easily set up a custom classification model using Amazon Comprehend and have a feedback loop set up with Amazon A2I for active learning on your Comprehend custom model. </p>
			<p>First, we will walk you through the following architecture on how you can train a custom classification model and create a real-time endpoint for inferencing or classifying documents in near real time.</p>
			<div>
				<div id="_idContainer273" class="IMG---Figure">
					<img src="Images/B17528_15_01.jpg" alt="Figure 15.1 – Comprehend custom classification training workflow&#13;&#10;" width="1108" height="398"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.1 – Comprehend custom classification training workflow</p>
			<p>This <a id="_idIndexMarker848"/>architecture walks through the following steps:</p>
			<ol>
				<li>Training documents, such as bank statements or pay stubs, are uploaded to Amazon S3.</li>
				<li>Amazon Textract extracts text from these documents and then some post-processing is done to create a labeled training file for Comprehend custom classification training.</li>
				<li>Using the training file, an Amazon Comprehend job is created to classify documents, such as bank statements or pay stubs.</li>
				<li>After training is completed, you have two options with Amazon Comprehend: either you can do batch inferencing on a batch of documents to classify them or you can create real-time endpoints. In the architecture, we are showing how you can set up a real-time endpoint to classify a document type.</li>
			</ol>
			<p>We are going to walk you through the preceding conceptual architecture using Jupyter Notebook and a few lines of Python code in the <em class="italic">Setting up to solve the use case</em> section.</p>
			<p>Now, we have a near real-time document classification endpoint. We will show you how you can set up humans in the loop with this Amazon Comprehend custom classification endpoint and set up a model retraining or active-learning loop to improve your model accuracy using the following architecture:</p>
			<div>
				<div id="_idContainer274" class="IMG---Figure">
					<img src="Images/B17528_15_02.jpg" alt="Figure 15.2 – Real-time classification with model retraining&#13;&#10;" width="1134" height="696"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.2 – Real-time classification with model retraining</p>
			<p>In <a id="_idIndexMarker849"/>this architecture, we will walk you through the following steps:</p>
			<ol>
				<li value="1"><strong class="bold">Client application</strong> sends the document to Amazon Textract. </li>
				<li><strong class="bold">Amazon Textract</strong> extracts the data or text in real-time API and extracted data is passed on to the Amazon Comprehend real-time classifier endpoint.</li>
				<li>The Amazon Comprehend custom classification endpoint classifies this document type.</li>
				<li>This classification endpoint is configured with Amazon A2I human in the loop. If the prediction of classification is <strong class="bold">high confidence</strong> based on your business threshold, which you can configure, the high-confidence predictions are directly sent to client applications.</li>
				<li>For low-confidence predictions, such as anything below the 95% confidence, the score predicted is low confidence for you. A human loop is created, and these predictions are sent for human review. Refer to <a href="B17528_03_Final_SB_ePub.xhtml#_idTextAnchor049"><em class="italic">Chapter 3</em></a>, <em class="italic">Introducing Amazon Comprehend</em>, to understand what a confidence score is and Comprehend custom features.</li>
				<li>The augmented or corrected data from human labelers are saved in an Amazon S3 bucket as a <strong class="bold">JSON</strong> file.</li>
				<li>This data is then combined with the original training dataset and the Amazon Comprehend custom model is retrained for active learning using human feedback.</li>
			</ol>
			<p>We will <a id="_idIndexMarker850"/>walk you through <em class="italic">steps 1 to 6</em> using Jupyter Notebook in the <em class="italic">Setting up the use case section</em>. Feel free to combine the augmented classified labels with the original dataset and try retraining for your understanding. You can automate this architecture using step functions and Lambda functions. We will share with you the blogs that can help you set up this architecture using Lambda functions in the <em class="italic">Further reading</em> section.<em class="italic"> </em></p>
			<p>In this section, we covered the architecture for both model training and retraining or active learning. Now, let's move on to the next section to see these concepts with code.</p>
			<h1 id="_idParaDest-177"><a id="_idTextAnchor181"/>Building the document classification workflow</h1>
			<p>In this section, we <a id="_idIndexMarker851"/>will get right down to action and start executing the tasks to build our solution. But first, there are prerequisites we will have to take care o<a id="_idTextAnchor182"/>f.</p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor183"/>Setting up to solve the use case</h2>
			<p>If you have not done so in the previous chapters, you will first have to create an Amazon SageMaker <a id="_idIndexMarker852"/>Jupyter notebook and set up <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) permissions for that notebook <a id="_idIndexMarker853"/>role to access the AWS services we will use in this notebook. After that, you will need to clone the GitHub repository (<a href="https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services">https://github.com/PacktPublishing/Natural-Language-Processing-with-AWS-AI-Services</a>), go to the <strong class="source-inline">Chapter 15</strong> folder, and open the <strong class="source-inline">chapter15 classify documents with human in the loop.ipynb</strong> notebook.</p>
			<p>Now, let's move to the next section to show you how you can set up the libraries and upload training data to Amazon S3 using this notebook.</p>
			<h3>Setting up and uploading sample documents to Amazon S3</h3>
			<p>In this step, we <a id="_idIndexMarker854"/>will follow instructions to set <a id="_idIndexMarker855"/>up an S3 bucket and upload documents:</p>
			<ol>
				<li value="1">Go to the notebook and run the cells below <strong class="bold">Step 1: Set up and upload sample documents to Amazon S3</strong> in the notebook to install libraries such as <strong class="source-inline">boto 3</strong> for setup.</li>
				<li>Move on to the next cell and enter a bucket name to create an S3 bucket in your account. Make sure you add the current month and date in <strong class="source-inline">MMDD</strong> for <strong class="source-inline">data_bucket</strong>, as shown in the following code block, before executing this cell:<p class="source-code">data_bucket = "doc-processing-bucket-MMDD"</p><p class="source-code">region = boto3.session.Session().region_name</p><p class="source-code">               os.environ["BUCKET"] = data_bucket</p><p class="source-code">os.environ["REGION"] = region</p><p class="source-code">if region=='us-east-1':</p><p class="source-code">    !aws s3api create-bucket --bucket $BUCKET</p><p class="source-code">else:</p><p class="source-code">    !aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$REGION</p></li>
				<li>Now run the following cell to upload or copy a sample bank statement or pay stub image as a training file from your local notebook to the S3 bucket that you just created:<p class="source-code">!aws s3 cp documents/train s3://{data_bucket}/train –recursive</p></li>
				<li>Now run the next two cells in the notebook to list the training images we just copied <a id="_idIndexMarker856"/>in Amazon S3. We created <a id="_idIndexMarker857"/>a function named <strong class="source-inline">get_s3_bucket_items</strong>. We are getting the image objects from S3 and saving them as images for Textract processing in future steps. Refer to the notebook to execute these steps.</li>
				<li>Run the following step to define a path or local directory structure to store data extracted from Amazon Textract:<p class="source-code">word_prefix=os.getcwd()+'/SAMPLE8/WORDS/'</p><p class="source-code">box_prefix=os.getcwd()+'/SAMPLE8/BBOX/'</p></li>
			</ol>
			<p>We've covered how to create an S3 bucket and we have loaded training data. Now, let's move on to the next section to extract text.</p>
			<h3>Extracting text from sample documents using Amazon Textract</h3>
			<p>Go to <a id="_idIndexMarker858"/>the notebook and run the calls in <strong class="bold">Step 2: Extract text from sample documents using Amazon Textract</strong> to define a function using Amazon Textract to extract data from the sample images in Amazon S3. We are using the DetectDocumentText sync API to do this extraction; you can also use <em class="italic">AsyncAPI</em> or <em class="italic">Textract batch APIs</em> to perform data extraction. Refer to <a href="B17528_04_Final_SB_ePub.xhtml#_idTextAnchor063"><em class="italic">Chapter 4</em></a>, <em class="italic">Automating Document Processing Workflows</em>, to dive deep into these APIs:</p>
			<p class="source-code">def data_retriever_from_path(path):    </p>
			<p class="source-code">    mapping={}</p>
			<p class="source-code">    for i in names:</p>
			<p class="source-code">        if os.path.isdir(path+i):</p>
			<p class="source-code">            mapping[i] = sorted(os.listdir(path+i))</p>
			<p class="source-code">    label_compre = []</p>
			<p class="source-code">    text_compre = []</p>
			<p class="source-code">    for i, j in mapping.items():</p>
			<p class="source-code">                for k in j:</p>
			<p class="source-code">            label_compre.append(i)</p>
			<p class="source-code">            text_compre.append(open(path+i+"/"+k, encoding="utf-8").read().replace('\n',' '))</p>
			<p class="source-code">    return label_compre, text_compre</p>
			<p>This function takes the <em class="italic">image's</em> path and returns the text and labels for the images.</p>
			<p>Let's <a id="_idIndexMarker859"/>call this function by passing the scanned document's images by running the following cell in the notebook:</p>
			<p class="source-code">tic = time.time()</p>
			<p class="source-code">pool = mp.Pool(mp.cpu_count())</p>
			<p class="source-code">pool.map(textract_store_train_LM, [table for table in images ])</p>
			<p class="source-code">print("--- %s seconds for extracting ---" % (time.time() - tic))</p>
			<p class="source-code">pool.close()</p>
			<p>The preceding function extracts the data and saves it in the local directory structure you defined in the <strong class="bold">Set up and Upload Sample Documents</strong> step. The following is the output:</p>
			<div>
				<div id="_idContainer275" class="IMG---Figure">
					<img src="Images/B17528_15_03.jpg" alt="Figure 15.3 – Textract output&#13;&#10;" width="494" height="392"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.3 – Textract output</p>
			<p>Now, we <a id="_idIndexMarker860"/>have extracted the text and associated labels, for example, <em class="italic">0</em> for a bank statement and <em class="italic">1</em> for pay stubs. Now, let's move to the next section for Comprehend training.</p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor184"/>Creating an Amazon Comprehend classification training job</h2>
			<p>We have extracted the data and labels in the previous step from our sample of scanned documents <a id="_idIndexMarker861"/>in Amazon S3. Now, let's understand how to set up a Comprehend classification training job using <strong class="bold">Step 3: Create Amazon Comprehend Classification training job</strong> in the notebook:</p>
			<ol>
				<li value="1">We will first create a function to map the extracted data and labels into a pandas DataFrame so that we can convert that into a CSV training file in the next step. Run the following code to define the function, which takes the extracted data location and returns labels and text from it:<p class="source-code">def data_retriever_from_path(path):    </p><p class="source-code">    mapping={}</p><p class="source-code">    for i in names:</p><p class="source-code">        if os.path.isdir(path+i):</p><p class="source-code">            mapping[i] = sorted(os.listdir(path+i))</p><p class="source-code">    # label or class or target list</p><p class="source-code">    label_compre = []</p><p class="source-code">    # text file data list</p><p class="source-code">    text_compre = []</p><p class="source-code">    # unpacking and iterating through dictionary</p><p class="source-code">    for i, j in mapping.items():</p><p class="source-code">        # iterating through list of files for each class</p><p class="source-code">        for k in j:</p><p class="source-code">            # appending labels/class/target</p><p class="source-code">            label_compre.append(i)</p><p class="source-code">            # reading the file and appending to data list</p><p class="source-code">            text_compre.append(open(path+i+"/"+k, encoding="utf-8").read().replace('\n',' '))</p><p class="source-code">    return label_compre, text_compre</p></li>
				<li>Now, we <a id="_idIndexMarker862"/>will call the function we defined in the previous step by running the following cell:<p class="source-code">label_compre, text_compre=[],[]</p><p class="source-code">path=word_prefix+'train/'</p><p class="source-code">label_compre_train, text_compre_train=data_retriever_from_path(path)</p><p class="source-code">label_compre.append(label_compre_train)</p><p class="source-code">text_compre.append(text_compre_train)</p><p class="source-code">if type(label_compre[0]) is list:</p><p class="source-code">        label_compre=[item for sublist in label_compre for item in sublist]</p><p class="source-code">        #print(label_compre)</p><p class="source-code">        text_compre=[item for sublist in text_compre for item in sublist]</p><p class="source-code">        #print(text_compre)</p><p class="source-code">data_compre= pd.DataFrame()</p><p class="source-code">data_compre["label"] =label_compre   </p><p class="source-code">data_compre["document"] = text_compre</p><p class="source-code">data_compre</p><p>You will get a pandas DataFrame with labels and documents, shown as follows:</p><div id="_idContainer276" class="IMG---Figure"><img src="Images/B17528_15_04.jpg" alt="Figure 15.4 – Labeled training DataFrame&#13;&#10;" width="630" height="426"/></div><p class="figure-caption">Figure 15.4 – Labeled training DataFrame</p></li>
				<li>Now, we <a id="_idIndexMarker863"/>will save this DataFrame as a CSV and upload it to Amazon S3 using S3. Put the <strong class="source-inline">boto3</strong> API object as the Comprehend training file for Amazon Comprehend training:<p class="source-code">csv_compre=io.StringIO()</p><p class="source-code">data_compre.to_csv(csv_compre,index=False, header=False)</p><p class="source-code">key='comprehend_train_data.csv'  </p><p class="source-code">input_bucket=data_bucket        </p><p class="source-code">output_bucket= data_bucket       </p><p class="source-code">response2 = s3.put_object(</p><p class="source-code">        Body=csv_compre.getvalue(),</p><p class="source-code">        Bucket=input_bucket,</p><p class="source-code">        Key=key)</p></li>
				<li>Now, go to the Amazon Comprehend console link (https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classification) to create a classification job. Click on <strong class="bold">Train Classifier</strong>.</li>
				<li>In <strong class="bold">Model name</strong>, enter <strong class="source-inline">doc-classifier</strong>, and in <strong class="bold">Version name</strong>, enter <strong class="source-inline">1</strong>, and scroll <a id="_idIndexMarker864"/>down to select <strong class="bold">Using Single-label model</strong> for <strong class="bold">Classifier mode</strong>. Also, make sure the data format is <strong class="source-inline">csv file</strong>.<p class="callout-heading">Important Note</p><p class="callout">We have <a id="_idIndexMarker865"/>the choice to add versions for Amazon Comprehend custom models. To learn more about this feature, refer to this link: <a href="https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html">https://docs.aws.amazon.com/comprehend/latest/dg/model-versioning.html</a>.</p><div id="_idContainer277" class="IMG---Figure"><img src="Images/B17528_15_05.jpg" alt="Figure 15.5 – Amazon Comprehend custom classification UI&#13;&#10;" width="791" height="679"/></div><p class="figure-caption">Figure 15.5 – Amazon Comprehend custom classification UI</p></li>
				<li>For <a id="_idIndexMarker866"/>the training data location, browse to the <strong class="source-inline">doc-processing-bucket-MMDD</strong> S3 bucket created in the <strong class="bold">Set up and upload sample documents to Amazon S3 </strong>step or enter <strong class="source-inline">s3://doc-processing-bucket-MMDD/comprehend_train_data.csv</strong>.</li>
				<li>For <strong class="bold">Test Dataset</strong>, go with the default <strong class="source-inline">Autosplit</strong>, which means Amazon Comprehend will automatically split the test data for you. You also have the choice to tune your model by bringing your own test dataset here.</li>
				<li>For output data, enter the <strong class="source-inline">s3://doc-processing-bucket-MMDD</strong> S3 bucket.</li>
				<li>For <a id="_idIndexMarker867"/>access permissions, select <strong class="bold">Create an IAM Role</strong> and enter <strong class="source-inline">classifydoc</strong> in <strong class="bold">NameSuffix</strong>. <div id="_idContainer278" class="IMG---Figure"><img src="Images/B17528_15_06.jpg" alt="Figure 15.6 – Amazon Comprehend custom classification IAM setting&#13;&#10;" width="751" height="678"/></div><p class="figure-caption">Figure 15.6 – Amazon Comprehend custom classification IAM setting</p></li>
				<li>Scroll down and click on the <strong class="bold">Train Classifier</strong> button to start training.<p class="callout-heading">Important Note </p><p class="callout">This training will take 30 minutes to complete as we have a large number of documents to train with in this chapter. You can use this time to set up a private workforce for setting up humans in the loop, which we did in <a href="B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 13</em></a>, <em class="italic">Improving the Accuracy of Document Processing Workflows</em>.</p></li>
			</ol>
			<p>Once <a id="_idIndexMarker868"/>your job is completed, move on to the next step.</p>
			<h2 id="_idParaDest-180"><a id="_idTextAnchor185"/>Creating Amazon Comprehend real-time endpoints and testing a sample document</h2>
			<p>In this <a id="_idIndexMarker869"/>section, we will show you <a id="_idIndexMarker870"/>how you can create a real-time endpoint <a id="_idIndexMarker871"/>with the trained model in the <strong class="bold">AWS Management Console</strong>. Comprehend uses the <strong class="bold">Inference Unit</strong> (<strong class="bold">IU</strong>) to analyze how many characters <a id="_idIndexMarker872"/>can be analyzed in real time per second. IU is a measure of the endpoint's throughput. You can adjust the IU of an endpoint anytime. After creating the endpoint, we will then show you how you can call this endpoint to test a sample bank statement using the Jupyter Notebook:</p>
			<ol>
				<li value="1">Go to this link, https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#endpoints, and click on <strong class="bold">Create Endpoint.</strong></li>
				<li>Enter <strong class="source-inline">classify-doc</strong> as the endpoint name, set <strong class="bold">Custom model</strong> as <strong class="source-inline">doc-classifier</strong>, which we trained in the previous step, and set <strong class="bold">Inference units</strong> to <strong class="bold">1</strong>.<div id="_idContainer279" class="IMG---Figure"><img src="Images/B17528_15_07.jpg" alt="Figure 15.7 – Amazon Comprehend Create real-time endpoint UI&#13;&#10;" width="811" height="678"/></div><p class="figure-caption">Figure 15.7 – Amazon Comprehend Create real-time endpoint UI</p></li>
				<li>Scroll <a id="_idIndexMarker873"/>down and select <strong class="bold">I Acknowledge</strong> and click on <strong class="bold">Create Endpoint</strong>. <p>Delete <a id="_idIndexMarker874"/>this endpoint at the cleanup section in the notebook to avoid incurring a cost.</p></li>
				<li>Now, copy the <strong class="bold">ARN</strong> of the endpoint, as shown in the next screenshot, and move to the Jupyter Notebook link:<div id="_idContainer280" class="IMG---Figure"><img src="Images/B17528_15_08.jpg" alt="Figure 15.8 – Comprehend custom classification endpoint ARN &#13;&#10;" width="1011" height="365"/></div><p class="figure-caption">Figure 15.8 – Comprehend custom classification endpoint ARN </p></li>
				<li>In the <a id="_idIndexMarker875"/>notebook, enter <a id="_idIndexMarker876"/>the preceding copied endpoint arn in the notebook cell as follows:<p class="source-code">ENDPOINT_ARN='your endpoint arn paste here'</p></li>
				<li>Now, we will take a sample test document or any pay stub not used in training for real-time classification. Run the following code to see the sample pay statement:<p class="source-code">documentName = "paystubsample.png"</p><p class="source-code">display(Image(filename=documentName))</p><p>You will get the following output:</p><div id="_idContainer281" class="IMG---Figure"><img src="Images/B17528_15_09.jpg" alt="Figure 15.9 – Sample pay stub document &#13;&#10;" width="817" height="644"/></div><p class="figure-caption">Figure 15.9 – Sample pay stub document </p></li>
				<li>Run the <a id="_idIndexMarker877"/>next two cells in the notebook under <strong class="bold">Extract Text from this sample doc using Textract</strong> to extract text from this sample document.</li>
				<li>Run the <a id="_idIndexMarker878"/>following cell, which calls a Comprehend ClassifyDocument API. This method takes the extracted text and custom classification endpoint and returns a response:<p class="source-code">response = comprehend.classify_document(</p><p class="source-code">    Text= page_string,</p><p class="source-code">    EndpointArn=ENDPOINT_ARN</p><p class="source-code">)</p><p class="source-code">print(response)</p><p>You will get the following response:</p></li>
			</ol>
			<div>
				<div id="_idContainer282" class="IMG---Figure">
					<img src="Images/B17528_15_10.jpg" alt="Figure 15.10 – ClassifyDocument response&#13;&#10;" width="1361" height="106"/>
				</div>
			</div>
			<p class="figure-caption">Figure 15.10 – ClassifyDocument response</p>
			<p>As per <a id="_idIndexMarker879"/>the response, the model <a id="_idIndexMarker880"/>endpoint has classified the document as a pay stub with 99% confidence. We tested this endpoint, so now let's move on to the next section to set up a human loop.</p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor186"/>Setting up active learning with a Comprehend real-time endpoint using human in the loop</h2>
			<p>In this <a id="_idIndexMarker881"/>section, we are going to show you a custom integration with a Comprehend classifier endpoint, which you can invoke using the A2I StartHumanLoop API. You <a id="_idIndexMarker882"/>can pass any type of AI/ML prediction response to this API to trigger a human loop. In <a href="B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 13</em></a>, <em class="italic">Improving the Accuracy of Document Processing Workflows</em>, we showed you a native integration with the Textract Analyze document API by passing a human loop workflow ARN to the AnalyzeDocument API. Setting up a custom workflow includes the following steps: </p>
			<ol>
				<li value="1">Create a <strong class="bold">worker task template</strong>.</li>
				<li>Create a <strong class="bold">human review workflow</strong>.</li>
				<li>Create and start an A2I human loop.</li>
				<li>Check the human loop status and start labeling.</li>
			</ol>
			<p>To get started, you need to create a private workforce and copy the private ARN in the <em class="italic">Environment setup</em> step in the Jupyter Notebook: </p>
			<ol>
				<li value="1">To create a private workforce, refer to the <em class="italic">Creating a private work team in AWS Console</em> section in <a href="B17528_13_Final_SB_ePub.xhtml#_idTextAnchor151"><em class="italic">Chapter 13</em></a>, <em class="italic">Improving the Accuracy of Document Processing Workflows</em>:<p class="source-code">REGION = 'enter your region'</p><p class="source-code">WORKTEAM_ARN= "enter your private workforce arn "</p><p class="source-code">BUCKET = data_bucket</p><p class="source-code">ENDPOINT_ARN= ENDPOINT_ARN</p><p class="source-code">role = sagemaker.get_execution_role()</p><p class="source-code">region = boto3.session.Session().region_name</p><p class="source-code">prefix = "custom-classify" + str(uuid.uuid1())</p></li>
				<li>Run <a id="_idIndexMarker883"/>the next cell and move to the <strong class="source-inline">Create worker task</strong> template. This <a id="_idIndexMarker884"/>is the UI that the workers are going to view while labeling. We will show the prediction results in the UI and the original document data. We have used a pre-built classification template (<a href="https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html">https://github.com/aws-samples/amazon-a2i-sample-task-uis/blob/master/text/document-classification.liquid.html</a>) for this use case. Run the notebook cell to define the HTML template.<p class="callout-heading">Important Note </p><p class="callout">You can create a custom UI HTML template based on what type of data you want to show to your labelers. For example, you can show the actual document on the right and entities highlighted on the left using custom UIs.</p></li>
				<li>We have defined or chosen the HTML template in the preceding step, in which we will create a function to create a UI task using the <strong class="source-inline">create_human_task_ui</strong> API by running the following code:<p class="source-code">def create_task_ui():</p><p class="source-code">    response = sagemaker.create_human_task_ui(</p><p class="source-code">        HumanTaskUiName=taskUIName,</p><p class="source-code">        UiTemplate={'Content': template})</p><p class="source-code">return response</p></li>
				<li>Run the next cell to invoke the function to create the UI task defined in the previous step. You will get a <strong class="source-inline">human task arn</strong> response.</li>
				<li>Now, we will define a human review workflow. This human review workflow needs <a id="_idIndexMarker885"/>the private workforce you created, the UI template task you created, and a data bucket where you want the output of human <a id="_idIndexMarker886"/>review. We will use the <strong class="source-inline">sagemaker.create_flow_definition</strong> API to create a flow definition or human review workflow by running the following code:<p class="source-code">create_workflow_definition_response = sagemaker.create_flow_definition(</p><p class="source-code">        FlowDefinitionName= flowDefinitionName,</p><p class="source-code">        RoleArn= role,</p><p class="source-code">        HumanLoopConfig= {</p><p class="source-code">            "WorkteamArn": WORKTEAM_ARN,</p><p class="source-code">            "HumanTaskUiArn": humanTaskUiArn,</p><p class="source-code">            "TaskCount": 1,</p><p class="source-code">            "TaskDescription": "Read the instructions",</p><p class="source-code">            "TaskTitle": "Classify the text"</p><p class="source-code">        },</p><p class="source-code">        OutputConfig={</p><p class="source-code">            "S3OutputPath" : "s3://"+BUCKET+"/output"</p><p class="source-code">        }</p><p class="source-code">    </p><p class="source-code">flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn']</p></li>
				<li>Now, we <a id="_idIndexMarker887"/>will get the response from the Comprehend custom <a id="_idIndexMarker888"/>classifier endpoint for the sample document for pay stubs on the sample data and parse this response for the human loop setup:<p class="source-code">response = comprehend.classify_document(</p><p class="source-code">    Text= page_string,</p><p class="source-code">    EndpointArn=ENDPOINT_ARN</p><p class="source-code">)</p><p class="source-code">print(response)</p><p class="source-code">p = response['Classes'][0]['Name']</p><p class="source-code">score = response['Classes'][0]['Score']</p><p class="source-code">        #print(f»S:{sentence}, Score:{score}»)</p><p class="source-code">response = {}</p><p class="source-code">response['utterance']=page_string</p><p class="source-code">response['prediction']=p</p><p class="source-code">response['confidence'] = score</p><p class="source-code">print(response)</p></li>
				<li>Now, using this preceding JSON response, we will set a confidence threshold. This <strong class="source-inline">StartHumanloop</strong> API needs the workflow ARN or flow definition ARN created in the previous step and the JSON response from the Comprehend classification to create a human loop. We are triggering this loop based on the confidence score threshold, as shown in the next code block:<p class="source-code">human_loops_started = []</p><p class="source-code">CONFIDENCE_SCORE_THRESHOLD = .90</p><p class="source-code">if(response['confidence'] &gt; CONFIDENCE_SCORE_THRESHOLD):</p><p class="source-code">        humanLoopName = str(uuid.uuid4())</p><p class="source-code">        human_loop_input = {}</p><p class="source-code">  </p><p class="source-code">        human_loop_input['taskObject'] = response['utterance']</p><p class="source-code">        start_loop_response = a2i_runtime_client.start_human_loop(</p><p class="source-code">        HumanLoopName=humanLoopName,</p><p class="source-code">        FlowDefinitionArn=flowDefinitionArn,</p><p class="source-code">        HumanLoopInput={</p><p class="source-code">                "InputContent": json.dumps(human_loop_input)</p><p class="source-code">            }</p><p class="source-code">        )</p><p class="source-code">        print(human_loop_input)</p><p class="source-code">        human_loops_started.append(humanLoopName)</p><p class="source-code">        print(f'Score is less than the threshold of {CONFIDENCE_SCORE_THRESHOLD}')</p><p class="source-code">        print(f'Starting human loop with name: {humanLoopName}  \n')</p><p class="source-code">else:</p><p class="source-code">         print('No human loop created. \n')</p><p class="callout-heading">Important Note</p><p class="callout">The <a id="_idIndexMarker889"/>preceding condition states anything greater than 90% confidence from your <a id="_idIndexMarker890"/>model endpoint will trigger a loop. This threshold is for demo purposes and needs to be changed for real use cases, such as anything below 90% that would trigger a human loop.</p></li>
				<li>Now, run <a id="_idIndexMarker891"/>the following code to get the link to your private work team to start labeling:<p class="source-code">workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]</p><p class="source-code">print("Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!")</p><p class="source-code">print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])</p><p>You <a id="_idIndexMarker892"/>will get a link to the following A2I portal:</p><div id="_idContainer283" class="IMG---Figure"><img src="Images/B17528_15_11.jpg" alt="Figure 15.11 – Amazon A2I login console&#13;&#10;" width="1592" height="483"/></div><p class="figure-caption">Figure 15.11 – Amazon A2I login console</p></li>
				<li>Select <strong class="bold">Task title</strong> and click on <strong class="bold">Start working</strong>; you will be redirected to the classification task UI.<div id="_idContainer284" class="IMG---Figure"><img src="Images/B17528_15_12.jpg" alt="Figure 15.12 – Amazon A2I sample classification task UI&#13;&#10;" width="1635" height="538"/></div><p class="figure-caption">Figure 15.12 – Amazon A2I sample classification task UI</p><p>Review the data on the left in the previous screenshot and classify it by selecting the <strong class="bold">Pay Stubs</strong> category, and then click <strong class="bold">Submit</strong>.</p></li>
				<li>After <a id="_idIndexMarker893"/>submitting this classification task as a human reviewer, go back <a id="_idIndexMarker894"/>to the notebook and run the following code to get the completed tasks:<p class="source-code">completed_human_loops = []</p><p class="source-code">resp = a2i_runtime_client.describe_human_loop(HumanLoopName=humanLoopName)</p></li>
				<li>Now, we will review the human-reviewed results from completed human reviews, which are stored automatically as a JSON file in Amazon S3 by running the following code:<p class="source-code">for resp in completed_human_loops:</p><p class="source-code">    splitted_string = re.split('s3://' + data_bucket  + '/', resp['HumanLoopOutput']['OutputS3Uri'])</p><p class="source-code">    output_bucket_key = splitted_string[1]</p><p class="source-code">    response = s3.get_object(Bucket=data_bucket, Key=output_bucket_key)</p><p class="source-code">    content = response["Body"].read()</p><p class="source-code">    json_output = json.loads(content)</p><p class="source-code">    pp.pprint(json_output)</p><p>You get the following response:</p></li>
			</ol>
			<div>
				<div id="_idContainer285" class="IMG---Figure">
					<img src="Images/B17528_15_13.jpg" alt="Figure 5.13 – Human-reviewed JSON response&#13;&#10;" width="1362" height="627"/>
				</div>
			</div>
			<p class="figure-caption">Figure 5.13 – Human-reviewed JSON response</p>
			<p>Using <a id="_idIndexMarker895"/>this data, you can augment or enrich your existing dataset used for training. Try <a id="_idIndexMarker896"/>combining this data with the Comprehend training data we created and try retraining your model to improve accuracy. We will point you to some blogs to accomplish this step in the <em class="italic">Further reading</em> section.</p>
			<p class="callout-heading">Important Note</p>
			<p class="callout">Please delete the model and the Comprehend endpoints created for the steps we did in this notebook.</p>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor187"/>Summary</h1>
			<p>In this chapter, we covered two things using a reference architecture as well as a code walkthrough. Firstly, we covered how you can extract data from various types of documents, such as pay stubs, bank statements, or identification cards using Amazon Textract. Then, we learned how you can perform some post-processing to create a labeled training file for Amazon Comprehend custom classification training. </p>
			<p>We showed you that even with 36 bank statement documents and 24 pay stubs as a training sample, you can achieve really good accuracy using Amazon Comprehend transfer-learning capabilities and AutoML with document or text classification. Obviously, the accuracy improves with more data.</p>
			<p>Then, you learned how to set up a training job in the AWS Management Console and how to set up a real-time classification endpoint using the AWS Management Console. </p>
			<p>Secondly, you learned how you can set up humans in the loop with the real-time classification endpoint to review/verify and validate what the model has classified. We then also discussed how you can retrain your existing model by adding this data with your existing training data and set up a retraining or active-learning loop. Please refer to the <em class="italic">Further reading</em> section to automate this workflow using Lambda functions.</p>
			<p>In the next chapter, we will cover how you can improve the accuracy of <strong class="bold">PDF batch processing</strong> with Amazon Textract and humans in the loop. So, stay tuned!</p>
			<h1 id="_idParaDest-183"><a id="_idTextAnchor188"/>Further reading</h1>
			<ul>
				<li><em class="italic">Active learning workflow for Amazon Comprehend custom classification models – Part 2</em>, <em class="italic">Shanthan Kesharaju, Joyson Neville Lewis, and Mona Mona</em> (<a href="https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)%20">https://aws.amazon.com/blogs/machine-learning/active-learning-workflow-for-amazon-comprehend-custom-classification-part-2/)</a></li>
				<li><em class="italic">Creating and Using Custom Classifiers (</em><a href="https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html">https://docs.aws.amazon.com/comprehend/latest/dg/getting-started-document-classification.html</a>)</li>
			</ul>
		</div>
	</div></body></html>