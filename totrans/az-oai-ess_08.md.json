["```py\n    import openai\n    import os\n    import re\n    import requests\n    import sys\n    from num2words import num2words\n    import pandas as pd\n    import numpy as np\n    from openai.embeddings_utils import (\n        get_embedding, cosine_similarity)\n    import tiktoken\n    from dotenv import load_dotenv\n    #Unzip the downloaded file\n    import zipfile\n    ```", "```py\n    # Azure\n    load_dotenv()\n    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n    OPENAI_DEPLOYMENT_ENDPOINT =os.getenv(\n        \"OPENAI_DEPLOYMENT_ENDPOINT\")\n    OPENAI_DEPLOYMENT_NAME = os.getenv(\"OPENAI_DEPLOYMENT_NAME\")\n    OPENAI_MODEL_NAME = os.getenv(\"OPENAI_MODEL_NAME\")\n    OPENAI_API_VERSION = os.getenv(\"OPENAI_API_VERSION\")\n    OPENAI_DEPLOYMENT_VERSION =os.getenv(\n        \"OPENAI_DEPLOYMENT_VERSION\")\n    KAGGLE_USERNAME = os.getenv(\"KAGGLE_USERNAME\")\n    KAGGLE_KEY = os.getenv(\"KAGGLE_KEY\")\n    server = os.getenv(\"DATABASESERVER\")\n    database = os.getenv(\"DATABASE\")\n    username = os.getenv(\"DATABASEUSERNAME\")\n    password = os.getenv(\"DATABASEPASSWORD\")\n    #init Azure OpenAI\n    openai.api_type = \"azure\"\n    openai.api_version = OPENAI_DEPLOYMENT_VERSION\n    openai.api_base = OPENAI_DEPLOYMENT_ENDPOINT\n    openai.api_key = OPENAI_API_KEY\n    load_dotenv()\n    ```", "```py\n    KAGGLE_USERNAME = '{username}'\n    KAGGLE_KEY='{key}'\n    ```", "```py\n    !kaggle datasets download -d shivamb/netflix-shows\n    ```", "```py\n    with zipfile.ZipFile(\"netflix-shows.zip\", 'r') as zip_ref:\n        zip_ref.extractall(\"netflix_dataset\")\n    ```", "```py\n    #Read Data from csv file\n    pd.read_csv(\"netflix_dataset/netflix_titles.csv\")\n    data\n    ```", "```py\n    data_content = data[['title', 'description']]\n    data_content\n    ```", "```py\n    'title' column in the data_content DataFrame is normalized by removing excess whitespace, unnecessary punctuation, and newline characters:\n    ```", "```py\n    pd.options.mode.chained_assignment = None\n    # s is input text\n    def normalize_text(s, sep_token = \" \\n \"):\n        s = re.sub(r'\\s+',  ' ', s).strip()\n        s = re.sub(r\". ,\",\"\",s)\n        # remove all instances of multiple spaces\n        s = s.replace(\"..\",\".\")\n        s = s.replace(\". .\",\".\")\n        s = s.replace(\"\\n\", \"\")\n        s = s.strip()\n        return s\n    data_content['title']= data_content[\"title\"].apply(\n        lambda x : normalize_text(x))\n    data_content\n    ```", "```py\n    the embeddings into the data_content DataFrame, laying the groundwork for potential further analysis or applications involving the generated embeddings:\n    ```", "```py\n    data_content['ada_v2'] = data_content[\"description\"]. apply(\n        lambda x : get_embedding(\n            x, engine = 'text-embedding-ada-002'))\n    ```", "```py\n    def search_docs(df, user_query, top_n=3, to_print=True):\n        embedding = get_embedding(\n            user_query,\n            engine=\"text-embedding-3-large\"\n        )\n        df[\"similarities\"] = df.ada_v2.apply(\n        lambda x: cosine_similarity(x, embedding))\n        res = (\n            df.sort_values(\"similarities\", ascending=False)\n            .head(top_n)\n        )\n        if to_print:\n            display(res)\n        return res\n    title = \"Blood & Water\"\n    description = data_content.loc[data_content['title'] == title, \n        \"description\"].iloc[0]\n    res = search_docs(data_content, description, top_n=15)\n    ```"]