- en: Predicting Taxi Fares with Deep Feedforward Networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will use a deep feedforward neural network to predict taxi
    fares in **New York City** (**NYC**), given inputs such as the pickup and drop
    off locations.
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, we saw how we can use a MLP
    with two hidden layers to perform a classification task (whether the patient is
    at risk of diabetes or not). In this chapter, we will build a deep neural network
    to perform a regression task of estimating taxi fares. As we shall see, we will
    need a deeper (that is, more complex) neural network to achieve this goal.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: The motivation for the problem that we're trying to tackle—making accurate predictions
    of taxi fares
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classification versus regression problems in machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-depth analysis of the NYC taxi fares dataset, including geolocation data
    visualization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecture of a deep feedforward neural network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training a deep feedforward neural network in Keras for regression problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analysis of our results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The key Python libraries required for this chapter are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: matplotlib 3.0.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: pandas 0.23.4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras 2.2.4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NumPy 1.15.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scikit-learn 0.20.2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To download the dataset required for this project, please refer to the instructions
    at [https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/Chapter03/how_to_download_the_dataset.txt](https://raw.githubusercontent.com/PacktPublishing/Neural-Network-Projects-with-Python/master/chapter3/how_to_download_the_dataset.txt).
  prefs: []
  type: TYPE_NORMAL
- en: The code for this chapter can be found in the GitHub repository for the book
    at [https://github.com/PacktPublishing/Neural-Network-Projects-with-Python](https://github.com/PacktPublishing/Neural-Network-Projects-with-Python).
  prefs: []
  type: TYPE_NORMAL
- en: 'To download the code into your computer, run the following `git clone` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After the process is complete, there will be a folder titled `Neural-Network-Projects-with-Python`.
    Enter the folder by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'To install the required Python libraries in a virtual environment, run the
    following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that you should have installed Anaconda on your computer first before
    running this command. To enter the virtual environment, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Navigate to the `Chapter03` folder by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following files are located in this folder:'
  prefs: []
  type: TYPE_NORMAL
- en: '`main.py`: This is the main code for the neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`utils.py`: This file contains auxiliary utility code that will help us in
    the implementation of our neural network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`visualize.py`: This file contains all the necessary code for exploratory data
    analysis and data visualization. Every plot in this chapter can be recreated by
    running this file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To run the code for the neural network, simply execute the `main.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'To recreate the data visualizations covered in this chapter, execute the `visualize.py` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Predicting taxi fares in New York City
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yellow cabs in NYC are perhaps one of the most recognizable icons in the city.
    Tens of thousands of commuters in NYC rely on taxis as a mode of transportation
    around the bustling metropolis. In recent years, the taxi industry in NYC has
    been put under increasing pressure from ride-hailing apps such as Uber.
  prefs: []
  type: TYPE_NORMAL
- en: In order to rise to the challenge from ride-hailing apps, yellow cabs in NYC
    are looking to modernize their operations, and to provide a user experience on
    par with Uber. In August 2018, the Taxi and Limousine Commission of NYC launched
    a new app that allows commuters to book a yellow cab from their phones. The app
    provides fare pricing upfront before they hail a cab. Creating an algorithm to
    provide fare pricing upfront is no simple feat. The algorithm needs to consider
    various environmental variables such as traffic conditions, time of day, and pick
    up and drop off locations in order to make an accurate fare prediction. The best
    way to do that is to leverage machine learning. By the end of this chapter, you
    will have created and trained a neural network to do exactly that.
  prefs: []
  type: TYPE_NORMAL
- en: The NYC taxi fares dataset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The dataset that we will be using for this project is the NYC taxi fares dataset,
    as provided by Kaggle. The original dataset contains a massive 55 million trip
    records from 2009 to 2015, including data such as the pick up and drop off locations,
    number of passengers, and pickup datetime. This dataset provides an interesting
    opportunity to use big datasets in machine learning projects, as well to visualize
    geolocation data.
  prefs: []
  type: TYPE_NORMAL
- en: Exploratory data analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's dive right into the dataset. The instructions to download the NYC taxi
    fares dataset can be found in the accompanying GitHub repository for the book
    (refer to the *Technical requirements* section). Unlike in the previous chapter,
    [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml), *Predicting Diabetes
    with Multilayer Perceptrons*, we're not going to import the original dataset of
    55 million rows. In fact, most computers would not be able to store the entire
    dataset in memory! Instead, let's just import the first 0.5 million rows. Doing
    this does have its drawbacks, but it is a necessary tradeoff in order to use the
    dataset in an efficient manner.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, run the `read_csv()` function with `pandas`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `parse_dates` parameter in `read_csv` allows `pandas` to easily recognize
    certain columns as dates, giving us the flexibility to work with such `datetime`
    values, as we shall see later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s take a look at the first five rows of the dataset by calling the `df.head()`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e0a77f4-ec95-4867-9af1-d8c38ed500ed.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that there are eight columns in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '`key`: This column seems identical to the `pickup_datetime` column. It was
    probably used as an unique identifier in the database it was stored in. We can
    safely remove this column without any loss of information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fare_amount`: This is the target variable we are trying to predict, the fare
    amount paid at the end of the trip.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pickup_datetime`: This column contains information on the pickup date (year,
    month, day of month), as well as the time (hour, minute, seconds).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pickup_longitude` and `pickup_latitude`: The longitude and latitude of the
    pickup location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dropoff_longitude` and `dropoff_latitude`: The longitude and latitude of the
    drop off location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`passenger_count`: The number of passengers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing geolocation data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The pick-up and drop-off longitude and latitude data are crucial to predicting
    the fare amount. After all, fares in NYC taxis are largely determined by the distance
    traveled.
  prefs: []
  type: TYPE_NORMAL
- en: First, let's understand what latitude and longitude represents. Latitude and longitude
    are coordinates in a geographic coordinate system. Basically, the latitude and longitude
    allows us to specify any location on Earth using a set of coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the **Latitude** and **Longitude** coordinate system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/395f3948-8e35-4a17-82ce-9103a7cb785d.png)'
  prefs: []
  type: TYPE_IMG
- en: We can think of the Earth as a scatterplot, with the **Longitude** and the **Latitude**
    being the axes. Then, every location on Earth is simply a point on the scatterplot.
    In fact, let's do exactly that; let's plot the pickup and drop off latitudes and
    longitudes on a scatterplot.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s restrict our data points to only pickups and drop offs within
    NYC. NYC has an approximate longitude range of `-74.05` to `-73.75` and a latitude
    range of `40.63` to `40.85`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Note that we copied the original DataFrame, `df`, into a new DataFrame, `df2`,
    to avoid overwriting the original DataFrame.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s define a new function that will take our DataFrame as an input,
    and plot the pickup locations on a scatterplot. We are also interested in overlaying
    the scatterplot with a few key landmarks in NYC. A quick Google search tells us
    that there are two main airports in NYC (JFK and LaGuardia), and their coordinates,
    along with the main districts in NYC, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'And here''s our function using `matplotlib` to plot the pickup locations on
    a scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s run the function we just defined:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following scatterplot showing the pickup locations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fe040127-a79a-4ea7-8fe8-5a9e12a42bff.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Isn''t it beautiful? Just by plotting the pickup locations on a scatterplot,
    we can clearly see a map of NYC, along with the grids that streets in NYC are
    known for. From the preceding scatterplot, we can make a few observations:'
  prefs: []
  type: TYPE_NORMAL
- en: In Manhattan, most pickups were around the `Midtown` area, followed by `Lower
    Manhattan`. In comparison, there are much fewer pickups in `Upper Manhattan`.
    This makes sense, since `Upper Manhattan` is a residential area, whereas more
    offices and tourist attractions are located at `Midtown` and `Lower Manhattan`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pickups are sparse outside Manhattan. The only two outliers were at `LaGuardia
    Airport` and `JFK Airport`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s also plot the scatterplot for drop off locations and see how it differs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f329a110-c91c-4f23-a810-8ccbcd5fd9e5.png)'
  prefs: []
  type: TYPE_IMG
- en: Comparing the pickup and drop off scatterplots, we can clearly see that there
    are more drop offs than pickups in residential areas such as `Upper Manhattan`
    and `Brooklyn`. Neat!
  prefs: []
  type: TYPE_NORMAL
- en: Ridership by day and hour
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Next, let's investigate how the number of rides varies by day and hour.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall that the raw data contains a single `pickup_datetime` column that contains
    the pickup date and time in `datetime` format. First, let''s separate the pickup
    year, month, day, day of week, and hour from the original `pickup_datetime` column
    into different columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Since we have previously used the `parse_dates` parameter when we imported the
    data into pandas, we can easily identify and separate the year, month, day and
    hour components using the `dt` function in pandas.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s plot a histogram to analyze the distribution of rides throughout
    the week:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/31adca56-d945-4d6a-928e-a54c26a5a8d2.png)'
  prefs: []
  type: TYPE_IMG
- en: Interestingly, we can see that the number of rides is not evenly distributed
    across each weekday. Instead, the number of rides increases linearly from Monday
    through Friday, and peaking on Friday. The weekends see a slight drop in the number
    of rides on Saturday, before falling sharply on Sunday.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also visualize ridership by hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following histogram for pickup hour:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c522d25-0791-4ae9-a9f8-9d1ea24ac8fd.png)'
  prefs: []
  type: TYPE_IMG
- en: We can see that there are more rides during the evening rush hour, as compared
    to the morning rush hour. In fact, the number of rides is pretty constant throughout
    the day. Starting at 6 P.M., the number of rides increases and peaks at 7 P.M.,
    before falling from 11 P.M. onwards.
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall from the previous project that we had to preprocess the data by removing
    missing values and other data anomalies. In this project, we'll perform the same
    process. We'll also perform feature engineering to improve both the quality and
    quantity of the features before training our neural network on it.
  prefs: []
  type: TYPE_NORMAL
- en: Handling missing values and data anomalies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s do a check to see whether there are any missing values in our dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following output showing the number of missing values in each
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/899f7a52-83c3-49c1-9e0b-7489fa94b96f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that there are only five rows (out of 500,000 rows) with missing
    data. With a missing data percentage of just 0.001%, it seems that we don''t have
    a problem with missing data. Let''s go ahead and remove those five rows with missing
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we should also check the data for outliers. In a dataset as
    massive as this, there are bound to be outliers, which can skew our model. Let''s
    run a quick statistical summary on our data to look at the distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The `describe` method produces the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1c460353-de5a-42ba-8ad2-308e0922ef01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The lowest fare in the dataset is $-44.90\. That doesn''t make sense; fares
    can''t be negative! Also, the highest fare is $500\. Did the passenger get ripped
    off? Or was it just an error? Let''s plot a histogram to better understand the
    distribution of fares:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll get the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/66030931-26cf-436f-bdf1-a0ab4abc1964.png)'
  prefs: []
  type: TYPE_IMG
- en: It doesn't seem like that there are too many outliers, so we can safely remove
    them. Another interesting trend that we can observe from the histogram is that
    there is a small spike in fares around $50\. Could this be a fixed fare from a
    specific location? Cities usually implement fixed fares for trips to and from
    airports. A quick Google search tells us that trips to and from JFK airport incurs
    a flat fare of $52 plus tolls. This could be the reason for the spike in the histogram
    around $50! We'll keep this important fact in mind when we do feature engineering
    later on.
  prefs: []
  type: TYPE_NORMAL
- en: 'For now, let''s remove rows with fares less than $0 and more than $100:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'From the previous table, we can see that there are also outliers in the `passenger_count` column.
    Let''s plot a histogram of `Passenger Count` to look at its distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'This gives us the following histogram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/313b50db-941d-46d9-aeae-aa5563eb9c94.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that there''s a small percentage of rows with `0` passenger counts.
    Instead of discarding those rows, let''s replace the outliers with the mode (that
    is, `1` passenger count):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We can also remove these outliers entirely, since only a few rows are affected.
    Instead, we chose to replace the outlier passenger count with the mode. Both methods
    are perfectly valid, but we chose the latter to illustrate the importance of visualizing
    your data with a histogram to identify outlier values, as well as the mode.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, let''s inspect the pickup and drop off latitude and longitude data to
    check for outliers. In the previous section on data visualization, we plotted
    a scatterplot with the restriction that the points should be located within the
    boundaries of NYC. Let''s plot a scatterplot now without that restriction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ll see the following scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/77a6482f-4a29-4473-b1c0-9f55e6ea3aeb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Do you see where the outliers are? The dots at the periphery of the scatterplot
    are outliers. They have latitude values as high as 1000 and as low as -3000\.
    Earth''s geographic coordinate system does not have such extreme latitudes and
    longitudes! Let''s remove these outliers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Let's summarize what we have done for data preprocessing. We first saw that
    missing values only constitute 0.001% of the dataset, so we can remove them safely
    without affecting the quantity of our training data. Next, we saw that there are
    outliers in `fare_amount`, and `passenger_count`, as well as the pickup and drop
    off latitude and longitude. We removed the outliers for the `fare_amount`, latitude
    and longitude. For the `passenger_count`, we replaced those rows that had a `0`
    passenger count with the `passenger count` = `1` mode.
  prefs: []
  type: TYPE_NORMAL
- en: Let's create a helper function to help us do all that data preprocessing. In
    machine learning projects, the number of steps can often get out of hand. It is
    important to adhere to strong software engineering practices, such as code modularization,
    to keep our project on track.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code takes a pandas DataFrame as input, and returns the DataFrame
    after performing data preprocessing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: We'll save this helper function under `utils.py` in our project folder. Then,
    to call our helper function for data preprocessing, we just have to call `from
    utils import preprocess` and we'll have access to this helper function. This keeps
    our code neat and manageable!
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As briefly discussed in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons* feature engineering is the process
    of using one's domain knowledge of the problem to create new features for the
    machine learning algorithm. In this section, we shall create features based on
    the date and time of pickup, and location-related features.
  prefs: []
  type: TYPE_NORMAL
- en: Temporal features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we've seen earlier in the section on data visualization, ridership volume
    depends heavily on the day of the week, as well as the time of day.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s look at the format of the `pickup_datetime` column by running the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/06303f0f-b30d-4301-a70e-5a88645314f0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Recall that neural networks require numerical features. Therefore, we can''t
    train our neural network using such a datetime string. Let''s separate the `pickup_datetime` column
    into different columns for `year`, `month`, `day`, `day_of_week`, and `hour`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s take a look at the new columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b5fa9eba-a1fb-4f52-87bb-2e510ebd4dc8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can see that the new columns capture the original information from the `pickup_datetime` column
    in a format that''s suitable for our neural network. Let''s drop the `pickup_datetime` column
    from our DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Geolocation features
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have seen earlier, the dataset contains information regarding the pickup
    and drop off coordinates. However, there is no information regarding the distance
    between the pickup and drop off points, which is arguably the most important factor
    in deciding taxi fares. Therefore, let's create a new feature that calculates
    the distance between each pair of pickup and drop off points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall from geometry that the *Euclidean Distance* is the straight-line distance
    between any two points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/d72541e9-883b-416a-a1ed-b6f1ac2758b2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s define a function to calculate the Euclidean distance between any two
    points, given the latitude and longitudes of the two points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And let''s apply the function to the DataFrame to create the new `distance`
    column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Our hypothesis was that the trip fare is closely correlated to the distance
    traveled. We can now plot the two variables on a scatterplot to analyze the correlation
    and see if our intuition was right:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following scatterplot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2c85bc07-2e52-4871-85d1-532bc29e1868.png)'
  prefs: []
  type: TYPE_IMG
- en: Nice! We can clearly see that our hypothesis is right. However, the distance
    traveled alone does not tell the whole story. If we look at the center of the
    graph, we can see three vertical lines of dots. These outlier data seems to suggest
    that there are certain trips where the distance traveled did not have an impact
    on the fare amount (which is between $40 and $60 for these outliers). Recall in
    the previous section on data visualization where we saw that there are certain
    pickups near airports, and these airport pickups have a flat fare of $52 plus
    tolls. This could explain the three vertical lines of dots between $40 and $60!
  prefs: []
  type: TYPE_NORMAL
- en: Clearly, we need to engineer a new feature that informs our neural network of
    the pickup and drop off distance from the three major airports in NYC. When we
    train the neural network on this feature, it should then learn that pickups and
    drop offs near airports have a flat fare between $40 and $60.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `euc_distance` function that we defined earlier to calculate
    the pickup and drop off distance from the three major airports in NYC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s print out the first few rows, along with a few relevant columns to verify
    that the Euclidean distance function is functioning as intended:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0665247a-2e68-49fa-abea-abcf6e154b57.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can do a quick calculation on the preceding rows to verify that the Euclidean
    distance function works correctly. Lastly, notice that there is still a `key`
    column in the dataset. This column is similar to the `pickup_datetime` column,
    and it was probably used as a unique identifier in the database it was stored
    in. We can safely remove this column without any loss of information. To remove
    the `key` column, use this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: To recap, in this section, we used feature engineering to construct new features
    based on our own domain knowledge of the problem. From the raw datetime information
    provided, we extracted and constructed new features for the pickup year, month,
    day, day of the week, and hour. We also constructed distance-based features that
    are crucial to the prediction of fares, such as the distance between pickup and
    drop off points, as well as the pickup and drop off distance from the three main
    airports in NYC.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the previous *Data preprocessing *section, we''re going to construct
    a helper function to summarize what we have done for feature engineering. This
    code modularization approach will help keep our code manageable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Feature scaling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a final preprocessing step, we should also scale our features before passing
    them to the neural network. Recall from the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, that scaling ensures that all
    features have a uniform range of scale. This ensures that features with a greater
    scale (for example, year has a scale of > 2000) does not dominate features with
    a smaller scale (for example, passenger count has a scale between 1 to 6).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we scale the features in the DataFrame, it''s a good idea to keep a
    copy of the prescaled DataFrame. The values of the features will be transformed
    after scaling (for example, year 2010 may be transformed to a value such as -0.134
    after scaling), which can make it difficult for us to interpret the values. By
    keeping a copy of the prescaled DataFrame, we can easily reference the original
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We should also drop the `fare_amount` target variable before scaling, as we
    do not want to modify the target variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, scale the features by calling the `scale` function from scikit-learn:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Lastly, convert the object returned by the `scale` function into a pandas DataFrame
    and concatenate the original `fare_amount` column that was dropped before scaling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Deep feedforward networks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we have done an in-depth visualization of the dataset,
    cleaned up the dataset by handling outliers, and also performed feature engineering
    to create useful features for our model. For the rest of the chapter, we'll talk
    about the architecture of deep feedforward neural networks, and we'll train one
    in Keras for a regression task.
  prefs: []
  type: TYPE_NORMAL
- en: Model architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*,we used a relatively simple
    MLP as our neural network. For this project, since there are more features, we
    shall use a deeper model to account for the additional complexity. The deep feedforward
    network will have four hidden layers. The first hidden layer will have 128 nodes,
    with each successive hidden layer having half the nodes of its predecessor. This
    neural network size is a good starting point for us and it should not take too
    long to train this neural network. A general rule of thumb is that we should start
    with a small neural network and only increase its complexity (size) as required.
  prefs: []
  type: TYPE_NORMAL
- en: In between each hidden layer, we will use the ReLU activation function to introduce
    non-linearity in the model. Since this is a regression problem, there will only
    be one node in the output layer (more on regression in the next sub-section).
    Note that we do not apply the ReLU activation function for the output layer as
    doing so would transform our predictions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the model architecture of the deep feedforward
    neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f9782fed-7257-48fd-bdb2-64a446305674.png)'
  prefs: []
  type: TYPE_IMG
- en: Loss functions for regression problems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important to understand what regression is, and how it affects the architecture
    of our neural network. Our task in this project is to predict taxi fares, which
    is a continuous variable. We can contrast this with the classification project
    that we did in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, where we designed a neural
    network to output a binary prediction (1 or 0), indicating whether the patient
    was at risk of diabetes.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to think about regression and classification is that in regression,
    we are trying to predict the value of a continuous variable (for example, cost,
    time, or height), whereas in classification, we are trying to predict a class
    (for example, diabetes or no diabetes).
  prefs: []
  type: TYPE_NORMAL
- en: Recall that in the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*,we used percentage accuracy
    as a metric for measuring how strong our predictions are. In regression, the **root
    mean square error** (**RMSE**) is often used as the error metric.
  prefs: []
  type: TYPE_NORMAL
- en: 'The formula for *RMSE* is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f0ee13e0-65b8-4183-bcb9-9df1e6c8f8a8.png)'
  prefs: []
  type: TYPE_IMG
- en: Notice how the formula takes the square of the difference between the predicted
    value and the actual value. This is to ensure that over estimations and under
    estimations are penalized equally (since the square of the error would be the
    same for both). We take the square-root to ensure that the magnitude of the error
    is similar to the actual values. The RMSE provides a loss function for our neural
    network, allowing it to tune its weights during the training process in order
    to reduce the error of its predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Model building in Python using Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let's implement our model architecture in Keras. Just like in the previous
    project, we're going to build our model layer by layer in Keras using the `Sequential`
    class.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, split the DataFrame into the training features (`X`) and the target
    variable that we''re trying to predict (`y`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, split the data into a training set (80%) and a testing set (20%):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let''s build our `Sequential` model in Keras according to the neural
    network architecture we outlined earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Before we start training our model, it is a good practice to verify the structure
    of our model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: The `summary()` function produces a table showing the number of layers and number
    of nodes in each layer, as well as the number of parameters in each layer (that
    is, the weights and biases). We can verify that this is consistent with the model
    architecture we outlined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s the table produced by the `summary()` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e06ec328-b384-447c-ac11-1e8cc6a32805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, we can compile and train our neural network on the training data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Since there''s a fair bit of data, it would take some time to train the neural
    network. After a few minutes, Keras would output the following at the end of the
    training epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/3b56dc90-735b-4b31-8723-a8421736e8ba.png)'
  prefs: []
  type: TYPE_IMG
- en: Results analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have our neural network trained, let's use it to make some predictions
    to understand its accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a function to make a prediction using a random sample from the
    testing set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: The `predict_random` function will pull a random row from the testing set and
    feed it to the model for prediction. The function will then calculate and display
    the RMSE of the prediction. Note that `df_prescaled` is required to provide us
    with the original values for day of week and hour, as the values in the testing
    set have already been transformed earlier and are no longer human-readable (for
    example, a day of week value of -0.018778 does not make much sense to us).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run the `predict_random` function, shown as follows and see what kind
    of results we get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'The trip details output by the `predict_random` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The following map depicts the travel details:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6138bc84-5f7e-4ce7-a0d3-ce5b0d87383b.png)'
  prefs: []
  type: TYPE_IMG
- en: The pickup and drop off points are visualized in the preceding map. The `Actual
    fare` was `$4.90`, while the `Predicted fare` is `$5.60`, giving us an error of
    `$0.70`. It looks like our model is working well and the predictions are fairly
    accurate! Note that the map and route shown in the preceding screenshot is purely
    for visualization and is not part of the original dataset or code.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s run `predict_random` a few more times to get more results:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/52e43b14-a1f0-4ec2-b273-919509000146.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The trip details output by the `predict_random` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Our prediction for this trip was almost spot on! The `Actual fare` was `$6.10`,
    while the fare predicted by our neural network is `$6.30`. It seems like our neural
    network makes really good predictions for short distance trips.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how well it does when the trip is further and more prone to traffic
    delays:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/5fe3e94c-d089-4091-9a2e-e891a48fb306.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The trip details output by the `predict_random` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from this sample, our neural network works really well even for
    long distance trips. The `Actual fare` was `$35.80`, while our neural network
    predicted a fare of `$38.11`. The error of `$2.31` (~6% discrepancy) is pretty
    impressive given the distance of the trip.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a final example, let''s see how our neural network performs for fixed-rate
    trips. Recall that all trips to/from JFK airport incur a fixed fare of $52 plus
    tolls, no matter the distance traveled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4d80be80-e731-4b09-8ece-96f7b82bcf52.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The trip details output by the `predict_random` function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Nice! Our neural network understands that the trip started from JFK airport,
    and hence the fare should be close to `$52`. This was made possible through feature
    engineering, where we introduced new features that represents the pickup and drop
    off distance away from JFK airport. These new features allowed our neural network
    to learn that trips to/from JFK airport should have a fare close to `$52`. This
    shows the importance of feature engineering!
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, let''s conclude the results by calculating the RMSE for the entire
    training and testing set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'We get the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7d1cee54-86bb-4881-81ff-3d2286e00ac4.png)'
  prefs: []
  type: TYPE_IMG
- en: The RMSE values show that on average, our model predicts a fare that is accurate
    within ~$3.50.
  prefs: []
  type: TYPE_NORMAL
- en: Putting it all together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have accomplished a lot in this chapter. Let's do a quick recap of the code
    that we have written so far.
  prefs: []
  type: TYPE_NORMAL
- en: 'We started off by defining a function for preprocessing. This `preprocess`
    function takes a DataFrame as an input and performs the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Removing missing values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing outliers in the fare amount
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replacing outliers in passenger count with the mode
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Removing outliers in latitude and longitude (that is, only considering points
    within NYC)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This function is saved under `utils.py` in our project folder.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we also defined a `feature_engineer` function for feature engineering.
    This function takes a DataFrame as an input and performs the following actions:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating new columns for year, month, day, day of the week, and hour
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating new column for the Euclidean distance between the pickup and drop off
    points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating new columns for the pickup and drop off distances away from JFK, Laguardia,
    and Newark airports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This function is also saved under `utils.py` in our project folder.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have defined our helper functions, we can proceed with our main
    neural network code. Let's create a new Python file, `main.py`, to house our main
    neural network code.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we import the necessary modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we import the first `500000` rows of the raw tabular data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We perform preprocessing and feature engineering using the functions that we
    defined previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we scale the features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we split the DataFrame into training and testing sets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'We build and train our deep feedforward neural network in Keras:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we analyze our results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: That's all of our code! Notice how creating helper functions for preprocessing
    and feature engineering in `utils.py` allows our main code to be relatively short.
    By modularizing our code into separate helper functions, we can focus on the implementation
    of each step of the machine learning framework.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we designed and implemented a deep feedforward neural network
    capable of predicting taxi fares in NYC within an error of ~$3.50\. We first performed
    exploratory data analysis, where we gained important insights on the factors that
    affect taxi fares. With these insights, we then performed feature engineering,
    which is the process of using your domain knowledge of the problem to create new
    features. We also introduced the concept of modularizing our functions in machine
    learning projects, which allowed us to keep our main code relatively short and
    neat.
  prefs: []
  type: TYPE_NORMAL
- en: We created our deep feedforward neural network in Keras, and trained it using
    the preprocessed data. Our results show that the neural network is able to make
    highly accurate predictions for both short and long distance trips. Even for fixed-rate
    trips, our neural network was able to produce highly accurate predictions.
  prefs: []
  type: TYPE_NORMAL
- en: This concludes the chapter on using a deep feedforward neural network for a
    regression prediction task. Together with the previous chapter, [Chapter 2](81c9304f-2e96-4a6d-8ece-d972006f3180.xhtml),
    *Predicting Diabetes with Multilayer Perceptrons*, we have seen how we can use
    neural networks for classification and regression. In the next chapter, [Chapter
    4](48f7db0c-7c74-42a2-82b7-a17c9f220423.xhtml), *Cats Versus Dogs – Image Classification
    Using* *CNNs*,we will introduce more complex neural networks for computer vision
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When reading a CSV file using pandas, how does pandas recognize that certain
    columns are datetime?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can use the `parse_dates` argument when reading the CSV file using the `read_csv`
    function in pandas.
  prefs: []
  type: TYPE_NORMAL
- en: How can we filter a DataFrame to only select rows within a certain range of
    values, assuming that we have a DataFrame, `df`, and we want to select rows with
    height values within the range of `160` and `180`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We can filter a DataFrame like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: This returns a new DataFrame with range of height values between `160` and `180`.
  prefs: []
  type: TYPE_NORMAL
- en: How can we use code modularization to organize our neural network projects?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We can compartmentalize our functions using modular pieces of code. For example,
    in this project, we defined a `preprocess` and `feature_engineer` function in
    `utils.py`, which allows us to focus on the implementation of the preprocessing
    and feature engineering functions separately.
  prefs: []
  type: TYPE_NORMAL
- en: How is regression different from classification tasks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In regression, we are trying to predict the value of a continuous variable (for
    example, taxi fare) whereas in classification, we are trying to predict a class
    (for example, diabetes or no diabetes).
  prefs: []
  type: TYPE_NORMAL
- en: True or false? For regression tasks, we should apply an activation function
    for the output layer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: False. For regression tasks, we should never apply an activation function for
    the output layer because doing so will transform our predictions, which then affects
    the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: What loss function is typically used when training a neural network for regression
    tasks?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The RMSE is a common loss function for regression tasks. The RMSE measures the
    absolute difference between the prediction and the actual target variable.
  prefs: []
  type: TYPE_NORMAL
