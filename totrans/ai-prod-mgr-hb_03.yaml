- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Machine Learning and Deep Learning Deep Dive
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the age of AI implementation, the current period of AI we find ourselves
    in, we must understand the pros and cons of both **machine learning** (**ML**)
    and **deep learning** (**DL**) in order to best navigate when to use either technology.
    Some other terms you might have come across with respect to AI/ML tools are **applied
    AI** or **deep tech**. As we’ve mentioned a few times over the course of this
    book, the underlying tech that will, for the most part, power AI products will
    be ML or DL. That’s because expert- or rule-based systems are slowly being powered
    by ML or not evolving at all. So, let’s dive a bit further into these technologies
    and understand how they differ.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the relationship between ML and DL and the
    way in which they bring their own sets of expectations, explanations, and elucidations
    to builders and users alike. Whether you work with products that incorporate ML
    models that have been around since the 50s or use cutting-edge models that have
    sprung into use recently, you’ll want to understand the implications either way.
    Incorporating ML or DL into your product will have different repercussions. Most
    of the time when you see an AI label on a product, it’s built using ML or DL,
    so we want to make sure you come out of this chapter with a firm understanding
    of how these areas differ and what this difference will tangibly mean for your
    future products.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012), we discussed how we’ve
    grappled with the idea of using machines since the 50s, but we wanted to expand
    on the history of ML and DL **artificial neural networks** (**ANNs**) to give
    you a sense of how long these models have been around. In this chapter, we will
    cover the following topics to get more familiar with the nuances related to ML
    and DL:'
  prefs: []
  type: TYPE_NORMAL
- en: The old – exploring ML
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The new – exploring DL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emerging technologies – ancillary and related tech
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explainability – optimizing for ethics, caveats, and responsibility
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy – optimizing for success
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The old – exploring ML
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML models attempt to create some representation of reality in order to help
    us make some sort of data-driven decision. Essentially, we use mathematics to
    represent some phenomenon that’s happening in the real world. ML essentially takes
    mathematics and statistics to predict or classify some future state. The paths
    diverge in one of two ways. The first group lies with the emergence of models
    that continue to progress through statistical models and the second group lies
    with the emergence of models that try to mimic our own natural neural intelligence.
    Colloquially, these are referred to as traditional ML and DL models.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of all the models we covered in the *Model types – from linear
    regression to neural networks* section of [*Chapter 2*](B18935_02.xhtml#_idTextAnchor067)
    as ML models, but we didn’t cover ANNs in great depth. We’ll discuss those further
    in the *Types of neural networks* section later on in this chapter. In this section,
    we will take a look at the traditional statistical ML models in order to understand
    both the historical relevance and prevalence of ML models. To recap the flow of
    ML, it’s essentially a process of retrieving data, preparing that data through
    data processing, wrangling and feature engineering, running that data through
    a model and evaluating that model for performance, and tuning it as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the most reliable and prevalent models used in ML have been around for
    ages. **Linear regression** models have been around since the late 1800s and were
    popularized through the work of Karl Pearson and Sir Francis Galton, two British
    mathematicians. Their contributions gave way to one of the most popular ML algorithms
    used today, although unfortunately, both were prominent eugenicists. Karl Pearson
    is also credited with inventing **principle component analysis** (**PCA**), an
    unsupervised learning method that reduces dimensions in a dataset, in 1901.
  prefs: []
  type: TYPE_NORMAL
- en: A popular ML method, **naive Bayes classifiers**, came onto the scene in the
    1960s but they’re based on the work of an English statistician named Thomas Bayes’
    and his theorem of conditional probabilities, which is from the 1700s. The logistic
    function was introduced by Belgian mathematician Pierre Francois Velhulst in the
    mid-1800s, and **logistic regression** models were popularized by a British statistician
    named David Cox in 1958.
  prefs: []
  type: TYPE_NORMAL
- en: '**Support vector machines** (**SVMs**) were introduced in 1963 by Soviet mathematicians
    Vladimir Vapnik and Alexey Chervonenis from the Institute of Control Sciences
    at the Russian Academy of Sciences. The first decision tree analytical algorithm
    was also invented in 1963 by American statisticians James N. Morgan and John A.
    Sonquist from the University of Michigan and it was used in their **automatic
    interaction detection** (**AID**) program, but even that was derived from a *Porphyrian
    tree*, a classification tree-based diagram that was created by the eponymous Greek
    philosopher in the 3rd century BCE. Random forests, made up of an ensemble of
    multiple decision trees, were invented by an American statistician, Leo Breiman,
    from the University of California in 2001.'
  prefs: []
  type: TYPE_NORMAL
- en: One of the simplest supervised learning models for classification and regression,
    the **KNN algorithm**, emerged from a technical analysis report that was done
    by statisticians Evelyn Fix and Joseph Lawson Hodges Jr. on behalf of the US Armed
    Forces in collaboration with Berkeley University in 1951\. K-means clustering,
    a method of unsupervised ML clustering, was first proposed by a mathematician
    at UCLA named James MacQueen in 1967.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, many of the algorithms that are used most commonly in ML models
    today have their roots quite far in our modern history. Their simplicity and elegance
    add to their relevance today. Most of the models we’ve covered in this section
    were covered in [*Chapter 2*](B18935_02.xhtml#_idTextAnchor067), with the exception
    of DL ANNs. In the following section, we will focus on DL.
  prefs: []
  type: TYPE_NORMAL
- en: The new – exploring DL
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Part of our intention with separating ML and DL conceptually in this book is
    really to create associations in the reader’s mind. For most technical folks in
    the field, there are specific models and algorithms that come up when you see
    “ML” versus “DL” as a descriptor on a product. Quick reminder here that DL is
    a subset of ML. If you ever get confused by the two terms, just remember that
    DL is a form of ML that’s grown and evolved to form its own ecosystem. Our aim
    is to demystify that ecosystem as much as possible so that you can confidently
    understand the dynamics at play with DL products as a product manager.
  prefs: []
  type: TYPE_NORMAL
- en: The foundational idea of DL is centered around our own biological neural networks
    and DL uses what’s often the umbrella term of ANNs to solve complex problems.
    As we will see in the next section, much of the ecosystem that’s been formed in
    DL has been inspired by our own brains, where the “original’’ neural networks
    are found. This inspiration comes not just from the function of the human brain,
    particularly the idea of learning through examples, but also from its structure
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because this isn’t an overly technical book meant for DL engineers, we will
    refrain from going into the terms and mathematics associated with DL. A basic
    understanding of an ANN would be helpful, however. As we go through this section,
    keep in mind that a neural network is composed of artificial neurons or nodes
    and that these nodes are stacked next to one another in layers. Typically, there
    are three types of layers:'
  prefs: []
  type: TYPE_NORMAL
- en: The input layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hidden layer(s)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we will go over the various types of ANNs, there are some basics to how
    these DL algorithms work. Think in terms of layers and nodes. Essentially, data
    is passed through each node of each layer and the basic idea is that there are
    weights and biases that are passed from each node and layer. The ANNs work through
    the data they’re training on in order to best arrive at patterns that will help
    them solve the problem at hand. An ANN that has at least three layers, which means
    an input, output, and a minimum of one hidden layer, is “deep” enough to be classed
    as a DL algorithm. That settles the layers.
  prefs: []
  type: TYPE_NORMAL
- en: What about the nodes? If you recall, one of the simplest models we covered in
    prior chapters is the linear regression model. You can think of each node as its
    own mini-linear regression model because this is the calculation that’s happening
    within each node of an ANN. Each node has its data, a weight for that data, and
    a bias or parameter that it’s measuring against to arrive at an output. The summation
    of all these nodes making these calculations at scale gives you a sense of how
    an ANN works. If you can imagine a large scale of hundreds of layers, each with
    many nodes within each layer, you can start to imagine why it can be hard to understand
    why an ANN arrives at certain conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: DL is often referred to as a black-box technology and this starts to get to
    the heart of why that is. Depending on our math skills, we humans can explain
    why a certain error rate or loss function is present in a simple linear regression
    model. We can conceptualize the ways a model, which is being fitted to a curve,
    can be wrong. We can also appreciate the challenge when presented with real-world
    data, which doesn’t lay out a perfect curve, for a model. But if we increase that
    scale and try to conceptualize potentially billions of nodes each representing
    a linear regression model, our brains will start to hurt.
  prefs: []
  type: TYPE_NORMAL
- en: Though DL is often discussed as a bleeding-edge technological advancement, as
    we saw in the prior section, this journey also started long ago.
  prefs: []
  type: TYPE_NORMAL
- en: Invisible influences
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s important to understand the underlying relationships that have influenced
    ML and DL as well as the history associated with both. This is a foundational
    part of the storytelling but it’s also helpful to better understand how this technology
    relates to the world around us. For many, understanding AI/ML concepts can be
    mystifying and unless you come from a tech or computer science background, the
    topics themselves can seem intimidating. Many will, at best, only acquire a rudimentary
    understanding of what this tech is and how it’s come about.
  prefs: []
  type: TYPE_NORMAL
- en: We want to empower anyone interested in exploring this underlying tech that
    will shape so many products and internal systems in the future by making a deeper
    understanding more accessible. Already, there’s favoritism going on. Most of the
    folks that intimately understand ML and DL already come from a computer science
    background whether it’s through formal education or through boot camps and other
    technical training programs. That means that for the most part, the folks that
    have pursued study and entrepreneurship in this field have traditionally been
    predominantly white and predominantly male.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the demographics, the level of investment in these technologies,
    from an academic perspective, has gone up. Let’s get into some of the numbers.
    Stanford University’s AI index states that AI investment at the graduate level
    among the world’s top universities has increased by 41.7%. That number jumps to
    102.9% at the undergraduate level. An extra 48% of recipients of AI PhDs have
    left academia in the past decade in pursuit of the private sector’s big bucks
    in the last 10 years. 10 years ago, only 14.2% of computer science PhDs were AI
    related. Now, that number is above 23%. The United States, in particular, is holding
    onto the talent it educates and attracts. Foreign students that come to the US
    to pursue an AI PhD stay at a rate of 81.8%.
  prefs: []
  type: TYPE_NORMAL
- en: The picture this paints is one of a world that’s in great need of talent and
    skill in AI/ML. This high demand for the AI/ML skill set, particularly a demographically
    diverse AI skill set, is making it hard for those that have the hard skills in
    this field to stay in academia and the private sector handsomely rewards those
    that have these skills. In the start-up circuits, many VCs and investors are able
    to confidently solidify their investments when they know a company has somebody
    with an AI PhD, on staff, whether or not their product needs this heavy expertise.
    Placing a premium on human resources with these sought-after skills is likely
    not going to go away anytime soon.
  prefs: []
  type: TYPE_NORMAL
- en: We dream of a world where people from many competencies and backgrounds come
    into the field of AI because diversity is urgently needed and the opportunity
    that’s ahead of us is too great for the gatekeeping that’s been going on to prevail.
    It’s not just important that the builders of AI understand the underlying tech
    and what makes its application of it so powerful. It’s equally important for the
    business stakeholders that harness the capabilities of this tech to also understand
    the options and capabilities that lie before them. At the end of the day, nothing
    is so complicated that it can’t be easily explained.
  prefs: []
  type: TYPE_NORMAL
- en: A brief history of DL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In 1943, Warren S. McCulloch and Walter Pitts published a paper, *A logical
    calculus of the ideas immanent in nervous activity*, which made a link between
    mathematics and neurology by creating a computer model based on the neural networks
    inherent in our own brains based on a combination of algorithms to create a “threshold”
    to mimic how we pass information from our own biological network of neurons. Then,
    in 1958, Frank Rosenblatt published a paper that would be widely considered the
    ancestor of neural nets, called *The Perceptron: A perceiving and recognizing
    automaton*. This was, for all intents and purposes, the first, simplest, and oldest
    ANN.'
  prefs: []
  type: TYPE_NORMAL
- en: In the 1960s, developments toward backpropagation, or the idea that a model
    learns from layers of past mistakes as it trains its way through a dataset, made
    significant strides toward what would eventually make up the neural network. The
    most significant part of the development that was happening at this time was coupling
    the idea of inspiring mathematical models with the way the brain works based on
    networks of neurons and backpropagation because this created the foundation of
    ANNs, which learned through past iterations.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note here that many ANNs work in a “feedforward” motion in
    that they go through the input, hidden layers, and output layers sequentially
    and in one direction only, from input to output. The idea of backpropagation essentially
    allows for the ANNs to learn bi-directionally so that they’re able to minimize
    the error in each node, resulting in a better performance.
  prefs: []
  type: TYPE_NORMAL
- en: It wasn’t until 1986 when David Rumelhart, Geoffrey Hinton, and Ronald Williams
    published a famous paper, *Learning representations by back-propagating errors*,
    that people fully began to appreciate the role backpropagation plays in the success
    of DL. The idea that you could backpropagate through time, allowing neural networks
    to assign the appropriate weights as well as train a neural network with hidden
    layers, was revolutionary at the time.
  prefs: []
  type: TYPE_NORMAL
- en: 'After each development, there was much excitement for ML and the power of neural
    networks but between the mid-60s and the 80s, there was one significant issue:
    a lack of data as well as funding. If you’ve heard the term “AI winter,” this
    is what it’s referring to. Developments were made on the modeling side but we
    didn’t have significant ways to apply the models that were being developed without
    the ability and willingness of research groups to get their hands on enough data
    to feed those models.'
  prefs: []
  type: TYPE_NORMAL
- en: Then, in 1997, Sepp Hochreiter and Jürgen Schmidhuber published their groundbreaking
    work titled *Long Short-Term Memory*, which effectively allowed DL to "solve complex,
    artificial long-time lag tasks that had never been solved by previous recurrent
    network algorithms." The reason why this development was so important was it allowed
    the idea of sequences to remain relevant for DL problems. Because neural networks
    involve hidden layers, it’s difficult for the notion of time to remain relevant,
    which makes a number of problems hard to solve. For instance, a traditional recurrent
    neural network might not be able to autocomplete a sentence in the way that a
    **Long short-term memory (LSTM)** can because it doesn’t understand the time sequence
    involved in the completion of a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Today, most DL models require a ton of supervised datasets, meaning the neural
    networks that power DL need lots of examples to understand whether something is,
    for example, a dog or a horse. If you think about it a bit though, this doesn’t
    actually relate that closely to how our brains work. A small child that’s just
    emerging and learning about the world might need to be reminded once or twice
    about the difference between a dog and a horse, but you likely aren’t reminding
    them of that difference thousands or millions of times.
  prefs: []
  type: TYPE_NORMAL
- en: In that sense, DL is evolving towards requiring fewer and fewer examples to
    learn. If you recall, in previous chapters, we went over supervised and unsupervised
    learning techniques, this becomes significant in the case of DL. Sure, these days
    we’re able to gather massive amounts of data for DL models to learn from but the
    models themselves are evolving to improve without needing much data toward the
    ultimate goal of unsupervised DL that can be trained with small amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve covered some of the histories and influences shaping the field
    of ML and DL more specifically. While we haven’t gone into many of the technical
    concepts too heavily, this gives us a good foundation with which to understand
    how ML and DL have developed over time and why they’ve risen to prominence. In
    the following section, we will get more hands-on and get into the specific algorithms
    and neural networks that are used most heavily in DL.
  prefs: []
  type: TYPE_NORMAL
- en: Types of neural networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’d like to now turn your attention toward some of the most popular kinds of
    neural networks used in DL today. Some of these will sound familiar based on the
    previous section, but it will help to familiarize yourself with some of these
    concepts especially if you plan on working as a product manager for a DL product.
    Even if you aren’t currently working in this capacity, you’ll want to take a look
    through these in case your career does veer toward DL products in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a list of some of the most used ANNs in DL:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Multilayer** **perceptrons** (**MLPs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Radial basis function** **networks** (**RBFNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Convolutional neural** **networks** (**CNNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recurrent neural** **networks** (**RNNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Long short-term memory** **networks** (**LSTMs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Generative adversarial** **networks** (**GANs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Self-organizing** **maps** (**SOMs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deep belief** **networks** (**DBNs**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following section, we will touch on these various neural networks to
    give you an idea of what they are best suited for. As we did in the previous chapter
    with ML algorithms, we will describe some of the most popular use cases of each
    type of ANN so that we can understand, at least in a general sense, what some
    of the core competencies of each ANN are so that you can start to keep those ideas
    in mind should you pursue the creation of your own DL products in the future.
    If your aim is to specialize exclusively in supporting or building DL products
    of your own, this will be a great summary overview of each ANN.
  prefs: []
  type: TYPE_NORMAL
- en: MLPs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: After David Rumelhart, Geoffrey Hinton, and Ronald Williams’s paper *Learning
    representations by back-propagating errors* came out in 1986, MLPs were popularized
    because in that paper they used backpropagation to train an MLP. Unlike RNNs,
    MLPs are another form of feedforward neural network that uses backpropagation
    to optimize the weights. For this reason, you can think of MLPs as some of the
    most basic forms of ANNs because they were among the first to appear and today
    they’re still used often to deal with the high compute power that’s needed by
    some of the newer ANNs out there. Their accessibility and reliability are still
    useful today, which is why we wanted to start this list with MLPs to give us a
    good foundation for conceptualizing the rest of the DL algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: The way they learn is the algorithm will send data forward through the input
    and middle layers to the output layer. Then, based on the results in the output
    layer, it will then calculate the error to assess how off it was at predicting
    values. This is where backpropagation comes in because it will get a sense of
    how wrong it was in order to then backpropagate the rate of error. It will then
    optimize itself to minimize that error by adjusting the weights in the network
    and will effectively update itself.
  prefs: []
  type: TYPE_NORMAL
- en: The idea is you would pass these steps through the model multiple times until
    you were satisfied with the performance. Remember the distinction between supervised
    and unsupervised learning in [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012)?
    Because MLPs use backpropagation to minimize their error rate by adjusting weights,
    MLPs are a supervised DL algorithm because they know based on our label data exactly
    how off they were from being right. These algorithms are also heavily used in
    ensembles with other ANNs as a final polishing stage.
  prefs: []
  type: TYPE_NORMAL
- en: RBFNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'RBFNs came on the scene in 1988 with D.S. Broomhead and David Lowe’s paper
    *Multivariable Functional Interpolation and Adaptive Networks*. RBFNs differ from
    most other ANNs we will cover in this chapter in that they only have three layers.
    While most ANNs, including the MLPs we discussed in the preceding section, will
    have an input and output layer with several hidden layers in between, RBFNs only
    have one hidden layer. Another key difference is rather than having the input
    layer be a computational layer, the input layer only passes data to the hidden
    layer in RBFNs, so this ANN is incredibly fast. These DL algorithms are feedforward
    models, so they are computationally only really passing through two layers: the
    hidden layer and the output layer.'
  prefs: []
  type: TYPE_NORMAL
- en: It would be helpful to think of these networks as similar to the KNN algorithm
    we discussed in the previous chapter, which aims to predict data points based
    on the data points around the value they’re trying to predict. The reason for
    this is RBFNs look to approximate values based on the distance, radius, or Euclidean
    distance between points and they will cluster or group data in circles or spheres
    to better make sense of a complex multivariable dataset similar to how a K-means
    clustering algorithm from [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012) would.
    This is a highly versatile algorithm that can be used with both classification
    and regression problems in both supervised and unsupervised ways.
  prefs: []
  type: TYPE_NORMAL
- en: SOMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: SOMs were introduced in the 1980s by Tuevo Hohonen and are another example of
    unsupervised competitive learning ANNs in which the algorithm takes a multivariable
    dataset and reduces it into a two-dimensional “map.” Each node will compete with
    the others to decide whether it’s the one that should be activated, so it’s essentially
    just a massive competition, which is how it self-organizes. Structurally though,
    SOMs are very different from most ANNs. There’s really just one layer or node
    outside of the input layer, which is called the Kohonen layer. The nodes themselves
    are also not connected the way they are in more traditional ANNs.
  prefs: []
  type: TYPE_NORMAL
- en: The training of a SOM mirrors our own brain’s ability to self-organize and map
    inputs. When we sense certain inputs, our brain organizes those inputs into certain
    areas that are apt for what we’re seeing, hearing, feeling, smelling, or tasting.
    The SOM will similarly cluster data points into certain groupings. The way that
    happens is through a learning/training process where the algorithm sends out the
    data through the input layer and weights, randomly selecting input data points
    to test against the nodes until a node is chosen based on the distance between
    it and the data point, which then updates the weight of the node. This process
    is repeated until the training set is complete and the optimal nodes have been
    selected.
  prefs: []
  type: TYPE_NORMAL
- en: SOMs will also be in the same class of clustering algorithms such as K-means,
    or the RBFNs we touched on in the preceding section, in that they are useful for
    finding relationships and groupings in datasets that are unlabeled or undiscovered.
  prefs: []
  type: TYPE_NORMAL
- en: CNNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CNNs, sometimes referred to as ConvNets, have multiple layers that are used
    largely for supervised learning use cases in which they detect objects, process
    images, and detect anomalies in medical and satellite images. The way this ANN
    works is through a feedforward, so it starts from the input layer and makes its
    way through the hidden layers to the ultimate output layer to categorize images.
    This type of ANN is characterized as categorical, so its ultimate goal is looking
    to put images into buckets of categories. Then, once they are categorized, it
    looks to group images by the similarities they share so that it can ultimately
    perform the object recognition that’s used to detect faces, animals, plants, or
    signs on the street. CNNs can be used for things such as facial recognition, object
    identification, and self-driving cars or what’s commonly referred to as computer
    vision applications of AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'The four important layers in CNNs are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The convolution layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **rectified linear unit** (**ReLU**) layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pooling layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fully connected layer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The convolution layer turns an image into a matrix of pixel values that are
    0s and 1s and then further reduces that matrix into a smaller matrix that’s a
    derivative from the first. The ReLU layer effectively pares down the dimensions
    of the image that you pass to the CNN. Even color images are passed through a
    grayscale when they’re originally assigned 0s and 1s. So, in the ReLU stage, the
    CNN actually gets rid of black pixels from the image so that it can reduce the
    image further and make it computationally easier for the model to process it.
    There’s another layer that reduces the dimensions of the image in another way:
    the pooling layer.'
  prefs: []
  type: TYPE_NORMAL
- en: While the ReLU layer pares down the gradient in the image itself, the pooling
    layer pares down the features of the image, so if we pass the CNN an image of
    a cat, the pooling layer is where we will see various features such as the ears,
    eyes, nose, and whiskers identified. You can think of the convolution, ReLU, and
    pooling layers as operations that take segments of each image you feed your model
    and concurrently fire the outputs of those prior steps as inputs into the fully
    connected layer, which is what actually passes through the neural network itself
    to classify the image. In essence, the convolution, ReLU, and pooling layers prepare
    the image to pass through the neural network to arrive at a conclusion.
  prefs: []
  type: TYPE_NORMAL
- en: RNNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several operations that feedforward neural networks weren’t able to
    do very well, including working with sequential data that is rooted in time, operations
    that needed to contextualize multiple inputs (not just the current input), and
    operations that require memorization from previous inputs. For these reasons,
    the main draw of RNNs is the internal memory they possess that allows them to
    perform and remember the kind of robust operations required of conversational
    AIs such as Apple’s Siri. RNNs do well with sequential data and place a premium
    on the context in order to excel at working with time-series data, DNA and genomics
    data, speech recognition, and speech-to-text functions. In contrast to the preceding
    CNN example, which works with a feedforward function, RNNs work in loops.
  prefs: []
  type: TYPE_NORMAL
- en: Rather than the motion going from the input layer, through the hidden layers,
    and ultimately to the output layer, the RNN cycles through a loop back and forth
    and this is how it retains its short-term memory. This means the data passes through
    the input layer, then loops through the hidden layers, before it ultimately passes
    to the output layer. It’s important to note that RNNs only have short-term memory,
    which is why there was a need for an LSTM network. More on that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, the RNN actually has two inputs. The first is the initial data that
    makes its way through the neural network and the second is actually the information
    and context it’s acquired along the way. This is the framework with which it also
    effectively alters its own weights to current and previous inputs, so it’s course-correcting
    as it goes through its loops. This process of retroactively adjusting weights
    to minimize its error rate is known as backpropagation, which you’ll recall from
    the previous section (*A brief history of DL*) as this was a major advancement
    that has helped DL become so successful.
  prefs: []
  type: TYPE_NORMAL
- en: It’s helpful to imagine that an RNN is actually a collection of neural networks
    that are continuously retrained and optimized for accuracy through backpropagation,
    which is why it’s also considered a supervised learning algorithm. Because it’s
    such a robust and powerful DL algorithm, we can see RNNs used for anything from
    captioning and understanding images to predicting time-series problems to natural
    language processing and machine translation.
  prefs: []
  type: TYPE_NORMAL
- en: LSTMs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LSTMs are basically RNNs with more memory power. Often, the way they manifest
    is through networks of the LSTM because what they do is actually connect layers
    of RNNs, which is what allows them to retain inputs over lags or longer periods
    of time. Much like a computer, LSTMs can write, read, or delete data from the
    memory it possesses. Because of this, it has the ability to learn about what data
    it needs to hold onto over time. Just as RNNs continuously adjust their weights
    and optimize for performance, LSTMs do the same thing by assigning levels of importance
    for what data to store or delete through its own weights.
  prefs: []
  type: TYPE_NORMAL
- en: LSTMs mirror our own ability to discard irrelevant or trivial information through
    time through LSTM cells, which have the ability to let the information come in
    as an input, be forgotten or excluded completely, or let it pass to influence
    the output. These categorizations are referred to as gates and they’re what allow
    LSTMs to learn through backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: GANs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GANs are our favorite type of ANN because they’re essentially made up of two
    neural networks that are pitted against each other, hence the name, and compete
    toward the goal of generating new data that’s passable for real-world data. Because
    of this generative ability, GANs are used for image, video, and voice generation.
    They were also initially used for unsupervised learning because of their generative
    and self-regulation abilities but they can be used for supervised and reinforcement
    learning as well. The way it works is one of the neural networks is referred to
    as the generator and the other is the discriminator and the two compete as part
    of this generative process.
  prefs: []
  type: TYPE_NORMAL
- en: 'GANs were first introduced in a breakthrough paper that came out in 2014 by
    Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio, which states that GANs *"simultaneously
    train two models: a generative model G that captures the data distribution, and
    a discriminative model D that estimates the probability that a sample came from
    the training data rather than G. The training procedure for G is to maximize the
    probability of D making* *a mistake,"*'
  prefs: []
  type: TYPE_NORMAL
- en: Citation
  prefs: []
  type: TYPE_NORMAL
- en: Goodfellow, I. J., Mirza, M., Xu, B., Ozair, S., Courville, A., & Bengio, Y.
    (2014). *Generative Adversarial Networks*. *arXiv*. [https://doi.org/10.48550/arXiv.1406.2661](https://doi.org/10.48550/arXiv.1406.2661)
  prefs: []
  type: TYPE_NORMAL
- en: We can think of discriminative and generative models as two sides of the same
    coin. Discriminative models look at the features a type of image might have, for
    example, looking for associations between all the images of dogs it’s currently
    learning from. Generative models start from the category itself and expand out
    into potential features a category in that image might possess. If we take the
    example of a category such as space kittens, the generative model might look at
    the example data it’s fed and deduce that if it creates an image, it should create
    something that involves space and kittens. The discriminative model then takes
    the image the generative model creates and confirms, based on its own learning,
    that any images in the space kittens category must contain both kittens and space
    as features.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to explain this is that the generative model maps the label to potential
    features and the discriminative model maps features to the label. What’s most
    interesting to us about GANs is they effectively pass or fail their own version
    of the Turing test. How do you know whether you passed? If the GAN correctly identifies
    a generated image as a falsified image, it’s passed (or failed?) its own test.
    It really depends on how you look at passing or failing for that matter. If it
    incorrectly labeled a falsified/generated image as a “real” image, it means the
    generative model is pretty strong because its own discriminator wasn’t able to
    discriminate properly. Then again, because it’s a double-sided coin, it means
    that the discriminator needs to be strengthened to be more discerning. This one
    is very meta.
  prefs: []
  type: TYPE_NORMAL
- en: The steps a GAN takes to run through its process first begin with a generator
    neural network that takes in data and returns an image, which is then fed to the
    discriminator along with other images from a real-world dataset. Then, the discriminator
    produces outputs that are numbered between 0 and 1, which it assigns as probabilities
    for each of the images it is discriminating, with 0 representing a fake and 1
    representing an authentic real-world image. GANs also use backpropagation, so
    every time the discriminator makes a wrong call, the GAN learns from previous
    mistakes to correct its weights and optimize itself for accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: DBNs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: DBNs also have multiple layers, including multiple hidden layers, but the nodes
    in one layer aren’t connected to each other, though they are connected to nodes
    in other layers. There are relations between the layers themselves, but not between
    the nodes within. DBNs are unsupervised learning layers of what are called **Restricted
    Boltzmann Machines** (**RBMs**), which are themselves another form of ANN. These
    layers of RBMs are chained together to form a DBN. Because of this chain, as data
    passes through the input layer of each RBM, the DBN learns and obtains features
    from the prior layer. The more layers of RBMs you add, the greater the improvement
    and training of the DBN overall. Also, every RBM is taught individually and the
    DBN training isn’t done until all the DBNs have been trained.
  prefs: []
  type: TYPE_NORMAL
- en: DBNs are referred to as generative ANNs because each of the RBMs learns and
    obtains potential values for your data points based on probability. Because of
    this generative ability that they have, they can be used for things such as image
    recognition, capturing motion data, or recognizing speech. They are also computationally
    energy-efficient because each cluster of RBMs operates independently. Rather than
    data passing through all the layers in concert as with feedforward ANNs, data
    stays local to each cluster.
  prefs: []
  type: TYPE_NORMAL
- en: As a product manager, you won’t need to have in-depth knowledge of each neural
    network because if you’re building a product with DL components, you’ve got internal
    experts that can help determine which neural networks to use. But it does help
    to know what some of the most common types of neural networks out there are so
    that you aren’t left in the dark about those determinations. In the next section,
    we will see how DL neural networks overlap with other emerging technologies for
    better context on the ability and influence of DL.
  prefs: []
  type: TYPE_NORMAL
- en: Emerging technologies – ancillary and related tech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ML and DL have been used heavily in applications related to natural language
    processing (**natural language generation** (**NLG**), as well as **natural language
    understanding** (**NLU**)), speech recognition, chatbots, virtual agents and assistants,
    decision management, process automation, text analytics, biometrics, cybersecurity,
    content creation, image and emotion recognition, and marketing automation. It’s
    important to remember, particularly from a product manager’s perspective, that
    AI will increasingly work its way into more of how we live our lives and do our
    work. This is doubly true if you work in an innovative capacity as a product manager
    where you’re involved with the ideation and creation of new use cases and MVPs
    for future products.
  prefs: []
  type: TYPE_NORMAL
- en: Over the passage of time, we’ll see AI continue to augment our workforce both
    through the process of internal automation as well as through the adoption of
    AI-based no-code/low-code external products and applications that will boost job
    functions, skills, and abilities across the board. AR, VR, and the metaverse also
    offer us new emerging fields where ML will learn more about our world, help us
    learn about ourselves, and also help us build new worlds altogether. We will also
    continue to see ML employed through AI-powered devices such as self-driving planes,
    trains, and automobiles, as well as biometrics, nanotechnologies, and IoT devices
    that share streams of data about our bodies and appliances that we can increasingly
    use to optimize our security, health and energy usage.
  prefs: []
  type: TYPE_NORMAL
- en: There are, of course, other forms of AI beyond ML and DL, as well as ancillary
    emerging technologies that are often used in concert with the tech we’ve covered
    in this chapter. For instance, with all the innovation and fame that’s accompanied
    the Boston Dynamics dog Spot, we were surprised to find out recently that they
    don’t actually use ML to train these little guys. But even Spot will soon see
    AI updates to its operating system to help it with things such as object recognition
    and semantic contextualization of those objects.
  prefs: []
  type: TYPE_NORMAL
- en: AI in general, and DL specifically, might be getting an update of its own soon
    through quantum computing since IBM made its aspirations more concrete by publicly
    announcing a “road map” for the development of its quantum computers, including
    the ambitious goal of building one containing 1,000 qubits by 2023\. IBM’s current
    largest quantum computer contains 65 qubits.
  prefs: []
  type: TYPE_NORMAL
- en: Quantum computing can massively help us deal with the ongoing issue of storing
    and retrieving data, particularly big data, in cost-effective ways. Because so
    many DL projects can take weeks to train and require access to big data, ancillary
    developments in quantum computing can prove groundbreaking in the area of DL to
    the point where the algorithms both require fewer data to train on and can also
    handle more data and compute power more quickly. This could also allow us greater
    opportunities for making sense of how the models come to certain conclusions and
    assist with perhaps the greatest hurdle of DL – explainability.
  prefs: []
  type: TYPE_NORMAL
- en: Explainability – optimizing for ethics, caveats, and responsibility
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Ethics and responsibility play a foundational role in dealing with your customers’
    data and behavior and because most of you will build products that help assist
    humans to make decisions, eventually someone is going to ask you how your product
    arrives at conclusions. Critical thinking is one of the foundational cornerstones
    of human reasoning and if your product is rooted in DL, your answer won’t be able
    to truly satisfy anyone’s skepticism. Our heartfelt advice is this: don’t create
    a product that will harm people, get you sued, or pose a risk to your business.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re leveraging ML or DL in a capacity that has even the potential to
    cause harm to others, if there’s a clear bias that affects underrepresented or
    minority groups (in terms of race, gender, or culture), go back to the ideation
    phase. This is true whether that’s immediate or downstream harm. This is a general
    risk all of ML poses to us collectively: the notion that we’re coding our societal
    biases into AI without taking the necessary precautions to make sure the data
    we feed our algorithms is truly unbiased.'
  prefs: []
  type: TYPE_NORMAL
- en: The engineers themselves that build these ANNs are unable to look under the
    hood and truly explain how ANNs make decisions. As we’ve seen with the, albeit
    layman, preceding explanations of DL algorithms, ANN structures are built on existing
    ML algorithms and scaled, so it’s almost impossible for anyone to truly explain
    how these networks come to certain conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is why DL algorithms are often referred to as a black box because
    they resist a truly in-depth analysis of the underpinnings of the logic that makes
    them work. DL has a natural opacity to it because of the nature and complexity
    of ANNs. Remember that ANNs effectively just make slight adjustments to the weights
    that affect each neuron within its layers. They are basically elaborate pattern
    finders using math and statistics to make optimizations to their weighting system.
    They do that hundreds of times for each data point over multiple iterations of
    training. We simply don’t have the mental capacity or language to explain this.
  prefs: []
  type: TYPE_NORMAL
- en: You also don’t have to be a DL engineer to truly understand how your product
    affects others. If you, as a product manager, are not able to fully articulate
    how DL is leveraged in your product and, at the very least, can’t prove that the
    outputs of your DL product aren’t causing harm to others, then it probably isn’t
    a product you want to go all in for.
  prefs: []
  type: TYPE_NORMAL
- en: DL is still very much in the research phase and many product managers are hesitant
    to incorporate it because of the issue of explainability we discussed earlier
    in the chapter. So we urge product managers to use caution when looking to wet
    their feet with DL. We have plenty of examples of ML causing harm to people even
    when it involves basic linear regression models. Moving forward without a sense
    of stewardship of and responsibility for our peers and customers with something
    as complicated and full of potential as DL is a recipe for adding more chaos and
    harm to the world.
  prefs: []
  type: TYPE_NORMAL
- en: Do we always have to be so cautious? Not necessarily. If DL applications get
    really good at saving lives by detecting cancer or they work better when applied
    to robotics, who are we to stand in the way of progress? Be critical about when
    to be concerned with your use of DL. If your system works effectively and is better
    because of DL and there isn’t some problem or concern springing from the opacity
    of the ANNs, then all is right with the world.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy – optimizing for success
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When it comes to DL, we can only truly grapple with its performance. Even from
    a performance perspective, a lot of DL projects fail to give the results their
    own engineers are hoping for, so it’s important to manage expectations. This is
    doubly true if you’re managing the expectations of your leadership team as well.
    If you’re a product manager or entrepreneur and you’re thinking of incorporating
    DL, do so in the spirit of science and curiosity. Remain open about your expectations.
  prefs: []
  type: TYPE_NORMAL
- en: But make sure you’re setting your team up for success. A big part of your ANN’s
    performance also lies in the data preparation you take before you start training
    your models. Passing your data through an ANN is the last step in your pipeline.
    If you don’t have good validation or if the quality of your data is poor, you’re
    not going to see positive results. Then, once you feel confident that you have
    enough data and that it’s clean enough to pass through an ANN, start experimenting.
    If you’re looking for optimal performance, you’ll want to try a few different
    models, or a selection of models together, and compare the performance.
  prefs: []
  type: TYPE_NORMAL
- en: The time it takes to fine-tune a DL model is also aggressively long. If you’re
    used to other forms of ML, it might shock you to experience training a model over
    the course of days or weeks. This is largely because the amount of data you need
    to train ANNs is vast; most of the time you need at least 10,000 data points,
    and all this data is passed through multiple layers of nodes and processed by
    your ANN. Your ANN is also, most of the time, going to be an ensemble of several
    types of ANNs we mentioned previously. The chain then becomes quite long.
  prefs: []
  type: TYPE_NORMAL
- en: The nature of understanding ANNs is inherently mysterious because of the complexity
    of the layers of artificial neurons. We cannot see deterministic qualities. Even
    when you do everything “right” and you get a good performance, you don’t really
    know why. You just know that it works. The same goes when something does go wrong
    or when you see poor performance. You once again don’t really know why. Perhaps
    the fault lies with the ANN or with the method you’re using or something has changed
    in the environment. The process of getting back to better performance is also
    iterative. And then it’s back to the drawing board.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that these are emerging tech algorithms. It may take us all some time
    to adjust to new technologies and truly understand the power they have. Or don't!
    Part of the disillusionment that’s happened with DL actually lies in the tempering
    of expectations. Some DL algorithms can make amazing things happen and can show
    immensely promising performance but others can so easily fall flat. It’s not a
    magic bullet. It’s just a powerful tool that needs to be used in the proper way
    by people that have the knowledge, wisdom, and experience to do so. Considering
    most of the ANNs we went over together are from the 80s, 90s, and early 2000s,
    that’s not much time.
  prefs: []
  type: TYPE_NORMAL
- en: So tread carefully here if you’re building, managing, or ideating on DL products.
    When in doubt, there are other more explainable models to choose from, which we’ve
    covered in [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012). It’s better to be
    safe than sorry. If you’ve got lots of time, patience, excitement, and curiosity
    along with a safe, recreational idea for applying DL, then you’re probably in
    a good position to explore that passion and create something the world could use
    in good faith.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We got the chance to go deep into DL in this chapter and understand some of
    the major social and historical influences that impact this subsection of ML.
    We also got the chance to look at some of the specific ANNs that are most commonly
    used in products powered by DL in order to get more familiar with the actual models
    we might come across as we build with DL. We ended the chapter with a look at
    some of the other emerging technologies that collaborate with DL, as well as getting
    further into some of the concepts that impact DL most: explainability and accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: DL ANNs are super powerful and exhibit great performance, but if you need to
    explain them, you will run into more issues than you would if you stick to more
    traditional ML models. We’ve now spent the first three chapters of the book getting
    familiar with the more technical side of AI product management. Now that we’ve
    got that foundation covered, we can spend some time contextualizing all this tech.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore some of the major areas of AI products
    we see on the market, as well as examples of the ethics and success factors that
    contribute most to commercialization.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Some Methods for Classification and Analysis of Multivariate Observations:
    [https://books.google.com/](https://books.google.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'K-Nearest Neighbors Algorithm: Classification and Regression Star [https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/](https://www.historyofdatascience.com/k-nearest-neighbors-algorithm-classification-and-regression-star/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random Forests [https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf](https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Decision Trees [https://www.cse.unr.edu/~bebis/CS479/PaperPresentations/DecisionTrees.pdf](https://www.cse.unr.edu/~bebis/CS479/PaperPresentations/DecisionTrees.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Support Vector Machine: The most popular machine learning algorithm [https://cml.rhul.ac.uk/svm.html](https://cml.rhul.ac.uk/svm.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Regression [https://uc-r.github.io/logistic_regression#:~:text=Logistic%20regression%20(aka%20logit%20regression,more%20predictor%20variables%20(X)](https://uc-r.github.io/logistic_regression#:~:text=Logistic%20regression%20(aka%20logit%20regression,more%20predictor%20variables%20(X))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logistic Regression History [https://holypython.com/log-reg/logistic-regression-history/](https://holypython.com/log-reg/logistic-regression-history/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayes Classifier [https://www.sciencedirect.com/topics/computer-science/bayes-classifier#:~:text=Na%C3%AFve%20Bayes%20classifier%20(also%20known,use%20Na%C3%AFve%20Bayes%20since%201960s](https://www.sciencedirect.com/topics/computer-science/bayes-classifier#:~:text=Na%C3%AFve%20Bayes%20classifier%20(also%20known,use%20Na%C3%AFve%20Bayes%20since%201960s)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Principal Component Analysis [https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/principal-component-analysis#:~:text=PCA%20was%20invented%20in%201901,the%20modeling%20of%20response%20data](https://www.sciencedirect.com/topics/agricultural-and-biological-sciences/principal-component-analysis#:~:text=PCA%20was%20invented%20in%201901,the%20modeling%20of%20response%20data)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics
    Instructors [https://www.tandfonline.com/doi/full/10.1080/10691898.2001.11910537](https://www.tandfonline.com/doi/full/10.1080/10691898.2001.11910537)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IBM promises 1000-qubit quantum computer—a milestone—by 2023 [https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023](https://www.science.org/content/article/ibm-promises-1000-qubit-quantum-computer-milestone-2023)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boston Dynamics says AI advances for Spot the robo-dog are coming [https://venturebeat.com/ai/boston-dynamics-says-ai-advances-for-spot-the-robo-dog-are-coming/](https://venturebeat.com/ai/boston-dynamics-says-ai-advances-for-spot-the-robo-dog-are-coming/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolutional Neural Network Tutorial [https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network](https://www.simplilearn.com/tutorials/deep-learning-tutorial/convolutional-neural-network)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative Adversarial Networks [https://arxiv.org/abs/1406.2661](https://arxiv.org/abs/1406.2661)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Self-Organizing Map [https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1990-Kohonen-PIEEE.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multivariable Functional Interpolation and Adaptive Networks [https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1988-Broomhead-CS.pdf](https://sci2s.ugr.es/keel/pdf/algorithm/articulo/1988-Broomhead-CS.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long Short-Term Memory [http://www.bioinf.jku.at/publications/older/2604.pdf](http://www.bioinf.jku.at/publications/older/2604.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning Representations by Back Propagating Errors [https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numerical solution of variational problems [https://www.sciencedirect.com/science/article/pii/0022247X62900045](https://www.sciencedirect.com/science/article/pii/0022247X62900045)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Perceptron: A Perceiving and Recognizing Automaton [https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Logical Calculus of the Ideas Immanent in Nervous Activity [https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf](https://www.cs.cmu.edu/~./epxing/Class/10715/reading/McCulloch.and.Pitts.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI Education [https://aiindex.stanford.edu/wp-content/uploads/2021/03/2021-AI-Index-Report-_Chapter-4](https://aiindex.stanford.edu/wp-content/uploads/2021/03/2021-AI-Index-Report-_Chapter-4.pdf)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
