["```py\nrepo_url = 'https://gitlab.com/secml/secml-zoo'\nfile_name = 'drebin-reduced.tar.gz'\nDrebinRed/' + file_name\noutput_dir = fm.join(settings.SECML_DS_DIR, 'drebin-red')\nmd5_digest = 'ecf87ddedf614dd53b89285c29cf1caf'\ndl_file_gitlab(repo_url, file_path, output_dir,\nbranch='v' + min_version, md5_digest=md5_digest)\n```", "```py\nExplanations for sample 137 (true class: 0)\n -7.49 suspicious_calls::android/net/Uri;->toString\n -5.63 suspicious_calls::getSystemService\n -5.42 api_calls::android/media/MediaPlayer;->start\n -4.99 used_permissions::ACCESS_NETWORK_STATE\n -4.55 req_permissions::android.permission.ACCESS_FINE_LOCATION\n```", "```py\nparams = {\"classifier\": clf,\n    \"distance\": 'l1',\n    \"double_init\": False,\n    \"lb\": 'x0', #feature addition, lb=0 for feature removal\n    \"ub\": 1,  #feature addition\n    \"attack_classes\": 'all',\n    \"y_target\": 0,\n    \"solver_params\": {'eta': 1, 'eta_min': 1, 'eta_max': None, 'eps': 1e-4}\n}\nfrom secml.adv.attacks.evasion import CAttackEvasionPGDLS\nevasion = CAttackEvasionPGDLS(**params)\n```", "```py\nfrom secml.adv.seceval import CSecEval\nsec_eval = CSecEval(\n    attack=evasion,\n    param_name=param_name,\n    param_values=param_values)\nsec_eval.run_sec_eval(adv_ds)\n```", "```py\n    from secml.ml.peval.metrics import CMetricTHatFPR, CMetricTPRatTH\n    ```", "```py\n    th = CMetricTHatFPR(fpr=fpr_th).performance_score(y_true=ts.Y, score=score_pred[:, 1].ravel())\n    ```", "```py\n    fig.sp.plot_sec_eval(sec_eval.sec_eval_data, metric=CMetricTPRatTH(th=th),percentage=True, label='SVM', color='green', marker='o')\n    fig.sp.ylabel(r'Detection Rate $(\\%)$')\n    fig.sp.xlabel(r\"$\\varepsilon$\")\n    ```", "```py\nimport ml_privacy_meter\nimport tensorflow as tf\ndatahandlerA = ml_privacy_meter.utils.attack_data.attack_data(dataset_path=dataset_path,\nmember_dataset_path=saved_path,\n            batch_size=100, attack_percentage=10,\ninput_shape=input_shape,\n            normalization=True)\n```", "```py\nattackobj = ml_privacy_meter.attack.meminf.initialize(\n    target_train_model=cmodelA,\n    target_attack_model=cmodelA,\n    train_datahandler=datahandlerA,\n    attack_datahandler=datahandlerA,\n    layers_to_exploit=[26],\n    gradients_to_exploit=[6],\n    device=None, epochs=10, model_name='blackbox1')\nattackobj.train_attack()\nattackobj.test_attack()\n```", "```py\ndefence = SpectralSignatureDefense(classifier, x_train, y_train,  batch_size=128, eps_multiplier=1, expected_pp_poison=percent_poison)\nreport, is_clean_lst = defence.detect_poison(nb_clusters=2,                                           nb_dims=10,reduce=\"PCA\")\npp = pprint.PrettyPrinter(indent=10)\npprint.pprint(report)\nis_clean = (is_poison_train == 0)\nconfusion_matrix = defence.evaluate_defence(is_clean)\n```", "```py\n    Email varchar (100) MASKED WITH (FUNCTION = 'email ()') NULL\n    ```", "```py\nHE = Pyfhel()\nHE.contextGen(p=65537, m=2**12)\nHE.keyGen() # Generates both a public and a private key\nHE.savepublicKey(pk_file)\nHE.saveContext(contx_file)\na = 1.5\nb = 2.5\nca = HE.encryptFrac(a)\ncb = HE.encryptFrac(b)\n```", "```py\nc2a = PyCtxt(pyfhel=HE_Cl, fileName=sec_con / \"ca.ctxt\", encoding=float)\nc2b = PyCtxt(pyfhel=HE_Cl, fileName=sec_con / \"cb.ctxt\", encoding=float)\ntry:\n    print (HE_Cl.decrypt(c2a))\n    raise Exception (\"This should not be reached!\")\nexcept RuntimeError:\n    print (\"The cloud tried to decrypt but couldn't!\")\n```", "```py\nc_mean = (c2a + c2b) / 2\nc_mean.to_file(sec_con / \"c_mean.ctxt\")\n```", "```py\nc_res = PyCtxt(pyfhel=HE, fileName=sec_con / \"c_mean.ctxt\", encoding=float)\nprint (\"Client decrypt results\", c_res.decrypt())\n```", "```py\nThe cloud tried to decrypt but couldn't!\nClient decrypt results 2.0\n```", "```py\nfrom mpyc.runtime import mpc\nsecint = mpc.SecInt(l)\nscaling = 10**args.accuracy\nlocations[i] = mpc.input(list(map(secint, position_i)), senders=sender_pid)\ntoas[i] = mpc.input(secint(toas_i), senders=sender_pid)\nx, y, z = await schmidt_multilateration(locations, toas)\n```", "```py\nimport numpy as np\nimport sklearn as sk\nfrom sklearn.pipeline import Pipeline\nfrom diffprivlib import models\nX_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", usecols=(0, 4, 10, 11, 12), delimiter=\", \")\ny_train = np.loadtxt(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", usecols=14, dtype=str, delimiter=\", \")\n```", "```py\ndp_pipe = Pipeline([\n    ('scaler', models.StandardScaler(bounds=([17, 1, 0, 0, 1], [90, 160, 10000, 4356, 99]))),\n    ('pca', models.PCA(2, data_norm=5, centered=True)),\n    ('lr', models.LogisticRegression(data_norm=5))])\ndp_pipe.fit(X_train, y_train)\nfor epsilon in epsilons:\n    _eps = epsilon / 3\n    dp_pipe.set_params(scaler__epsilon=_eps, pca__epsilon=_eps, lr__epsilon=_eps)\n    dp_pipe.fit(X_train, y_train)\n```", "```py\n    SHADOW_DATASET_SIZE = int(shadow_X.shape[0] / 2)\n    smb = ShadowModelBundle(\n        shadow_model,\n        shadow_dataset_size=SHADOW_DATASET_SIZE,\n        num_models=)\n    ```", "```py\n    attacker_X, attacker_y = smb.fit_transform(shadow_X, shadow_y.values,                                         fit_kwargs=dict(epochs=epochs,\n    batch_size=batch_size,verbose=1))\n    ```", "```py\n    clf = RandomForestClassifier(max_depth=2)\n    clf.fit(attacker_X, attacker_y\n    ```", "```py\n    ATTACK_TEST_DATASET_SIZE = unused_X.shape[0]\n    data_in = target_X_train[:ATTACK_TEST_DATASET_SIZE], target_y_train[:ATTACK_TEST_DATASET_SIZE]\n    unused_X1 = unused_X.values.reshape((unused_X.shape[0],\n    unused_X.shape[1], 1))\n    data_out = unused_X1[:ATTACK_TEST_DATASET_SIZE], unused_y[:ATTACK_TEST_DATASET_SIZE]\n    ```", "```py\n    attack_test_data, real_membership_labels = prepare_attack_data(tm, data_in, data_out)\n    attack_guesses = clf.predict(attack_test_data)\n    attack_accuracy = np.mean(attack_guesses == real_membership_labels)\n    print('attack accuracy: {}'.format(attack_accuracy))\n    acc = accuracy_score(real_membership_labels, attack_guesses)\n    print('attack acc: {}'.format(acc))\n    ```", "```py\noptimizer = DPKerasSGDOptimizer(\n    l2_norm_clip=l2_norm_clip,\n    noise_multiplier=noise_multiplier,\n    num_microbatches=int(microbatches_perc * batch_size),\n    learning_rate=learning_rate)\n```", "```py\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.compat.v2.losses.Reduction.NONE)\n    classifier.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n    ```", "```py\nsampling_probability = batch_size / 50000\nsteps = epochs * 50000 // batch_size\norders = [1 + x / 10\\. for x in range(1, 100)] + list(range(12, 64))\nrdp = compute_rdp(q=sampling_probability,\n                  noise_multiplier=noise_multiplier,\n                  steps=steps,\n                  orders=orders)\nepsilon = get_privacy_spent(orders, rdp, target_delta=1e-5)[0]\nprint(\"Privacy Budget Epsilon\", epsilon)\n```", "```py\nimport torchvision.models as models\nimport eagerpy as ep\nfrom foolbox import PyTorchModel, accuracy, samples\nimport foolbox.attacks as fa\nimport numpy as np\n```", "```py\nmodel = models.resnet18(pretrained=True).eval()\npreprocessing = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], axis=-3)\nfmodel = PyTorchModel(model, bounds=(0, 1), preprocessing=preprocessing)\nimages, labels = ep.astensors(*samples(fmodel, dataset=\"imagenet\", batchsize=16))\nclean_acc = accuracy(fmodel, images, labels)\nprint(f\"clean accuracy:  {clean_acc * 100:.1f} %\")\nattacks = [fa.FGSM(),fa.LinfPGD(),fa.LinfBasicIterativeAttack(),\nfa.LinfAdditiveUniformNoiseAttack(), fa.LinfDeepFoolAttack()]\nepsilons = [0.0,0.0005,0.001,0.0015,0.002,0.003,0.005, 0.01, 0.02, 0.03, 0.1, 0.3, 0.5, 1.0]\n```", "```py\nfor i, attack in enumerate(attacks):\n    _, _, success = attack (fmodel, images, labels, epsilons=epsilons)\n    assert success.shape == (len(epsilons), len(images))\n    success_ = success.numpy()\n    assert success_.dtype == np.bool\n    attack_success[i] = success_\n    print(\"  \", 1.0 - success_.mean(axis=-1).round(2))\n```", "```py\nrobust_accuracy = 1.0 - attack_success.max(axis=0). mean(axis=-1)\n```"]