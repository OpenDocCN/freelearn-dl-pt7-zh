["```py\n    data_bucket = \"doc-processing-bucket-MMDD\"\n    region = boto3.session.Session().region_name\n                   os.environ[\"BUCKET\"] = data_bucket\n    os.environ[\"REGION\"] = region\n    if region=='us-east-1':\n        !aws s3api create-bucket --bucket $BUCKET\n    else:\n        !aws s3api create-bucket --bucket $BUCKET --create-bucket-configuration LocationConstraint=$REGION\n    ```", "```py\n    !aws s3 cp documents/train s3://{data_bucket}/train –recursive\n    ```", "```py\n    word_prefix=os.getcwd()+'/SAMPLE8/WORDS/'\n    box_prefix=os.getcwd()+'/SAMPLE8/BBOX/'\n    ```", "```py\ndef data_retriever_from_path(path):    \n    mapping={}\n    for i in names:\n        if os.path.isdir(path+i):\n            mapping[i] = sorted(os.listdir(path+i))\n    label_compre = []\n    text_compre = []\n    for i, j in mapping.items():\n                for k in j:\n            label_compre.append(i)\n            text_compre.append(open(path+i+\"/\"+k, encoding=\"utf-8\").read().replace('\\n',' '))\n    return label_compre, text_compre\n```", "```py\ntic = time.time()\npool = mp.Pool(mp.cpu_count())\npool.map(textract_store_train_LM, [table for table in images ])\nprint(\"--- %s seconds for extracting ---\" % (time.time() - tic))\npool.close()\n```", "```py\n    def data_retriever_from_path(path):    \n        mapping={}\n        for i in names:\n            if os.path.isdir(path+i):\n                mapping[i] = sorted(os.listdir(path+i))\n        # label or class or target list\n        label_compre = []\n        # text file data list\n        text_compre = []\n        # unpacking and iterating through dictionary\n        for i, j in mapping.items():\n            # iterating through list of files for each class\n            for k in j:\n                # appending labels/class/target\n                label_compre.append(i)\n                # reading the file and appending to data list\n                text_compre.append(open(path+i+\"/\"+k, encoding=\"utf-8\").read().replace('\\n',' '))\n        return label_compre, text_compre\n    ```", "```py\n    label_compre, text_compre=[],[]\n    path=word_prefix+'train/'\n    label_compre_train, text_compre_train=data_retriever_from_path(path)\n    label_compre.append(label_compre_train)\n    text_compre.append(text_compre_train)\n    if type(label_compre[0]) is list:\n            label_compre=[item for sublist in label_compre for item in sublist]\n            #print(label_compre)\n            text_compre=[item for sublist in text_compre for item in sublist]\n            #print(text_compre)\n    data_compre= pd.DataFrame()\n    data_compre[\"label\"] =label_compre   \n    data_compre[\"document\"] = text_compre\n    data_compre\n    ```", "```py\n    csv_compre=io.StringIO()\n    data_compre.to_csv(csv_compre,index=False, header=False)\n    key='comprehend_train_data.csv'  \n    input_bucket=data_bucket        \n    output_bucket= data_bucket       \n    response2 = s3.put_object(\n            Body=csv_compre.getvalue(),\n            Bucket=input_bucket,\n            Key=key)\n    ```", "```py\n    ENDPOINT_ARN='your endpoint arn paste here'\n    ```", "```py\n    documentName = \"paystubsample.png\"\n    display(Image(filename=documentName))\n    ```", "```py\n    response = comprehend.classify_document(\n        Text= page_string,\n        EndpointArn=ENDPOINT_ARN\n    )\n    print(response)\n    ```", "```py\n    REGION = 'enter your region'\n    WORKTEAM_ARN= \"enter your private workforce arn \"\n    BUCKET = data_bucket\n    ENDPOINT_ARN= ENDPOINT_ARN\n    role = sagemaker.get_execution_role()\n    region = boto3.session.Session().region_name\n    prefix = \"custom-classify\" + str(uuid.uuid1())\n    ```", "```py\n    def create_task_ui():\n        response = sagemaker.create_human_task_ui(\n            HumanTaskUiName=taskUIName,\n            UiTemplate={'Content': template})\n    return response\n    ```", "```py\n    create_workflow_definition_response = sagemaker.create_flow_definition(\n            FlowDefinitionName= flowDefinitionName,\n            RoleArn= role,\n            HumanLoopConfig= {\n                \"WorkteamArn\": WORKTEAM_ARN,\n                \"HumanTaskUiArn\": humanTaskUiArn,\n                \"TaskCount\": 1,\n                \"TaskDescription\": \"Read the instructions\",\n                \"TaskTitle\": \"Classify the text\"\n            },\n            OutputConfig={\n                \"S3OutputPath\" : \"s3://\"+BUCKET+\"/output\"\n            }\n\n    flowDefinitionArn = create_workflow_definition_response['FlowDefinitionArn']\n    ```", "```py\n    response = comprehend.classify_document(\n        Text= page_string,\n        EndpointArn=ENDPOINT_ARN\n    )\n    print(response)\n    p = response['Classes'][0]['Name']\n    score = response['Classes'][0]['Score']\n            #print(f»S:{sentence}, Score:{score}»)\n    response = {}\n    response['utterance']=page_string\n    response['prediction']=p\n    response['confidence'] = score\n    print(response)\n    ```", "```py\n    human_loops_started = []\n    CONFIDENCE_SCORE_THRESHOLD = .90\n    if(response['confidence'] > CONFIDENCE_SCORE_THRESHOLD):\n            humanLoopName = str(uuid.uuid4())\n            human_loop_input = {}\n\n            human_loop_input['taskObject'] = response['utterance']\n            start_loop_response = a2i_runtime_client.start_human_loop(\n            HumanLoopName=humanLoopName,\n            FlowDefinitionArn=flowDefinitionArn,\n            HumanLoopInput={\n                    \"InputContent\": json.dumps(human_loop_input)\n                }\n            )\n            print(human_loop_input)\n            human_loops_started.append(humanLoopName)\n            print(f'Score is less than the threshold of {CONFIDENCE_SCORE_THRESHOLD}')\n            print(f'Starting human loop with name: {humanLoopName}  \\n')\n    else:\n             print('No human loop created. \\n')\n    ```", "```py\n    workteamName = WORKTEAM_ARN[WORKTEAM_ARN.rfind('/') + 1:]\n    print(\"Navigate to the private worker portal and do the tasks. Make sure you've invited yourself to your workteam!\")\n    print('https://' + sagemaker.describe_workteam(WorkteamName=workteamName)['Workteam']['SubDomain'])\n    ```", "```py\n    completed_human_loops = []\n    resp = a2i_runtime_client.describe_human_loop(HumanLoopName=humanLoopName)\n    ```", "```py\n    for resp in completed_human_loops:\n        splitted_string = re.split('s3://' + data_bucket  + '/', resp['HumanLoopOutput']['OutputS3Uri'])\n        output_bucket_key = splitted_string[1]\n        response = s3.get_object(Bucket=data_bucket, Key=output_bucket_key)\n        content = response[\"Body\"].read()\n        json_output = json.loads(content)\n        pp.pprint(json_output)\n    ```"]