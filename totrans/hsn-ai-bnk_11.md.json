["```py\n#import libraries & define variables\nimport pandas as pd\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.datasets import make_classification\n```", "```py\ncat_val = ''\ncat_dict = {}\nfor index, row in df_xtics.iterrows():\n    ...\n\ndf_bank['age_c'] = pd.cut(df_bank['age'], [0,35,45,55,65,70,75,200])\n\n#ID Conversions\ndf_bank['age_c_codes']=df_bank['age_c'].cat.codes.astype(str)\nage_map={'0':'Less than 35 years'\n,'1':'35 to 44 years'\n,'2':'45 to 54 years'\n,'3':'55 to 64 years'\n,'4':'.65 to 69 years'\n,'5':'.70 to 74 years'\n,'6':'.75 and over'}\n```", "```py\n#3\\. map back the survey data\ndf_bank['age_c1']=df_bank['age_c_codes'].map(age_map)\ndf_bank['age_c1_val']=df_bank['age_c1'].map(cat_dict['Age of Householder'])\n\nX_flds = ['balance','day', 'duration', 'pdays',\n       'previous', 'age_c1_val']\nX = df_bank[X_flds]\ny = df_bank['y']\n```", "```py\nX, y = make_classification(n_samples=1000, n_features=3,\n                           n_informative=2, n_redundant=0,\n                           random_state=0, shuffle=False)\nclf = RandomForestClassifier(n_estimators=100, max_depth=2,\n                             random_state=0)\nclf.fit(X, y)\nprint(clf.feature_importances_)\n```", "```py\nsudo cp dataset.csv /var/lib/Neo4j/import/edge.csv\nsudo cp product.csv /var/lib/Neo4j/import/product.csv\nsudo cp customer.csv /var/lib/Neo4j/import/customer.csv\n```", "```py\nusername: test, password: test\n```", "```py\nMATCH (n) DETACH DELETE n;\n```", "```py\nLOAD CSV WITH HEADERS FROM \"file:///customer.csv\" AS row\nCREATE (c:Customer {customer_id: row.customer});\n```", "```py\nLOAD CSV WITH HEADERS FROM \"file:///product.csv\" AS row\nCREATE (p:Product {product_name: row.product});\n```", "```py\nLOAD CSV WITH HEADERS FROM \"file:///edge.csv\" AS line\nWITH line\nMATCH (c:Customer {customer_id:line.customer})\nMATCH (p:Product {product_name:line.product})\nMERGE (c)-[:HAS {TYPE:line.type, VALUE:toInteger(line.value)}]->(p)\nRETURN count(*);\n```", "```py\nMATCH (c)-[cp]->(p) RETURN c,cp,p;\n```", "```py\n#import libraries and define parameters\nfrom Neo4j import GraphDatabase\nimport spacy\n\n#define the parameters, host, query and keywords\nuri = \"bolt://localhost:7687\"\ndriver = GraphDatabase.driver(uri, auth=(\"test\", \"test\"))\nsession = driver.session()\n\ncheck_q = (\"MATCH (c:Customer)-[r:HAS]->(p:Product)\" \n \"WHERE c.customer_id = $customerid AND p.product_name = \\\n  $productname\" \n \"RETURN DISTINCT properties(r)\")\n...\nintent_dict = {'check':check_q, 'login':check_c}\n\n#list of key intent, product and attribute\nproduct_list = ['deposit','loan']\nattribute_list = ['pricing','balance']\nintent_list = ['check']\nprint('loading nlp model')\nnlp = spacy.load('en_core_web_md')\n```", "```py\nif name == '' or reset:\n    name = input('Hello, What is your name? ')\n    print('Hi '+name)\n    #check for login\n    query_str = intent_dict['login']\n    result = session.read_transaction(run_query, query_str, name, \\\n                                 product, attribute, attribute_val)\n```", "```py\n#Sentences Intent and Entities Extraction\ninput_sentence = input('What do you like to do? ')\nif input_sentence == \"reset\":\n    reset = True \nentities = intent_entity_attribute_extraction(nlp, input_sentence, \\\n                         tokens_intent, tokens_products, tokens_attribute)\n#actually can build another intent classifier here based on the scores and words matched as features, as well as previous entities\nintent = entities[0]\nproduct = entities[1]\nattribute = entities[2]\nattribute_val = entities[3]\n```", "```py\nwhile intent == '':\n    input_sentence = input('What do you want to do?')\n    entities = intent_entity_attribute_extraction(nlp, input_sentence, \\\n                     tokens_intent, tokens_products, tokens_attribute)\n    intent = entities[0]\n\nwhile product == '':\n    input_sentence = input('What product do you want to check?')\n    entities = intent_entity_attribute_extraction(nlp, input_sentence, \\\n                     tokens_intent, tokens_products, tokens_attribute)\n    product = entities[1]\n\nwhile attribute == '':\n    input_sentence = input('What attribute of the ' + product + \\\n                        ' that you want to '+intent+'?')\n    entities = intent_entity_attribute_extraction(nlp, input_sentence, \\\n                      tokens_intent, tokens_products, tokens_attribute)\n    attribute = entities[2]\n```", "```py\n#execute the query to extract the answer\nquery_str = intent_dict[intent]\nresults = session.read_transaction(run_query, query_str, name, \\\n                                    product,attribute,attribute_val)\nif len(results) >0:\n    for result in results:\n        if result['TYPE'] == attribute:\n            print(attribute + ' of ' + product + ' is '+ \\\n                  str(result['VALUE']))\nelse:\n    print('no record')\n\n```", "```py\nloading nlp model\nHello, What is your name? testing\nHi testing\nFailed to find testing\nHello, What is your name? abc\nHi abc\nWhat do you like to do? do sth\nmatching...\n\nWhat do you want to do?check sth\nmatching...\ncheck \nWhat product do you want to check?some product\nmatching...\n\nWhat product do you want to check?deposit\nmatching...\n deposit \nWhat attribute of the deposit that you want to check?sth\nmatching...\n\nWhat attribute of the deposit that you want to check?pricing\nmatching...\n pricing\npricing of deposit is 1\n```"]