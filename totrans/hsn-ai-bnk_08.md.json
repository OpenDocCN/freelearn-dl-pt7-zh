["```py\n'''*************************************\n#1\\. Import libraries and key variable values\n'''\nimport quandl\nimport pandas as pd\nimport numpy as np\nfrom sklearn import linear_model\nfrom sklearn.metrics import r2_score\nimport sqlite3\nimport math\nimport os\n#not needed when using database\nimport pickle\n\n#API Key\n\n#dates variables for all the download\n\n#db file\n```", "```py\n'''*************************************\n#2\\. Define function to download data for each of the asset\n'''\n\n```", "```py\n'''*************************************\n#3\\. Market Return\n'''\n```", "```py\n'''*************************************\n#4\\. Risk Free Rate\n'''\n#day count\n\n#risk free rate\n\n# override return of market\n```", "```py\n'''*************************************\n#5\\. Asset Return and parameters\n'''\n#list of stocks for selection in the active portfolio\n\n#connect to the databases and reset it everytime with drop indicator\n\n#write out the risk free and market parameters\n\n#loop through the tickers\nfor tkr in list_tkr:\n #calculate the CAPM:\n #download data for the ticker\n\n#make sure the ticket we select has market data\n\n #linear regression\n\n#obtain the result and write out the parameters\n```", "```py\n'''*************************************\n#1\\. Import libraries and key variable values\n'''\nimport sqlite3\nimport datetime\n\n#create a table to store weight\n```", "```py\n'''*************************************\n#2\\. Find out the weight of the securities in the active portfolio\n'''\n#total alpha/variance of the active securities\n\n#insert into the table the weight of each active securities\n```", "```py\n'''*************************************\n#3\\. Find out the weight of the active portfolio in the total portfolio\n'''\n#calculate the parameters of the active portfolio\n\n#read back the risk free and market para\n\n#calculate the weight of active portfolio\n\n#display the result\n```", "```py\n'''*************************************\n#1\\. Import libraries and key variable values\n\n'''\nimport quandl\nimport plotly\nimport plotly.graph_objs as go\nimport numpy as np\n\nfrom datetime import datetime\ntry:\n    import Image\nexcept ImportError:\n    from PIL import Image\nimport os\nimport h5py\n\n#dates parameters\n...\n#quandl setting\n...\n#parameters for the image generation\n...\n#create path for the output dataset\n...\n#ticker lists\n...\n#generate png file for each of the input or now\n...\n#generate interactive plot to the ticket stock price or not\n...\n```", "```py\n'''*************************************\n#2\\. Define the function to rescale the stock price according to the min and max values\n\n'''\n#input_X is a series of price\n#output_X is a series of price expressed in pixel\ndef rescale(input_X, pixel, min_x,max_x):\n...\n```", "```py\n'''*************************************\n#3\\. Go through the tickers\n'''\nfor tkr in tkr_list:\n    ...\n    #if the ticker has been downloaded, skip the ticket and go for the next \n     one\n    ...\n    #download and create dataset\n    ...\n    #sort the date from ascending to descending...\n    ...    \n    #charting interactive chart for viewing the data\n    ...\n    #calculate mid price of the day\n    ...    \n    #remove the file if there is one\n    ...\n    #remove the file if there is one\n    ...\n    #create dataset within the HDF5 file\n    #now we create the dataset with a fixed size to fit all the data, it \n     could also be create to fit fixed batches    \n    ...\n\n    #loop through the dates\n    for i in range(num_img):\n        ...\n        #create min and max values for the mid price plot within a given \n         timeframe\n        ...\n        #in case of low liquidity ETF which has the same price, no graph be \n         drawn\n        ...\n        #draw the dot on the x, y axis of the input image array\n        ...\n        #output the image for visualization\n        ...        \n        #draw the dot on the target image for training\n        ...        \n        #stack up for a numpy for Image Recognition\n        ...\n```", "```py\n'''*************************************\n#1\\. Import libraries and key variable values\n'''\n'''*************************************\n#2\\. Define functions\n'''\ndef lr_schedule(epoch):\ndef resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\ndef resnet_v1(input_shape, depth, num_classes=10):\ndef resnet_v2(input_shape, depth, num_classes=10):\n\n```", "```py\n#3\\. Execute the model training\n'''\n# Computed depth from supplied model parameter n\n\n# Model name, depth and version\n\n# create list of batches to shuffle the data\n\n#check if the prev step is completed before starting\n\n#decide if we should load a model or not\n\n#loop through the tickers\n\n#load dataset saved in the previous preparation step\n\n#start if both file exists:\n\n#calculate number of batches\n #do it at the first one\n\n# Input image dimensions.\n        # Prepare model model saving directory.\n\n        # Prepare callbacks for model saving and for learning rate \n          adjustment\n\n        # loop over batches\n\n            # Run training, without data augmentation.\n\n        #when model training finished for the ticket, create a file to \n         indicate its completion\n\n# Score trained model.\n\n```", "```py\n'''*************************************\n#1\\. Import libraries and key variable values\n'''\n#folder path\n\n#date range for full dataset\n\n#Create list of dates\n\n#API key for quandl\n\n#Parameters for the image generation\n\n#model path\n\n#number of channel for the image\n\n#strategies parameter\n```", "```py\n'''*************************************\n#2\\. Define functions\n'''\n```", "```py\n'''*************************************\n#3\\. Running the test\n'''\n#Get the data\n\n#write header for the log of the strategy back-testing\n\n#loop through the dates\n #make sure both start and end dates are valid\n\n#prepare the input data\n\n#if no trend, then drop this data point\n\n#stack up for a numpy for Image Recognition\n #print the historical data\n\n#make prediction\n#Obtain predicted price\n```", "```py\n#calculate expected values\n\n#Strategy Back-Testing\n #Benchmark - Strategy 0 - buy and hold\n\n#Testing of strategy1\n\n#Testing of strategy2\n\n#print the final result of the strategies\n\n```"]