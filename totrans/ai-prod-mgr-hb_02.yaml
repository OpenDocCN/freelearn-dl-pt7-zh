- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model Development and Maintenance for AI Products
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will be exploring the nuances of model development, from
    linear regression to deep learning neural network models. We’ll cover the variety
    of models that are available to use, as well as what’s entailed for the maintenance
    of those models, from how they’re developed and trained to how they’re deployed
    and ultimately tested. This will be a basic overview to understand the end-to-end
    process of model maintenance that product managers can expect from the engineering
    and dev ops teams that support their products.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: 'There’s a lot involved with bringing any new product to market, and if you’ve
    been a product manager for a while, you’re likely familiar with the **new product
    development** (**NPD**) process – or set of steps. As a precursor to the rest
    of the chapter, particularly for those that are unfamiliar with the NPD process,
    we’re going to be summarizing each of the steps in the first section of this chapter.
    Overall, this chapter will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the stages of NPD
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model types – from linear regression to neural networks
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training – when is a model ready for market?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment – what happens after the workstation?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing and troubleshooting
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Refreshing – the ethics of how often we update our models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the stages of NPD
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will be covering the various stages of the NPD cycle as
    it relates to the emergence of an AI/ML product. Through each stage, we’ll cover
    the major foundational areas, from the ideation to the launch of an acceptable
    first version of a product. The steps are laid out incrementally from the discovery
    stage, in which you brainstorm about the need you’re looking to address in the
    market and why that need needs to be bolstered by AI. In the define stage, you
    bring in your product requirements for your product. In the design stage, you
    bring in the active visual and experiential elements of your end product. In the
    implementation stage, you build it out. In the marketing stage, you craft a message
    for your broader audience. In the training stage, you put your product to the
    test and make sure it’s being used as intended. Finally, in the launch stage,
    you release your product to a broader audience for feedback. Let’s get into these
    stages in more detail in the following sections.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Discovery
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this phase, you’re ideating. You look to isolate the particular problem you’re
    trying to solve, and in the context of a **machine learning** (**ML**) product,
    a crucial part of this first phase is understanding why you’re trying to solve
    that particular problem with ML in the first place. To borrow a phrase from Simon
    Sinek’s popular book *Find Your Why* ([https://simonsinek.com/books/find-your-why/](https://simonsinek.com/books/find-your-why/)),
    this is where you “find your why.” This is the phase in which you contemplate
    the fundamentals of the problem at hand and look to isolate what is most urgent
    about the problem so that you can later address an unmet need or under-served
    customers.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: This requires gathering qualitative and quantitative customer feedback about
    the particular issue they’re facing that you’re looking to address. The biggest
    focus here is creativity – to brainstorm potential solutions that you can then
    analyze and further explore (or discard) later.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Define
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second phase is all about defining your **minimal viable product** (**MVP**).
    You’ve taken all the feedback about the problem and potential solutions in the
    first step, but now you’re actually building a plan from those ideas. You have
    to start somewhere, right? So, this step is all about screening your ideas from
    the discovery stage to select the one that has the highest potential to solve
    your customers’ biggest problem. This is where all those creative brainstorming
    sessions are put to the test and analyzed to best understand which of the ideas
    from phase one have legs. What you’re looking for here is the minimum number of
    features you’d need to create a version of your product that will address the
    main problem areas – or assumptions of – for the customers you’re looking to serve.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: As far as your model goes, this is also where you define some metrics for model
    performance that will mark the minimum performance your model will need to reach
    in order to be a good, viable option for your customer. Remember, this is just
    for your MVP. The idea is that you first begin with your MVP and then you iterate
    through sprints or product development processes to incrementally make your product
    perform better or build in features your customers might prefer or need over time.
    Model performance will work the same way. As you partner with your customers,
    you will refine the product, the models, and the performance of those models together
    over time.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Design
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first and second steps of this process, you identify the problem you
    want to solve, come up with ideas, and then define the minimum amount of work
    you’ll need to take on the problem at hand. Now, in this third design step, you
    actually build out that MVP and start to piece together what it might look like.
    This is the step that’s most heavy on finding the solution. In this step, you’re
    coming up with mockups for how folks might interact with your product, what the
    UI might look like, and how the product experience might unfold. For AI products,
    this is also where you start to identify which of the models mentioned in the
    following section will best serve your product.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一过程中，第一步和第二步是识别您想解决的问题，提出想法，并定义解决该问题所需的最低工作量。现在，在第三步设计阶段，您实际构建出MVP，并开始拼凑它可能的样子。这一步骤最为注重解决方案的找寻。在这一阶段，您会为产品的用户交互设计制作原型，定义UI的外观，以及产品体验如何展开。对于AI产品，这也是您开始识别以下章节中提到的哪些模型最适合为您的产品服务的时刻。
- en: This step is all about creating a roadmap of the UI/UX elements. It’s where
    you will want to involve some of your customers in the solution and, for an AI
    product, where you’ll set some performance benchmarks and goals for your model
    to hit. Building performance into the design process and managing these expectations
    with eventual users of your product is a great way to crystalize the concept and
    test it early on.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段完全是关于创建UI/UX元素的路线图。在这一阶段，您需要邀请一些客户参与解决方案的设计，并且对于AI产品，您需要设定一些性能基准和目标，以确保您的模型能够达到这些要求。在设计过程中将性能因素融入其中，并与最终用户管理这些期望，是清晰化概念并及早进行测试的好方法。
- en: Step 4 – Implementation
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第4步 – 实施
- en: The implementation phase is where all the ideating and planning from the first
    three steps are put to the ultimate test. This is the phase in which you’re actually
    working to materialize everything you just worked hard on strategizing. For all
    intents and purposes, this is essentially your first sprint, and as a product
    manager, you’re effectively working as a project manager in this phase to make
    sure that what you end up with meets the needs you set out to address.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 实施阶段是对前三个步骤中所有构思和规划的最终考验。这是一个您将实际努力将所有策略付诸实践的阶段。实质上，这是您第一次冲刺，作为产品经理，您实际上扮演着项目经理的角色，确保最终成果能够满足您最初设定的需求。
- en: This is the doing part in which you actually bring in your engineers, ML engineers,
    developers, UI/UX folks, and project managers to create the MVP and achieve the
    performance your customers and the leadership are expecting. What you should be
    left with is a version of your MVP that does what you said it would do, as you
    said it would. You know you’ve succeeded with this step when your MVP meets the
    planning criteria.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这是执行部分，在这一阶段，您实际带入了工程师、机器学习工程师、开发人员、UI/UX人员和项目经理来创建最小可行产品（MVP），并实现客户和领导层所期望的性能。完成后，您应该得到一个能够按照您的承诺执行的MVP版本。只有当您的MVP符合规划标准时，您才知道这一阶段成功了。
- en: Step 5 – Marketing
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第五步 – 营销
- en: Marketing is happening in the background of all these steps because even part
    of *step 1* relates heavily to marketing. Understanding the language of your customer,
    their needs, and their pain points is a huge prerequisite for getting your messaging
    right. Marketing is the delivery and communication of your message to your wider
    market base, and the reason why it’s *step 5* is that you want to have a working
    MVP before you craft the official message that will go out for your current and
    prospective customers to see.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 营销始终在这些步骤的背后进行，因为即使*第一步*也与营销密切相关。了解客户的语言、需求和痛点是制定正确信息的关键前提。营销是将您的信息传递给更广泛市场的过程，之所以它是*第五步*，是因为您希望在传递针对现有和潜在客户的官方信息之前，先有一个可用的MVP。
- en: With AI products, marketing undergoes specific scrutiny because the AI market
    is heavily competitive and companies are in a communication quagmire. If you communicate
    too much about your product and which models make it worthy of the AI stamp, you’re
    giving away too much of the secret sauce. If you communicate too little about
    the actual tech that’s giving it AI/ML capabilities, you’re likely to face criticism
    that you’re overselling your solutions’ AI capabilities. We can say with a lot
    of confidence that most companies err on the side of under-communicating when
    it comes to AI products. This is the step in which you will need to agree with
    all your stakeholders on how you best want to communicate AI capabilities to the
    outside world.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Step 6 – Training
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The process of training users and documenting your product happens in this sixth
    phase so that you can create the justifications for the choices you’ve made for
    your MVP and your product overall. Part of training your users on your product
    is also managing expectations for how they are to interpret the performance of
    your product. This part will be especially important with AI/ML products because
    they often optimize, rank, classify, recommend, or predict future values, and
    it will be especially important to help your customers understand when they can
    trust or question certain results.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: This process is intuitive for the most part because when it comes to AI/ML,
    we don’t know how far off we are from the predictions or optimizations until a
    future point in time. Part of the training that must happen, then, is to manage
    expectations with your customers about what margins of error are healthy for them
    to expect. This step is all about informing others about your product and how
    to best interact with it.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: Step 7 – Launch
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this final step, we launch the product into the market officially. So far,
    you’ve spoken to your internal stakeholders and teams, received customer feedback,
    and maybe one or two customers have partnered with you to help create your offering
    and bring it to market. Maybe you’ve had a soft launch or gotten other beta testers/users
    to help you as well, but ultimately, the final step is your official hard launch.
    A big part of this final step is actually scaling back to your original definitions
    for performance and customer success. Is this final version of your product hitting
    the metrics you originally set with your customers? Is the performance of the
    product what everyone expected? Are you actively seeking to define future achievable
    goals?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered the process that’s commonly followed in NPD, we can move
    on to the models that are commonly employed in that development cycle. In the
    following section, we will review the most popular ML model types that are commonly
    used in production, as well as some of the characteristics those models share.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: Model types – from linear regression to neural networks
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the previous chapter, we looked at a few model types that you’ll likely
    encounter, use, and implement in various types of products for different purposes.
    To jog your memory, here’s a list of the ML models/algorithms you’ll likely use
    in production for various products:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们介绍了一些你可能会遇到、使用和实现的模型类型，这些模型广泛应用于各种产品的不同用途。为了帮助你回忆，这里列出了你在生产环境中可能会用于各种产品的ML模型/算法：
- en: '**Naive Bayes classifier**: This algorithm “*naively*” considers every feature
    in your dataset as its own independent variable, so it’s essentially trying to
    find associations probabilistically without holding any assumptions about the
    data. It’s one of the simpler algorithms out there and its simplicity is actually
    what makes it so successful with classification. It’s commonly used for binary
    values, such as trying to decipher whether something is spam or not.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**朴素贝叶斯分类器**：该算法“*天真地*”将数据集中的每个特征视为独立的变量，因此它本质上是在没有任何关于数据假设的情况下，以概率的方式寻找关联。它是众多算法中相对简单的一种，而正是这种简单性使得它在分类任务中如此成功。它通常用于二分类问题，例如判断某个内容是否为垃圾邮件。'
- en: '**Support Vector Machine** (**SVM**): This algorithm is also largely used for
    classification problems and will essentially try to split your dataset into two
    classes so that you can use it to group your data and try to predict where future
    data points will land along these major splits. If you don’t see compelling groups
    within the data, SVMs allow you to add more dimensions to be able to see groupings
    more easily.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持向量机** (**SVM**)：该算法也广泛用于分类问题，基本上会尝试将数据集分成两类，以便你可以用它来对数据进行分组，并预测未来数据点会如何在这些主要分隔线上分布。如果你在数据中没有看到明显的分组，SVM允许你添加更多维度，从而更容易地看到数据的分组。'
- en: '**Linear regression**: These models have been around since the 50s and they’re
    the simplest models we have for regression problems, such as predicting future
    data points. They essentially use one or more variables in your dataset to predict
    your dependent variable. The “linear” part of this model tries to find the best
    line to fit your data, and this line is what dictates how it makes predictions.
    Here, we once again see a relatively simple model heavily used because of how
    versatile and dependable it is.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**线性回归**：这些模型自50年代以来就已经存在，它们是解决回归问题的最简单模型之一，例如预测未来的数据点。它们基本上利用数据集中的一个或多个变量来预测因变量。该模型中的“线性”部分试图找到最适合数据的直线，而这条直线决定了模型如何进行预测。在这里，我们再次看到一个相对简单的模型，正因为它的多功能性和可靠性，它被广泛使用。'
- en: '**Logistic regression**: This model works a lot like linear regression in that
    you have independent and dependent variables, but it doesn’t predict a numerical
    value – it predicts a future binary categorical state, such as whether or not
    someone might default on a loan in the future, for instance.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**逻辑回归**：该模型与线性回归非常相似，都会使用自变量和因变量，但它并不预测数值，而是预测未来的二分类状态，例如预测某人未来是否会违约贷款。'
- en: '**Decision trees**: This algorithm works well for both categorical and numerical
    predictions, so it’s used for both kinds of ML problems, such as predicting a
    future state or a future price. Decision trees are used often for both kinds of
    problems, which has contributed to its popularity. Its comparison to a tree comes
    from the nodes and branches, which effectively function like a flow chart. The
    model learns from the flow of past data to predict future values.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**决策树**：该算法适用于分类和数值预测，因此它既能用于分类问题，也能用于数值预测问题，如预测未来的状态或价格。决策树常用于这两类问题，这也促成了它的流行。它之所以被称为“决策树”，是因为它的节点和分支类似于流程图。该模型从过去数据的流向中学习，从而预测未来的值。'
- en: '**Random forest**: This algorithm builds from the previous decision trees and
    is also used for both categorical and numerical problems. The way it works is
    it splits the data into different “random” samples, creates decision trees for
    each sample, and then takes an average or majority vote for its predictions (depending
    on whether you’re using it for categorical or numerical predictions). It’s hard
    to understand how random forest comes to conclusions, so if interpretability isn’t
    super high on the list of concerns, you can use it.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**随机森林**：该算法在之前的决策树基础上进行构建，也适用于分类和数值问题。其工作原理是将数据分割成不同的“随机”样本，为每个样本创建决策树，然后通过平均值或多数投票来做出预测（具体取决于你是用于分类预测还是数值预测）。由于随机森林的决策过程较难理解，因此如果可解释性不是你关注的重点，可以使用它。'
- en: '**K-Nearest Neighbors** (**KNNs**): This algorithm exclusively works on categorical
    and numerical predictions, so it looks for a future state and offers results in
    groups. The number of data points in the group is set by the engineer/data scientist
    and the way the model works is by grouping the data and determining characteristics
    that data shares with its neighbors and making the best guess for future values
    based on those neighbors.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**K-means clustering**: This algorithm will group data points to see patterns
    (or clusters) better, but it looks for an optimal number of clusters as well.
    This is unsupervised learning, so the model looks to find patterns that it can
    learn from because it’s not given any information (or supervision) to go off of
    from the engineer that’s using it. Also, the number of clusters assigned is a
    hyperparameter, and you will need to choose what number of clusters is optimal.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Principal component analysis** (**PCA**): Often, the largest problem with
    using unsupervised ML on very large datasets is there’s actually too much uncorrelated
    data to find meaningful patterns. This is why PCA is used so often, because it’s
    a great way to reduce dimensions without actually losing or discarding information.
    This is especially useful for massive datasets, such as finding patterns in genome
    sequencing or drug discovery trials.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Neural networks**: Deep learning models are lumped under the term neural
    networks for the most part because they all mimic the way the human brain processes
    information through layers of nodes and their edges. There are several neural
    network types with their own particulars, but for now, it suffices to say that
    neural networks are what make up the models used in what we call **deep learning**.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you see that a product is labeled as an AI/ML product, it likely uses some
    form or combination of these aforementioned models. We will be going over these
    models in later chapters of this book but for now, this is a good introduction
    to the model types you’ll most often come across where ML and AI are referenced.
    Now that we’ve introduced the models, let’s go into how those models are trained
    and made ready for use in production.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Training – when is a model ready for market?
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explore the standard process for gathering data to
    train a model and tune hyperparameters optimally to achieve a certain level of
    performance and optimization. In the implementation phase (*step 4* of the NPD
    process), we’re looking for a level of performance that would be considered optimal
    based on the define phase (*step 2* of the NPD process) before we move to the
    next phase of marketing and crafting our message for what success looks like when
    using our product. A lot has to happen in the implementation phase before we can
    do that.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: Data accessibility is the most important factor when it comes to AI/ML products.
    At first, you might have to start with third-party data, which you’ll have to
    purchase, or public data that’s freely available or easily scraped. This is why
    you’ll likely want or need to partner with a few potential customers. Partnering
    with customers you can trust to stick with you and help you build a product that
    can be successful with real-world data is crucial to ending up with a product
    that’s ready for market. The last thing you want is to create a product based
    on pristine third-party datasets or free ones that then becomes overfitted to
    real-world data and performs poorly with data coming from your real customers
    that it’s never seen before.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Having a wide variety of data is important here, so in addition to making sure
    it’s real-world data, you also need to make sure that your data is representative
    of many types of users. Unless your product caters to very specific user demographics,
    you’re going to want to have a model trained on data that’s as varied as possible
    for good model performance as well as good usability ethics. There will be more
    on that in the final section.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: Iterative hyperparameter tuning will also be hugely important as you continuously
    retrain your models for performance. The performance metrics and benchmarks in
    the define phase (*step 2* of the NPD) will inform how your ML engineers will
    go about tuning their hyperparameters. Most of the time, we don’t yet know what
    the optimal model architecture for a certain use case is. We want to explore how
    a model functions with various datasets and start somewhere so that we can see
    which hyperparameters give us superior performance.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: We always use the term hyperparameters when defining model optimizations because
    “parameters” refer to the boundaries within the training data that the model is
    using to make predictions. When it comes to adjustments to the model and how it
    functions, the term will always be **hyperparameter**.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Examples of what hyperparameters do include the degree of features that should
    be used in a linear model, the maximum depth that should be allowed for a decision
    tree model, how many trees should be included in a random forest model, or how
    many neurons or layers should be included for a neural network layer. In all these
    cases, we’re looking at the external settings of the model itself and all these
    settings are worthy of scrutiny based on the model performance they produce. Having
    competent AI/ML engineers that are comfortable with navigating these shifts in
    performance will be important in creating a product that’s set up for success.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: We want to go into some applied examples of models and their comparisons to
    give product managers out there who are unfamiliar with AI/ML performance benchmarks
    a sense of how you can go about evaluating whether one model is better than another.
    The following are a few examples of performance metrics that your ML engineers
    will look at as they evaluate whether or not they’re using optimal models. You’ll
    notice some of the names are familiar from our previous list of model types.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要介绍一些模型的应用示例及其比较，以便为那些不熟悉 AI/ML 性能基准的产品经理提供一些关于如何评估一个模型是否优于另一个模型的思路。以下是一些你的
    ML 工程师在评估是否使用最优模型时会关注的性能指标。你会注意到，其中一些名称在我们之前列出的模型类型中是熟悉的。
- en: 'These comparisons were done on a personal project, which was a model we had
    created to predict the price of Ether, a form of cryptocurrency. If you’d like
    to see the entire project outlined, you can do so here: [https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3](https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些比较是在一个个人项目中进行的，该项目是我们创建的一个模型，用于预测以太币的价格，这是一种加密货币。如果你想查看整个项目的概述，可以点击这里：[https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3](https://medium.com/analytics-vidhya/predicting-ether-prices-model-selection-for-machine-learning-8a50321f51a3)。
- en: The first model we wanted to use was an **Ordinary Least Squares** (**OLS**)
    regression model because this is the most straightforward of the linear regression
    models that we wanted to select to give us a good baseline before we approached
    other model types.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望使用的第一个模型是**普通最小二乘法**（**OLS**）回归模型，因为这是我们希望选择的线性回归模型中最简单的一种，能够为我们提供一个好的基准，之后再考虑其他模型类型。
- en: 'The results of the OLS regression model are as follows:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: OLS 回归模型的结果如下：
- en: '![Figure 2.1 – OLS regression model results](img/Image98224.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.1 – OLS 回归模型结果](img/Image98224.jpg)'
- en: Figure 2.1 – OLS regression model results
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – OLS 回归模型结果
- en: There are a number of metrics that are automatically generated when you train
    a model. Here is an example of what the full set looks like, but for the purpose
    of comparison, we will be focusing on the **R-squared of the model in the test
    set** line in *Figure 2**.1* to get the rate of error that’s comparable between
    models. The **R-squared** metric is also referred to as the “coefficient of determination”
    and the reason why we use this particular metric so often in regression models
    is that it best assesses how far the data lies from the fitted regression line
    that the regression model creates. With the preceding OLS regression model, we
    see an R-squared of **0.889** for the test set using an 80/20 split of the training
    data. We used 80% of the data for training and the remaining 20% of the data for
    testing.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 当你训练一个模型时，会自动生成一些指标。以下是完整指标集的一个示例，但为了比较的目的，我们将专注于*图 2.1*中的**测试集模型的 R 方值**这一行，以便得到不同模型之间可比较的误差率。**R
    方值**也被称为“决定系数”，我们在回归模型中常常使用这个指标，因为它最能评估数据点距离回归模型拟合的回归线的远近。对于前面的 OLS 回归模型，我们在使用
    80/20 数据划分的测试集上看到的 R 方值是**0.889**。我们使用了 80% 的数据用于训练，剩余的 20% 数据用于测试。
- en: The next model we tested was a random forest to compare results with a tree-based
    model. One of our hyperparameters for this random forest example was setting our
    cross-validation to `10` so that it would run through the training 10 times and
    produce an average of those 10 as a final score. That average was an R-squared
    of 0.963, higher than our OLS model!
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们测试的下一个模型是随机森林，用于与基于树的模型进行结果比较。我们为这个随机森林示例设置的超参数之一是将交叉验证设置为`10`，这样它就会运行 10
    次训练，并将这 10 次的平均值作为最终得分。这个平均值是 R 方值 0.963，高于我们的 OLS 模型！
- en: 'The results of the random forest model are as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林模型的结果如下：
- en: '![Figure 2.2 – Random forest model results](img/Image98234.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 2.2 – 随机森林模型结果](img/Image98234.jpg)'
- en: Figure 2.2 – Random forest model results
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – 随机森林模型结果
- en: 'Finally, the last comparison was with our KNN model, which produced a score
    of 0.994\. The hyperparameter we chose in this model was 6, which means we are
    looking for a group of 6 neighbors for each grouping. This KNN model gives us
    our best performance because we’re ideally looking for the closest we can get
    to a perfect score of 1\. However, we must keep this in mind with a caveat: although
    you are looking to get as close as you can to 1, the closer you get to 1, the
    more suspicious you should be of your model.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: 'The results of the KNN model are as follows:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.3 – KNN model results](img/Image98243.jpg)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 – KNN model results
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: Getting this high a score likely means that our model is not working well at
    all, or that it’s working especially well on the training data but won’t perform
    as well on new datasets. This phenomenon is called **overfitting** and it’s a
    big topic of conversation in data science and ML circles. The reason for it is
    that, fundamentally, all models are flawed and are not to be trusted until you’ve
    done your due diligence in selecting the best model. This game of choosing the
    right model, training it, and releasing it into the wild must be done under intense
    supervision. This is especially true if you’re charging for a product or service
    and attempting to win the confidence of customers that will be vouching on behalf
    of you and your products someday. If you’re an AI/ML product manager, you should
    look for good performance that gets better and better incrementally with time,
    and you should be highly suspicious of excellent model performance from the get-go.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Once you have comprehensive, representative data that you’re training your models
    on, and you’ve trained those models enough times and adjusted those models accordingly
    to get the performance you’re seeking (and promising to customers), you’re ready
    to move forward!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve gone over some of the major aspects of model maintenance, we
    can move on to what deployment looks like. Keep in mind that the entire process
    of ideating your product, choosing the right model to employ in your product,
    and gauging the performance of that model based on your training efforts is a
    collaborative effort. That collaboration doesn’t end when you’ve trained your
    models; it intensifies. This is because you’re now tasked with how exactly to
    integrate those models into the infrastructure of your product for your customers.
    Let’s get into that in the following section.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Deployment – what happens after the workstation?
  id: totrans-72
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012), we discussed deployment
    strategies that can be used as you manage your AI/ML products in production. In
    this section, we’d like you to understand the avenues available from a DevOps
    perspective, where you will ultimately use and deploy the models in production
    outside of the training workstation or training environment itself. Perhaps you’re
    using something such as GitLab to manage the branches of your code repository
    for various applications of AI/ML in your product and experimenting there. However,
    once you are ready to make changes or update your models after retraining, you’ll
    push the new models into production regularly. This means you need a pipeline
    that can support this kind of experimentation, retraining, and deployment regularly.
    This section will primarily focus on the considerations after we place a finished
    ML model into production (a live environment) where it will be accessed by end
    users.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'How you manage these future deployments will vary widely depending on whether
    your AI/ML product offering is **business-to-business** (**B2B**) or **business-to-consumer**
    (**B2C**). If you’re managing a B2C product, you’ll likely make changes in phases
    and you’ll likely use the deployment strategies outlined in [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012),
    to manage how your updated product is received and when certain groups of users
    will see the new updated models. This is just the nature of a B2C product: it’s
    one product going out to thousands, if not millions, of individual consumers,
    and your one product will mean many different things to individual users. If your
    product is a B2B product, then you manage expectations often at the customer level.
    One customer might have a different experience of your AI/ML product than another.
    The models you use could also very well change from one customer to another because
    the data you’re using to train your models will be different from one customer
    to another.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Another thing to keep in mind is how you’re going to handle discussions about
    your models and the collective training data you have among all your customers.
    With some products, you might not face much discussion about whether you use all
    your data to train your models. Some companies, however, are very particular about
    how their data is accessed and used. They might be okay with giving you historical
    data to train your model with as long as that data isn’t being used to help the
    performance of other customers in their peer group, for example.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, some customers might expect you to train your models on all
    the data you have to give your models the best shot at having as comprehensive
    a dataset as they possibly can. Remember that, as the strength of the models currently
    stands, the general rule is that the more data you have, the more examples you’re
    able to give your models. This means that the more examples you have, theoretically,
    the stronger performance you should have across the board. Managing expectations
    with your customers and their threshold for data sharing is an important part
    of the deployment cycle because it’s going to inform how often you update and
    how you deploy responsibly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: You’ll likely have different teams that manage different areas of the deployment
    process. Perhaps your data scientists create and develop the models and train
    them, another team validates that work and the training data as well, and a third
    team of engineers deploys the models into the production environment. You might
    also have a team of ML engineers that specialize in different areas of this entire
    process.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you are ready to deploy your models, you will need to have a team analyze
    the deployment environment for the following reasons:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: To choose the best way to access the model (most often through an API or some
    UI/platform that’s currently being used by your end user)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get a sense of how often it will be called
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To determine how many GPUs/CPUs and how much memory it will need to run
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To figure out how it will be continuously fed data
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll leave the solutioning up to your onsite experts, but this is an important
    point for the AI/ML product manager to keep in mind: the time/money/effort/resources
    that will be required to keep your AI/ML algorithms running for your product will
    be a huge consideration when you choose the models and strategize how you’ll deploy
    them in production.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The final part of deployment is training the end users on how to use the model
    and its results. Interpretability is important for any AI/ML project to succeed,
    but in the context of a product that’s used and relied upon by end users, whether
    they are B2B or B2C customers, you will need to account for how to communicate
    through potentially confusing moments. Training your customers through in-app
    prompts or your customer success teams will allow your end users to learn how
    to activate your AI/ML features, access the data they need from these features,
    and interpret the output it gives them in a way that continuously reinforces your
    product’s value – this is all part of managing your deployment.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: Testing and troubleshooting
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012), we discussed the idea of
    continuous maintenance, which included continuous integration, continuous delivery,
    continuous training, and continuous monitoring. This section will build on that
    and expand on how to test and troubleshoot issues related to ML products on an
    ongoing basis so that your product is set up for success. Once you’ve made your
    first deployment, we jump right into the continuous training and continuous maintenance
    portion of the continuous maintenance process we discussed in [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Remember, managing the performance of your models post-deployment is crucial
    and it will be a highly iterative, never-ending process of model maintenance.
    As is the case with traditional software development, you will continue to test,
    troubleshoot, and fix bugs for your AI/ML products as well. The only difference
    is that you will also screen for lags in performance and bugs related to your
    model.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: Continuously monitoring your model makes sure that it’s always working properly
    and that the outputs it generates are effective. The last thing you want is for
    your product to be spewing out wildly inaccurate recommendations or predictions.
    Imagine that your model operated incorrectly and it took your customer weeks or
    months to notice that this had serious negative consequences downstream. They
    would question your integrity as a company because they trusted you to maintain
    and keep up the platform that they rely on for their own workflows. As a result,
    they might cancel their contract with you, pull their data out of your database,
    or give you negative reviews and negative referrals to other prospective customers.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: Even when all the aspects of your model work properly, you will still need to
    track the continuous performance of your model and its outputs. The metrics for
    success we looked at in the training section previously are the same metrics you’ll
    create a log of that you routinely monitor to make sure model performance isn’t
    lagging. In addition to statistical performance metrics such as the F-score or
    R-squared, you’ll also want to keep track of your accuracy, recall, and precision
    rates. This entire process of monitoring your model’s performance should be automated
    so that you’re alerted when certain metrics go over a certain threshold, in the
    form of a flag of some sort so that you’re not always having to manually check.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: We don’t just monitor the models themselves but we also continuously maintain
    the supporting code and documentation as well. This is notoriously a last priority
    for most companies that ultimately rely on the historical knowledge of the few
    developers that have been there the longest. Get it all documented and make it
    a practice of doing so regularly. You might find that there isn’t enough training
    material or that the resources that currently exist just aren’t adequate to explain
    what the product does. You might also find that the data feed that your model
    uses for training has issues with updates or wasn’t properly connected in the
    first place. Perhaps it’s an issue on your end users’ side and they might not
    be accessing the AI/ML features of your product properly. Any number of these
    issues can happen routinely, which is why having teams devoted to the successful
    execution of your AI/ML product is crucial to its success.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: Every model is going to have some form of degradation or drift over time. For
    example, if new data comes in that the model is training on that’s not been cleaned
    in the same way that the training data was, your model’s performance is going
    to suffer from a lack of uniformity in the data. Data hygiene is generally an
    important consideration when evaluating performance because it can wreak havoc
    and these kinds of changes might be hard to pinpoint.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Over months and years, if you see changes to how data is being reported and
    formatted, or if there are new fields or categories of data being added that weren’t
    present when the models were first being trained, you’re going to see the variance
    in your results. Data also can morph over time if your market changes or if the
    demographics of your users change. If major events impact the entirety of your
    dataset, this will adversely impact your model results because the baseline you
    built as your foundation will have been rendered unreliable because the majority
    of the training data might not apply to the new or current situation.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Outside of the training data, there is one last important area of drift, and
    that’s what’s often referred to as concept drift – or changes in your customer’s
    expectations of what a correct prediction might be. For example, in some contexts,
    such as optimizing for a spam filter, you might find that certain new tactics
    mean that model outputs need to be reimagined to keep up with new trends in how
    spam emails evade the filter settings that originally worked well. Change is the
    only constant and the outside world is large and full of unpredictability. Any
    changes coming from outside factors could contribute to various types of concept
    drift, requiring us to go back to the drawing board and tweak our models and redeploy
    them to address a changing world.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Continuous monitoring and testing are a big reason why many companies will use
    an enterprise data science platform to keep track of their deployments. We highly
    recommend this if you have the budget for it because if you’re working with many
    customers, as well as internal and external applications of your AI/ML models,
    you’ll likely have many “reuse” use cases for your models. You’ll benefit from
    the project tracking these platforms offer if you’re managing at scale.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered some of the most important considerations when testing
    and troubleshooting the use of your models in production, and the importance of
    regular monitoring for maintaining a level of oversight, not only to keep on top
    of the technical performance and robustness of your models but also to remain
    ethical. In the following section, we will focus more on the ethical considerations
    when building products with AI/ML components to build responsibly and harness
    some industry best practices.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Refreshing – the ethics of how often we update our models
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When we think about the amazing power we have as humans, the complex brain operations
    we employ for things such as weighing up different choices or deciding whether
    or not we can trust someone, we may find it hard or impossible to believe that
    we could ever use machines to do even a fraction of what our minds can do. Most
    of us make choices, selections, and judgments without fully understanding the
    mechanism that powers those experiences. However, when it comes to ML, with the
    exception of neural networks, we can understand the underlying mechanisms that
    power certain determinations and classifications. We love the idea that ML can
    mirror our own ability to come to conclusions and that we can employ our critical
    thinking skills to make sure that process is as free from bias as possible.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: The power of AI/ML allows us to automate repetitive, boring, uninspiring actions.
    We’d rather have content moderators, for instance, be replaced with algorithms
    so that humans don’t have to suffer through flagging disturbing content on the
    internet on a daily basis. However, ML models, for all their wonderful abilities,
    aren’t able to reason the way we can. Automated structures that are biased or
    that degrade over time have the power to cause a lot of harm when they’re deployed
    in a way that directly impacts humans and when that deployment isn’t closely and
    regularly monitored for performance. The harm that can cause at scale, across
    all live deployments of AI/ML, is what keeps ethicists and futurists up at night.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Part of the danger with AI/ML is in the automation process itself. The types
    of drift we went over in the prior section impact how models derive meaning from
    the training data they learn from. Even when performance and maintenance appear
    normal, that doesn’t mean that the models aren’t taking liberties, resulting in
    real-world harm for the end user or for human beings that could be impacted downstream
    from the end user, whether or not they actually interact with the models themselves.
    A common example of this is the pervasive and unnecessary use of facial recognition
    software.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'In February 2022, President Biden signed two pieces of legislation into law
    that expanded on AI accountability in the US: Artificial Intelligence for the
    Military Act of 2021 and the AICT Act of 2021\. Will Griffin from *Fortune* magazine
    writes “*While this legislation falls far short of the calls for regulation consistent
    with the European Union model and desired by many in the A.I. ethics community,
    it plants the seeds of a thoughtful and inevitable A.I. ethics regulatory regime*.”
    It’s important to remember that AI ethics and regulations vary depending on where
    you live. In the US, we still lag behind European standards both in terms of legislation
    that’s put in place to rein in AI misconduct and in terms of how we enforce existing
    laws.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'AI is still considered a wild west legislatively speaking, and we will likely
    see strides being made toward further defining the scope for how AI can interact
    with us as we see more and more use cases for AI products expand during this decade.
    Recently, the US made strides toward publishing a blueprint for an AI Bill of
    Rights that covers the following areas:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Safe and effective systems
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Algorithmic discrimination protections
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data privacy notices and explanation
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human alternatives, consideration, and fallback
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For now, we will use the European standards for framing how AI/ML product managers
    should think about their products because, even without deliberate laws that enforce
    AI ethics, entrepreneurs and technologists still face risks, such as losing customers,
    receiving bad press, or being taken to court, as a result of their algorithmic
    choices.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'The European Commission outlines the following four key areas as ethical principles:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '**Respect for human autonomy**: “*AI systems should not unjustifiably subordinate,
    coerce, deceive, manipulate, condition or herd humans. Instead, they should be
    designed to augment, complement and empower human cognitive, social and cultural
    skills. The allocation of functions between humans and AI systems should follow
    human-centric design principles and leave meaningful opportunity for* *human choice.*”'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prevention of harm**: “*AI systems should neither cause nor exacerbate harm
    or otherwise adversely affect human beings. This entails the protection of human
    dignity as well as mental and* *physical integrity*.”'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fairness**: “*While we acknowledge that there are many different interpretations
    of fairness, we believe that fairness has both a substantive and a procedural
    dimension. The substantive dimension implies a commitment to: ensuring equal and
    just distribution of both benefits and costs, and ensuring that individuals and
    groups are free from unfair bias, discrimination* *and stigmatisation.*”'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Explicability**: “*This means that processes need to be transparent, the
    capabilities and purpose of AI systems openly communicated, and decisions – to
    the extent possible – explainable to those directly and indirectly affected. Without
    such information, a decision cannot be duly contested. An explanation as to why
    a model has generated a particular output or decision (and what combination of
    input factors contributed to that) is not always possible. These cases are referred
    to as ‘black box’ algorithms and require* *special attention.*”'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Citation
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Bruschi, D., Diomede, N. *A framework for assessing AI ethics with applications
    to cybersecurity*. *AI Ethics* (2022). [https://doi.org/10.1007/s43681-022-00162-8](https://doi.org/10.1007/s43681-022-00162-8
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: )
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Many companies might be tempted to create an AI ethics role within their companies
    and make it that person’s problem or scapegoat if and when they fail to meet certain
    standards, but this is a lazy and unethical way of managing the ethics around
    your AI programs if that’s all you choose to do. A better way would be to train
    and empower all of the resources that are involved in building your AI/ML products
    to be aware of the surrounding ethics and potential harm that could be caused
    to the customers or third parties interacting with your product.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: While we must recognize the importance of understanding that recurring model
    updates are vital to maintaining good ethics with regard to ML and AI, as we’ve
    discussed previously in this chapter, it’s also important to look into how your
    product can affect groups of people downstream who don’t even use your product.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: We don’t exist in a vacuum. As we saw in the previous sections of this chapter,
    many factors at play already work against algorithms used in AI/ML products, which
    you have to keep track of even to stay on top of the natural chaos created by
    the constant input and output of data. This natural tendency that models have
    toward various types of drift is what demands a focus on ethics. According to
    a recent episode from TechTarget’s *Today I Learned* podcast, FICO, the credit
    reporting and analytics vendor, conducted a survey of AI users and it showed that
    67% of respondents do not monitor their models for accuracy or drift, which is
    pretty mind-blowing. These were AI users who were directly responsible for building
    and maintaining AI systems, which shows that the problems that come with unethical
    AI/data practices are a norm.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: Ethical AI practices should be applied throughout every step we’ve outlined
    in this in-depth chapter on model maintenance. If we build AI/ML products that
    we are sure don’t cause harm, both directly as part of our products’ integrity
    and indirectly as part of our products’ model maintenance, we can confidently
    market and promote our products without fear of retribution or punishment from
    the market that we want to serve. Every entrepreneur and technologist will have
    their own relationship with ethical business practices but, eventually, if you
    are a champion, promoter, or leader of a product that has come to market that
    harms others, you will be asked to explain what measures were put in place to
    inform your customers of the potential risks.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered the NPD cycle and a review of the common AI/ML model
    types. We also covered an overview of how to train, deploy, and troubleshoot the
    models that are chosen, giving us a reasonable foundation on what to expect when
    working with models in production. We also touched on some of the most important
    ethical practices, coming from some of the most rigorous standards that exist,
    when building products with AI/ML components.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: If you’re interested in expanding further on building ethical AI, we’ve provided
    some handy links in the following section for additional study. Keep in mind that
    we’re at a critical juncture with regard to AI/ML ethics. We’re building this
    ship as we’re sailing it, and as AI/ML products continue to enter the zeitgeist,
    we will see additional measures put in place to reign in the potential harm caused
    by improper AI deployments through the diligent work of lawmakers and activists.
    We’re not there yet, but with each new development, we get closer and closer to
    building a world that doesn’t just embrace the promise of AI but limits the issues
    that AI poses as well.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve had a chance to introduce some of the main concepts we’ll discuss
    throughout the book in [*Chapter 1*](B18935_01.xhtml#_idTextAnchor012). We’ve
    also gotten further into the requirements of maintaining ML models and familiarizing
    ourselves with the process of building products with AI/ML components in this
    chapter. These first two chapters are meant to serve as an introductory foundation
    so that we can get deeper into the concepts we’ve brought up so far in subsequent
    chapters. In [*Chapter 3*](B18935_03.xhtml#_idTextAnchor101), we’ll focus on splitting
    deep learning from the broader umbrella term of ML, and discuss some of the differences
    between traditional ML algorithms and deep learning neural networks.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: Additional resources
  id: totrans-123
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reading about and familiarizing ourselves with AI ethics is important for everyone
    because AI is becoming increasingly impossible to avoid in our day-to-day lives.
    Additionally, if you actively work in the field of AI/ML as a data scientist,
    developer, engineer, product manager, or leader, it’s doubly important that you’re
    aware of the potential risks AI poses and how to build AI responsibly.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 'For further reading on ethical AI principles, we recommend the following reputable
    publications:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '*Blueprint for An AI Bill of* *Rights*: [https://www.whitehouse.gov/ostp/ai-bill-of-rights/](https://www.whitehouse.gov/ostp/ai-bill-of-rights/'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'DoD Joint Artificial Intelligence Center Ethical Principles for AI: [https://www.defense.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/](https://www.defense.gov/News/Releases/Release/Article/2091996/dod-adopts-ethical-principles-for-artificial-intelligence/'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: 'National AI Initiative Office on *Advancing Trustworthy* *AI*: [https://www.ai.gov/strategic-pillars/advancing-trustworthy-ai/](https://www.ai.gov/strategic-pillars/advancing-trustworthy-ai/'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithmic Justice League: [https://www.ajl.org/library/research](https://www.ajl.org/library/research'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'AItruth.org 12 Tenets of Trust: [https://www.aitruth.org/aitrustpledge](https://www.aitruth.org/aitrustpledge'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Intel.gov’s *Principles of AI ethics for the intelligence* *community*: [https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community](https://www.intelligence.gov/principles-of-artificial-intelligence-ethics-for-the-intelligence-community'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'European Commission’s *Ethics Guidelines for Trustworthy* *AI*: [https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html](https://ec.europa.eu/futurium/en/ai-alliance-consultation.1.html'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Ethics Guidelines for Trustworthy AI: [https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf](https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: 'UNESCO Recommendations on AI Ethics: [https://en.unesco.org/artificial-intelligence/ethics](https://en.unesco.org/artificial-intelligence/ethics'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '“*Today I Learned*” podcast on ethical AI, with insights from Scott Zoldi,
    the chief analytics officer at FICO: [https://www.techtarget.com/searchcio/podcast/How-machine-learning-model-management-plays-into-AI-ethics](https://www.techtarget.com/searchcio/podcast/How-machine-learning-model-management-plays-into-AI-ethics'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Find Your Why*, Simon Sinek: [https://simonsinek.com/books/find-your-why/](https://simonsinek.com/books/find-your-why/'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'High-Level Expert Group on Artificial Intelligence Set Up By The European Commision:
    [https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf](https://www.aepd.es/sites/default/files/2019-12/ai-ethics-guidelines.pdf)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Framing TRUST in Artificial Intelligence (AI) Ethics Communication: Analysis
    of AI Ethics Guiding Principles through the Lens of Framing Theory: [https://www.proquest.com/docview/2721197134](https://www.proquest.com/docview/2721197134)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'America must win the race for A.I. ethics: [https://fortune.com/2022/02/15/america-must-win-the-race-for-a-i-ethics-tech-artificial-intelligence-politics-biden-dod-will-griffin/](https://fortune.com/2022/02/15/america-must-win-the-race-for-a-i-ethics-tech-artificial-intelligence-politics-biden-dod-will-griffin/)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'S.1776 - Artificial Intelligence for the Military Act of 2021: [https://www.congress.gov/bill/117th-congress/senate-bill/1776/text?q=%7B%22search%22%3A%5B%22s1776%22%5D%7D&r=1&s=1](https://www.congress.gov/bill/117th-congress/senate-bill/1776/text?q=%7B%22search%22%3A%5B%22s1776%22%5D%7D&r=1&s=1)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'S.1705 - AICT Act of 2021: [https://www.congress.gov/bill/117th-congress/senate-bill/1705/text?r=82&s=1](https://www.congress.gov/bill/117th-congress/senate-bill/1705/text?r=82&s=1)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
