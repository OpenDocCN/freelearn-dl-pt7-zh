<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">MAB for Financial Engineering</h1>
                </header>
            
            <article>
                
<p class="mce-root">Today, <strong>machine learning</strong> (<strong>ML</strong>) has taken on a fundamental role in many environments of the financial ecosystem: from the approval of loans and the management of activities, to the assessment of risks. <strong>Artificial intelligence</strong> (<strong>AI</strong>) systems have great importance in the management of equity portfolios and in the creation of algorithms for trading. Again, AI is increasingly important for fraud detection, and the search for and identification of fraudulent practices. Algorithms that are capable of learning and calibrating how they act to new threats are overcoming the limits of traditional processes that are based on rigid checklists. In this chapter, we will address some of the financial engineering problems with <strong>reinforcement learning</strong> (<strong>RL</strong>) to learn about optimization and anomaly identification techniques. </p>
<p class="mce-root"><span>By the end of this chapter, we will have learned about the fundamental concepts of finance problems and how to model credit risk using Markov chains. We will also understand how to build a pricing optimization system to find the best price to launch a new product. Finally, we will learn how to optimize equity portfolios.</span></p>
<p class="mce-root">In this chapter, we will cover the following topics:</p>
<ul>
<li>Finance problem essentials</li>
<li>Modeling credit risks as Markov chains</li>
<li>Pricing optimization system</li>
<li>Optimizing equity portfolios</li>
<li>Fraud detection techniques</li>
</ul>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>Check out the following video to see the Code in Action:<br/>
<a href="http://bit.ly/34ee91x">http://bit.ly/34ee91x</a></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Finance problem essentials</h1>
                </header>
            
            <article>
                
<p>Technological innovation and the financial sphere have been proceeding hand in hand for several years, further accelerating with the entry<span> </span><span>of machine learning</span><span> into the field. The high volumes of data, the possibility of accessing accurate historical documentation, and the quantitative nature of the financial sphere makes it one of the most suitable industries </span>in which to integrate automatic learning. <span>In this way, the operators of the sector are freed from a series of necessary activities that are of little creative value.</span></p>
<p>Machine learning allows machines to make autonomous decisions: instead of a series of instructions for carrying out an activity, instructions are provided on how to learn to perform these activities independently. This capacity for self-learning, combined with the analysis of big data and special algorithms, has taken on a fundamental role in various financial operations, from risk assessment to loan approval.</p>
<p>Through machine learning, a financial company can innovate its work activities and increase efficiency, output, and, <span>ultimately,</span><span> </span><span>profitability. Understanding the technological evolution that's undertaken by these companies reveals numerous opportunities, but also the need to recognize change and welcome and manage it.</span></p>
<p>In the complex set of financial activities, it is difficult to hypothesize an area in which machine learning cannot intervene to speed up, simplify, and streamline procedures, and it is no coincidence that it is precisely in this context that there is a profound reflection on the role that human employees will have in the near future. But there is no need to worry: from the perspective of continuous growth, financial organizations will limit themselves to directing their staff toward high value-added activities, where artificial agents will be important consultants but cannot have a decision-making role.</p>
<p>Finance has always been rich in terms of numbers, but in recent decades, it has grown in complexity. The digital revolution first and then that of communications has made the availability of data of all kinds grow exponentially. Interactions on social networks, queries on search engines, banking transactions, and e-commerce activities add to the immense catalog of digitized information that can be automatically analyzed.</p>
<p>A new demand for data management services is born from recommendation systems for the contents of e-commerce sites because of the need to know and to stabilize increasingly complex credit systems. For finance, the pressure of competition in almost perfect markets leads to continuous improvement. We are witnessing a constant tension between agents trying to break the equilibrium, aspiring to new forms of profit, and agents pushing toward equilibrium points to realize small, systematic profits.</p>
<p>In the financial sphere, there are many fields in which artificial agents can be useful to simplify activities, <span>as shown in the following diagram</span>:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-568 image-border" src="assets/de1defae-4c6e-412c-9a6c-775c81885ecb.png" style="width:18.75em;height:17.83em;"/></p>
<p>In the upcoming sections, we will analyze the most widespread activities that use algorithms based on machine learning.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Financial trading</h1>
                </header>
            
            <article>
                
<p>Financial trading is a high-yield speculative investment activity that involves the financial market. The financial market is defined as a place where financial assets are traded. Trading on financial markets is based on a set of factors: technical analysis, micro and macroeconomic fundamentals, news, and market sentiment. When we talk about high-frequency trading, where the positions are maintained even for fractions of a second, the management that's done by advanced algorithms is fundamental. The introduction of machine learning is responsible for a strong refinement of techniques and can be used for strategic processing based on various indicators, to identify arbitration opportunities and evaluate performance, learn the critical issues, and apply an improved model to the upcoming trading opportunities.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Credit scoring</h1>
                </header>
            
            <article>
                
<p>The credit assessment process is a pillar of the business of commercial banks and has been refined over the years with new methodologies and access to ever larger datasets. Within this activity, which is often referred to as <strong>credit scoring</strong>, machine learning can make the difference and it is no coincidence that many institutions are already active on the front. Here too, machine learning is given a role in extending the procedures in place: in addition to all of the consolidated parameters, which continue to be the basis of credit scoring, machine learning can complete the evaluation process by examining extremely heterogeneous data such as behavior on social networks.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Financial chatbot</h1>
                </header>
            
            <article>
                
<p>Among the first ever uses of machine learning in the banking sector, is virtual assistance. Speaking of cost reduction, entrusting a large part of customer care activities to a bot supported by machine learning is extremely efficient. Also, this rule is applied according to which routine requests (counterclaim, transfer, and withdrawal) are both the most common and the most easily assigned to software. It is no coincidence that the Bank of America introduced its Erica bot in 2016 to simplify the management of personal finance to its tens of millions of customers.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Robo-advisor</h1>
                </header>
            
            <article>
                
<p>An example of a virtual assistant is the robo-advisor, who compared to the simple automation of routine operations, belongs to the world of financial consulting. Through the robo-advisor, it is possible to receive personalized asset management advice based on our objectives and, possibly, to buy or sell financial products. The same robo-advisor can then follow the investment trend by offering the client periodic reports and proposing any corrective measures.</p>
<p>In the next section, we will use Markov chains to model a company's credit risk.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modeling credit risks as Markov chains</h1>
                </header>
            
            <article>
                
<p>A financial company is exposed to different types of risk, which are generally divided into three main groups: market risk, credit risk, and operational risk. In the international financial landscape of recent years, credit scoring has acquired a crucial role in what is defined as the <strong>credit risk analysis</strong> process. The goal of <strong>credit scoring</strong> models is to be able to correctly classify who applies for access to a credit channel to reduce the risk related to the possible insolvency of the applicant. Following the global crisis that broke out in the United States due to the delinquencies on sub-prime mortgages, financial and credit institutions have had to face major losses over the last decade, followed by a long period of recession. All of this inevitably brought the entire credit risk analysis process under the magnifying glass, with emphasis on credit scoring techniques.</p>
<p>Credit scoring has undergone significant growth in recent decades. Before these developments, loans were granted following mostly subjective assessments, based on the personal relationships that were created between the applicant and the credit institution's credit analyst. In most cases, the latter was represented precisely by the bank to which funding was requested. However, the ever-growing requests for financing and the multitude of financial products available have made it necessary to adapt the credit management system. Increasingly, we have tried to apply automatic and objective techniques that allow the analysis of the potential customer in a faster and more efficient way. The output of these techniques involves the adoption of a <strong>score</strong> that can reliably classify the customer's creditworthiness.</p>
<p>A correct assessment of credit risk is essential to be able to achieve successful management in all of the activities of a bank. The need to increase the accuracy of risk assessment by financial intermediaries has led to the development, updating, and discovery of new models and techniques for calculating the probability of default and expected recovery rates. A precise analysis on the evolution of the creditworthiness of the debtor, and a correct estimate of the parameters that influence the credit risk, are also indispensable to solve the problems related to the pricing of loans and bonds. Among the various models and tried-and-tested approaches, there are the more modern ones that exploit the new technological capabilities of data storage, analysis, and training to statistical theory in order to identify credit risk components more accurately.</p>
<p>In the next section, we will deal with modeling credit scoring using some packages already available in R.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The CreditMetrics package</h1>
                </header>
            
            <article>
                
<p>To address credit scoring techniques, we will use the <kbd>CreditMetrics</kbd> package that's available on CRAN. This package contains a set of functions for computing the <kbd>CreditMetrics</kbd> risk model.</p>
<p>The following table gives some information about this package:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Package</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><kbd>CreditMetrics</kbd></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Date</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">2015-02-19</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Version</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">0.0-2</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Title</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Functions for calculating the <kbd>CreditMetrics</kbd> risk model</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Author</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Andreas Wittmann</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The <kbd>CreditMetrics</kbd> model was proposed for the first time by J.P. Morgan as a tool for calculating the <strong>Value At Risk</strong> (<strong>VAR</strong>) related to credit exposures. This model is one of the most widespread credit risk management systems. It aims to define a composition of the loan portfolio so that it's consistent with the expected risk-return combination desired by the intermediary, and therefore with a more efficient allocation of capital. The credit risk value, in particular, varies with the quality associated with the receivables present in the portfolio, generating movements of the single credits (migrations) among the three main classes identified (the financial distress, the upgrading or improvement of the credit rating, and the downgrading or deterioration of the quality associated with the individual loan). The credit risk differs substantially from the market risk (<kbd>riskmetrics</kbd>) because, for the latter, it is possible to assume a normal probability distribution that is symmetrical with respect to its average value, while what's relative to portfolios that are exposed to the risk of credit is positively asymmetric. In the next section, we will discuss a practical case of credit risk modeling using the <kbd>CreditMetrics</kbd> package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The CreditMetrics risk model</h1>
                </header>
            
            <article>
                
<p>Credit risk is the risk that an unexpected event, related to the repayment capacity or creditworthiness of a counterparty, will change the value of the credit position.</p>
<p>In assessing credit risk, we can distinguish between the default mode approach, which only considers the occurrence of insolvency, and a multi-state approach, in which even the deterioration of the counterpart's creditworthiness represents a source of credit risk.</p>
<p class="mce-root"/>
<p>The first approach envisages two possible states for a credit position: default or non-default. The occurrence of the default event is determined exclusively by the default probability of the associated binary variable. The multi-state approach considers the migration risk, which is the risk that the value of a position will change due to a deterioration in the creditworthiness of the counterparty. The default status represents one of the possible states and the migration in this state coincides with the insolvency event.</p>
<p>The fundamental tool on which the multi-state approach is based is the transition matrix, which can be estimated based on historical observations and is provided by rating agencies.</p>
<p>We will begin our analysis by defining the migration matrix, which, as we anticipated, is provided by rating agencies:</p>
<ol>
<li>To start, we will import the <kbd>CreditMetrics</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">library(CreditMetrics)</pre>
<ol start="2">
<li>Now, let's reproduce the experiment:</li>
</ol>
<pre style="padding-left: 60px">set.seed(1)</pre>
<p style="padding-left: 60px">This command sets the seed of R's random number generator. You must use this function every time you want to get a reproducible random result. When we use this command, the random numbers that are generated will always be the same, so with each execution of the code, the results that are obtained will always be the same. Each seed value will correspond to a sequence of values that are generated for a given random number generator.</p>
<p style="padding-left: 60px">Now, let's define the migration matrix, which represents the transition matrix of a Markov process. Rating agencies, such as <kbd>Standard% Poor</kbd>, provide transition matrices based on historical data related to over 20 years of observations on companies in different sectors.</p>
<p style="padding-left: 60px">There are seven rating categories, from the highest AAA class to the lowest CCC class. The last state is the default, which is characterized by being an absorbent state in which the probability of exit is null.</p>
<ol start="3">
<li>Then, we define the rating classes:</li>
</ol>
<pre style="padding-left: 60px">RatingClasses &lt;- c("AAA", "AA", "A", "BBB", "BB", "B", "CCC", "D")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="4">
<li>After doing this, we define the transition matrix:</li>
</ol>
<pre style="padding-left: 60px">TransitionMatrix &lt;- matrix(c(90.710, 8.340, 0.710, 0.075, 0.095, 0.025, 0.022, 0.023,<br/>            0.710, 90.550, 7.810, 0.720, 0.060, 0.120, 0.020, 0.010,<br/>             0.092, 2.220, 91.250, 5.420, 0.720, 0.230, 0.011, 0.057,<br/>             0.020, 0.420, 5.890, 85.880, 5.290, 1.190, 1.140, 0.170,<br/>             0.036, 0.124, 0.670, 7.730, 80.590, 8.790, 1.010, 1.050,<br/>             0.011, 0.119, 0.230, 0.440, 6.510, 83.440, 4.060, 5.190,<br/>             0.220, 0.000, 0.230, 1.330, 2.360, 11.210, 64.830, 19.820,<br/>              0, 0, 0, 0, 0, 0, 0, 100<br/>              )/100, 8, 8, dimnames = list(RatingClasses, RatingClasses), byrow = TRUE)</pre>
<p style="padding-left: 60px">The following matrix is printed:</p>
<pre style="padding-left: 60px"><strong>       AAA     AA      A    BBB     BB      B    CCC      D</strong><br/><strong>AAA 0.90710 0.08340 0.0071 0.00075 0.00095 0.00025 0.00022 0.00023</strong><br/><strong>AA 0.00710 0.90550 0.0781 0.00720 0.00060 0.00120 0.00020 0.00010</strong><br/><strong>A 0.00092 0.02220 0.9125 0.05420 0.00720 0.00230 0.00011 0.00057</strong><br/><strong>BBB 0.00020 0.00420 0.0589 0.85880 0.05290 0.01190 0.01140 0.00170</strong><br/><strong>BB 0.00036 0.00124 0.0067 0.07730 0.80590 0.08790 0.01010 0.01050</strong><br/><strong>B 0.00011 0.00119 0.0023 0.00440 0.06510 0.83440 0.04060 0.05190</strong><br/><strong>CCC 0.00220 0.00000 0.0023 0.01330 0.02360 0.11210 0.64830 0.19820</strong><br/><strong>D 0.00000 0.00000 0.0000 0.00000 0.00000 0.00000 0.00000 1.00000</strong></pre>
<p>In this table, the ratings in the first column are the starting or current ratings. The ratings in the first row are the ratings at the risk horizon. Furthermore, each row of the matrix sums to 100%. The meaning of the transition matrix is now clear. This is a square matrix containing the probabilities of the transition matrix. For example, there is an 8.33% chance that an AAA rated credit will downgrade to an AA rating within one year. In this way, we can recover the credit rating that's going to be the most likely to occur in any year as the current one. As a rule, the transition matrix should be calculated for the same time interval as the risk horizon over which we are estimating the risk. In our case, we are satisfied with the values provided:</p>
<ol>
<li>To start, we can create the <kbd>markovchain</kbd> object, as follows:</li>
</ol>
<pre style="padding-left: 60px">MCModel &lt;- new("markovchain", transitionMatrix = TransitionMatrix, states=RatingClasses, byrow = TRUE, name="MarkovChainModel")</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">The <kbd>markovchain</kbd> class has been designed to handle homogeneous Markov chain processes.</p>
<p style="padding-left: 60px">The following slots are passed:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>transitionMatrix</kbd><span>: This is the square transition matrix containing the probabilities of the transition matrix.</span></li>
<li><kbd>states</kbd><span>: This is the name of the states. It must be of the same</span> <kbd>colnames</kbd> <span>and</span> <kbd>rownames</kbd> <span>as the transition matrix—this is a character vector, listing the states for which transition probabilities are defined.</span></li>
<li><kbd>byrow</kbd><span>: This is a binary flag—a logical element indicating whether transition probabilities are shown by row or by column.</span></li>
<li><kbd>name</kbd><span>: This is an optional character element to name the discrete time Markov chains.</span></li>
</ul>
</li>
</ul>
<ol start="2">
<li>To show a summary of the model we've just created, use the following command:</li>
</ol>
<pre style="padding-left: 60px">MCModel</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px">MCModel<br/><br/><strong>A  8 - dimensional discrete Markov Chain defined by the following states:</strong><br/><strong> AAA, AA, A, BBB, BB, B, CCC, D</strong><br/><strong> The transition matrix  (by rows)  is defined as follows:</strong><br/><strong>       AAA     AA      A    BBB     BB      B    CCC      D</strong><br/><strong>AAA 0.90710 0.08340 0.0071 0.00075 0.00095 0.00025 0.00022 0.00023</strong><br/><strong>AA 0.00710 0.90550 0.0781 0.00720 0.00060 0.00120 0.00020 0.00010</strong><br/><strong>A 0.00092 0.02220 0.9125 0.05420 0.00720 0.00230 0.00011 0.00057</strong><br/><strong>BBB 0.00020 0.00420 0.0589 0.85880 0.05290 0.01190 0.01140 0.00170</strong><br/><strong>BB 0.00036 0.00124 0.0067 0.07730 0.80590 0.08790 0.01010 0.01050</strong><br/><strong>B 0.00011 0.00119 0.0023 0.00440 0.06510 0.83440 0.04060 0.05190</strong><br/><strong>CCC 0.00220 0.00000 0.0023 0.01330 0.02360 0.11210 0.64830 0.19820</strong><br/><strong>D 0.00000 0.00000 0.0000 0.00000 0.00000 0.00000 0.00000 1.00000</strong></pre>
<p style="padding-left: 60px">As we can see, four slots are listed—<kbd>states</kbd>, <kbd>byrow</kbd>, <kbd>transitionMatrix</kbd>, and <kbd>name</kbd>. To retrieve the elements contained in each one, use the name of the object (<kbd>MarkovChainModel</kbd>), followed by the name of the slot, separated by the <kbd>@</kbd><span> </span><span>symbol</span><span>.</span></p>
<ol start="3">
<li>For example, to print the states, we will write the following:</li>
</ol>
<pre style="padding-left: 60px">MCModel@states</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>[1] "AAA" "AA"  "A"   "BBB" "BB"  "B"   "CCC" "D"</strong> </pre>
<p style="padding-left: 60px">Other information that we can extract from the newly developed model is the transition probability that represents the probability of passing from one state to another. Recall that a Markov chain is said to be homogeneous in time if the probabilities of transition from one state to another are independent of the time index. To obtain this information, we will use the <kbd>transitionProbability()</kbd> function, which allows us to get the transition probabilities from initial to subsequent states.</p>
<ol start="4">
<li>Let's learn how to get this information:</li>
</ol>
<pre style="padding-left: 60px">transitionProbability(MCModel,"AAA","AA")</pre>
<p style="padding-left: 60px">The following result is returned:</p>
<pre style="padding-left: 60px"><strong>[1] 0.0834</strong></pre>
<p style="padding-left: 60px">We can confirm this result by analyzing the transition matrix. In that matrix, the transition from the AAA state to the AA state is given by the element p<sub>12</sub>, which is just equal to 0.083.</p>
<p style="padding-left: 60px">Now, let's calculate the credit spread for the migration matrix. The credit spread indicates a series of measures that are used to determine how much an investor is paid to compensate for the assumption of the intrinsic credit risk in the security.</p>
<p style="padding-left: 60px">To calculate the credit spread, we will use the <kbd>cm.cs()</kbd> function, which requires a migration matrix and the loss given default as input. The loss given default represents the loss that the credit institution suffers due to the insolvency of the counterparty when it becomes effective. Therefore, it is never predictable a priori; it only occurs when the credit recovery operation ends.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="5">
<li>In our case, we will set this value as an initial variable, as follows:</li>
</ol>
<pre style="padding-left: 60px">LGD &lt;- 0.40</pre>
<ol start="6">
<li>The preceding code indicates that, in the case of insolvency, the loss of the bank will be 40%. Now, we can apply the <kbd>cm.cs()</kbd> function, as follows:</li>
</ol>
<pre style="padding-left: 60px">CreditRiskSpread&lt;-cm.cs(TransitionMatrix, LGD)</pre>
<ol start="7">
<li>This function returns the credit spread for time <em>t = 1</em> of each rating in the migration matrix, as follows:</li>
</ol>
<pre style="padding-left: 60px"><strong>AAA           AA            A          BBB           BB           </strong><br/><strong>9.200423e-05 4.000080e-05 2.280260e-04 6.802313e-04 4.208845e-03 </strong><br/><strong> B          CCC</strong><br/><strong>2.097852e-02 8.259931e-02</strong> </pre>
<ol start="8">
<li>Let's calculate the value of the credit in one year. To do this, we can use the <kbd>cm.ref()</kbd> function. The following arguments are required:</li>
</ol>
<ul>
<li style="list-style-type: none">
<ul>
<li><span>Migration matrix, where the last row gives the default class</span></li>
<li>Loss given default</li>
<li>Rating of companies</li>
<li>Exposure at default</li>
<li>Riskless interest rate</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">The first two arguments have already been defined and used, that is, the migration matrix and loss given default. For the remaining three, it is necessary to initialize them.</p>
<ol start="9">
<li>Let's start with the rating of the companies whose credit value we want to evaluate. We will set three values, as follows:</li>
</ol>
<pre style="padding-left: 60px">Rating &lt;- c("B", "BB", "CCC")</pre>
<p style="padding-left: 60px"><strong>Exposure At Default</strong> (<strong>EAD</strong>) is the amount of loss that a bank may suffer due to default. Since the default occurs on an unknown future date, this loss is conditioned by the amount the bank exposed to the borrower at the time of default.</p>
<ol start="10">
<li>We will set three values, as follows:</li>
</ol>
<pre style="padding-left: 60px">EAD &lt;- c(4000, 10000, 500000)</pre>
<ol start="11">
<li>Then, we have to set the riskless interest rate; this parameter represents the interest expected by an investor from a completely risk-free investment over a given period of time. We set this value as follows:</li>
</ol>
<pre style="padding-left: 60px">Rindex &lt;- 0.02</pre>
<p style="padding-left: 60px">Now that we have all of the arguments that are required by the <kbd>cm.ref()</kbd><span> </span><span>function</span><span>, we just have to apply it:</span></p>
<pre style="padding-left: 60px">RefValue&lt;-cm.ref(TransitionMatrix, LGD, EAD, Rindex, Rating)</pre>
<p style="padding-left: 60px">Two values are returned:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>constVal</kbd><span>: Credit value in one year</span></li>
<li><kbd>constPV</kbd><span>: Portfolio of all the credit values in one year</span></li>
</ul>
</li>
</ul>
<ol start="12">
<li>To extract these values, we can use the following commands:</li>
</ol>
<pre style="padding-left: 60px">RefValue$constVal<br/>RefValue$constPV</pre>
<p style="padding-left: 60px">The following results are printed:</p>
<pre style="padding-left: 60px">&gt; RefValue$constVal<br/> <strong>        B         BB        CCC</strong><br/><strong>   3839.399   9760.818 451244.261</strong><br/>&gt; RefValue$constPV<br/><strong>[1] 464844.5</strong></pre>
<ol start="13">
<li>Finally, we can search the absorbing state of the model. Remember that the absorbing state is a state that once entered, cannot be left. To evaluate the absorbing state, we can use the <kbd>absorbingStates()</kbd> function as follows:</li>
</ol>
<pre style="padding-left: 60px">absorbingStates(MCModel)</pre>
<p style="padding-left: 60px"> The following result is returned:</p>
<pre style="padding-left: 60px"><strong>[1] "D"</strong></pre>
<p>It is easy to understand that the default is a state absorbed in the sense that, once reached, it cannot be abandoned anymore. In the next section, we will address the problem of price optimization using the multi-armed bandit analysis. </p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pricing optimization system</h1>
                </header>
            
            <article>
                
<p>Pricing is something more than simply aligning prices with those of competitors in the market. One of the most negative aspects of global trade is that there is always someone, somewhere, selling the same products at a much lower price. Automatically aligning prices with competitors is not a sustainable strategy.</p>
<p class="mce-root"/>
<p>There are two pricing strategies. The first considers the trader's point of view and offers an intuitive pricing method, according to which the choice of the right price must depend on the manager's intuition. Since this strategy is very subjective, and since the results depend substantially on the manager's ability, it is difficult to evaluate it. And if the manager leaves the company, much of the knowledge about it should be lost. The second is based on a more theoretical point of view and offers an econometric pricing method, in which the choice of prices must be made based on advanced mathematical parameters.</p>
<p>Once we have chosen a range of prices to apply to the financial product, it is good practice to adopt an optimization procedure that evaluates the market reactions to the new product we want to launch. In the simplest case, an optimization problem consists of maximizing or minimizing a real function by systematically choosing the input values from an allowed set and calculating the value of the function. The generalization of theory and optimization techniques to other formulations constitutes a vast area of applied mathematics. More generally, optimization includes searching for the best available values of some objective functions in each domain, including a variety of different types of objective functions and different types of domains.</p>
<p>There are many optimization methods available; the following are some of the most important:</p>
<ul>
<li>Linear programming</li>
<li>Least squares method</li>
<li>Simplex algorithm</li>
<li>Lagrange multiplier method</li>
<li>Stochastic optimization</li>
</ul>
<p>In this example, we will try to address the problem of price optimization using multi-armed bandit analysis and the Bandit R package. To learn more about multi-armed bandit algorithms, see <a href="80162fc2-33f6-4f5a-9f70-6d063b32d9c9.xhtml">Chapter 4</a>, <em>Multi-Armed Bandit Models</em>. We will begin by introducing the <span>Bandit </span>package.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">The Bandit package</h1>
                </header>
            
            <article>
                
<p>This package contains a set of functions for analyzing A/B split test data and web metrics in general. The following table gives some information about this package:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Package</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign"><kbd>Bandit</kbd></p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Date</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">2015-02-19</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Version</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">0.5.0</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Title</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Functions for simple A/B split test and multi-armed bandit analysis</p>
</td>
</tr>
<tr>
<td>
<p class="CDPAlignCenter CDPAlign">Author</p>
</td>
<td>
<p class="CDPAlignCenter CDPAlign">Thomas Lotze and Markus Loecher</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>In the upcoming sections, we will formalize the problem and then face it through multi-armed bandit analysis.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Pricing strategy for new financial services</h1>
                </header>
            
            <article>
                
<p>A financial company that is very active in the market is considering the release of a new financial service. After having tested all of the services already available on the market by competitors and having compared their performance, the company decides to establish a range of prices to be attributed to the launch of its own service.</p>
<p>To check which of the identified prices best suits the needs of consumers, they have decided to test four types of prices by collecting subscriptions to the service. Each price will be attributed to the service for a period of time, during which the users who have been contacted and the accessions that have been obtained will be registered.</p>
<p>The monitoring campaign will last three months, and an analysis will be carried out for each month. In the end, the best performing price will be adopted. Follow these steps:</p>
<ol>
<li>To start, we need to import the <kbd>Bandit</kbd> library:</li>
</ol>
<pre style="padding-left: 60px">library(Bandit)</pre>
<ol start="2">
<li>Now, let's reproduce the experiment:</li>
</ol>
<pre style="padding-left: 60px">set.seed(1)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<ol start="3">
<li>Now, we report the data that was collected in the first month related to the users contacted and to the purchases of the services performed, as well as to the prices offered:</li>
</ol>
<pre style="padding-left: 60px">UsersContacted1 &lt;- c(10000, 9580, 10011, 10007)<br/>Purchases1 &lt;- c(571, 579, 563, 312)<br/>Prices &lt;- c(299, 306, 312, 335)</pre>
<ol start="4">
<li>As we can see, these are three vectors, which contain the data for each category. At this point, we can move on to the simulation of the posterior distribution for each arm at various prices:</li>
</ol>
<pre style="padding-left: 60px">PostDistr1Month = sim_post(Purchases1,UsersContacted1, ndraws = 10000)</pre>
<p style="padding-left: 60px">Here, we used the <kbd>sim_post()</kbd> function, which simulates the posterior distribution of the Bayesian probabilities for each arm being the best binomial bandit. The following arguments were passed:</p>
<ul>
<li style="list-style-type: none">
<ul>
<li><kbd>Purchases1</kbd><span>: A vector of the number of successes</span></li>
<li><kbd>UsersContacted1</kbd><span>: A vector of the number of trials</span></li>
<li><kbd>ndraws</kbd><span>: The number of random draws from the posterior</span></li>
</ul>
</li>
</ul>
<p style="padding-left: 60px">In this way, we get 10,000 assessments of the posterior distribution for the Bayesian probabilities. In the following are the first 10 assessments:</p>
<pre style="padding-left: 60px"><strong>               [,1]       [,2]       [,3]       [,4]</strong><br/><strong>    [1,] 0.05836046 0.06371775 0.05441352 0.03088567</strong><br/><strong>    [2,] 0.05829739 0.06186407 0.05624850 0.02976481</strong><br/><strong>    [3,] 0.05621800 0.05805901 0.05795378 0.03280708</strong><br/><strong>    [4,] 0.05841852 0.06459235 0.05968413 0.03087549</strong><br/><strong>    [5,] 0.05342895 0.06145472 0.05901734 0.03027870</strong><br/><strong>    [6,] 0.05382709 0.06170789 0.05352246 0.03130340</strong><br/><strong>    [7,] 0.05566469 0.05698650 0.05440684 0.03335165</strong><br/><strong>    [8,] 0.05723522 0.06025616 0.05833294 0.03082094</strong><br/><strong>    [9,] 0.05617222 0.06314493 0.05721080 0.03309235</strong><br/><strong>   [10,] 0.05308393 0.05988580 0.05163597 0.03038333</strong></pre>
<ol start="5">
<li>We can, therefore, evaluate the winner: </li>
</ol>
<pre style="padding-left: 60px">ProbWinner1 &lt;- prob_winner(PostDistr1Month)</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p style="padding-left: 60px">The <kbd>prob_winner()</kbd> function was used, which computes the probability that each arm is the winner, given simulated posterior results obtained in the preceding step. This function accepts only one argument—the simulated results from the posterior, provided by the <kbd>sim_post()</kbd> function.</p>
<ol start="6">
<li>We now assign the names to the <span>winners </span>we have simulated:</li>
</ol>
<pre style="padding-left: 60px">names(ProbWinner2) &lt;- Prices</pre>
<ol start="7">
<li>Now, let's visualize the simulation results:</li>
</ol>
<pre style="padding-left: 60px">ProbWinner1</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>   299    306    312    335</strong><br/><strong>0.1397 0.7846 0.0757 0.0000</strong></pre>
<p style="padding-left: 60px">As we can see, the simulation told us that the price that seems to have been the most popular among users is $306, which collected 78.5% of the probability.</p>
<p>As we anticipated, we continue our monitoring by extending the analysis to the second month.</p>
<ol>
<li>To start, we report the data collected in the second month relating to the users contacted and the purchases of the services performed:</li>
</ol>
<pre style="padding-left: 60px">UsersContacted2 &lt;- c(12350, 12001, 11950, 12500)<br/>Purchases2 &lt;- c(621, 625, 601, 520)</pre>
<p style="padding-left: 60px">As we can see, these are two vectors that respectively contain the four data for each category.</p>
<ol start="2">
<li>At this point, we can move on to the simulation of the posterior distribution for each arm at various prices:</li>
</ol>
<pre style="padding-left: 60px">PostDistr2Month = sim_post(Purchases2,UsersContacted2, ndraws = 10000)</pre>
<ol start="3">
<li>We can, therefore, evaluate the winner:  </li>
</ol>
<pre style="padding-left: 60px">ProbWinner2 &lt;- prob_winner(PostDistr2Month)</pre>
<ol start="4">
<li>We now assign the names to the <span>winners </span>we have simulated:</li>
</ol>
<pre style="padding-left: 60px">names(ProbWinner2) &lt;- Prices</pre>
<ol start="5">
<li>Now, let's visualize the simulation results:</li>
</ol>
<pre style="padding-left: 60px">ProbWinner2</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>   299    306    312    335</strong><br/><strong> 0.196679 0.602588 0.200732 0.000001</strong></pre>
<p style="padding-left: 60px">As we can see, the simulation told us that the price that seems to have been the most popular among users is $306, which collected 60.3% of the probability.</p>
<ol start="6">
<li>Finally, let's move on to the last month of price monitoring:</li>
</ol>
<pre style="padding-left: 60px">UsersContacted3 &lt;- c(14864, 14990, 14762, 10073)<br/>Purchases3 &lt;- c(803, 825, 791, 141)</pre>
<ol start="7">
<li>At this point, we can move on to the simulation of the posterior distribution for each arm at various prices:</li>
</ol>
<pre style="padding-left: 60px">PostDistr3Month = sim_post(Purchases3,UsersContacted3, ndraws = 10000)</pre>
<ol start="8">
<li>We can, therefore, evaluate the winner:  </li>
</ol>
<pre style="padding-left: 60px">ProbWinner3 &lt;- prob_winner(PostDistr3Month)</pre>
<ol start="9">
<li>We now assign the names to the <span>winners </span>we have simulated:</li>
</ol>
<pre style="padding-left: 60px">names(ProbWinner3) &lt;- Prices</pre>
<ol start="10">
<li>Now, let's visualize the simulation results:</li>
</ol>
<pre style="padding-left: 60px">ProbWinner3</pre>
<p style="padding-left: 60px">The following results are returned:</p>
<pre style="padding-left: 60px"><strong>   299    306    312    335</strong><br/><strong>0.272597 0.529096 0.198307 0.000000</strong></pre>
<p>As we can see, the simulation told us that the price that seems to have been the most popular among users is $306, which collected 52.9 % of the probability.</p>
<p>Let's try to see whether the results obtained are statistically significant. When can we say that our experiment is significant? Nothing is significant at all. We decide how convincing the experiment must be to make us conclude that it really works. A fairly common way to represent the significance of a study is the P-value. The P-value is a number that represents the probability that the result found is due to chance, rather than to the phenomenon under consideration. Usually, by designing the experiment, you decide that you want to reach a particular P-value, for example, 1%, and you decide accordingly how big the sample must be; in other cases, the sample size is not under our control and the significance of the study is calculated a posteriori.</p>
<p>To perform a significance test, we will use the <kbd>significance_analysis()</kbd> function, as follows:</p>
<pre>significance_analysis(Purchases3,UsersContacted3)</pre>
<p>This function performs overall proportion comparison, and the following values are returned:</p>
<ul>
<li><kbd>successes</kbd>: A vector of the number of successes</li>
<li><kbd>totals</kbd>: A vector of the number of trials</li>
<li><kbd>estimated_proportion</kbd>: The number of successes/number of trials</li>
<li><kbd>lower</kbd>: 0.95 confidence interval on the estimated amount by which this alternative outperforms the next-lower alternative</li>
<li><kbd>upper</kbd>: 0.95 confidence interval on the estimated amount by which this alternative outperforms the next-lower alternative</li>
<li><kbd>significance</kbd>: P-value for the test that this alternative outperforms the next-lower alternative</li>
<li><kbd>order</kbd>: order by highest success proportion</li>
<li><kbd>best</kbd>: 1 if it is part of the "highest performing group"—those groups that were not significantly different from the best group</li>
<li><kbd>p_best</kbd>: Bayesian posterior probability that this alternative is the best binomial bandit</li>
</ul>
<p>The data for the third month of monitoring returns the following results for the significance test:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-569 image-border" src="assets/08d12858-2479-43d9-a992-1ff47143df8c.png" style="width:33.08em;height:11.25em;"/></p>
<p>The results confirm that the fourth value that we have chosen as the price has produced non-significant results, so we can leave it out in subsequent analyses. The monitoring conducted so far has provided us with enough data. Let's go on to calculate the distribution of the improvement amounts that another arm could have on the current best arm.</p>
<p>To start, we will calculate the value remaining as follows:</p>
<pre>ValueRemaining &lt;- value_remaining(Purchases3,UsersContacted3)</pre>
<p>We have used the <kbd>value_remaining()</kbd> function that returns the distribution of improvement amounts that another arm might have over the current best arm. Finally, we will calculate the potential value remaining:</p>
<pre>PotentialValue &lt;- quantile(ValueRemaining, 0.95)<br/>PotentialValue</pre>
<p>In the previous code, we used the <kbd>quantile()</kbd> function. This function returns the quantiles of the indicated function (<kbd>ValueRemaining</kbd>) corresponding to the required value (0.95). </p>
<p>The following result is returned:</p>
<pre><strong>       95%</strong><br/><strong>0.07145922</strong></pre>
<p>This value tells us that, compared to the price that seems to be winning ($306), any other value could beat it with a probability of up to 7.14%, which represents the 95% quantile of the remaining value.</p>
<p>In the following section, we will tackle an optimization problem: we will try to evaluate the optimal configuration of a financial portfolio.</p>
<p class="mce-root"/>
<p class="mce-root"/>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Optimizing equity portfolios</h1>
                </header>
            
            <article>
                
<p>The selection of an optimal portfolio is a typical decision problem, and as such, its solution consists of the following elements: the identification of a set of alternatives, using selection criteria to sort through the different possibilities, and the solution of the problem. To optimize a financial portfolio, we start by measuring the yield and risk of the products available. The risk-return variables can be considered two sides of the same coin since a certain level of risk will correspond to a given return. The return can be defined as the sum of the results produced by the investment concerning the capital employed, while the concept of risk can be translated into the degree of variability of returns associated with a given financial instrument. The preceding problem can be modeled as a MAB problem with financial products such as arms and product performance as a result. Before analyzing the code, we will define some concepts related to the world of financial investments.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Exchange-traded fund portfolio optimization</h1>
                </header>
            
            <article>
                
<p>The term <strong>exchange-traded fund</strong> (<strong>ETF</strong>) identifies a particular type of investment fund with two main characteristics: it is traded on the stock exchange as a share, and its sole investment objective is to replicate the index to which it reports (benchmark) through totally passive management.</p>
<p>An ETF summarizes the characteristics of a fund and an action, allowing investors to exploit the strengths of both instruments:</p>
<ul>
<li>Diversification and risk reduction of the funds</li>
<li>Flexibility and information transparency of real-time trading of shares</li>
</ul>
<p>Given its characteristics, the ETF lends itself to various modes of employment: medium/long-term investment, even intraday type trading and short selling to take a bearish position on the benchmark index. The possibility of easily diversifying the portfolio, the precision with which the benchmark index is replicated, and the low management costs mean that the ETF is particularly suitable for the construction of an accumulation plan through periodic payments—even small ones<span>—that are </span>made by individual investors. Let's see how an ETF dataset is structured.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">ETF dataset</h1>
                </header>
            
            <article>
                
<p>An ETF is, therefore, a collection of securities that draws an underlying index. The most well-known example is the SPDR S&amp;P 500 (SPY) ETF, which replicates the S&amp;P 500 index. In the example we are about to tackle, we will use a dataset containing the historical series of the following six ETFs:</p>
<ul>
<li><strong>SPY</strong>: SPDR S&amp;P 500 ETF</li>
<li><strong>XLF</strong>: Financial Select Sector SPDR Fund</li>
<li><strong>IWM</strong>: iShares Russell 2000 ETF; IEF</li>
<li><strong>IEF</strong>: iShares 7-10 Year Treasury Bond ETF</li>
<li><strong>GLD</strong>: SPDRÂ Gold Shares</li>
<li><strong>VWO</strong>: Vanguard FTSE Emerging Markets ETF</li>
</ul>
<p>These figures refer to the period from 1 January 2009 to 1 January 2019 and were downloaded from the Yahoo Finance website.</p>
<p>To start, we will import the dataset:</p>
<pre>dataset = read.csv('ETFs.csv')</pre>
<p>The dataset contains the following:</p>
<ul>
<li><strong>150 observations</strong>: Monthly historical series</li>
<li><strong>6 variables</strong>: <kbd>EFTreturns</kbd></li>
</ul>
<p>This information is returned using the <kbd>str()</kbd> function, as follows:</p>
<pre>str(dataset)</pre>
<p>The following list is printed:</p>
<pre>&gt; str(dataset)<br/><strong>'data.frame':  150 obs. of  6 variables:</strong><br/><strong> $ SPY: num  0.01054 -0.01962 0.00759 0.0443 0.03392 ...</strong><br/><strong> $ IEF: num  -0.00725 0.01668 -0.00467 0.00217 -0.01765 ...</strong><br/><strong> $ XLF: num  0.00325 -0.03047 -0.0089 0.03873 0.02405 ...</strong><br/><strong> $ IWM: num  0.00852 -0.00655 0.00786 0.01624 0.04372 ...</strong><br/><strong> $ VWO: num  -0.0105 -0.0232 0.0426 0.038 0.0666 ...</strong><br/><strong> $ GLD: num  0.0197 0.0255 -0.0111 0.0205 -0.0231 ...</strong></pre>
<p>In the following screenshot, we can see the first 20 rows of the dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-570 image-border" src="assets/99f114f6-5eb4-4545-81a2-776e87b1be97.png" style="width:41.67em;height:16.83em;"/></p>
<p>More information can be obtained using the <kbd>summary()</kbd> function, which produces summaries of each variable:</p>
<pre>summary(dataset)</pre>
<p>The following results are returned:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-571 image-border" src="assets/eb00f1f0-bd2a-419e-acf2-dda7bff1df9b.png" style="width:39.00em;height:11.67em;"/></p>
<p>In this way, we have obtained a series of statistical descriptors that show us the distribution of the values assumed by the indices. To get an overview of the data, we can trace a boxplot. A boxplot describes the distribution of a dataset by simple dispersion and position indexes. A boxplot can be either horizontal or vertical and contains a rectangular partition divided by two segments. The rectangle (box) is delimited by the following features: first quartile (25<sup>th</sup> percentile) and the third quartile (75<sup>th</sup> percentile). The line inside the box represents the median (50<sup>th</sup> percentile). Generally, the <kbd>boxplot()</kbd> function is used to plot a boxplot, as follows:</p>
<pre>boxplot(dataset)</pre>
<p>The following diagram shows the boxplot of the ETFs contained in the dataset:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-572 image-border" src="assets/0092954a-da47-4390-8fb7-0a1d61a8f88a.png" style="width:45.83em;height:30.00em;"/></p>
<p>The <kbd>boxplot()</kbd> function can also be used to identify outlier values. Outliers are extreme values that are far from other available observations. These values tend to distort the results of the data analysis. For these reasons, the outliers must be previously identified in the data cleaning phase or processed in the subsequent data analysis phase. Analyzing the previous diagram, we can see that the XLF variable shows different anomalous values at the extremes.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Upper confidence bounds approach</h1>
                </header>
            
            <article>
                
<p>As we mentioned in Chapter 4, <em>Multi-Armed Bandit Models</em>, the game allows us to carry out exploitation and exploration together. At the beginning of the game, we don't know which arm is the best. Therefore, we cannot characterize any arm. Hence, the UCB algorithm employs that all arms have the same observed average value. So, a confidence limit for each arm will be created and an arm will be selected randomly.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p>In this context, each arm will give a reward or not. If the arm selected returns a mistake, the average that's observed by the arm will decrease, as well as the confidence limit. If the arm that's selected returns a reward, the observed average will increase, and the confidence limit will also increase. Taking advantage of the best, we are decreasing the confidence limit. Adding more and more rounds, the likelihood that other arms are doing well also increases.</p>
<p>Our goal is to select the stock that showed the maximum return for the highest number of observations. To do this, we transform our matrix with the monthly returns into a matrix in which, for each row, there will be some zeros, except for the maximum value, which will present a 1. To do this, we will initialize a matrix of the same size as the starting dataset to zero. Then, we'll enter a unit value at the maximum value of each row of the starting dataset:</p>
<pre>DataSel&lt;- matrix(0, nrow = 150, ncol = 6)<br/>rowmax = apply(dataset, 1, max)<br/>for (i in 1:150){<br/>  for (j in 1:6){<br/>    if (dataset[i,j] == rowmax[i])<br/>      DataSel[i,j] &lt;- 1<br/>  }<br/>}</pre>
<p>From this moment on, we will work on this dataset. To start, we will set the number of observation and the number of arms:</p>
<pre>NumObs = 150<br/>NumArms = 6</pre>
<p>After doing this, we will try to initialize a series of variables that will be useful in our calculations:</p>
<pre>EFTSelected = integer()<br/>NumSelections = integer(NumArms)<br/>RewSum = integer(NumArms)<br/>TotRew = 0</pre>
<p>The names of the variables are quite intuitive, but let's verify their meaning:</p>
<ul>
<li><kbd>EFTSelected</kbd>: The EFT selected in the iterative cycle</li>
<li><kbd>NumSelections</kbd>: The number of selections made</li>
<li><kbd>RewSum</kbd>: The sum of rewards for each arm</li>
<li><kbd>TotRew</kbd>: The total reward obtained</li>
</ul>
<p>At this point, we must use two iterative cycles to pass the entire matrix. The first cycle will allow us to cross all of the rows, while the second will work on the columns. Previously, we defined these as the number of <kbd>NumObs</kbd> rows and as the number of <kbd>NumArms</kbd> columns:</p>
<pre>for (n in 1:NumObs){</pre>
<p>For each line, we initialize two further variables:</p>
<pre>EFT = 0<br/>MaxUpBound = 0</pre>
<p>Now, we can go through the columns:</p>
<pre>for (i in 1:NumArms){</pre>
<p> </p>
<p>Recall that, to perform an upper confidence bound at each round, two variables are computed: the sum of the rewards obtained by the lever <em>i</em> after <em>n</em> plays, and the number of times the lever <em>i</em> is played by the strategy in the first <em>n</em> plays. We calculate the average rewards obtained by the lever <em>i</em> after <em>n</em> plays as follows:</p>
<pre>if(NumSelections[i]&gt; 0 ){<br/>      AverageReward = RewSum[i]/NumSelections[i]</pre>
<p>We calculate the confidence interval after <em>n</em> plays using the following command:</p>
<pre>DeltaI  = sqrt(3/2 * log(n)/NumSelections[i])</pre>
<p>Then, we select the lever <em>i</em> that returns the maximum UCB, as follows:</p>
<pre>UpBound = AverageReward + DeltaI</pre>
<p>After doing this, we make some checks:</p>
<pre>} else{<br/>      UpBound  = 1e400<br/>    }<br/>    if(UpBound &gt; MaxUpBound){<br/>      MaxUpBound = UpBound<br/>      EFT = i<br/>    }<br/>  }</pre>
<p>Finally, we update the values:</p>
<pre>  EFTSelected = append(EFTSelected, EFT)<br/>  NumSelections[EFT] = NumSelections[EFT] + 1<br/>  reward = DataSel[n, EFT]<br/>  print(reward)<br/>  RewSum[EFT] = RewSum[EFT] + reward<br/>  TotRew = TotRew + reward<br/>}</pre>
<p>At this point, our analysis has been completed and we can view the results. To visualize the results, we need to draw a histogram. A histogram is a graph that shows the frequency that a given item appears in a specific range. A histogram is similar to a bar chart, but normally its area is used to graphically represent the frequency with which a given element appears. Histograms are used to represent a set of continuous data, such as time, a measurement, or a temperature. The main problem with histograms is the difficulty of comparing two sets of data and the impossibility of obtaining a precise reading of the values assumed by the data.</p>
<p>To draw a histogram, we will use the <kbd>hist()</kbd> function, which computes a histogram of the given data values, as follows:</p>
<pre>hist(EFTSelected,<br/>     col = 'blue',<br/>     main = 'Histogram of EFTs selections',<br/>     xlab = 'EFTs',<br/>     ylab = 'Number of times each EFT was selected')</pre>
<p>The following histogram is printed:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-573 image-border" src="assets/14c98532-878c-4d02-a6b1-ff2c37228fef.png" style="width:37.67em;height:27.42em;"/></p>
<p>From the analysis of the preceding diagram, it seems that stock (GLD) number 6 is the one that's selected the most, by the algorithm.</p>
<p>Finally, let's see how we can deal with the problems of identifying fraud.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Fraud detection techniques</h1>
                </header>
            
            <article>
                
<p>In the banking sector, fraud prevention is essential. And here, too, the implementation of machine learning within consolidated algorithms is a clear success factor. Here, we will return to the predictive capacity of AI—a suspicious movement is not only anomalous in terms of the level of figures and perhaps of geographical location, but also that which deviates from a behavioral model of the client that the AI has clearly identified. In this way, in the face of obvious anomalies, the AI can set blocks or limitations without waiting for the fraud to manifest itself in all of its potential.</p>
<p>Fraud detection problems have generally been addressed using supervised algorithms. In these algorithms, a series of labels guide the machine to the identification of system anomalies. Reinforcement learning is a very robust algorithm that allows an agent to receive states from an environment and then perform actions based on those states. Depending on these actions, it will be rewarded accordingly. As we saw in <a href="aed130c4-9d8b-42d1-826a-e26a4162ebcf.xhtml">Chapter 2</a>, <em>Building Blocks of Reinforcement Learning</em>, the three essential elements are as follows:</p>
<ul>
<li>State</li>
<li>Action</li>
<li>Reward</li>
</ul>
<p class="mce-root">If you want to use this to tackle a classification problem, it is necessary to carefully define the three parameters we just mentioned.<br/>
Suppose we want to identify the fraudulent use of credit cards, which is one of the most common computer crimes. The available data provides us with some variables that propose the behavior of the user and then the binary class (1.0) that labels the operation. In this case, a correct formulation of the problem includes the following parameters:</p>
<ul>
<li class="mce-root"><kbd>status</kbd>: These are all of the variables that summarize the user's behavior.</li>
<li class="mce-root"><kbd>action</kbd>: This is the binary value containing the operation label (0 = valid operation and 1 = fraudulent operation).</li>
<li class="mce-root"><kbd>reward</kbd>: This provides feedback to the system. The reward is obtained through an evaluation of the action. You get a reward if the action = 0, or if the operation is valid. This will allow the reinforcement learning-based system to learn when an operation is valid and to discern it from fraudulent ones.</li>
</ul>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root">To improve the reward function, negative recompense can be envisaged in the case of fraudulent exploitation.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>In this chapter, we learned how to solve financial problems using reinforcement learning techniques. After introducing the field of application, we studied some practical cases. <span>For starters, we learned how</span> to model credit risks such as Markov chains to perform credit scoring analysis. Then, we learned how to choose the best price for a new product to be launched on the market. Once we have chosen a range of prices to apply to the financial product, it is good practice to adopt an optimization procedure that evaluates the market reactions to the new product we want to launch. To do this, we modeled the system through an algorithm based on the multi-armed bandit approach. Finally, we learned how to optimize the choice of a stock market based on the returns that had been obtained in recent years.</p>
<p>In the next chapter, we will learn how to use reinforcement learning in healthcare. First, we will learn how to choose the optimal policies from observational data and understand how to detect breast cancer using TD-learning. Finally, we will learn how to forecast thyroid disease using R.</p>


            </article>

            
        </section>
    </body></html>