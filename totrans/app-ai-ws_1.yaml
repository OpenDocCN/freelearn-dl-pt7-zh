- en: 1\. Introduction to Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Overview
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will be introduced to the fundamentals of Artificial Intelligence
    (AI), which are the foundations of various fields of AI. You will also come across
    different algorithms, including MinMax and A*, through simple coding exercises
    using the Python programming language. You will also be implementing your first
    AI through a simple tic-tac-toe game where you will be teaching the program how
    to win against a human player. By the end of this chapter, you will learn how
    to use popular Python libraries to develop intelligent AI-driven programs.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before discussing the different AI techniques and algorithms, we will look at
    the fundamentals of AI and machine learning and go through a few basic definitions.
    Real-world examples will be used to present the basic concepts of AI in an easy-to-digest
    way.
  prefs: []
  type: TYPE_NORMAL
- en: AI attempts to replicate human intelligence using hardware and software solutions.
    It is based on reverse engineering. For example, artificial neural networks are
    modeled after the way the human brain works. Beyond neural networks, there are
    many other models in neuroscience that can be used to solve real-world problems
    using AI. Companies that are known to be using AI in their fields include Google,
    with Google Translate, Apple, with Face ID, Amazon, with its Alexa products, and
    even Uber and Tesla, who are still working on building self-driving cars.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, machine learning is a term that is often confused with AI.
    It originates from the 1950s and was first defined by Arthur Lee Samuel in 1959.
  prefs: []
  type: TYPE_NORMAL
- en: 'In his book called *Machine Learning*, Tom Mitchell proposed a simple definition
    of it: "*The field of machine learning is concerned with the question of how to
    construct computer programs that automatically improve with experience.*"'
  prefs: []
  type: TYPE_NORMAL
- en: We can understand this as machine learning being the field where the goal is
    to build a computer program capable of learning patterns from data and improve
    its learning ability with more data.
  prefs: []
  type: TYPE_NORMAL
- en: He also proposed a more formal definition, which is that a computer program
    is said to learn from experience, **E**, with respect to a task, **T**, and a
    performance measure, **P**, if its performance on **T**, as measured by **P**,
    improves with experience, **E**. This can be translated as what a computer program
    requires in order for it to be learning. We can see **E** (the experience) as
    the data that needs to be fed to the machine, **T**, as the type of decision that
    the machine needs to perform, and **P** as the measure of its performance.
  prefs: []
  type: TYPE_NORMAL
- en: From these two definitions, we can conclude that machine learning is one way
    to achieve AI. However, you can have AI without machine learning. For instance,
    if you hardcode rules and decision trees, or you apply search techniques, you
    can create an AI agent, even though your approach has little to do with machine
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: AI and machine learning have helped the scientific community harness the explosion
    of big data with more and more data being created every second. With AI and machine
    learning, scientists can extract information that human eyes cannot process fast
    enough on these huge datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have been introduced to AI and machine learning, let's focus on
    AI.
  prefs: []
  type: TYPE_NORMAL
- en: How Does AI Solve Problems?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*AI automates human intelligence based on the way a human brain processes information.*'
  prefs: []
  type: TYPE_NORMAL
- en: Whenever we solve a problem or interact with people, we go through a process.
    By doing this, we limit the scope of a problem or interaction. This process can
    often be modeled and automated in AI.
  prefs: []
  type: TYPE_NORMAL
- en: '*AI makes computers appear to think like humans.*'
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, it feels like the AI knows what we need. Just think about the personalized
    coupons you receive after shopping online. AI knows which product we will most
    likely be purchasing. Machines are able to learn your preferences through the
    implementation of different techniques and models, which we will look at later
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: '*AI is performed by computers that are executing low-level instructions.*'
  prefs: []
  type: TYPE_NORMAL
- en: Even though a solution may appear to be intelligent, we write code, just like
    with any other software solution in AI. Even if we are simulating neurons, simple
    machine code and computer hardware executes the *thinking* process.
  prefs: []
  type: TYPE_NORMAL
- en: Most AI applications have one primary objective. When we interact with an AI
    application, it seems human-like because it can restrict a problem domain to a
    primary objective. Therefore, the process whereby the AI reaches the objective
    can be broken down into smaller and simpler low-level instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '*AI may stimulate human senses and thinking processes for specialized fields.*'
  prefs: []
  type: TYPE_NORMAL
- en: You must be able to simulate human senses and thoughts, and sometimes trick
    AI into believing that we are interacting with another human. In some special
    cases, we can even enhance our own senses.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, when we interact with a chatbot, for instance, we expect the bot
    to understand us. We expect the chatbot or even a voice recognition system to
    provide a computer-human interface that fulfills our expectations. In order to
    meet these expectations, computers need to emulate human thought processes.
  prefs: []
  type: TYPE_NORMAL
- en: Diversity of Disciplines in AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A self-driving car that cannot sense other cars driving on the same highway
    would be incredibly dangerous. The AI agent needs to process and sense what is
    around it in order to drive the car. However, this is not enough since, without
    understanding the physics of moving objects, driving the car in a normal environment
    would be an almost impossible, not to mention deadly, task.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to create a usable AI solution, different disciplines are involved,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Robotics**: To move objects in space'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Algorithm theory**: To construct efficient algorithms'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Statistics**: To derive useful results, predict the future, and analyze the
    past'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Psychology**: To model how the human brain works'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software engineering**: To create maintainable solutions that endure the
    test of time'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computer science or computer programming**: To implement our software solutions
    in practice'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Mathematics**: To perform complex mathematical operations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control theory**: To create feed-forward and feedback systems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Information theory**: To represent, encode, decode, and compress information'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graph theory**: To model and optimize different points in space and to represent
    hierarchies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Physics**: To model the real world'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Computer graphics and image processing**: To display and process images and
    movies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this book, we will cover a few of these disciplines, including algorithm
    theory, statistics, computer science, mathematics, and image processing.
  prefs: []
  type: TYPE_NORMAL
- en: Fields and Applications of AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that we have been introduced to AI, let's move on and see its application
    in real life.
  prefs: []
  type: TYPE_NORMAL
- en: Simulation of Human Behavior
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Humans have five basic senses that can be divided into visual (seeing), auditory
    (listening), kinesthetic (moving), olfactory (smelling), and gustatory (tasting).
    However, for the purposes of understanding how to create intelligent machines,
    we can separate these disciplines as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Listening and speaking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remembering things
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thinking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seeing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A few of these are out of scope for us because the purpose of this chapter
    is to understand the fundamentals. In order to move a robot arm, for instance,
    we would have to study complex university-level math to understand what''s going
    on, but we will only be sticking to the practical aspects in this book:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Listening and speaking**: Using a speech recognition system, AI can collect
    information from a user. Using speech synthesis, it can turn internal data into
    understandable sounds. Speech recognition and speech synthesis techniques deal
    with the recognition and construction of human sounds that are emitted or that
    humans can understand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For instance, imagine you are on a trip to a country where you don't speak the
    local language. You can speak into the microphone of your phone, expect it to
    *understand* what you say, and then translate it into the other language. The
    same can happen in reverse with the locals speaking and AI translating the sounds
    into a language you understand. Speech recognition and speech synthesis make this
    possible.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: An example of speech synthesis is Google Translate. You can navigate to [https://translate.google.com/](https://translate.google.com/)
    and make the translator speak words in a non-English language by clicking the
    loudspeaker button below the translated word.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Understanding language**: We can understand natural language by processing
    it. This field is called natural language processing, or NLP.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When it comes to NLP, we tend to learn languages based on statistical learning
    by learning the statistical relationship between syllables.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Remembering things**: We need to represent things we know about the world.
    This is where creating knowledge bases and hierarchical representations called
    **ontologies** comes into play. Ontologies categorize things and ideas in our
    world and contain relations between these categories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Thinking**: Our AI system has to be an expert in a certain domain by using
    an expert system. An expert system can be based on mathematical logic in a deterministic
    way, as well as in a fuzzy, non-deterministic way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The knowledge base of an expert system is represented using different techniques.
    As the problem domain grows, we create hierarchical ontologies.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We can replicate this structure by modeling the network on the building blocks
    of the brain. These building blocks are called neurons, and the network itself
    is called a neural network.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Seeing**: We have to interact with the real world through our senses. We
    have only touched upon auditory senses so far, in regard to speech recognition
    and synthesis. What if we had to see things? If that was the case, we would have
    to create computer vision techniques to learn about our environment. After all,
    recognizing faces is useful, and most humans are experts at that.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computer vision depends on image processing. Although image processing is not
    directly an AI discipline, it is a required discipline for AI.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Moving**: Moving and touching are natural to us humans, but they are very
    complex tasks for computers. Moving is handled by robotics. This is a very math-heavy
    topic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Robotics is based on control theory, where you create a feedback loop and control
    the movement of your object based on the feedback gathered. Control theory has
    applications in other fields that have absolutely nothing to do with moving objects
    in space. This is because the feedback loops that are required are similar to
    those modeled in economics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Simulating Intelligence – the Turing Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Alan Turing, inventor of the Turing machine, an abstract concept that's used
    in algorithm theory, suggested a way to test intelligence. This test is referred
    to as the **Turing test** in AI literature.
  prefs: []
  type: TYPE_NORMAL
- en: Using a text interface, an interrogator chats to a human and a chatbot. The
    job of the chatbot is to mislead the interrogator to the extent that they cannot
    tell whether the computer is human.
  prefs: []
  type: TYPE_NORMAL
- en: What Disciplines Do We Need to Pass the Turing Test?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: First, we need to understand a spoken language to know what the interrogator
    is saying. We do this by using **Natural Language Processing** (**NLP**). We also
    must respond to the interrogator in a credible way by learning from previous questions
    and answers using AI models.
  prefs: []
  type: TYPE_NORMAL
- en: We need to be an expert of things that the human mind tends to be interested
    in. We need to build an expert system of humanity, involving the taxonomy of objects
    and abstract thoughts in our world, as well as historical events and even emotions.
  prefs: []
  type: TYPE_NORMAL
- en: Passing the Turing test is very hard. Current predictions suggest we won't be
    able to create a system good enough to pass the Turing test until the late 2020s.
    Pushing this even further, if this is not enough, we can advance to the Total
    Turing Test, which also includes movement and vision.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will move on and look at the tools and learning models in AI.
  prefs: []
  type: TYPE_NORMAL
- en: AI Tools and Learning Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous sections, we discovered the fundamentals of AI. One of the core
    tasks of AI is learning. This is where intelligent agents come into the picture.
  prefs: []
  type: TYPE_NORMAL
- en: Intelligent Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When solving AI problems, we create an actor in the environment that can gather
    data from its surroundings and influence its surroundings. This actor is called
    an **intelligent agent**.
  prefs: []
  type: TYPE_NORMAL
- en: 'An intelligent agent is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Is autonomous
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observes its surroundings through sensors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acts in its environment using actuators (which are the components that are responsible
    for moving and controlling a mechanism)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Directs its activities toward achieving goals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agents may also learn and have access to a knowledge base.
  prefs: []
  type: TYPE_NORMAL
- en: We can think of an agent as a function that maps perceptions to actions. If
    the agent has an internal knowledge base, then perceptions, actions, and reactions
    may alter the knowledge base as well.
  prefs: []
  type: TYPE_NORMAL
- en: Actions may be rewarded or punished. Setting up a correct goal and implementing
    a carrot and stick situation helps the agent learn. If goals are set up correctly,
    agents have a chance of beating the often more complex human brain. This is because
    the primary goal of the human brain is survival, regardless of the game we are
    playing. An agent's primary motive is reaching the goal itself. Therefore, intelligent
    agents do not get embarrassed when making a random move without any knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: The Role of Python in AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to put basic AI concepts into practice, we need a programming language
    that supports AI. In this book, we have chosen Python. There are a few reasons
    why Python is such a good choice for AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Convenience and Compatibility:** Python is a high-level programming language.
    This means that you don''t have to worry about memory allocation, pointers, or
    machine code in general. You can write code in a convenient fashion and rely on
    Python''s robustness. Python is also cross-platform compatible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Popularity:** The strong emphasis on developer experience makes Python a
    very popular choice among software developers. In fact, according to a 2018 developer
    survey by [https://www.hackerrank.com](https://www.hackerrank.com), across all
    ages, Python ranks as the number one preferred language of software developers.
    This is because Python is easily readable and simple. Therefore, Python is great
    for rapid application development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Efficiency:** Despite being an interpreted language, Python is comparable
    to other languages that are used in data science, such as R. Its main advantage
    is memory efficiency, since Python can handle large, in-memory databases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Python is a multi-purpose language. It can be used to create desktop applications,
    database applications, mobile applications, and games. The network programming
    features of Python are also worth mentioning. Furthermore, Python is an excellent
    prototyping tool.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why Is Python Dominant in Machine Learning, Data Science, and AI?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To understand the dominant nature of Python in machine learning, data science,
    and AI, we have to compare Python to other languages that are also used in these
    fields.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to R, which is a programming language built for statisticians, Python
    is much more versatile and easy as it allows programmers to build a diverse range
    of applications, from games to AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to Java and C++, writing programs in Python is significantly faster.
    Python also provides a high degree of flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some languages that are similar in nature when it comes to flexibility
    and convenience: Ruby and JavaScript. Python has an advantage over these languages
    because of the AI ecosystem that''s available for Python. In any field, open source,
    third-party library support vastly determines the success of that language. Python''s
    third-party AI library support is excellent.'
  prefs: []
  type: TYPE_NORMAL
- en: Anaconda in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We installed Anaconda in the *Preface*. Anaconda will be our number one tool
    when it comes to experimenting with AI.
  prefs: []
  type: TYPE_NORMAL
- en: Anaconda comes with packages, IDEs, data visualization libraries, and high-performance
    tools for parallel computing in one place. Anaconda hides configuration problems
    and the complexity of maintaining a stack for data science, machine learning,
    and AI. This feature is especially useful in Windows, where version mismatches
    and configuration problems tend to arise the most.
  prefs: []
  type: TYPE_NORMAL
- en: Anaconda comes with Jupyter Notebook, where you can write code and comments
    in a documentation style. When you experiment with AI features, the flow of your
    ideas resembles an interactive tutorial where you run each step of your code.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '**IDE** stands for **Integrated Development Environment**. While a text editor
    provides some functionalities to highlight and format code, an IDE goes beyond
    the features of text editors by providing tools to automatically refactor, test,
    debug, package, run, and deploy code.'
  prefs: []
  type: TYPE_NORMAL
- en: Python Libraries for AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The list of libraries presented here is not complete as there are more than
    700 available in Anaconda. However, these specific ones will get you off to a
    good start because they will give you a good foundation to be able to implement
    the fundamental AI algorithms in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '**NumPy**: NumPy is a computing library for Python. As Python does not come
    with a built-in array data structure, we have to use a library to model vectors
    and matrices efficiently. In data science, we need these data structures to perform
    simple mathematical operations. We will use NumPy extensively in future chapters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**SciPy**: SciPy is an advanced library containing algorithms that are used
    for data science. It is a great complementary library to NumPy because it gives
    you all the advanced algorithms you need, whether it be a linear algebra algorithm,
    image processing tool, or a matrix operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**pandas**: pandas provides fast, flexible, and expressive data structures,
    such as one-dimensional series and two-dimensional DataFrames. It efficiently
    loads, formats, and handles complex tables of different types.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**scikit-learn**: scikit-learn is Python''s main machine learning library.
    It is based on the NumPy and SciPy libraries. scikit-learn provides you with the
    functionality required to perform both classification and regression, data preprocessing,
    as well as supervised and unsupervised learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**NLTK**: We will not deal with NLP in this book, but NLTK is still worth mentioning
    because this library is the main natural language toolkit of Python. You can perform
    classification, tokenization, stemming, tagging, parsing, semantic reasoning,
    and many other operations using this library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TensorFlow**: TensorFlow is Google''s neural network library, and it is perfect
    for implementing deep learning AI. The flexible core of TensorFlow can be used
    to solve a vast variety of numerical computation problems. Some real-world applications
    of TensorFlow include Google voice recognition and object identification.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Brief Introduction to the NumPy Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The NumPy library will play a major role in this book, so it is worth exploring
    it further.
  prefs: []
  type: TYPE_NORMAL
- en: 'After launching your Jupyter Notebook, you can simply import `numpy` as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Once `numpy` has been imported, you can access it using its alias, `np`. NumPy
    contains the efficient implementation of some data structures, such as vectors
    and matrices.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how we can define vectors and matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can declare a matrix using the following syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The `array` method creates an array data structure, while `.mat` creates a matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can perform many operations with matrices. These include addition, subtraction,
    and multiplication. Let''s have a look at these operations here:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Addition in matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Subtraction in matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Multiplication in matrices:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Matrix addition and subtraction work cell by cell.
  prefs: []
  type: TYPE_NORMAL
- en: 'Matrix multiplication works according to linear algebra rules. To calculate
    matrix multiplication manually, you have to align the two matrices, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1: Multiplication calculation with two matrices'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.1: Multiplication calculation with two matrices'
  prefs: []
  type: TYPE_NORMAL
- en: To get the *(i,j)*th element of the matrix, you compute the dot (scalar) product
    on the *i*th row of the matrix with the *j*th column. The scalar product of two
    vectors is the sum of the product of their corresponding coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another frequent matrix operation is the determinant of the matrix. The determinant
    is a number associated with square matrices. Calculating the determinant using
    NumPy''s `linalg` function (linear algebra algorithms) can be seen in the following
    line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Technically, the determinant can be calculated as `1*3 – 2*3 = -3`. Notice that
    NumPy calculates the determinant using floating-point arithmetic, so the accuracy
    of the result is not perfect. The error is due to the way floating points are
    represented in most programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also transpose a matrix, as shown in the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: When calculating the transpose of a matrix, we flip its values over its main
    diagonal.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy has many other important features, so we will use it in most of the chapters
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.01: Matrix Operations Using NumPy'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will be using Jupyter Notebook and the following matrix to solve this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will calculate the square of the matrix, which is determinant of the matrix
    and the transpose of the matrix shown in the following figure, using NumPy:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2: A simple matrix representation'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.2: A simple matrix representation'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Import the `numpy` library as `np`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a two-dimensional array called `A` for storing the `[[1,2,3],[4,5,6],[7,8,9]]`
    matrix using `np.mat`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you have created an `np.array` instead of `np.mat`, the solution for the
    array multiplication will be incorrect.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, we perform matrix multiplication using the asterisk and save the result
    in a variable called `matmult`, as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, manually calculate the square of `A` by performing matrix multiplication.
    For instance, the top-left element of the matrix is calculated as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `np.linalg.det` to calculate the determinant of the matrix and save the
    result in a variable called `det`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output (might vary slightly) is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Use `np.matrix.transpose` to get the transpose of the matrix and save the result
    in a variable called `transpose`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: If `T` is the transpose of matrix `A`, then `T[j][i]` is equal to `A[i][j]`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/316Vd6Z](https://packt.live/316Vd6Z).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2BrogHL](https://packt.live/2BrogHL).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By completing this exercise, you have seen that NumPy comes with many useful
    features for vectors, matrices, and other mathematical structures.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming section, we will be implementing AI in an interesting tic-tac-toe
    game using Python.
  prefs: []
  type: TYPE_NORMAL
- en: Python for Game AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An AI game player is nothing but an intelligent agent with a clear goal: to
    win the game and defeat all the other players. AI experiments have achieved surprising
    results when it comes to games. Today, no human can defeat an AI in the game of
    chess.'
  prefs: []
  type: TYPE_NORMAL
- en: The game *Go* was the last game where human players could consistently defeat
    a computer player. However, in 2017, Google's game-playing AI called AlphaGo defeated
    the world number 1 ranked Go player.
  prefs: []
  type: TYPE_NORMAL
- en: Intelligent Agents in Games
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An intelligent agent plays according to the rules of the game. The agent can
    sense the current state of the game through its sensors and can evaluate the potential
    steps. Once the agent finds the best possible step, it performs the action using
    its actuators. The agent finds the best possible action to reach the goal based
    on the information it has. Actions are either rewarded or punished. The carrot
    and stick are excellent examples of rewards and punishment. Imagine a donkey in
    front of your cart. You put a carrot in front of the eyes of the donkey, so the
    animal starts walking toward it. As soon as the donkey stops, the rider may apply
    punishment with a stick. This is not a human way of moving, but rewards and punishment
    control living organisms to some extent. The same happens to humans at school,
    at work, and in everyday life as well. Instead of carrots and sticks, we have
    income and legal punishment to shape our behavior.
  prefs: []
  type: TYPE_NORMAL
- en: In most games, a good sequence of actions results in a reward. When a human
    player feels rewarded, that makes the human feel happy. Humans tend to act in
    a way that maximizes their happiness. Intelligent agents, on the other hand, are
    only interested in their goal, which is to maximize their reward and minimize
    the punishment that's affecting their performance score.
  prefs: []
  type: TYPE_NORMAL
- en: When modeling games, we must determine their state space. An action causes a
    state transition. When we explore the consequences of all possible actions, we
    get a decision tree. This tree goes deeper as we start exploring the possible
    future actions of all players until the game ends.
  prefs: []
  type: TYPE_NORMAL
- en: The strength of AI is the execution of millions of possible steps each second.
    Therefore, game AI often boils down to a search exercise. When exploring all of
    the possible sequences of moves in a game, we get the state tree of a game.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a chess AI. What is the problem with evaluating all possible moves
    by building a state tree consisting of all of the possible sequences of moves?
  prefs: []
  type: TYPE_NORMAL
- en: Chess is an EXPTIME game complexity-wise. The number of possible moves explodes
    combinatorically.
  prefs: []
  type: TYPE_NORMAL
- en: 'White starts with 20 possible moves: the eight pawns may move either one or
    two steps, and the two knights may move either up-up-left, or up-up-right. Then,
    black can make any of these 20 moves. There are already 20*20 = 400 possible combinations
    after just one move per player.'
  prefs: []
  type: TYPE_NORMAL
- en: After the second move, we get 8,902 possible board constellations, and this
    number just keeps on growing. Just take seven moves, and you have to search through
    10,921,506 possible constellations.
  prefs: []
  type: TYPE_NORMAL
- en: The average length of a chess game is approximately 40 moves. Some exceptional
    games take more than 200 moves to finish.
  prefs: []
  type: TYPE_NORMAL
- en: As a consequence, the computer player simply does not have time to explore the
    whole state space. Therefore, the search activity has to be guided with proper
    rewards, punishment, and simplifications of the rules.
  prefs: []
  type: TYPE_NORMAL
- en: Breadth First Search and Depth First Search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Creating a game AI is often a search exercise. Therefore, we need to be familiar
    with the two primary search techniques:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Breadth First Search** (**BFS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Depth First Search** (**DFS**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These search techniques are applied on a directed rooted tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'A tree is a data structure that has **nodes**, and **edges** connecting these
    nodes in such a way that any two nodes of the tree are connected by exactly one
    path. Have a look at the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3: A directed rooted tree'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.3: A directed rooted tree'
  prefs: []
  type: TYPE_NORMAL
- en: When the tree is rooted, there is a special node in the tree called the **root**,
    which is where we begin our traversal. A directed tree is a tree where the edges
    may only be traversed in one direction. Nodes may be internal nodes or leaves.
    **Internal nodes** have at least one edge, through which we can leave the node.
    A **leaf** has no edges pointing out from the node.
  prefs: []
  type: TYPE_NORMAL
- en: In AI search, the root of the tree is the starting state. We traverse from this
    state by generating the successor nodes of the search tree. Search techniques
    differ, depending on the order in which we visit these successor nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Breadth First Search (BFS)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'BFS is a search technique that, starting from the root node (node 1), will
    start exploring the closest node on the same depth (or level) before moving to
    the next depth:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.4: A BFS tree'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.4: A BFS tree'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, you can see the search order of the BFS technique.
    Starting from the root node (`1`), BFS will go to the next level and explore the
    closest node (`2`) before looking at the other nodes on the same level (`3` and
    `4`). Then, it will move to the next level and explore `5` and `6` as they are
    close to each other before going back through to node `3`, finishing on the last
    node (`7`), and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Depth First Search (DFS)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'DFS is a search technique that, starting from the root node (node 1), will
    start exploring the same branch as much as possible before moving to the next
    closest branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.5: A DFS tree'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.5: A DFS tree'
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding figure, you can see the search order of the DFS technique.
    Starting from the root node (`1`), DFS will go to the closest node (`2`) and explore
    all the way to the end of the branch (`3`) on the third depth before going back
    to the node (`2`) and finish by exploring its second branch (`4`). Then, it will
    move back to the second depth and start the same process with the next branch
    (`6`) before finishing with the last branch (`7`).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, suppose we have a tree defined by its root and a function that generates
    all the successor nodes from the root. In the following example, each node has
    a value and a depth. We start from `1` and may either increase the value by `1`
    or `2`. Our goal is to reach the value `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we have initialized the root node as having
    a value and depth of `1`. Then, we created a function called `succ` that takes
    a node as input. This function will have 3 different cases:'
  prefs: []
  type: TYPE_NORMAL
- en: If the input node value is `5`, then return nothing as we will have already
    reached our goal (`5`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the input node value is `4`, then return the value `5` and add `1` to the
    current depth.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the value is anything else, then add `1` to the depth and create two cases
    for the value, `+1` and `+2`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'First, we will perform BFS, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we have implemented the `bfs_tree` function
    by taking a node as input. This function can be broken down into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The `nodes_to_visit` and `visited_nodes` variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **second part** is where BFS is implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: The `current_node` variable takes away the first element of the `nodes_to_visit`
    variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `visited_nodes` variable adds this element to its list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `nodes_to_visit` variable adds the newly generated nodes from the call of
    `succ` with the `current_node` as input to it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding three instructions are wrapped into a loop defined by the number
    of elements inside the `nodes_to_visit` variable. As long as `nodes_to_visit`
    has at least one element, then the loop will keep going.
  prefs: []
  type: TYPE_NORMAL
- en: The `visited_nodes` variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, BFS is searching through the values of the same depth before
    moving to the next level of depth and exploring the values of it. Notice how depth
    and value are increasing in sequence. This will not be the case in DFS.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we had to traverse a graph instead of a directed rooted tree, BFS would
    look different: whenever we visit a node, we would have to check whether the node
    had been visited before. If the node had been visited before, we would simply
    ignore it.'
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will only use Breadth First Traversal on trees. DFS is surprisingly
    similar to BFS. The difference between DFS and BFS is the sequence in which you
    access the nodes. While BFS visits all the children of a node before visiting
    any other nodes, DFS digs deep into the tree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a look at the following example, where we''re implementing DFS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding code snippet, we have implemented the `dfs_tree` function
    by taking a node as input. This function can be broken down into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: The `nodes_to_visit` and `visited_nodes` variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **second part** is where DFS is implemented:'
  prefs: []
  type: TYPE_NORMAL
- en: The `current_node` variable takes away the last element of the `nodes_to_visit`
    variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `visited_nodes` variable adds this element to its list.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `nodes_to_visit` variable adds the newly generated nodes from the call of
    `succ` with `current_node` as input to it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding three instructions are wrapped into a loop defined by the number
    of elements inside the `nodes_to_visit` variable. As long as `nodes_to_visit`
    has at least one element, then the loop will keep going.
  prefs: []
  type: TYPE_NORMAL
- en: At the end, that is at the `visited_nodes`.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the main difference between BFS and DFS is the order in which
    we took an element out of `nodes_to_visit`. For BFS, we take the first element,
    whereas for DFS, we take the last one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Notice how the DFS algorithm digs deep fast (the depth reaches higher values
    faster than BFS). It does not necessarily find the shortest path first, but it
    is guaranteed to find a leaf before exploring a second path.
  prefs: []
  type: TYPE_NORMAL
- en: In game AI, the BFS algorithm is often better for the evaluation of game states
    because DFS may get lost. Imagine starting a chess game, where a DFS algorithm
    may easily get lost in exploring the options for a move.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the State Space of a Game
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let''s explore the state space of a simple game: tic-tac-toe. A state space
    is the set of all possible configurations of a game, which, in this case, means
    all the possible moves.'
  prefs: []
  type: TYPE_NORMAL
- en: In tic-tac-toe, a 3x3 game board is given. Two players play this game. One plays
    with the sign X, while the other plays with the sign O. X starts the game, and
    each player makes a move after the other. The goal of the game is to get three
    of your own signs horizontally, vertically, or diagonally.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s denote the cells of the tic-tac-toe board, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.6: Tic-tac-toe board'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.6: Tic-tac-toe board'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, `X` started at position `1`. `O` retaliated at position
    `5`, `X` made a move at position `9`, and then `O` moved to position `3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.7: Tic-tac-toe board with noughts and crosses'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.7: Tic-tac-toe board with noughts and crosses'
  prefs: []
  type: TYPE_NORMAL
- en: This was a mistake by the second player, because now `X` is forced to place
    a sign on cell `7`, creating two future scenarios for winning the game. It does
    not matter whether `O` defends by moving to cell `4` or `8` – `X` will win the
    game by selecting the other unoccupied cell.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can try out the game at [http://www.half-real.net/tictactoe/](http://www.half-real.net/tictactoe/).
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we will only explore the state space belonging to the cases
    when the AI player starts. We will start with an AI player who plays randomly,
    placing a sign in an empty cell. After playing with this AI player, we will create
    a complete decision tree. Once we generate all possible game states, you will
    experience their combinatorial explosion. As our goal is to make these complexities
    simple, we will use several different techniques to make the AI player smarter
    and reduce the size of the decision tree.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this experiment, we will have a decision tree that has fewer than
    200 different game endings and, as a bonus, the AI player will never lose a single
    game.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make a random move, you will have to know how to choose a random element
    from a list using Python. We will use the `choice` function of the `random` library
    to do so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This time, the output is `6`, but for you, it can be any number from the list.
  prefs: []
  type: TYPE_NORMAL
- en: The output of the `choice` function is a random element of the list.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: We will use the factorial notation in the following section. A factorial is
    denoted by the "!" exclamation mark. By definition, 0! = 1, and n! = n*(n-1)!.
    In our example, 9! = 9* 8! = 9*8*7! = … = 9*8*7*6*5*4*3*2*1.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating the Number of Possible States in a Tic-Tac-Toe Game
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Make a rough estimate of the number of possible states on each level of the
    state space of the tic-tac-toe game:'
  prefs: []
  type: TYPE_NORMAL
- en: In our estimation, we will not stop until all of the cells of the board have
    been filled. A player might win before the game ends, but for the sake of uniformity,
    we will continue the game.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first player will choose one of the nine cells. The second player will choose
    one out of the eight remaining cells. The first player can then choose one out
    of the seven remaining cells. This goes on until either player wins the game,
    or the first player is forced to make the ninth and last move.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of possible decision sequences is, therefore, 9! = 362,880\. A few
    of these sequences are invalid because a player may win the game in fewer than
    nine moves. It takes at least five moves to win a game because the first player
    needs to move three times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To calculate the exact size of the state space, we have to calculate the number
    of games that are won in five, six, seven, and eight steps. This calculation is
    simple, but due to its brute-force nature, it is beyond our scope. Therefore,
    we will settle on the magnitude of the state space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After generating all possible tic-tac-toe games, researchers counted 255,168
    possible games. Out of those games, 131,184 were won by the first player, 77,904
    were won by the second player, and 46,080 games ended with a draw. Visit [http://www.half-real.net/tictactoe/allgamesoftictactoe.zip](http://www.half-real.net/tictactoe/allgamesoftictactoe.zip)
    to download all possible tic-tac-toe games.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Even a simple game such as tic-tac-toe has a lot of states. Just imagine how
    hard it would be to start exploring all possible chess games. Therefore, we can
    conclude that brute-force searching is rarely ideal.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.02: Creating an AI with Random Behavior for the Tic-Tac-Toe Game'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we'll create a framework for the tic-tac-toe game for experimentation.
    We will be modeling the game on the assumption that the AI player always starts
    the game. You will create a function that prints your internal representation,
    allows your opponent to enter a move randomly, and determines whether a player
    has won.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To ensure that this happens correctly, you will need to have completed the previous
    exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Begin by opening a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We will import the `choice` function from the `random` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, model the nine cells in a simple string for simplicity. A nine-character
    long Python string stores these cells in the following order: "`123456789`". Let''s
    determine the index triples that must contain matching signs so that a player
    wins the game:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Define the sign constants for empty cells, the AI, and the opponent player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have assigned a different sign for the AI
    and the player.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Create a function that prints a board. We will add an empty row before and
    after the board so that we can easily read the game state:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Describe a move of the human player. The input arguments are the boards, the
    row numbers from `1` to `3`, and the column numbers from `1` to `3`. The return
    value of this function is a board containing the new move:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, we have defined a function called `opponent_move` that will help us to
    calculate the index of the board based on the input (row and column). You will
    be able to see the resulting position on the board.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, we need to define a random move on the part of the AI player. We will
    generate all possible moves with the `all_moves_from_board` function, and then
    select a random move from the list of possible moves:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we defined a function called `all_moves_from_board`
    that goes through all the indexes on the board and checks whether they are empty
    (`v == EMPTY_SIGN`). If that's the case, this means that the move can be played
    and that the index has been added to a list of moves (`move_list`). Finally, we
    defined the `ai_move` function in order to randomly let the AI choose an index
    that is equal to a move in the game.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Determine whether a player has won the game:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have defined the `game_won_by` function, which
    checks whether the board contains a combo of three identical indexes from the
    `combo_indices` variable to end the game.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Finally, create a game loop so that we can test the interaction between the
    computer player and the human player. We will conduct a brute-force search in
    the following examples:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we defined the function, which can be broken
    down into various parts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The first part is to initialize the board and fill it with empty signs (`board
    = EMPTY_SIGN * 9`). Then, we create a counter of the empty cell, which will help
    us to create a loop and determine the AI's turn.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The second part is to create a function for the player and the AI engine to
    play the game against each other. As soon as one player makes a move, the `empty_cell_count`
    variable will decrease by 1\. The loop will keep going until either the `game_won_by`
    function finds a winner or there are no more possible moves on the board.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Use the `game_loop` function to run the game:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output (partially shown) is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.8: Final output (partially shown) of the game'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16060_01_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.8: Final output (partially shown) of the game'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fUws2l](https://packt.live/3fUws2l).
  prefs: []
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3hVzjcT](https://packt.live/3hVzjcT).
    You must execute the entire Notebook in order to get the desired result.
  prefs: []
  type: TYPE_NORMAL
- en: By completing this exercise, you have seen that even an opponent who is playing
    randomly may win from time to time if their opponent makes a mistake.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.01: Generating All Possible Sequences of Steps in a Tic-Tac-Toe
    Game'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This activity will explore the combinatorial explosion that is possible when
    two players play randomly. We will be using a program that, building on the previous
    results, generates all possible sequences of moves between a computer player and
    a human player.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s assume that the human player may make any possible move. In this example,
    given that the computer player is playing randomly, we will examine the wins,
    losses, and draws belonging to two randomly playing players:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this activity:'
  prefs: []
  type: TYPE_NORMAL
- en: Reuse all the function codes of *Steps 2–9* from the previous *Exercise 1.02*,
    *Creating an AI with Random Behavior for the Tic-Tac-Toe Game*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function that maps the `all_moves_from_board` function on each element
    of a list of board spaces/squares. This way, we will have all of the nodes of
    a decision tree. The decision tree starts with `[ EMPTY_SIGN * 9 ]` and expands
    after each move.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a `filter_wins` function that takes finished games out of the list of
    moves and appends them in an array containing the board states won by the AI player
    and the opponent player.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a `count_possibilities` function that prints and returns the number
    of decision tree leaves that ended with a draw, were won by the first player,
    and were won by the second player:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We have up to nine steps in each state. In the 0th, 2nd, 4th, 6th, and 8th iterations,
    the AI player moves. In all other iterations, the opponent moves. We create all
    possible moves in all steps and take out finished games from the move list.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, execute the number of possibilities to experience the combinatorial
    explosion.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 322.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we've understood the significance of an intelligent agent. We also examined
    the game states for a game AI. Now, we will focus on how to create and introduce
    intelligence to an agent.
  prefs: []
  type: TYPE_NORMAL
- en: We will look at reducing the number of states in the state space, analyze the
    stages that a game board can undergo, and make the environment work in such a
    way that we win.
  prefs: []
  type: TYPE_NORMAL
- en: Have a look at the following exercise, where we'll teach an intelligent agent
    to win.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.03: Teaching the Agent to Win'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will see how the steps needed to win can be reduced. We
    will be making the agent that we developed in the previous section activity detect
    situations where it can win a game.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reuse the previous code from *Steps 2–6* from *Activity 1*, *Generating All
    Possible Sequences of Steps in a Tic-Tac-Toe Game*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define two functions, `ai_move` and `all_moves_from_board`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We create `ai_move` so that it returns a move that will consider its own previous
    moves. If the game can be won in that move, `ai_move` will select that move:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have defined the `ai_move` function, which
    will make the AI choose a winning move from a list of all the possible moves from
    the current state of the game if it's applicable. If not, it will still choose
    a random move.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, test the code snippet with a game loop. Whenever the AI has the opportunity
    to win the game, it will always place the `X` in the correct cell:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 1.9: The agent winning the game'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '](img/B16060_01_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure 1.9: The agent winning the game'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, count all the possible moves. To do this, we must change the `all_moves_from_board`
    function to include this improvement. We must do this so that, if the game is
    won by `AI_SIGN`, it will return that value:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have defined a function to generate all possible
    moves. As soon as we find a move that wins the game for the AI, we return it.
    We do not care whether the AI has multiple options to win the game in one move
    – we just return the first possibility. If the AI cannot win, we return all possible
    moves. Let's see what this means in terms of counting all of the possibilities
    at each step.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Enter the following function to find all the possibilities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/317pyTa](https://packt.live/317pyTa).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YnLpDS](https://packt.live/2YnLpDS).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With that, we have seen that the AI is still not winning most of the time. This
    means that we need to introduce more concepts to the AI to make it stronger. To
    teach the AI how to win, we need to teach it how to make defensive moves against
    losses.
  prefs: []
  type: TYPE_NORMAL
- en: Defending the AI against Losses
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the next activity, we will make the AI computer player play better compared
    to our previous exercise so that we can reduce the state space and the number
    of losses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.02: Teaching the Agent to Realize Situations When It Defends Against
    Losses'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this activity, we will force the computer to defend against a loss if the
    player puts their third sign in a row, column, or diagonal line:'
  prefs: []
  type: TYPE_NORMAL
- en: Reuse all the code from *Steps 2–6* from the previous, *Exercise 1.03*, *Teaching
    the Agent to Win*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function called `player_can_win` that takes all the moves from the
    board using the `all_moves_from_board` function and iterates over it using a variable
    called `next_move`. On each iteration, it checks whether the game can be won by
    the sign, and then it returns `true` or `false`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extend the AI's move so that it prefers making safe moves. A move is safe if
    the opponent cannot win the game in the next step.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test the new application. You will find that the AI has made the correct move.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Place this logic in the state space generator and check how well the computer
    player is doing by generating all possible games.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 325.
  prefs: []
  type: TYPE_NORMAL
- en: Once we complete this activity, we notice that despite our efforts to make the
    AI better, it can still lose in **962** ways. We will eliminate all these losses
    in the next activity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.03: Fixing the First and Second Moves of the AI to Make It Invincible'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this activity, we will be combining our previous activities by teaching
    the AI how to recognize both a win and a loss so that it can focus on finding
    moves that are more useful than others. We will be reducing the possible games
    by hardcoding the first and second moves:'
  prefs: []
  type: TYPE_NORMAL
- en: Reuse the code from *Steps 2–4* of the previous, *Activity 1.02*, *Teaching
    the Agent to Realize Situations When It Defends Against Losses*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Count the number of empty fields on the board and make a hardcoded move in case
    there are 9 or 7 empty fields. You can experiment with different hardcoded moves.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Occupying any corner, and then occupying the opposite corner, leads to no losses.
    If the opponent occupies the opposite corner, making a move in the middle results
    in no losses.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After fixing the first two steps, we only need to deal with 8 possibilities
    instead of 504\. We also need to guide the AI into a state where the hardcoded
    rules are enough so that it never loses a game.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 328.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s summarize the important techniques that we applied to reduce the state
    space so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Empirical simplification**: We accepted that the optimal first move is a
    corner move. We simply hardcoded a move instead of considering alternatives to
    focus on other aspects of the game. In more complex games, empirical moves are
    often misleading. The most famous chess AI victories often contain a violation
    of the common knowledge of chess grand masters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Symmetry**: After we started with a corner move, we noticed that positions
    1, 3, 7, and 9 were equivalent to the perspective of winning the game. Even though
    we didn''t take this idea further, we noticed that we could even rotate the table
    to reduce the state space even further and consider all four corner moves as the
    exact same move.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reduction in different permutations leading to the same state**: Suppose
    we can make the moves A or B and suppose our opponent makes move X, where X is
    not equal to either move A or B. If we explore the sequence A, X, B, and we start
    exploring the sequence B, X, then we don''t have to consider the sequence B, X,
    A. This is because the two sequences lead to the exact same game state, and we
    have already explored a state containing these three moves before, that is, A,
    X, and B. The order of the sequence doesn''t matter as it leads to the same result.
    This allows us to significantly reduce the number of possible moves.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forced moves for the player**: When a player collects two signs horizontally,
    vertically, or diagonally, and the third cell in the row is empty, we are forced
    to occupy that empty cell either to win the game or to prevent the opponent from
    winning the game. Forced moves may imply other forced moves, which reduces the
    state space even further.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forced moves for the opponent**: When a move from the opponent is clearly
    optimal, it does not make sense to consider scenarios where the opponent does
    not make the optimal move. When the opponent can win the game by occupying a cell,
    it does not matter whether we go on a long exploration of the cases when the opponent
    misses the optimal move. We save a lot less by not exploring cases when the opponent
    fails to prevent us from winning the game. This is because after the opponent
    makes a mistake, we will simply win the game.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Random move**: When we cannot decide and don''t have the capacity to search,
    we move randomly. Random moves are almost always inferior to a search-based educated
    guess, but at times, we have no other choice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heuristics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will formalize informed search techniques by defining and
    applying heuristics to guide our search. We will be looking at heuristics and
    creating them in the sections ahead.
  prefs: []
  type: TYPE_NORMAL
- en: Uninformed and Informed Searches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the tic-tac-toe example, we implemented a greedy algorithm that first focused
    on winning, and then focused on not losing. When it comes to winning the game
    immediately, the greedy algorithm is optimal because there is never a better step
    than winning the game. When it comes to not losing, it matters how we avoid the
    loss. Our algorithm simply choses a random safe move without considering how many
    winning opportunities we have created.
  prefs: []
  type: TYPE_NORMAL
- en: BFS and DFS are part of uninformed searching because they consider all possible
    states in the game, which can be very time-consuming. On the other hand, heuristic
    informed searches will explore the space of available states intelligently in
    order to reach the goal faster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Heuristics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want to make better decisions, we apply heuristics to guide the search
    in the right direction by considering long-term benefits. This way, we can make
    a more informed decision in the present based on what could happen in the future.
    This can also help us solve problems faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can construct heuristics as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In terms of the utility of making a move in the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of the utility of a given game state from the perspective of a player
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of the distance from our goal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heuristics are functions that evaluate a game state or a transition to a new
    game state based on their utility. Heuristics are the cornerstones of making a
    search problem informed.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will use utility and cost as negated terms. Maximizing utility
    and minimizing the cost of a move are considered synonyms.
  prefs: []
  type: TYPE_NORMAL
- en: A commonly used example of a heuristic evaluation function occurs in pathfinding
    problems. Suppose we are looking to reach a destination or a goal. Each step has
    an associated cost symbolizing the travel distance. Our goal is to minimize the
    cost of reaching the destination or goal (minimizing the travel distance).
  prefs: []
  type: TYPE_NORMAL
- en: One example of heuristic evaluation for solving this pathfinding problem will
    be to take the coordinates between the current state (position) and the goal (destination)
    and calculate the distance between these two points. The distance between two
    points is the length of the straight line connecting the points. This heuristic
    is called the **Euclidean distance** (as shown in the *Figure 1.10*).
  prefs: []
  type: TYPE_NORMAL
- en: Now, suppose we define our pathfinding problem in a maze, where we can only
    move up, down, left, or right. There are a few obstacles in the maze that block
    our moves, so using the Euclidean distance is not ideal. A better heuristic would
    be to use the Manhattan distance, which can be defined as the sum of the horizontal
    and vertical distances between the coordinates of the current state and the goal.
  prefs: []
  type: TYPE_NORMAL
- en: Admissible and Non-Admissible Heuristics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The two heuristics we just defined regarding pathfinding problems are called
    admissible heuristics when they're used on their given problem domain.
  prefs: []
  type: TYPE_NORMAL
- en: Admissible means that we may underestimate the cost of reaching the end state
    but that we never overestimate it. Later, we will explore an algorithm that finds
    the shortest path between the current state and the goal state. The optimal nature
    of this algorithm depends on whether we can define an admissible heuristic function.
  prefs: []
  type: TYPE_NORMAL
- en: An example of a non-admissible heuristic would be the Euclidean distance that's
    applied to a real-world map.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine that we want to move from point A to point B in the city of Manhattan.
    Here, the Euclidean distance will be the straight line between the two points,
    but, as we know, we cannot just go straight in a city such as Manhattan (*unless
    we can fly*). In this case, the Euclidean distance is underestimating the cost
    of reaching the goal. A better heuristic would be the Manhattan distance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.10: Euclidian (blue line) distance and Manhattan (red line) distance
    in the city of Manhattan'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_10.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.10: Euclidian distance (blue line) and Manhattan distance (red line)
    in the city of Manhattan'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The preceding map of Manhattan is sourced from Google Maps.
  prefs: []
  type: TYPE_NORMAL
- en: Since we overestimated the cost of traveling from the current node to the goal,
    the Euclidean distance is not admissible when we cannot move diagonally.
  prefs: []
  type: TYPE_NORMAL
- en: Heuristic Evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can create a heuristic evaluation for our tic-tac-toe game state from the
    perspective of the starting player by defining the utility of a move.
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic 1: Simple Evaluation of the Endgame'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s define a simple heuristic by evaluating a board. We can set the utility
    for the game as one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: +1, if the state implies that the AI player will win the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: -1, if the state implies that the AI player will lose the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0, if a draw has been reached or no clear winner can be identified from the
    current state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This heuristic is simple because anyone can look at a board and analyze whether
    a player is about to win.
  prefs: []
  type: TYPE_NORMAL
- en: The utility of this heuristic depends on whether we can play many moves in advance.
    Notice that we cannot even win the game within five steps. In *Activity 1.01*,
    *Generating All Possible Sequences of Steps in a Tic-Tac-Toe Game*, we saw that
    by the time we reach step five, we have 13,680 possible combinations leading to
    it. In most of these 13,680 cases, our heuristic returns zero as we can't identify
    a clear winner yet.
  prefs: []
  type: TYPE_NORMAL
- en: If our algorithm does not look deeper than these five steps, we are completely
    clueless on how to start the game. Therefore, we should invent a better heuristic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Heuristic 2: Utility of a Move'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let''s change the utility for the game as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Two AI signs in a row, column, or diagonal, and the third cell is empty: +1000
    for the empty cell.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The opponent has two signs in a row, column, or diagonal, and the third cell
    is empty: +100 for the empty cell.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'One AI sign in a row, column, or diagonal, and the other two cells are empty:
    +10 for the empty cells.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'No AI or opponent signs in a row, column, or diagonal: +1 for the empty cells.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Occupied cells get a value of minus infinity. In practice, due to the nature
    of the rules, -1 will also do.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why do we use a multiplicative factor of 10 for the first three rules compared
    to the fourth one? We do this because there are eight possible ways of making
    three in a row, column, and diagonal. So, even by knowing nothing about the game,
    we are certain that a lower-level rule may not accumulate to overriding a higher-level
    rule. In other words, we will never defend against the opponent's moves if we
    can win the game.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: As the job of our opponent is also to win, we can compute this heuristic from
    the opponent's point of view. Our task is to maximize this value, too, so that
    we can defend against the optimal plays of our opponent. This is the idea behind
    the Minmax algorithm as well, which will be covered later in this chapter. If
    we wanted to convert this heuristic into a heuristic that describes the current
    board, we could compute the heuristic value for all open cells and take the maximum
    of the values for the AI character so that we can maximize our utility.
  prefs: []
  type: TYPE_NORMAL
- en: For each board, we will create a utility matrix.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, consider the following board, with `O` signs as the player and
    `X` signs as the AI:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.11: Tic-tac-toe game state'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_11.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.11: Tic-tac-toe game state'
  prefs: []
  type: TYPE_NORMAL
- en: 'From here, we can construct its utility matrix shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.12: Tic-tac-toe game utility matrix'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_12.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.12: Tic-tac-toe game utility matrix'
  prefs: []
  type: TYPE_NORMAL
- en: On the second row, the left cell is not beneficial if we were to select it.
    Note that if we had a more optimal utility function, we would reward blocking
    the opponent.
  prefs: []
  type: TYPE_NORMAL
- en: The two cells of the third column both get a `10`-point boost for two in a row.
  prefs: []
  type: TYPE_NORMAL
- en: The top-right cell also gets `100` points for defending against the diagonal
    of the opponent.
  prefs: []
  type: TYPE_NORMAL
- en: From this matrix, evidently, we should choose the top-right move. At any stage
    of the game, we were able to define the utility of each cell; this was a static
    evaluation of the heuristic function.
  prefs: []
  type: TYPE_NORMAL
- en: We can use this heuristic to guide us toward an optimal next move or to give
    a more educated score on the current board by taking the maximum of these values.
    We have technically used parts of this heuristic in the form of hardcoded rules.
    Note, though, that the real utility of heuristics is not the static evaluation
    of a board, but the guidance it provides for limiting the search space.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.04: Tic-Tac-Toe Static Evaluation with a Heuristic Function'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, you will be performing a static evaluation on the tic-tac-toe
    game using a heuristic function.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reuse the code from *Steps 2–6* of *Activity 1.01*, *Generating All Possible
    Sequences of Steps in a Tic-Tac-Toe Game*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a function that takes the board as input and returns `0` if the cell
    is empty, and `-1` if it''s not empty:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, create a function that takes the utility vector of possible moves, takes
    three indices inside the utility vector representing a triple, and returns a function,
    as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, the returned function will expect a `points`
    parameter and the `utilities` vector as input and will add points to each cell
    in (`i`, `j`, `k`), as long as the original value of that cell is non-negative
    (`>=0`). In other words, we increased the utility of empty cells only.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, create the utility matrix belonging to any board constellation where you
    will add the `generate_add_score` function defined previously to update the score.
    You will also implement the rules that we discussed prior to this activity. These
    rules are as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Two AI signs in a row, column, or diagonal, and the third cell is empty: +1000
    for the empty cell.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The opponent has two signs in a row, column, or diagonal, and the third cell
    is empty: +100 for the empty cell.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'One AI sign in a row, column, or diagonal, and the other two cells are empty:
    +10 for the empty cells.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'No AI or opponent signs in a row, column, or diagonal: +1 for the empty cells.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s create the utility matrix now:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a function that selects the move with the highest utility value. If
    multiple moves have the same utility, the function returns both moves:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, run the application, as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/2VpGyAv](https://packt.live/2VpGyAv).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/2YnyO3K](https://packt.live/2YnyO3K).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By completing this exercise, we have observed that the AI is underperforming
    compared to our previous activity, *Activity 1.03*, *Fixing the First and Second
    Moves of the AI to Make It Invincible*. In this situation, hardcoding the first
    two moves was better than setting up the heuristic, but this is because we haven't
    set up the heuristic properly.
  prefs: []
  type: TYPE_NORMAL
- en: Using Heuristics for an Informed Search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have not experienced the real power of heuristics yet as we made moves without
    the knowledge of the effects of our future moves, thereby effecting reasonable
    play from our opponents.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, a more accurate heuristic leads to more losses than simply hardcoding
    the first two moves in the game. Note that in the previous section, we selected
    these two moves based on the statistics we generated based on running the game
    with fixed first moves. This approach is essentially what heuristic search should
    be all about.
  prefs: []
  type: TYPE_NORMAL
- en: Types of Heuristics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Static evaluation cannot compete with generating hundreds of thousands of future
    states and selecting a play that maximizes our rewards. This is because our heuristics
    are not exact and are likely not admissible either.
  prefs: []
  type: TYPE_NORMAL
- en: We saw in the preceding exercise that heuristics are not always optimal. We
    came up with rules that allowed the AI to always win the game or finish with a
    draw. These heuristics allowed the AI to win very frequently, at the expense of
    losing in a few cases. A heuristic is said to be admissible if we underestimate
    the utility of a game state, but we never overestimate it.
  prefs: []
  type: TYPE_NORMAL
- en: In the tic-tac-toe example, we likely overestimated the utility in a few game
    states, and why is that? Because we ended up with a loss 12 times. A few of the
    game states that led to a loss had a maximum heuristic score. To prove that our
    heuristic is not admissible, all we need to do is find a potentially winning game
    state that we ignored while choosing a game state that led to a loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two more features that describe heuristics, that is, optimal and
    complete:'
  prefs: []
  type: TYPE_NORMAL
- en: Optimal heuristics always find the best possible solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Complete heuristics has two definitions, depending on how we define the problem
    domain. In a loose sense, a heuristic is said to be complete if it always finds
    a solution. In a strict sense, a heuristic is said to be complete if it finds
    all possible solutions. Our tic-tac-toe heuristic is not complete because we ignored
    many possible winning states on purpose, favoring a losing state.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, defining an accurate heuristic requires a lot of details and
    thinking in order to obtain a perfect AI agent. If you are not correctly estimating
    the utility in the game states, then you can end up with an AI underperforming
    hardcoded rules.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we'll look at a better approach to executing the shortest
    pathfinding between the current state and the goal state.
  prefs: []
  type: TYPE_NORMAL
- en: Pathfinding with the A* Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first two sections, we learned how to define an intelligent agent and
    how to create a heuristic that guides the agent toward a desired state. We learned
    that this was not perfect because, at times, we ignored a few winning states in
    favor of a few losing states.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will learn about a structured and optimal approach so that we can execute
    a search for finding the shortest path between the current state and the goal
    state by using the A* ("*A star*" instead of "*A asterisk*") algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a look at the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.13: Finding the shortest path in a maze'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_13.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.13: Finding the shortest path in a maze'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a human, it is simple to find the shortest path by merely looking at the
    figure. We can conclude that there are two potential candidates for the shortest
    path: route one starts upward, and route two starts to the left. However, the
    AI does not know about these options. In fact, the most logical first step for
    a computer player would be moving to the square denoted by the number `3` in the
    following figure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Why? Because this is the only step that decreases the distance between the
    starting state and the goal state. All the other steps initially move away from
    the goal state:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.14: Shortest pathfinding game board with utilities'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_14.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.14: Shortest pathfinding game board with utilities'
  prefs: []
  type: TYPE_NORMAL
- en: In the next exercise, we'll see how the BFS algorithm performs on the pathfinding
    problem before introducing you to the A* algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise 1.05: Finding the Shortest Path Using BFS'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this exercise, we will be finding the shortest path to our goal using the
    BFS algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will help you to complete this exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Begin by importing the `math` library:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, describe the board, the initial state, and the final state using Python.
    Create a function that returns a list of possible successors. Use tuples, where
    the first coordinate denotes the row number from `1` to `7` and the second coordinate
    denotes the column number from `1` to `9`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, use array comprehension to generate the successor states, as shown in
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The function is generating all the possible moves from a current field that
    does not end up being blocked by an obstacle. We also add a filter to exclude
    moves that return to a field we have visited already to avoid infinite loops.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, implement the initial costs, as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, implement the updated costs using `costs`, `current_node`, and `successor_node`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, implement the BFS algorithm to search the state of the tree and save
    the result in a variable called `bfs`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have reused the `bfs_tree` function that we
    looked at earlier in the *Breadth First Search* section of this book. However,
    we added the `update_costs` function to update the costs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Here, you can see that a simple BFS algorithm successfully determines the cost
    from the start node to any nodes, including the target node.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now, measure the number of steps required to find the goal node and save the
    result in the `bfs_v` variable, as shown in the following code snippet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In the preceding code snippet, we have added a step counter variable in order
    to print the number of steps at the end of the search.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To access the source code for this specific section, please refer to [https://packt.live/3fMYwEt](https://packt.live/3fMYwEt).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can also run this example online at [https://packt.live/3duuLqp](https://packt.live/3duuLqp).
    You must execute the entire Notebook in order to get the desired result.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In this exercise, we used the BFS algorithm to find the shortest path to the
    goal. It took BFS `110` steps to reach the goal. Now, we will learn about an algorithm
    that can find the shortest path from the start node to the goal node: the A* algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the A* Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A* is a complete and optimal heuristic search algorithm that finds the shortest
    possible path between the current game state and the winning state. The definition
    of complete and optimal in this state are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Complete means that A* always finds a solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimal means that A* will find the best solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To set up the A* algorithm, we need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An initial state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A description of the goal states
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admissible heuristics to measure progress toward the goal state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A way to generate the next steps toward the goal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Once the setup is complete, we execute the A* algorithm using the following
    steps on the initial state:'
  prefs: []
  type: TYPE_NORMAL
- en: We generate all possible next steps.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We store these children in the order of their distance from the goal.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We select the child with the best score first and repeat these three steps on
    the child with the best score as the initial state. This is the shortest path
    to get to a node from the starting node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let''s take, for example, the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.15: Tree with heuristic distance'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_15.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.15: Tree with heuristic distance'
  prefs: []
  type: TYPE_NORMAL
- en: The first step will be to generate all the possible moves from the origin, `A`,
    which is moving from `A` to `B (A,B)` or to `C (A,C)`.
  prefs: []
  type: TYPE_NORMAL
- en: The second step is to use the heuristic (the distance) to order the two possible
    moves, `(A,B)`, with `10`, which is shorter compared to `(A,C)` with `100`.
  prefs: []
  type: TYPE_NORMAL
- en: The third step is to choose the shortest heuristic, which is `(A,B)`, and move
    to `B`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will repeat the same steps with `B` as the origin.
  prefs: []
  type: TYPE_NORMAL
- en: At the end, we will reach the goal `F` with the path (`A,B,D,F`) with a cumulative
    heuristic of 24\. If we were following another path, such as (`A,B,E,F`), the
    cumulative heuristic will be 30, which is higher than the shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: We did not even look at (`A,C,F`) as it was already way over the shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: 'In pathfinding, a good heuristic is the Euclidean distance. If the current
    node is (x, y) and the goal node is (u, v), then we have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*distance_from_end( node ) = sqrt( abs( x – u ) ** 2 + abs( y – v ) ** 2 )*'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `distance_from_end(node)` is an admissible heuristic estimation showing
    how far we are from the goal node.
  prefs: []
  type: TYPE_NORMAL
- en: 'We also have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`sqrt` is the square root function. Do not forget to import it from the `math`
    library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`abs` is the absolute value function, that is, `abs( -2 ) = abs( 2 ) = 2`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`x ** 2` is `x` raised to the second power.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use the `distance_from_start` matrix to store the distances from the
    start node. In the algorithm, we will refer to this cost matrix as `distance_from_start(n1)`.
    For any node, `n1`, that has coordinates `(x1, y1)`, this distance is equivalent
    to `distance_from_start[x1][y1]`.
  prefs: []
  type: TYPE_NORMAL
- en: We will use the `succ(n)` notation to generate a list of successor nodes from
    `n`.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Have a look at the pseudocode of the algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'Regarding the retrieval of the shortest path, we can use the `costs` matrix.
    This matrix contains the distance of each node on the path from the start node.
    As cost always decreases when walking backward, all we need to do is start with
    the end node and walk backward greedily toward decreasing costs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'A* shines when we have one start state and one goal state. The complexity of
    the A* algorithm is `O( E )`, where `E` stands for all possible edges in the field.
    In our example, we have up to four edges leaving any node: up, down, left, and
    right.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'To sort the frontier list in the proper order, we must use a special Python
    data structure: a priority queue.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Have a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The data still contains the second item. If you type in the following command,
    you will be able to see it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: Why is it important that the heuristic being used by the algorithm is admissible?
  prefs: []
  type: TYPE_NORMAL
- en: Because this is how we guarantee the optimal nature of the algorithm. For any
    node `x`, we are measuring the sum of the distances from the start node to `x`.
    This is the estimated distance from `x` to the end node. If the estimation never
    overestimates the distance from `x` to the end node, we will never overestimate
    the total distance. Once we are at the goal node, our estimation is zero, and
    the total distance from the start to the end becomes an exact number.
  prefs: []
  type: TYPE_NORMAL
- en: We can be sure that our solution is optimal because there are no other items
    in the priority queue that have a lower estimated cost. Given that we never overestimate
    our costs, we can be sure that all of the nodes in the frontier of the algorithm
    have either similar total costs or higher total costs than the path we found.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we can see how to implement the A* algorithm to find
    the path with the lowest cost:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 1.16: Shortest pathfinding game board'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_16.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.16: Shortest pathfinding game board'
  prefs: []
  type: TYPE_NORMAL
- en: 'We import `math` and `heapq`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Next, we'll reuse the initialization code from *Steps 2–5* of the previous,
    *Exercise 1.05*, *Finding the Shortest Path Using BFS*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'We have omitted the function to update costs because we will do so within the
    A* algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we need to initialize the A* algorithm''s frontier and internal lists.
    For `frontier`, we will use a Python `PriorityQueue`. Do not execute this code
    directly; we will use these four lines inside the A* search function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, it is time to implement a heuristic function that measures the distance
    between the current node and the goal node using the algorithm we saw in the heuristic
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: 'The final step will be to translate the A* algorithm into functioning code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: There are a few differences between our implementation and the original algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: We defined a `distance_from_start` function to make it easier and more semantic
    to access the `costs` matrix. Note that we number the node indices starting with
    1, while in the matrix, indices start with zero. Therefore, we subtract 1 from
    the node values to get the indices.
  prefs: []
  type: TYPE_NORMAL
- en: When generating the successor nodes, we automatically ruled out nodes that are
    in the internal set. `successors = succ(node, internal)` makes sure that we only
    get the neighbors whose examination is not closed yet, meaning that their score
    is not necessarily optimal.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, we may skip the step check since internal nodes will never end up
    in `succ(n)`.
  prefs: []
  type: TYPE_NORMAL
- en: Since we are using a priority queue, we must determine the estimated priority
    of nodes before inserting them. However, we will only insert the node in the frontier
    if we know that this node does not have an entry with a lower score.
  prefs: []
  type: TYPE_NORMAL
- en: It may happen that nodes are already in the frontier queue with a higher score.
    In this case, we remove this entry before inserting it into the right place in
    the priority queue. When we find the end node, we simply return the length of
    the shortest path instead of the path itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'To follow what the A* algorithm does, execute the following example code and
    observe the logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: Here, we build the `astar_verbose` function by reusing the code from the `astar`
    function and adding print functions in order to create a log.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.17: Astar function logs'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_17.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.17: Astar function logs'
  prefs: []
  type: TYPE_NORMAL
- en: We have seen that the A* search returns the right values. The question is, how
    can we reconstruct the whole path?
  prefs: []
  type: TYPE_NORMAL
- en: 'For this, we remove the `print` statements from the code for clarity and continue
    with the A* algorithm that we implemented in the previous step. Instead of returning
    the length of the shortest path, we have to return the path itself. We will write
    a function that extracts this path by walking backward from the end node, analyzing
    the `costs` matrix. Do not define this function globally yet. We define it as
    a local function in the A* algorithm that we created previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we''ve seen how to deconstruct the path, let''s return it inside the
    A* algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we have reused the `a-star` function defined
    previously with the notable difference of adding the `get_shortest_path` function.
    Then, we use this function to replace the priority queue since we want the algorithm
    to always choose the shortest path.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.18: Output showing the priority queue'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_18.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.18: Output showing the priority queue'
  prefs: []
  type: TYPE_NORMAL
- en: Technically, we do not need to reconstruct the path from the `costs` matrix.
    We could record the parent node of each node in the matrix and simply retrieve
    the coordinates to save a bit of searching.
  prefs: []
  type: TYPE_NORMAL
- en: We are not expecting you to understand all the preceding script as it is quite
    advanced, so we are going to use a library that will simplify it for us.
  prefs: []
  type: TYPE_NORMAL
- en: A* Search in Practice Using the simpleai Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `simpleai` library is available on GitHub and contains many popular AI tools
    and techniques.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can access this library at [https://github.com/simpleai-team/simpleai](https://github.com/simpleai-team/simpleai).
    The documentation of the `simpleai` library can be accessed here: [http://simpleai.readthedocs.io/en/latest/](http://simpleai.readthedocs.io/en/latest/).
    To access the `simpleai` library, first, you have to install it.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `simpleai` library can be installed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'Once `simpleai` has been installed, you can import classes and functions from
    the `simpleai` library into a Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '`SearchProblem` gives you a frame for defining any search problems. The `astar`
    import is responsible for executing the A* algorithm inside the search problem.'
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, we have not used classes in the previous code examples to focus
    on the algorithms in a plain old style without any clutter.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the `simpleai` library will force us to use classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To describe a search problem, you need to provide the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`constructor`: This initializes the state space, thus describing the problem.
    We will make the `Size`, `Start`, `End`, and `Obstacles` values available in the
    object by adding it to these as properties. At the end of the constructor, do
    not forget to call the super constructor, and do not forget to supply the initial
    state.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`actions( state )`: This returns a list of actions that we can perform from
    a given state. We will use this function to generate new states. Semantically,
    it would make more sense to create action constants such as UP, DOWN, LEFT, and
    RIGHT, and then interpret these action constants as a result. However, in this
    implementation, we will simply interpret an action as "move to `(x, y)`", and
    represent this command as `(x, y)`. This function contains more-or-less the logic
    that we implemented in the `succ` function previously, except that we won''t filter
    the result based on a set of visited nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`result( state0, action)`: This returns the new state of action that was applied
    to `state0`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`is_goal( state )`: This returns `true` if the state is a goal state. In our
    implementation, we will have to compare the state to the end state coordinates.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cost( self, state, action, newState )`: This is the cost of moving from `state`
    to `newState` via `action`. In our example, the cost of a move is uniformly 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Have a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we used the `simpleai` package to simplify our
    code. We also had to define a class called `ShortestPath` in order to use the
    package.
  prefs: []
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.19: Output showing the queue using the simpleai library'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_19.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.19: Output showing the queue using the simpleai library'
  prefs: []
  type: TYPE_NORMAL
- en: The `simpleai` library made the search description a lot easier than the manual
    implementation. All we need to do is define a few basic methods, and then we have
    access to an effective search implementation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will be looking at the Minmax algorithm, along with
    pruning.
  prefs: []
  type: TYPE_NORMAL
- en: Game AI with the Minmax Algorithm and Alpha-Beta Pruning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the first two sections, we saw how hard it was to create a winning strategy
    for a simple game such as tic-tac-toe. The previous section introduced a few structures
    for solving search problems with the A* algorithm. We also saw that tools such
    as the `simpleai` library help us to reduce the effort we put in to describe a
    task with code.
  prefs: []
  type: TYPE_NORMAL
- en: We will use all of this knowledge to supercharge our game AI skills and solve
    more complex problems.
  prefs: []
  type: TYPE_NORMAL
- en: Search Algorithms for Turn-Based Multiplayer Games
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Turn-based multiplayer games such as tic-tac-toe are similar to pathfinding
    problems. We have an initial state and we have a set of end states where we win
    the game.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge with turn-based multiplayer games is the combinatorial explosion
    of the opponent's possible moves. This difference justifies treating turn-based
    games differently to a regular pathfinding problem.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in the tic-tac-toe game, from an empty board, we can select one
    of the nine cells and place our sign there, assuming we start the game. Let's
    denote this algorithm with the `succ` function, symbolizing the creation of successor
    states. Consider we have the initial state denoted by `Si`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we have `succ(Si) returns [ S1, S2, ..., Sn ]`, where `S1, S2, ..., Sn`
    are successor states:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.20: Tree diagram denoting the successor states of the function'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_20.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.20: Tree diagram denoting the successor states of the function'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, the opponent also makes a move, meaning that from each possible state,
    we have to examine even more states:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.21: Tree diagram denoting parent-successor relationships'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_21.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.21: Tree diagram denoting parent-successor relationships'
  prefs: []
  type: TYPE_NORMAL
- en: 'The expansion of possible future states stops in one of two cases:'
  prefs: []
  type: TYPE_NORMAL
- en: The game ends.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to resource limitations, it is not worth explaining any more moves beyond
    a certain depth for the state of a certain utility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once we stop expanding, we have to make a static heuristic evaluation of the
    state. This is exactly what we did previously with the A* algorithm, when choosing
    the best move; however, we never considered future states.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, even though our algorithm became more and more complex, without using
    the knowledge of possible future states, we had a hard time detecting whether
    our current move would likely be a winning one or a losing one.
  prefs: []
  type: TYPE_NORMAL
- en: The only way for us to take control of the future was to change our heuristic
    while knowing how many games we would win, lose, or tie in the future. We could
    either maximize our wins or minimize our losses. We still did not dig deep enough
    to see whether our losses could have been avoided through smarter play on the
    part of the AI.
  prefs: []
  type: TYPE_NORMAL
- en: All these problems can be avoided by digging deeper into future states and recursively
    evaluating the utility of the branches.
  prefs: []
  type: TYPE_NORMAL
- en: To consider future states, we will learn about the **Minmax** algorithm and
    its variant, the **NegaMax** algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: The Minmax Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Suppose there is a game where a heuristic function can evaluate a game state
    from the perspective of the AI player. For instance, we used a specific evaluation
    for the tic-tac-toe exercise:'
  prefs: []
  type: TYPE_NORMAL
- en: +1,000 points for a move that won the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: +100 points for a move preventing the opponent from winning the game
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: +10 points for a move creating two in a row, column, or diagonal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: +1 point for a move creating one in a row, column, or diagonal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This static evaluation is straightforward to implement on any node. The problem
    is that as we go deep into the tree of all possible future states, we do not yet
    know what to do with these scores. This is where the Minmax algorithm comes into
    play.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we construct a tree with each possible move that could be performed
    by each player up to a certain depth. At the bottom of the tree, we evaluate each
    option. For the sake of simplicity, let''s assume that we have a search tree that
    appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.22: Example of a search tree up to a certain depth'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_22.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.22: Example of a search tree up to a certain depth'
  prefs: []
  type: TYPE_NORMAL
- en: The AI plays with `X`, and the player plays with `O`. A node with `X` means
    that it is `X`'s turn to move. A node with `O` means it is `O`'s turn to act.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose there are all `O` leaves at the bottom of the tree, and we didn''t
    compute any more values because of resource limitations. Our task is to evaluate
    the utility of the leaves:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.23: Example of a search tree with possible moves'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_23.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.23: Example of a search tree with possible moves'
  prefs: []
  type: TYPE_NORMAL
- en: 'We have to select the best possible move from our perspective because our goal
    is to maximize the utility of our move. This aspiration to maximize our gains
    represents the Max part in the Minmax algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.24: Example of a search tree with the best possible move'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_24.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.24: Example of a search tree with the best possible move'
  prefs: []
  type: TYPE_NORMAL
- en: 'If we move one level higher, it is our opponent''s turn to act. Our opponent
    picks the value that is the least beneficial to us. This is because our opponent''s
    job is to minimize our chances of winning the game. This is the Min part of the
    Minmax algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.25: Minimizing the chances of winning the game'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_25.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.25: Minimizing the chances of winning the game'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the top, we can choose between a move with utility `101` and another move
    with utility `21`. Since we are maximizing our value, we should pick `101`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.26: Maximizing the chances of winning the game'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_26.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.26: Maximizing the chances of winning the game'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how we can implement this idea:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'This is the Minmax algorithm. We evaluate the leaves from our perspective.
    Then, from the bottom up, we apply a recursive definition:'
  prefs: []
  type: TYPE_NORMAL
- en: Our opponent plays optimally by selecting the worst possible node from our perspective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We play optimally by selecting the best possible node from our perspective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We need a few more things in order to understand the application of the Minmax
    algorithm on the tic-tac-toe game:'
  prefs: []
  type: TYPE_NORMAL
- en: '`is_end_state` is a function that determines whether the state should be evaluated
    instead of digging deeper, either because the game has ended, or because the game
    is about to end using forced moves. Using our utility function, it is safe to
    say that as soon as we reach a score of 1,000 or higher, we have effectively won
    the game. Therefore, `is_end_state` can simply check the score of a node and determine
    whether we need to dig deeper.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the `successors` function only depends on the state, it is practical
    to pass the information of whose turn it is to make a move. Therefore, do not
    hesitate to add an argument if needed; you do not have to follow the pseudo code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want to minimize our efforts in implementing the Minmax algorithm. For this
    reason, we will evaluate existing implementations of the algorithm. We will also
    simplify the duality of the description of the algorithm in the remainder of this
    section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The suggested utility function is quite accurate compared to the utility functions
    that we could be using in this algorithm. In general, the deeper we go, the less
    accurate our utility function has to be. For instance, if we could go nine steps
    deep into the tic-tac-toe game, all we would need to do is award 1 point for a
    win, 0 for a draw, and -1 point for a loss, given that, in nine steps, the board
    is complete, and we have all of the necessary information to make the evaluation.
    If we could only look four steps deep, this utility function would be completely
    useless at the start of the game because we need at least five steps to win the
    game.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Minmax algorithm could be optimized further by pruning the tree. Pruning
    is an act where we get rid of branches that do not contribute to the result. By
    eliminating unnecessary computations, we save precious resources that could be
    used to go deeper into the tree.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing the Minmax Algorithm with Alpha-Beta Pruning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The last consideration in the previous thought process primed us to explore
    possible optimizations by reducing the search space by focusing our attention
    on nodes that matter.
  prefs: []
  type: TYPE_NORMAL
- en: There are a few constellations of nodes in the tree where we can be sure that
    the evaluation of a subtree does not contribute to the end result. We will find,
    examine, and generalize these constellations to optimize the Minmax algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s examine pruning through the previous example of nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.27: Search tree demonstrating pruning nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_27.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.27: Search tree demonstrating pruning nodes'
  prefs: []
  type: TYPE_NORMAL
- en: After computing the nodes with values `101`, `23`, and `110`, we can conclude
    that two levels above, the value `101` will be chosen. Why?
  prefs: []
  type: TYPE_NORMAL
- en: Suppose X <= 110\. Here, the maximum of `110` and X will be chosen, which is
    `110`, and X will be omitted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose X > 110\. Here, the maximum of `110` and X is X. One level above, the
    algorithm will choose the lowest value out of the two. The minimum of `101` and
    X will always be `101`, because X > 110\. Therefore, X will be omitted a level
    above.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is how we prune the tree.
  prefs: []
  type: TYPE_NORMAL
- en: On the right-hand side, suppose we computed branches `10` and `21`. Their maximum
    is `21`. The implication of computing these values is that we can omit the computation
    of nodes Y1, Y2, and Y3, and we know that the value of Y4 is less than or equal
    to `21`. Why?
  prefs: []
  type: TYPE_NORMAL
- en: The minimum of `21` and Y3 is never greater than `21`. Therefore, Y4 will never
    be greater than `21`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now choose between a node with utility `101` and another node with a
    maximal utility of `21`. It is obvious that we have to choose the node with utility
    `101`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.28: Example of pruning a tree'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_28.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.28: Example of pruning a tree'
  prefs: []
  type: TYPE_NORMAL
- en: This is the idea behind alpha-beta pruning. We prune subtrees that we know are
    not going to be needed.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see how we can implement alpha-beta pruning in the Minmax algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will add an alpha and a beta argument to the argument list of Minmax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we added the `alpha` and `beta` arguments to
    the `MinMax` function in order to calculate the new alpha score as being the maximum
    between `alpha` and `beta` in the maximizing branch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need to do the same with the minimizing branch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding code snippet, we added the new beta score in the `else` branch,
    which is the minimum between `alpha` and `beta` in the minimizing branch.
  prefs: []
  type: TYPE_NORMAL
- en: We are done with the implementation. It is recommended that you mentally execute
    the algorithm on our example tree step by step to get a feel for the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important piece is missing that has prevented us from doing the execution
    properly: the initial values for `alpha` and `beta`. Any number that is outside
    the possible range of utility values will do. We will use positive and negative
    infinity as initial values to call the Minmax algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: In the next section, we will look at the DRYing technique while using the NegaMax
    algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: DRYing Up the Minmax Algorithm – the NegaMax Algorithm
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Minmax algorithm works great, especially with alpha-beta pruning. The only
    problem is that we have `if` and `else` branches in the algorithm that essentially
    negates each other.
  prefs: []
  type: TYPE_NORMAL
- en: As we know, in computer science, there is DRY code and WET code. **DRY** stands
    for **Don't Repeat Yourself**. **WET** stands for **Write Everything Twice**.
    When we write the same code twice, we double our chance of making a mistake while
    writing it. We also double our chances of each maintenance effort being executed
    in the future. Hence, it is better to reuse our code.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing the Minmax algorithm, we always compute the utility of a node
    from the perspective of the AI player. This is why we have to have a utility-maximizing
    branch and a utility-minimizing branch in the implementations that are dual in
    nature. As we prefer clean code that describes the problem only once, we could
    get rid of this duality by changing the point of view of the evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever the AI player's turn comes, nothing changes in the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever the opponent's turn comes, we negate the perspective. Minimizing the
    AI player's utility is equivalent to maximizing the opponent's utility.
  prefs: []
  type: TYPE_NORMAL
- en: 'This simplifies the Minmax algorithm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: There are necessary conditions for using the NegaMax algorithm; for instance,
    the evaluation of the board state has to be symmetric. If a game state is worth
    +20 from the first player's perspective, it is worth -20 from the second player's
    perspective. Therefore, we often normalize the scores around zero.
  prefs: []
  type: TYPE_NORMAL
- en: Using the EasyAI Library
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have already looked at the `simpleai` library, which helped us execute searches
    on pathfinding problems. Now, we will use the `EasyAI` library, which can easily
    handle an AI search on two-player games, reducing the implementation of the tic-tac-toe
    problem to writing a few functions on scoring the utility of a board and determining
    when the game ends.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install `EasyAI`, type the following command in Jupyter Notebook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: You can read the documentation of the library on GitHub at [https://github.com/Zulko/easyAI](https://github.com/Zulko/easyAI).
  prefs: []
  type: TYPE_NORMAL
- en: 'Activity 1.04: Connect Four'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this activity, we will practice using the `EasyAI` library and develop a
    heuristic. We will be using the game *Connect Four* for this. The game board is
    seven cells wide and seven cells high. When you make a move, you can only select
    the column in which you drop your token. Then, gravity pulls the token down to
    the lowest possible empty cell. Your objective is to connect four of your own
    tokens horizontally, vertically, or diagonally, before your opponent does, or
    you run out of empty spaces.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: The rules of the game can be found at [https://en.wikipedia.org/wiki/Connect_Four](https://en.wikipedia.org/wiki/Connect_Four).
  prefs: []
  type: TYPE_NORMAL
- en: Open a new Jupyter Notebook file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write the `init` method to generate all the possible winning combinations in
    the game and save them for future use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write a function to enumerate all the possible moves. Then, for each column,
    check whether there is an unoccupied field. If there is one, make the column a
    possible move.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function to make a move (it will be similar to the possible move function),
    and then check the column of the move and find the first empty cell, starting
    from the bottom.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Reuse the lose function from the tic-tac-toe example.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Implement the show method that prints the board and try out the game.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The solution to this activity can be found on page 330.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The expected output is this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.29: Expected output for the game Connect Four'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16060_01_29.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1.29: Expected output for the game Connect Four'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how AI can be used to enhance or substitute human
    abilities such as to listen, speak, understand language, store and retrieve information,
    think, see, and move.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we moved on to learning about intelligent agents and the way they interact
    with the environment, solving a problem in a seemingly intelligent way to pursue
    a goal.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we introduced Python and learned about its role in AI. We looked at a
    few important Python libraries for developing AI and prepared data for the intelligent
    agents. We then created a tic-tac-toe game based on predefined rules. We quantified
    these rules into a number, a process that we call heuristics. We learned how to
    use heuristics in the A* search algorithm to find an optimal solution to a problem.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we got to know about the Minmax and NegaMax algorithms so that the
    AI could win two-player games. In the next chapter, you will be introduced to
    regression.
  prefs: []
  type: TYPE_NORMAL
