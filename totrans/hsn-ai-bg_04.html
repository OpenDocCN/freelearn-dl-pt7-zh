<html><head></head><body><div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Your First Artificial Neural Networks</h1>
                </header>
            
            <article>
                
<p class="mce-root"> In the past few chapters, we learned about the basics of machine learning, and how to get our environments set up for creating <strong>Artificial Intelligence</strong> (<strong>AI</strong>) applications. Now that we've learned the basics, it's time to put our knowledge to use.</p>
<p class="mce-root">In this chapter, we'll focus on:</p>
<ul>
<li class="mce-root">How to construct basic AI applications, starting with constructing a basic feedforward network with TensorFlow</li>
<li class="mce-root">We'll discuss the essential elements of <strong>Artificial Neural Networks</strong> (<strong>ANNs</strong>), and then code up an example of a basic feedforward network to illustrate this</li>
</ul>
<p> ANNs allow us to define complex non-linear problems, and as we delve into the mechanics of true deep learning, you'll begin to see how powerful AI applications can be ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Technical requirements</h1>
                </header>
            
            <article>
                
<p>We'll be utilizing the GPU-enabled TensorFlow environment that we developed in the previous chapter. You will need: </p>
<ul>
<li>Python 3.6</li>
<li>GPU TensorFlow</li>
<li>PyTorch</li>
</ul>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Network building blocks</h1>
                </header>
            
            <article>
                
<p>The most basic form of an ANN is known as a <strong>feedforward network</strong>, sometimes called a <strong>multi-layer perceptron</strong>. These models, while simplistic in nature, contain the core building blocks for the various types of ANN that we will examine going forward. </p>
<p><span>In essence, a feedforward neural network is nothing more than a <strong>directed graph</strong>; there are no loops of recurrent connections between the layers, and information simply flows forward through the graph. Traditionally, when these networks are illustrated, you'll see them represented as in </span><span>the f</span>ollowing diagram<span>:</span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1370 image-border" src="Images/a351a10d-ed3d-4470-8556-4b53f75d5c7f.png" style="width:40.25em;height:23.00em;" width="979" height="559"/></div>
<div class="CDPAlignCenter CDPAlign packt_figref">A feedforward neural network</div>
<p>In this most basic form, ANNs are typically ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Network layers</h1>
                </header>
            
            <article>
                
<p>The <strong>input layer</strong> consists of the<span> </span>features<span> </span>that we are passing to our neural network. If we had, say, a <em>10 x 10</em> pixel image as our input, we would have 100 input units. Nothing is actually done in the input layer, but it is the connection between the input and hidden layers that is important. </p>
<p>Our input layer connections perform a linear transformation on the input vectors, and sends the results of that transformation to the hidden layer, through which the results are transformed through the<span> </span><strong>activation function</strong>. Once we perform this computation, we pass the results onto the hidden layer. <strong>Hidden layers</strong> are where our activation functions live, and our network can have any number of them. Hidden layers are so called such because they compute values that are not seen in the training set; their job is to transform the network's input into something that the output layer can use. They allow us to learn more complicated features in a dataset.</p>
<p>The output of the last hidden layer gets sent to the final layer, the <strong>output layer</strong>. The output layer is the final layer in our network; it transforms the results of the hidden layers into whatever you'd like the output to be binary classification, real numbers, and so on. We do this by utilizing special types of activation function. In general:</p>
<ul>
<li>
<p>For classification problems, we'll often use a function called a<span> </span><strong>softmax</strong></p>
</li>
<li>
<p>For regression tasks, we'll use a<span> </span><strong>linear</strong><span> </span>function</p>
</li>
</ul>
<p>Your choice of activation function really depends on your loss function, as we'd like to make the derivative of the loss function easy to compute during training.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Naming and sizing neural networks</h1>
                </header>
            
            <article>
                
<p>We refer to networks by the amount of<span> </span><strong>fully connected layers</strong><span> </span>that they have, minus the input layer. The network in the following figure, therefore, would be a two-layer neural network. A single-layer network would not have an input layer; sometimes, you'll hear logistic regressions described as a special case of a single-layer network, one utilizing a<span> </span><strong>sigmoid</strong><span> </span>activation function. When we talk about deep<em> </em>neural networks in particular, we are referring to networks that have several hidden layers as shown in the following diagram:</p>
<p class="CDPAlignCenter CDPAlign"> <img src="Images/f9f29bc5-4dc8-45bc-97c9-c26607fb64dc.png" style="width:31.08em;height:18.00em;" width="1380" height="804"/></p>
<p>Networks are typically sized in terms of the number of parameters that they have ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Setting up network parameters in our MNIST example</h1>
                </header>
            
            <article>
                
<p>Looking at our MNIST example, we can now set up our overall network parameters. We'll define <kbd>input_layer_size</kbd> as the size of the incoming data, <kbd>784</kbd>. This will give us the number of neurons in the input layer. The parameters <kbd>hidden_one</kbd> and <kbd>hidden_two</kbd> will define the amount of neurons in the hidden layer. Meanwhile, <kbd>number_classes</kbd> constructs the output layer as the potential number of classes that a piece of input data could be classified as:</p>
<pre class="mce-root">## Size of the input data<br/>input_layer_size = 784 <br/><br/>## Define the size of the hidden layers; We want them to be smaller than the input<br/>hidden_layer_one = 256<br/>hidden_layer_two = 256 <br/><br/>## Size of the potential output classes<br/>number_classes = 10 </pre>
<p>In total, these will define the size of our network's input and output layers with respect to the size of the <kbd>MNIST</kbd> dataset's shape.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Activation functions</h1>
                </header>
            
            <article>
                
<p><strong>Activation functions</strong> are the building blocks that make neural networks able to do what they do: convert inputs into desired outputs within ANNs in a nonlinear fashion. As such, they are frequently referred to as <strong>nonlinearities</strong>.<strong> </strong>Putting this together with what we learned earlier, in a neural network we compute the sum of products of input (<em>X</em>) and their corresponding weights <em>w</em>, and apply an activation function <em>f</em> (<em>x</em>) to it to get the output of that layer and feed it as an input to the next layer.</p>
<p>Without a nonlinearity, a unit would be just a simple linear function, and our network something such as a linear regression. When we think about traditional analytical models, such as linear regression or support vector machines, ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Historically popular activation functions</h1>
                </header>
            
            <article>
                
<p>Three activation functions that you will commonly see used are the <kbd>sigmoid</kbd>, <kbd>tanh</kbd>, and <strong>Rectified Linear Unit</strong> (<strong>ReLU</strong>)<strong> </strong>functions. While popular, each of these has a caveat that frequently comes with their use. </p>
<p>During the mid-early 2010s, it was popular to use sigmoids or tanh activation functions in the fully connected layers of a network. Sigmoids have fallen out of fashion, but you might still see them around. They are bounded between the values of 0 and 1 (that is: they can represent any value between that range).</p>
<pre>import math<br/>import numpy as np <br/><br/>def sigmoid(x):<br/> s_out = []<br/> for item in x:<br/>     s_out.append(1/(1+math.exp(-item)))<br/> return s_out</pre>
<p>We can easily plot a <kbd>sigmoid</kbd> function in Python to take a look:</p>
<pre>x = np.arange(-10., 10., 0.2)<br/>f = sigmoid(x)<br/>plt.plot(f,sig)<br/>plt.show()</pre>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1373 image-border" src="Images/b858f3d1-92ee-48ac-a873-4015595f3bdf.png" style="width:27.25em;height:18.25em;" width="375" height="252"/></p>
<p>The function is also built into TensorFlow simply as <kbd>tf.sigmoid.</kbd> The <kbd>tanh</kbd> is a very similar function; it's simply a rescaled version of the sigmoid: </p>
<pre>import numpy as np<br/>import matplotlib.pyplot as plt<br/><br/>tanh = np.tanh(np.arange(-5, 5, .1))<br/><br/>fig = plt.figure()<br/>ax = fig.add_subplot(111)<br/>ax.plot(np.arange(-5, 5, .1), tanh)<br/>ax.set_ylim([-1.0, 1.0])<br/>ax.set_xlim([-5,5])<br/>plt.show()</pre>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1376 image-border" src="Images/92357548-d753-4494-aa20-1248929c1fee.png" style="width:27.83em;height:18.00em;" width="390" height="252"/></p>
<p>Likewise, the <kbd>tanh</kbd> function is available in TensorFlow simply as <kbd>tf.tanh</kbd>. </p>
<p>Both of these are prone to the vanishing gradient problem<strong>.</strong> Both <kbd>sigmoid</kbd> and <kbd>tanh</kbd> are both prone to what is known as <strong>saturation</strong>. When a unit saturates at either end of these functions, the gradient when weights are initialized too large, they become saturated.</p>
<p><span>Both the <kbd>sigmoid</kbd> and <kbd>tanh</kbd> functions are fundamentally bounded—</span><span>they have limits. Nonlinearities become saturated when they take on values too close to the boundaries of these functions.</span> <kbd>Tanh</kbd><span>, unlike <kbd>sigmoid</kbd>, is always centered on zero, and therefore, less likely to saturate. As such, it is </span>always preferable to use <kbd>tanh</kbd> over <kbd>sigmoid</kbd><em> </em><span>for your activation function.</span></p>
<p>As a result of the finicky nature of these activation functions, a new function began to be utilized in the late 2000s called <strong>ReLU</strong>:</p>
<div class="CDPAlignCenter CDPAlign packt_figref"><img class="alignnone size-full wp-image-123 image-border" src="Images/964d22d8-c6d2-45e8-8ccd-14ad6065c908.png" style="width:22.92em;height:17.08em;" width="373" height="279"/></div>
<p>ReLU is a simple and efficient nonlinearity that computes the maximum:</p>
<div class="CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/de4fdd39-2523-47fb-9566-ebce0b8b0170.png" style="width:9.33em;height:1.50em;" width="1370" height="220"/></div>
<p>ReLU makes convergence (having a small error rate) much faster because of its linear and non-saturating nature, and its computational efficiency. ReLUs utilize matrices of zeros, which is significantly more efficient than the exponentials that sigmoids or tanh functions utilize, sometimes making them up to six times faster than tanh. <span>ReLUs, on the other hand, run into an issue known as the <em>dying neuron problem</em>. ReLU nonlinearities can die in training when large gradients combined with odd weight updating causes the function to output a</span> gradient of zero, as a result of having a large valued learning rate. Like the other activations function, ReLu is available in TensorFlow as <kbd>tf.nn.relu</kbd>.</p>
<p>In recent years, practitioners have backed away from the <kbd>sigmoid</kbd> and <kbd>tanh</kbd> functions and created more stable methods based on ReLU.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Modern approaches to activation functions</h1>
                </header>
            
            <article>
                
<p>In recent years, several modifications have been made to the ReLU function to solve the dying neuron problem and make them more robust. Most notable of these is a solution called the <strong>Leaky ReLU</strong>. Leaky ReLU introduces a small slope to the ReLU function to keep potentially dead neurons alive, by allowing a small <strong>gradient</strong> to keep the units active. The Leaky ReLu function is available in TensorFlow as:</p>
<pre class="mce-root">tf.nn.leaky_relu(features,alpha=0.2,name=None)</pre>
<p>Another adaption, the <strong>Parametric Rectified Linear Unit</strong> (<strong>PreLU</strong>), takes this further by making that small gradient a parameter that can be adjusted during training. Instead of predefining a slope of the function, the slope becomes an adaptable parameter, hence ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Weights and bias factors</h1>
                </header>
            
            <article>
                
<p>Two key parts of ANNs are weights and biases. These elements help us squash and stretch our nonlinearities to help us better approximate a function. </p>
<p><strong>Weights</strong> are applied at every transformation in a neural network, and help us stretch a function. They essentially change the steepness of the nonlinearity. <strong>Bias factors</strong> are important parts of ANNs as well; you've probably noticed them in the diagrams shown so far in this chapter. Bias factors are values that allow us to shift our activation function left or right to help us best approximate a natural function. </p>
<p>How does this work in practice? Let's say you have a simple two-neuron setup such as the one in the following diagram: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1377 image-border" src="Images/bed4a48b-499c-4eaf-9467-b5e65ca0c058.png" style="width:16.92em;height:7.92em;" width="451" height="211"/></div>
<p>Let's see how adding weights into the mix can help change a function. In Python, we can represent this as a simple setup as a function that takes in the input data <kbd>x</kbd>, a weights matrix <kbd>w</kbd>, computes the dot product between them, and runs them through a non-linearity:</p>
<pre>def single_output(x, w):<br/>        return np.tanh(np.dot(x, w))</pre>
<p>We can then run the function with various weight values, and plot it's output: </p>
<pre>x = np.arange(-5, 5, .1)<br/>f1 = single_output(x, 0.5)<br/>f2 = single_output(x, 1.0)<br/>f3 = single_output(x, 2.0)<br/>plt.plot(x,f1)<br/>plt.plot(x,f2)<br/>plt.plot(x,f3)<br/>plt.show()</pre>
<p>If you run this code, you should see something such as the following chart: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1378 image-border" src="Images/ec15c41f-7fa6-4914-8223-67b179782588.png" style="width:28.00em;height:18.08em;" width="390" height="252"/></div>
<p>As you can see, the simple weight factor is bending our sigmoid depending on it's magnitude! Now, let's say that you want the network to output 0.5, when the input equals 5. With the help of a bias factor, we can achieve transformations of the sort: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1379 image-border" src="Images/617d445b-f770-413e-8f87-614bca9e72d0.png" style="width:31.67em;height:20.08em;" width="891" height="567"/></div>
<p>In Python, we simply have to add the bias factor to shift the output:</p>
<pre>def single_output(x, w, b):<br/> return np.tanh(np.dot(x, w) + b)</pre>
<p>Run the following code to see how different bias values can shift the curve from left and right; we'll set all of the weights to 1, so that we can clearly see the shift: </p>
<pre>x = np.arange(-5, 5, .1)<br/>f1 = single_output(x, 1.0, 2.0)<br/>f2 = single_output(x, 1.0, 1.0)<br/>f3 = single_output(x, 1.0, -2.0)<br/>f4 = single_output(x, 1.0, 0.0)<br/>plt.plot(x,f1)<br/>plt.plot(x,f2)<br/>plt.plot(x,f3)<br/>plt.plot(x,f4)<br/>plt.show()</pre>
<p>The code should produce a curve such as the following. As you can see in the following graph, we've shifted the curve so that it better approximates the function we want: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1380 image-border" src="Images/ebcd39ae-f6f4-4225-850e-fa1b3cb7a601.png" style="width:28.58em;height:18.42em;" width="390" height="252"/></div>
<p>Weights and biases are updated during the training of a neural network. One of the goals of learning to adjust out weights and biases is so that our transformations throughout our network result in a value that is as close as possible to reality. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Utilizing weights and biases in our MNIST example</h1>
                </header>
            
            <article>
                
<p>Let's get back to our MNIST example. Let's set up our weights and biases based on the network parameters that we defined before. We'll denote our weights for connections between our input layer and first hidden layer at <kbd>w1</kbd>, those between our first hidden layer and second hidden layer as <kbd>w<em>2</em></kbd>, and those between our second hidden layer and output layer as <kbd>w_out</kbd><em>. </em>Notice how the weights track the incoming size and the outgoing size of the data at a given layer:</p>
<pre>weights = { 'w1': tf.Variable(tf.random_normal([input_layer_size, hidden_layer_one])), 'w2': tf.Variable(tf.random_normal([hidden_layer_one, hidden_layeR_two])),  'w_out': tf.Variable(tf.random_normal([hidden_layer_two, number_classes])) ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Loss functions</h1>
                </header>
            
            <article>
                
<p><strong>Loss functions</strong> are another essential building block of neural networks, and they measure the difference between our predictions and reality. </p>
<p>We tend to think of functions as mathematical expressions; which they are, but they also have a shape and surface, or topology. Topology in itself is an entire branch of mathematics and too much for the contents of this book, but the important takeaway is that these functions have topologies of peaks and valleys, much such as a real topological map would:</p>
<p class="mce-root"/>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1381 image-border" src="Images/ebbc3fff-0a99-4cc5-b826-a48caa7e47a4.png" style="width:19.50em;height:13.75em;" width="315" height="222"/></div>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft"><span>In the AI field, when creating neural networks, we seek to find the minimum point on these loss functions, called the <strong>global minima</strong>. This represents the point at which our rate of error (how far off we are) between our actual and predicted values is smallest. The process of getting to the global minima is called <strong>convergence</strong>.</span></p>
<p class="CDPAlignCenter CDPAlign CDPAlignLeft"><span>Loss functions come in two variations: </span></p>
<ul>
<li><strong>Convex loss functions</strong>: Loss functions that curve down, such as a bowl. These loss functions are the easiest way to find the global minima. </li>
<li><strong>Non-convex loss functions</strong>: Loss functions that look like the preceding example, with many peaks and valleys. These loss functions are the most difficult when it comes to finding the local minima.</li>
</ul>
<p>Non-convex loss functions are difficult, because they may have two hazards called <strong>local minima</strong> and <strong>saddle points</strong>. Local minima are exactly what they sound such as: the valleys in the loss function that are not the lowest valleys across the entire topology:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1382 image-border" src="Images/cce5d22f-4497-4db0-86cf-2d2a99427eff.png" style="width:32.17em;height:16.67em;" width="969" height="500"/></div>
<p>Saddle points are areas in the topology where the <strong>gradient</strong> is equal to zero. Learning algorithms get stuck at these points, and we'll address how to remedy this in our next section on the core learning algorithm of neural networks: <strong>gradient descent</strong>. </p>
<p>So, how do we choose a loss function for our network? The problem that we are trying to solve will determine which loss function we should choose for our network. Choosing an appropriate loss, function can be a lengthy task, so for now we'll focus on a few general rules. We can start with using the <strong>mean square error</strong> (<strong>MSE</strong>) loss function for regression problems.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using a loss function for simple regression</h1>
                </header>
            
            <article>
                
<p>Linear regression is one of the simplest models we can implement; you've probably used it before in your own job. Simple regression attempts to find the <strong>line of best fit</strong> for two linearly distributed variables. We can use all of the principles that we've precedingly learned about weights, biases, and loss functions, and apply them to a simple regression to see how they work together. </p>
<p>Now, let's get back to loss functions. MSE measures the average squared difference between an observation’s actual and predicted values. The output is a single number representing the cost or score associated with our current set of weights:</p>

<p>Let's develop a linear regression in TensorFlow to see how <kbd>loss</kbd> functions, ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Using cross-entropy for binary classification problems</h1>
                </header>
            
            <article>
                
<p>While we can use MSE for regression problems, we need to use a different type of loss for classification problems. For that, we use a function known as <strong>cross-entropy</strong>. Cross entropy measure the performance of a classification model whose outputs are between 0 and 1. A low cross entropy means that a predicted classification is similar to the actual classification. A high cross entropy, on the other hand, means that a predicted classification is different from the real classification. </p>
<p> It's also known as <strong>Bernoulli negative log-likelihood</strong> and <strong>Binary cross-entropy</strong>:</p>
<pre>def CrossEntropy(yHat, y):<br/>    if yHat == 1:<br/>         return -log(y)<br/>    else:<br/>        return -log(1 - y)</pre>
<p>Defining <kbd>loss</kbd> functions for classification problems with more than one right answer can be a bit more tricky; we'll cover this as we work through multi-class classification in the following chapters. We'll talk about customizing your <kbd>loss</kbd> functions towards the end of this book. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Defining a loss function in our MNIST example</h1>
                </header>
            
            <article>
                
<p>Since we have a basic binary classification task of, recognizing digits, we're going to utilize <kbd>cross entropy</kbd> as our <kbd>loss</kbd> function. We can easily implement it with a built-in function in TensorFlow:</p>
<pre>loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(network_output, y))</pre>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Stochastic gradient descent</h1>
                </header>
            
            <article>
                
<p><strong>Gradient descent</strong> is the means by which we find the global minima in our loss function, and it's how neural networks learn. In gradient descent, we calculate the value of individual <strong>gradients</strong>, or slopes of the loss function. This helps us reach our minima. Think about descending a hill blindfolded; the only way you can reach the bottom is by feeling the slope of the ground. In gradient descent, we use calculus to feel what the slope of the ground is, to make sure we are headed in the right direction towards our minima's. </p>
<p>In bland old gradient descent, we have to calculate the loss of every single sample that is being passed into the network at a given time, resulting in many redundant calculations.</p>
<p>We can mitigate this redundancy by utilizing a method called <strong>stochastic gradient descent</strong>. Stochastic gradient descent is actually one of the simplest procedures available for optimization. It just so happens that it also works surprisingly well. Typically with deep learning, we are working with high-dimensional data. Unlike with vanilla gradient descent, with stochastic gradient descent we're able to approximate the gradient from a given pass by sampling the loss of one particular data point at a time, reducing redundancy.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Learning rates</h1>
                </header>
            
            <article>
                
<p>Because stochastic gradient descent randomly samples, our location along the surface of our loss function jumps all over the place! We can mitigate this behavior by decreasing a parameter known as our <strong>learning rate</strong>. The learning rate is something called a <strong>hyperparameter</strong>, a parameter that controls the training process of the network. Learning rates control how much we are adjusting the weights of our network, with respect to the gradient of the loss function. In other words, it determines how quickly or slowly we descend while trying to reach our global minimum. The lower the value, the slower we descend downhill, just like on the right in the diagram as described as follows. Think of slowly rolling a tire down a hill - the ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Utilizing the Adam optimizer in our MNIST example</h1>
                </header>
            
            <article>
                
<p>The <strong>a<span>daptive gradient descent method</span></strong> (<strong>Adam</strong>) takes an initial learning rate and adaptively computes updates to it. Adam stores an exponentially decaying average of past squared gradients and of past gradients, which amounts to measuring something similar to momentum. This helps us prevent overshooting or undershooting during our training process.</p>
<p>Adam is easily implemented in TensorFlow with the following command line: </p>
<pre><strong>tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_func)</strong></pre>
<p>The <kbd>tf.train</kbd> class contains various different optimizers that are executed at runtime and contain TensorFlow's version of the Adam optimizer; it takes our initially defined <kbd>learning_rate</kbd> as a parameter. We then call the <kbd>minimize</kbd> method and pass it to our <kbd>loss</kbd> function, wrapping up our learning processing into one object, called <kbd>optimizer</kbd>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Regularization</h1>
                </header>
            
            <article>
                
<p>Recall from the <a href="c72aa49d-41f1-4a15-bee5-9efc9190f282.xhtml" target="_blank">Chapter 2</a>, <em>Machine Learning Basics</em> that overfitting and underfitting can happen when a machine learning model learns it's training dataset too well, or when it doesn't learn it well enough. Artificial neural networks are not immune from this problem! Overfitting often occurs in neural network because the amount of parameters that they have is too large for the training data. In other words, the model is too complex for the amount of data that it is being trained on. </p>
<p>One way that we can prevent overfitting in our networks is through a technique called <strong>regularization</strong>. Regularization works by shrinking the parameters of a model to create a less-complex model, thereby reducing overfitting. Let's say we have a loss ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">The training process</h1>
                </header>
            
            <article>
                
<p>Training is the process by which we teach a neural network to learn, and it's controlled programmatically in our code. Recall, from <a href="c72aa49d-41f1-4a15-bee5-9efc9190f282.xhtml">Chapter 2</a>, <em>Machine Learning Basics</em>, that there are two forms of learning in the AI world: supervised learning and unsupervised learning. In general, most ANNs are supervised learners, and they learn by example from a <strong>training set</strong>. A singular unit in a training cycle in a neural network is called an <strong>epoch.</strong> By the end of one epoch, your network has been exposed to every data point in the dataset once. At the end of one epoch, epochs are defined as a <strong>hyperparameter</strong> when first setting up your network.<strong> </strong>Each of these epochs contain two processes: <strong>forward propagation</strong> and <strong>backpropagation</strong>.</p>
<p>Within an epoch we have <strong>iterations</strong>, which tell us what proportion of the data has gone through both forward propagation and backpropagation. For instance, if we have a dataset with 1,000 data points and send them all through forward propagation and backpropagation at once, we would have one iteration within an epoch; however, sometimes, to speed up training, we want to break down the amount of data to go through in one pass, so we <strong>minibatch</strong> the data. We could minibatch the 1,000-point dataset into four iterations of 250 data points each, all within a singular epoch. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Putting it all together</h1>
                </header>
            
            <article>
                
<p>Now that we've gone through all of the elements of a basic feedforward neural network, it's time to begin assembling the pieces. The first thing we'll do is define our <strong>hyperparameters. </strong>We'll train the network for 50 epochs, each time feeding a batch of 100 samples into the network. At the end of each epoch, the <kbd>batch_size</kbd> parameters will tell the network to print out the current value of the loss, as well as the accuracy of the network:</p>
<pre>## Network Parametersepochs = 15batch_size = 100display_step = 1</pre>
<p>Next, we'll create <kbd>placeholders</kbd> for our MNIST data features (<em>x</em>) and their correct label (<em>y</em>), which we'll use to represent the data while constructing the network:</p>
<pre> # Create the Variablesx = tf.placeholder("float", [None, ...</pre></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Forward propagation</h1>
                </header>
            
            <article>
                
<p>Forward propagation is the process of how information flows through our network during the learning phase of training. Before we walk through the process, let's return to our MNIST example. First, we need to initialize the feedforward network that we precedingly created. To do that, we can simply create an instance of the function, and feed it the input placeholder, as well as the weight and bias dictionaries:</p>
<pre>network_output = feedforward_network(x, weights, biases)</pre>
<p>This model instance gets fed into our <kbd>loss</kbd> function that we preceedingly defined: </p>
<pre>loss_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=network_output, labels=y))</pre>
<p>Which subsequently gets fed into the optimizer we defined: </p>
<pre>training_procedure = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss_func)</pre>
<p>With all of this defined, you can begin to see why placeholders are so essential in TensorFlow. The placeholders for the input, as well as the randomly initialized weights and biases, provide a basis for which TensorFlow builds the model from. Without these, the program wouldn't know how to compile the network because it wouldn't have any concept of the input, output, weight, and bias values.</p>
<p>Training happens behind the scenes in TensorFlow, so let's walk through the process manually to gain a better understanding of what's under the hood. At its simplest, forward propagation is just matrix multiplications offset by a bias unit, and then processed through activation functions. <span>Let's look at the example of the following singular unit, where <em>X1</em>:<em>X3</em> represents our input layer (plus a bias value), and the empty unit represents a node in the hidden layer: </span></p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1387 image-border" src="Images/c99a9d52-28a8-4c79-96ea-f3f28cfaf1ca.png" style="width:23.33em;height:13.33em;" width="589" height="336"/></div>
<p>Each connection between an input value and a hidden layer unit represents a multiplication of the input value times the weight: </p>
<p class="CDPAlignCenter CDPAlign"><img style="font-size: 1em;width:8.75em;height:1.17em;" class="fm-editor-equation" src="Images/4b2376cd-a9e4-4238-9c7f-c88e0216a829.png" width="1200" height="160"/> </p>
<p>Remember, both our inputs as well as our weights are matrices, so we represent their multiplication as the<span> </span><strong>dot product</strong>. We take those values and sum them all together, so <img class="fm-editor-equation" src="Images/353132e0-4b32-407a-9915-23719ad9bf0f.png" style="width:15.75em;height:1.42em;" width="2570" height="220"/>. Finally, we take the result of that operation, and feed it through our hidden layer's activation function.</p>
<p>Let's say that we are utilizing a ReLU as the activation function of our hidden layer units; then our unit computes: </p>
<div class="mce-root CDPAlignCenter CDPAlign"><img class="fm-editor-equation" src="Images/1bada7b2-7db0-48c2-ab4c-83928390baf1.png" style="width:34.75em;height:1.42em;" width="5410" height="220"/></div>
<p>The output of this function is then multiplied by a second set of weight matrices, just as we did with the output of the first layer. This process can be repeated over and over depending on how many hidden layers are in our network: </p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1388 image-border" src="Images/6f001240-3f74-4364-9499-62d4142e4f22.png" style="width:27.33em;height:17.75em;" width="956" height="620"/></div>
<p>Our last layer of the network often contains a squashing function, such as a softmax to output prediction values. At the end of this whole process, our error from that pass is calculated, and the error is sent back through the network in a process called <strong>backpropagation</strong>. </p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Backpropagation</h1>
                </header>
            
            <article>
                
<p><strong>Backpropagation</strong>, or <strong>Backprop</strong>, is a core learning algorithm that we utilize in AI applications, and learning about it will be essential to creating and debugging your neural networks going forward. Short for <strong>backpropagation of error</strong>, it is the means by which ANNs calculate how erroneous they are with their predictions.</p>
<p><span>You can think of it as the complement to the gradient descent optimization algorithm that we precedingly discussed. </span>Recall that at their core, ANNs seek to learn a set of weight parameters that help them approximate a function that replicates our training data. Backpropagation measures how error changes after each training cycle, and gradient descent tries to optimize the error. Backprop computes the gradient ...</p></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Forwardprop and backprop with MNIST</h1>
                </header>
            
            <article>
                
<p>Remember that, to run a training process in TensorFlow, we run our computations through a session. To get started, let's open a new training session. </p>
<ol>
<li><span>In TensorFlow, before we enter the training process, we need to initialize our model class as an object, and bring all of our variable placeholders online with the </span><kbd>tf.global_variables_initializer()</kbd><span> command: </span></li>
</ol>
<pre style="padding-left: 60px">with tf.Session() as sess:<br/>    ## Initialize the variable<br/>    sess.run(tf.global_variables_initializer())</pre>
<ol start="2">
<li>Now, we can write the core of the training process, which is what we call the training loop. We'll define the loop by the number of training epochs for the model. In it, we'll first batch out our incoming data; our model cannot and should not handle all of the data at once, and so we define the total amount of the incoming samples by the batch size of 100 that we precedingly defined. So in this case, for each epoch in the 15 epochs that we've told the network to train, we'll run 100 samples of the training data through each time:</li>
</ol>
<pre style="padding-left: 60px">for epoch in range(epochs):<br/> <br/>     ## Batch the incoming data<br/>     total_batch = int(mnist.train.num_examples/batch_size) </pre>
<p class="mce-root"/>
<ol start="3">
<li>Within the same loop, we'll create another loop that runs the training process by batch. We'll create a batch for the x and y data, and run those examples through a TensorFlow session that runs the training procedure and computes the loss:</li>
</ol>
<pre style="padding-left: 60px">for batch in range(total_batch):<br/>            batch_x, batch_y = mnist.train.next_batch(batch_size)<br/>            <br/>            _, loss = sess.run([training_procedure, loss_func], feed_dict={x: batch_x, y: batch_y})                  </pre>
<ol start="4">
<li>So far, we've defined the bare minimum that's necessary to train a model in TensorFlow. In addition to the training procedure itself, you'll also often see a procedure to keep track of the current value of the loss, as well as accuracy metrics so that we know how well (or poorly) our model is training. For that, we'll define a loop that's at the level of the batching loop precedingly defined, so that it runs at the end of each training epoch. In it, fetch the predictions from the network at that epoch by running the output of the network through a <kbd>softmax</kbd> function. Softmax functions spit out probabilities for which class a sample potentially belongs to in a classification problem: </li>
</ol>
<pre style="padding-left: 60px">if epoch % display == 0:<br/>            pred = tf.nn.softmax(network_output) </pre>
<ol start="5">
<li>Once we have those probabilities, we need to select the highest probability from the tensor that's returned out of the softmax. Fortunately for us, TensorFlow has an easy function for this called <kbd>tf.argmax</kbd>. Once we have that, we can compare it against the actual value of y that we should have expected:</li>
</ol>
<pre style="padding-left: 60px">correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</pre>
<ol start="6">
<li>Once we have the correct prediction, we can calculate the <kbd>accuracy</kbd>, save a model checkpoint, and return the current epoch, value of the loss function, and accuracy of the model at that step:</li>
</ol>
<pre style="padding-left: 60px">accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))<br/>            <br/>saver.save(sess, save_model)<br/>                <br/>print("Epoch:", '%04d' % (epoch+1), "loss {:.9f}".format(loss), "Accuracy:", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))</pre>
<ol start="7">
<li>At the end of the training process, you should see an output such as follows: </li>
</ol>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-1393 image-border" src="Images/08249642-3522-4a54-b87b-ca3c05bcb3d8.png" style="width:23.00em;height:15.00em;" width="871" height="566"/></p>
<p>Now that we've setup our network and trained it, let's go ahead and look at a few tools that can help us inspect it's training progress.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Managing a TensorFlow model</h1>
                </header>
            
            <article>
                
<p>TensorBoard is a tool built into TensorFlow that visualizes the values of your network's parameters over the coarse of the training process. It can also help to visualize data, and can run several exploratory analysis algorithms. It helps you explore the underlying TensorFlow graph in a simple, easy to use graphical interface. </p>
<p>Once a TensorFlow model is trained, say the MNIST example defined precedingly, TensorFlow allows us to create something called a <strong>Model Summary</strong>. Summaries are, as you probably guessed, condensed versions of a model that contain the necessary key aspects that we need to use TensorBoard.</p>
<ol>
<li>To create a summary, we first need to initialize the <kbd>writer</kbd>; we'll insert the line preceding just before ...</li></ol></article></section></div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Saving model checkpoints</h1>
                </header>
            
            <article>
                
<p>In Tensorflow, a checkpoint is a binary file that contains the model weights and gradients that were calculated during training. Should you want to load up a model for further training, or access the model at a certain point during training, we can save and restore checkpoints with all of the training information that we need. To save a checkpoint, we can use a saver utility that is provided to us in native TensorFlow: </p>
<pre>save_model = os.path.join(job_dir, 'saved_mnist.ckpt')<br/>saver = tf.train.Saver()</pre>
<p>Then, during the training cycle, we can periodically save checkpoints by calling the <kbd>saver</kbd>: </p>
<pre>saver.save(sess, save_model)</pre>
<p>Note that you can choose to save the model checkpoints in whatever directory that you wish. A TensorFlow saver will create three files: </p>
<ul>
<li>A <kbd>.meta</kbd> file that describes the structure of the saved graph</li>
<li>A <kbd>.data</kbd> file that stores the values of all of the variables in the graph (The weights and gradients)</li>
<li>A <kbd>.index</kbd> file which identifies the particular checkpoint</li>
</ul>
<p>To re-load a TensorFlow model from it's checkpoints, we load the meta graph, and then restore the values of the graph's variables within a TensorFlow session. Here, <kbd>meta_dir</kbd> is the location of the <kbd>.meta</kbd> file, and <kbd>restore_dir</kbd> is the location of the <kbd>.data</kbd> file:</p>
<pre>init = tf.global_variables_initializer()<br/>saver = tf.train.import_meta_graph(meta_dir)<br/>with tf.Session() as sess:<br/>    sess.run(init)<br/>    saver.restore(sess, restore_dir)</pre>
<p>TensorFlow checkpoints can only be used in training, not for deploying a model. There is a separate process for readying a model for deployment, and we will cover it in <a href="765cdda6-7a90-4553-aa8c-3b3d5775f23b.xhtml" target="_blank">Chapter 13</a>, <em>Deploy and Maintaining AI Applications</em>.</p>


            </article>

            
        </section>
    </div>



  
<div id="sbo-rt-content"><section>

                            <header>
                    <h1 class="header-title">Summary</h1>
                </header>
            
            <article>
                
<p>Feedforward networks are a basic and essential class of network. This chapter has helped us study the building blocks of neural networks, and will help illuminate network topics going forward. </p>
<p>Feedforward neural networks are best represented as directed graphs; information flows through in one direction and is transformed by matrix multiplications and activation functions. Training cycles in ANNs are broken into epochs, each of which contains a forward pass and a backwards pass. On the forward pass, information flows from the input layer, is transformed via its connections with the output layers and their activation functions, and is put through an output layer function that renders the output in the form we want it; probabilities, ...</p></article></section></div>



  </body></html>