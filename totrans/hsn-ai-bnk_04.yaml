- en: Time Series Analysis
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapter, we introduced AI, machine learning, and deep learning.
    We also discovered how the banking sector functions and how the use of AI can
    enhance banking processes. We learned the importance of banking processes being
    easily accessible. We also learned about a machine learning modeling approach
    called **CRISP-DM**. Overall, the chapter provided the necessary background for
    the application of machine learning in the banking industry to solve various business
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will learn about an algorithm that analyzes historical data
    to forecast future behavior, known as **time series analysis**. Time series analysis
    works on the basis of one variable—time. It is the process of capturing data points,
    also known as **observations**, at specific time intervals. The goal of this chapter
    is to understand time series analysis in detail through examples and explain how
    **Machine-to-Machine** (**M2M**) communication can be helpful in the implementation
    of time series analysis. We will also understand the concepts of financial banking
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics :'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: M2M communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The basic concepts of financial banking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI modeling techniques
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demand forecasting using time series analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Procuring commodities using neural networks on Keras
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A **time series** is technically defined as the ordered sequence of values
    of a variable captured over a uniformly spaced time interval. Put simply, it is
    the method of capturing the value of a variable at specific time intervals. It
    can be 1 hour, 1 day, or 20 minutes. The captured values of a variable are also
    known as **data points**. Time series analysis is performed in order to understand
    the structure of the underlying sources that produced the data. It is also used
    in forecasting, feedforward control, monitoring, and feedback. The following is
    a list of some of the known applications of time series analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: Utility studies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stock market analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weather forecasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sales projections
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Workload scheduling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Expenses forecasting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Budget analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time series analysis is achieved by applying various analytical methods to extract
    meaningful information from raw data that has been captured from various data
    sources. Time series analysis is also useful for producing statistics and other
    characteristics of data—for example, the size of data, the type of data, the frequency
    of data, and more. In time series analysis, the capturing of a value is done at
    a point of observation.
  prefs: []
  type: TYPE_NORMAL
- en: Let's try to understand this through an example. When using time series analysis
    modeling, the branch manager of a specific branch can predict or forecast the
    expenses that will occur in the upcoming year. The branch manager can do this
    by employing a time series analysis machine learning model and then training the
    model using historical yearly expense records. The recorded observations can be
    plotted on a graph with a specific time (each day, in this example) on the *x*
    axis and historical expenses on the *y* axis. Therefore, time series analysis
    is an algorithm that is used to forecast the future values of one variable (that
    is, yearly expenses in this example) based on the values captured for another
    variable (in this case, time).
  prefs: []
  type: TYPE_NORMAL
- en: Let's understand this in more detail using another example. In this example,
    we will imagine that a bank wants to perform expense projections based on the
    historical data it has. The bank manager wants to know and forecast the expenses
    in the year 2020 for the branch that he manages. So, the process of forecasting
    the expenses will start by collecting historical expenses information from the
    year 2000\. First, the bank manager will look at the expenses data for the year.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we mentioned earlier, time series analysis is done by capturing the values
    of a variable. Can you guess the variable in this example? I am sure that you
    will have guessed it by now. The variable under observation is the total expense
    amount per year. Let''s assume that the following is the data per year:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Year** | **Total expense (in USD)** |'
  prefs: []
  type: TYPE_TB
- en: '| 2000 | 20,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2001 | 22,500 |'
  prefs: []
  type: TYPE_TB
- en: '| 2002 | 21,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2003 | 18,000 |'
  prefs: []
  type: TYPE_TB
- en: '| 2004 | 25,700 |'
  prefs: []
  type: TYPE_TB
- en: '| 2005 | 22,100 |'
  prefs: []
  type: TYPE_TB
- en: '| 2006 | 23,300 |'
  prefs: []
  type: TYPE_TB
- en: '| 2007 | 17,600 |'
  prefs: []
  type: TYPE_TB
- en: '| 2008 | 18,200 |'
  prefs: []
  type: TYPE_TB
- en: '| 2009 | 20,400 |'
  prefs: []
  type: TYPE_TB
- en: '| 2010 | 21,200 |'
  prefs: []
  type: TYPE_TB
- en: '| 2011 | 20,900 |'
  prefs: []
  type: TYPE_TB
- en: '| 2012 | 22,600 |'
  prefs: []
  type: TYPE_TB
- en: '| 2013 | 17,500 |'
  prefs: []
  type: TYPE_TB
- en: '| 2014 | 19,300 |'
  prefs: []
  type: TYPE_TB
- en: '| 2015 | 20,100 |'
  prefs: []
  type: TYPE_TB
- en: '| 2016 | 22,200 |'
  prefs: []
  type: TYPE_TB
- en: '| 2017 | 22,500 |'
  prefs: []
  type: TYPE_TB
- en: '| 2018 | 19,400 |'
  prefs: []
  type: TYPE_TB
- en: '| 2019 | 23,800 |'
  prefs: []
  type: TYPE_TB
- en: Many options are available to analyze this data and predict future expenses.
    The analytical methods vary in terms of complexity. The simplest one will be to
    average out the expenses and assume the resultant value to be the number of expenses
    for the year 2020\. However, this is solely for the purpose of our example. You
    can find the average of expenses by using various other mathematical and analytical
    methods as well. With this option, the total number of expenses for the year 2020
    will be $20,915.
  prefs: []
  type: TYPE_NORMAL
- en: 'The complex method may involve analyzing detailed expenses, predicting future
    values for each individual expense type, and deriving the total expenses amount
    based on it. This may provide a more accurate prediction than the averaging option.
    You can apply a more complex analytical method based on your needs. This example
    is provided so that you can understand how time series analysis works. The amount
    of historical data that we have used in this example is very limited. AI and machine
    learning algorithms use large amounts of data to generate predictions or results.
    The following is a graphical representation of this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/90ebad2e-e7a3-41dd-812e-6494224f4423.jpg)'
  prefs: []
  type: TYPE_IMG
- en: In the following section, we will learn how machines can communicate with each
    other using a concept known as **M2M communication**.
  prefs: []
  type: TYPE_NORMAL
- en: M2M communication
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: M2M communication is extremely powerful and can dramatically improve the functions
    of commercial banking.
  prefs: []
  type: TYPE_NORMAL
- en: M2M communication represents the communication between two machines or devices
    through various channels such as physical networks, information-sharing networks,
    software communication, and application interfaces. The sole purpose of M2M communication
    is the exchange of information across two or more machines or between software
    running on those machines.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of M2M communication assumes that no human intervention is required
    while exchanging information between machines. M2M communication can also take
    place over wireless networks. Wireless networks have made M2M communication easier
    and more accessible. The following list includes several common applications of
    M2M communication:'
  prefs: []
  type: TYPE_NORMAL
- en: Manufacturing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smart utility management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Home appliances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Healthcare device management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, M2M communication is different from IoT. IoT uses sensors to trigger
    inputs, whereas M2M communication specifically refers to the interaction between
    two systems.
  prefs: []
  type: TYPE_NORMAL
- en: Commercial banking is a group of financial services that includes deposits,
    checking account services, loan services, drafts, certificates of deposits, and
    savings accounts for individuals and businesses. Commercial banks are the usual
    destination for peoples' banking needs. *But how do banks function and make money?*
    This is a very common question that we will answer right now. Commercial banks
    make money when they earn interest from various types of loans that they provide
    to their customers. The types of loans can vary, for example, automobile loans,
    business loans, personal loans, and mortgage loans. Usually, a commercial bank
    has a specialty in one or more types of loans.
  prefs: []
  type: TYPE_NORMAL
- en: Commercial banks get their capital from various types of account services that
    they provide to their customers. The types of accounts include checking accounts,
    savings accounts, corporate accounts, money market accounts, and more. Banks utilize
    this capital to invest in high-return investment options such as mutual funds,
    stocks, and bonds. Banks have to pay interest to those customers who have their
    accounts with the bank. The rate of interest is far less when compared to loans,
    however.
  prefs: []
  type: TYPE_NORMAL
- en: The role of M2M communication in commercial banking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider an example that involves transferring money from one customer's account
    to another customer's account. In the past, this was a manual task that required
    filling in an appropriate form, submitting the form to the appropriate department
    where ledger entries were created, and then the amount was debited from one account
    and credited to the beneficiary's account.
  prefs: []
  type: TYPE_NORMAL
- en: Nowadays, this process has changed entirely. With a mobile phone, the customer can
    transfer funds from one account to another without any hassle. The beneficiary's
    account will be credited with the money within a few minutes. Incredible, isn't
    it? So, how did this happen? Well, M2M communication and process automation have
    played a major role in making this happen. It has become possible for machines
    (that is, computer systems, cloud-based virtual machines, and mobile devices)
    to connect over a wireless or wired network and transfer every piece of necessary
    information to another machine or software running on that machine. Nowadays,
    you only have to visit the bank for a few specific reasons. Customers can now
    even open a savings bank account or a loan account straight from their mobile
    devices.
  prefs: []
  type: TYPE_NORMAL
- en: The basic concepts of financial banking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we move full steam ahead into another example, we will first craft out
    our data, AI, and business techniques and knowledge. If you are familiar with
    all of these concepts, feel free to skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: Financial knowledge is a good place to start to understand how our decisions
    in forecasting business activities impact financial decision-making in non-financial
    firms. Additionally, when predicting future activities using a machine learning
    model, we also learn how the finance industry can prepare for this future volume
    of business. What financing does to help with core business activities in non-financial
    firms is covered in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: The functions of financial markets – spot and future pricing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Financial markets, such as exchanges, play the role of markets for products
    to be exchanged. For example, consider commodities such as natural gas—we can
    either buy it directly from sellers or buy it via an exchange. As it turns out,
    long-running economics theories encourage you to buy the product from an exchange
    as much as possible if the product is standardized. **Chicago Mercantile Exchange**
    (**CME**) in the US could be a popular choice for commodities and, needless to
    say, the **New York Stock Exchange** (**NYSE**) is the market for publicly listed
    equities.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, let's stick to natural gas as a product that we need. Of course,
    in some cases, it could be more efficient to buy it from big oil companies such
    as Shell—that is, if we want these physical goods from producers on a regular
    basis.
  prefs: []
  type: TYPE_NORMAL
- en: Within exchange markets, there are two prices— the spot price and the future
    price. **Spot price** means you can have goods (delivered) now if you pay; **future
    price** means you get the goods later by paying now.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing between a physical delivery and cash settlement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Even if a change in ownership is to take place, it could occur in two forms,
    that is, via physical delivery or a cash settlement. Ultimately, physical delivery
    or a cash settlement depends on whether we need the goods immediately or not.
    However, on any given trading day, we must weigh up the cost of only two options:
    *physical delivery (cost of natural gas + cost of financing + cost of storage)
    as opposed to a cash settlement*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Essentially, we have four options, as presented in the following table—assuming
    that we need to have the physical natural gas product in 3 months time for the
    generation of electricity:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Physical delivery** | **Cash settlement** |'
  prefs: []
  type: TYPE_TB
- en: '| **Spot** | Finance the purchase to get the product now; store it for 3 months.
    | Buy the product now and own it on paper. There is no need to keep the goods. 
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Future** | Finance the purchase now to get the product in the future; get
    it in 3 months. | Finance to buy the product in the future. 3 months later, purchase
    on spot from the market with physical delivery. |'
  prefs: []
  type: TYPE_TB
- en: 'To weigh up the options, we require the following data:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Storage costs** should be provided by the internal source if the company
    owns the storage facility for natural gas. It is assumed to be rather static,
    for example, at around 0.12 per MMBtu. MMBtu is a unit used to measure the energy
    content in fuel. It stands for one **Million British Thermal Units**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **financing cost** should cover the storage period and the interest expenses
    for the purchase cost. It is assumed to be $0.1 per MMBtu. This should be fed
    by the bank.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **cost of natural gas** (spot price) should be provided by the market data
    provider. The real-time Henry Hub spot price should be provided by Thomson Reuters,
    for example, at around $2.5 per MMBtu.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **cost of futures** should be provided by CME. Data should be available
    on Quandl free of charge. It should be around $3 per MMBtu for 3-month contract.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numbers given here merely provide an indication of the magnitude of values.
    Of course, they could be optimized by comparing the options—however, the decisions
    can be derived by linear algebra, and not many machine learning techniques are
    needed. In real life, we should not impose a machine learning solution on anything
    if we can have a nice deterministic formula to do so.
  prefs: []
  type: TYPE_NORMAL
- en: Options to hedge price risk
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To avoid the price swinging outside the predefined price range of natural gas,
    we will need heuristic rules such as deciding what to do at what price given a
    fixed target purchase quantity. Alternatively, we need the rules to adjust what
    has been already placed to sell or buy more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take the following example. If the price is beyond the acceptable range, for
    example, lower than $2.84 or higher than $3.95, we can choose to pocket the profit
    by doing one of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Writing options (selling insurance) if the price drops a lot.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the loss by buying options (buying insurance) if the price shoots up
    unfavorably.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the per-unit payoff from the hedged position by
    buying insurance against the high procurement price and selling the benefits at
    a low procurement price:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4cb00173-c7a8-4eb2-b418-544488501838.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, we have sold insurance at an extremely low price—which means that even
    though we should have enjoyed a lower cost of procurement, we gave it away at
    the benefit of taking an insurance premium. On the other hand, there will be positive
    payoff when the price is too expensive, that may eat into the profitability of
    the company—by paying a premium to buy insurance. The exact price of the insurance
    is called option pricing and will be addressed in [Chapter 7](d29ff3a8-3879-4d50-8795-a39bae5cc793.xhtml),
    *Sensing Market Sentiment for Algorithmic Marketing at Sell Side*. We now assume
    that the price we pay for the insurance is the same as the price we earn from
    selling insurance.
  prefs: []
  type: TYPE_NORMAL
- en: AI modeling techniques
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the following sections, we will introduce the **Autoregressive Integrated
    Moving Average** (**ARIMA**), the most traditional type of forecasting model.
    We will also introduce a neural network model. ARIMA is a class of statistical
    models that is used to forecast a time series using past values. ARIMA is an acronym
    for the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AR** (**autoregression**): Autoregression is a process that takes previous
    data values as inputs, applies this to the regression equation, and generates
    resultant prediction-based data values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**I** (**integrated**): ARIMA uses an integrated approach by using differences
    in observations to make the time series equally spaced. This is done by subtracting
    the observation from an observation on a previous step or time value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MA** (**moving average**): A model that uses the observation and the residual
    error applied to past observations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Introducing the time series model – ARIMA**'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For this project, we will fit data into a time series model called **ARIMA**.
    ARIMA is a specific type of time series model in statistics, which is commonly
    used to predict data points in the future, with parameters on autoregressive terms
    (*p*), non-seasonal differences (*d*), and lagged terms (*q*).
  prefs: []
  type: TYPE_NORMAL
- en: This ARIMA model belongs to parametric modeling—models that are fitted by known
    parameters. Normally, we classify this type of model as a statistical model because
    we need to make assumptions about what the data looks like. This is considerably
    different for wider machine learning models that do not have any preset assumptions
    about what the data looks like.
  prefs: []
  type: TYPE_NORMAL
- en: However, in a real banking scenario, a statistical approach is still prevalent
    among the econometrics, quantitative finance, and risk management domains. This
    approach works when we have a handful of data points, for example, around 30 to
    100 data points. However, when we have a wealth of data, this approach may not
    fare as well as other machine learning approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'ARIMA assumes that there is a stationary trend that we can describe. The autoregressive
    terms, *p* and *d*, are each significant in their own way:'
  prefs: []
  type: TYPE_NORMAL
- en: '*p* means the number of past period(s) that is affecting the current period
    value (for example, *p = 1: Y current period = Y current -1 period * coefficient
    + constant*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Non-seasonal difference (*d*) refers to the number of past periods progression
    impacting the current period values (for example, *d = 1*: the difference between *Y* now versus *Y* in
    the past period).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lagged terms (*q*) means the number of the past period's forecast errors impacting
    the current period values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider an example in which *q = 1: Y* impacted by an error in the *t - 1* period—here,
    error refers to the difference between the actual and predicted values.'
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, ARIMA specifies how the previous period's coefficient, constant,
    error terms, and even predicted values impact the current predicted values. It
    sounds scary, but it is, in fact, very understandable.
  prefs: []
  type: TYPE_NORMAL
- en: After the model is fit, it will be asked to make a prediction and be compared
    against the actual testing data. The deviation of the prediction from the testing
    data will record the accuracy of the model. We will use a metric called the **Mean
    Square Error** (**MSE**) in this chapter to determine the fitness of the model
    to the data.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing neural networks – the secret sauce for accurately predicting demand
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We may have a good data source, but we should not forget that we also need a
    smart algorithm. You may have read about neural networks thousands of times, but
    let's look at a short explanation before we use them extensively throughout the
    book. A neural network is an attempt by a computer to mimic how our brain works—it
    works by connecting different computing points/neurons with different settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'Architecture-wise, it looks like layers of formulas. Those of you reading this
    book probably have some background in algebra, and can see how the interested
    outcome *Y* is related to *X*, the variable, with *b* being the coefficient and
    *c* being the constant term:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5eb98bf-4c05-4d02-9ccf-9d61d6cbac22.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Y* is what we wish to predict on the left-hand side; on the right-hand side, *bX
    + c* are the forms that describe how the feature (*X*) is related to *Y*. In other
    words, *Y* is the output, while *X* is the input. The neural network describes
    the relationship between the input and the output.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose that *Z* is what we want to predict:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e582ab05-9812-4fb9-bf27-7931cad554a0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'It seems that the formulas are linked:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/30df07a7-15f5-4c36-a4e8-8e274f6dfad2.png)'
  prefs: []
  type: TYPE_IMG
- en: This is the simplest form of a neural network, with one input layer, one hidden
    layer, and one output layer. Each of the layers has one neuron (point).
  prefs: []
  type: TYPE_NORMAL
- en: I encourage you to read research papers and introductory text on machine learning
    or even enroll yourself for online courses. Useful resources from Packt include Sebastian
    Raschka and Vahid Mirjalili's *Python Machine Learning* ([https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition](https://www.packtpub.com/big-data-and-business-intelligence/python-machine-learning-second-edition)) and Rowel
    Atienza's *Advanced Deep Learning with* *Keras* ([https://www.packtpub.com/big-data-and-business-intelligence/advanced-deep-learning-keras](https://www.packtpub.com/big-data-and-business-intelligence/advanced-deep-learning-keras))*.*
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are other concepts in neural networks, such as backpropagation. This refers
    to the feedback mechanism that fine-tunes the neural network's parameters, which
    mostly connect neurons within the network (except when it is a constant parameter
    at the layer). It works by comparing the output at output layer *Z* (predicted)
    versus the actual value of *Z* (actual). The wider the gap between actual and
    predicted, the more adjustment of *b*, *c*, *d*, and *e* is needed.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how gaps are measured is also an important piece of knowledge—this
    is called **metrics** and will be addressed in [Chapter 3](61949743-f7c3-4295-aaee-dab1d169d25c.xhtml),
    *Using Features and Reinforcement Learning to Automate Bank Financing.*
  prefs: []
  type: TYPE_NORMAL
- en: Neural network architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Architecture concerns the layers and number of neurons at each layer, as well
    as how the neurons are interconnected in a neural network. The input layer is
    represented as **features**. The output layer can be a single number or a series
    of numbers (called a **vector**), which generates a number ranging from 0 to 1
    or a continuous value—subject to the problem domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, to understand the structure of a neural network, we can project
    that it will look like the following screenshot from TensorFlow Playground ([https://playground.tensorflow.org/](https://playground.tensorflow.org/)),
    which is the visualization of another network with the same hidden layers—three
    layers with a size of 6:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/2225db38-32a7-49d4-9d47-930cd76d6e65.png)'
  prefs: []
  type: TYPE_IMG
- en: Using epochs for neural network training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Besides the design of the neural network, we also utilize the `epoch` parameter,
    which indicates the number of times the same set of data is fed to the neural
    network.
  prefs: []
  type: TYPE_NORMAL
- en: We need to increase the number of epochs if we do not have enough data to satisfy
    the number of parameters in neural networks. Given that we have *X* parameters
    in the neural network, we need at least *X* data points to be fed to the network.
    Unfortunately, if our data point is only *X*/2, we need to set `epoch` to 2 in
    order to make sure that we can feed *X* data points (all of them are fed twice)
    to the network.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before feeding the features to the machine learning model, we will normalize
    the input features of different magnitudes to be of the same magnitude. For example,
    the price and volume of goods are different types of numeric data. The scaling
    process will make sure that both of them are scaled to the same range, from 0
    to 1\. In classical statistical modeling processes, this step is very important
    to avoid a particular feature of bigger scales that dominate the influence on
    the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Apart from data column-level scaling, we also need to pay attention to the sampling
    bias of the model. Normally, we will set aside a portion of the data unseen by
    the machine while it is training and learning on another set of data—which is
    called a **training set**. Later on, the testing set (which is the dataset kept
    aside) will be used to check against the prediction made by the model.
  prefs: []
  type: TYPE_NORMAL
- en: Demand forecasting using time series analysis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a look at the first example of forecasting the
    demand for electricity consumption, and predict the energy expenses using time
    series analysis. We will start with a brief problem statement and define steps
    to solve the problem. This will give you a better understanding of how to find
    solutions to problems using time series analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Today, electricity or energy is a very basic necessity for all of us. We use
    electricity and pay bills. Now, as a customer, we want to analyze electricity
    consumption and predict future consumption and predict energy expenses. This is
    the problem that we will solve in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time series analysis is the optimal approach for solving problems similar to
    the one defined in the preceding problem statement. Machine learning models need
    large datasets to be fed before the actual solution is derived. These large datasets
    are used by machine learning models to derive a pattern or identify an existing
    pattern that might not be visible when the data is scattered. Similarly, our first
    step would be to obtain a large amount of data and process it to extract meaningful
    information. This is going to be a three-step process. Here are the steps that
    we will follow:'
  prefs: []
  type: TYPE_NORMAL
- en: Downloading the data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Preprocessing the data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Model fitting the data
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Downloading the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Start by downloading data regarding electricity consumption and energy expenses.
    Even though we can download data from public websites now, in a true production
    environment, it is not uncommon to download data from an internal database and
    pass it to users as a flat file (a text file with no database structure).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the files from the following paths:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Consumption**: [https://www.eia.gov/opendata/qb.php?category=873&sdid=ELEC.CONS_TOT.NG-CA-98.M](https://www.eia.gov/opendata/qb.php?category=873&sdid=ELEC.CONS_TOT.NG-CA-98.M)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cost**: [https://www.eia.gov/opendata/qb.php?category=41625&sdid=ELEC.COST.NG-CA-98.M](https://www.eia.gov/opendata/qb.php?category=41625&sdid=ELEC.COST.NG-CA-98.M)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Revenue**: [https://www.eia.gov/opendata/qb.php?category=1007&sdid=E LEC.REV.CA-RES.M](https://www.eia.gov/opendata/qb.php?category=1007&sdid=ELEC.REV.CA-RES.M)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many ways of obtaining data, for example, using an API or robots.
    We will address these other methods of extracting data as we move further into
    the book. In [Chapter 4](0c281efb-a1b8-423f-976b-0fa47f5da990.xhtml), *Mechanizing
    Capital Market Decisions,* we'll obtain data through an API call. If we were to
    use a robot, for example, we could have used **Beautiful Soup** to parse the website
    or register the API. However, in this example, we simply visit the site using
    a browser and navigate to the download button to download the data.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'After we obtain the data, we align it together in the same time series, as
    the data we''ve downloaded can cover different periods of time. As data scientists,
    we strive to align our data in one single sheet of data, with all of the required
    data listed column by column (that is, cost, consumption, sales, and more):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/80f80a27-42ee-4915-a5bb-7de60f89f01a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Each line (or row) of the data should represent a single month. Right before
    we feed our data for the machine to learn the patterns, we will need to set aside
    some data for testing and some for learning. With the testing data, we can see
    whether the model predicts well, without training on the learning data first.
    This is a fundamental step in all ML/predictive models. We do not feed the testing
    dataset for ML/training. The line that calls the function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: In this program, we set aside the earliest 70% of data points as training data
    for the machine to learn and adapt to, while keeping the latter 30% of data points
    as testing data. This is data that will be used to compare against the prediction
    made by the model, not used to fit the data.
  prefs: []
  type: TYPE_NORMAL
- en: Model fitting the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once the data is clean, we will start training the machine to learn about the
    pattern. The training data will be fed to the machine as fitting. The model is
    like a shirt and the training data is like the body we're attempting to fit it
    to.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the steps to fit our data into an ARIMA model:'
  prefs: []
  type: TYPE_NORMAL
- en: For each data file/field in the consolidated file, we run *step 3* and *step
    4* (which have been marked in the code file for the following code block).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If the Boolean variable, `parameter_op`, is set to `True`, then we will run
    *step 5* (which is marked as well). This explores all the possible combinations
    of parameters in ARIMA with regard to `p`, `d`, and `q`, which are set as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`p`: Ranging from 0 to 12'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`d`: Ranging from 0 to 2'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`q`: Ranging from 0 to 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For combinations of any of the preceding values, we calculate the fitness of
    the data to the actual pattern and measure the error values. The combinations
    with the lowest error values are selected as the chosen parameters of the ARIMA
    model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The following is the code snippet to fine-tune the parameters used (please
    refer to the full code file on GitHub: [https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-for-Banking](https://github.com/PacktPublishing/Hands-On-Artificial-Intelligence-for-Banking)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! We have now delivered a model that can provide volume forecasts
    for the future!
  prefs: []
  type: TYPE_NORMAL
- en: Procuring commodities using neural networks on Keras
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will take a look at another more complex example. As before,
    we will define the problem statement and then define steps to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we want to forecast the procurement of commodities based on
    historical data. The commodity that we are going to use is natural gas. In the
    case of natural gas, we do not have any control over its pricing because it is
    a hugely globalized commodity. However, we can still set up the internal procurement
    strategy when the pricing of the natural gas hits a certain range. The profitability
    ratio target will constrain the maximum pricing we can pay for the raw material
    to be profitable for the owners of the firm. We will track the profitability ratio,
    which is the ratio of cost of natural gas to sales.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand this pricing constraint with an example. In this example,
    we assume that for each dollar spent where the unit cost of natural gas (for electric
    power) increased, the cost of materials to sales of the energy company will increase
    by **9.18%** (this is based on 3 years of data):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6a26e3a0-4c56-4591-9a36-5147ead969ee.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The following table shows the weighted average for sales on an annual basis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/761ff695-2f42-4796-b6ec-f358d0014b85.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, you can see the cost of natural gas to sales from **2015** to **2017**.
    In **2017**, at an average unit weight of **$3.91**, the cost of natural gas to
    sales is at **36.45%**. We assume that the average unit weight and cost to sales
    are in a constant relationship—averaging the values of the cost of materials rate
    across the years (from **2015**-**2017**, that is, **7.66%**, **9.32%**, and **9.66%**).
    We took an average of all three figures to come to a weighted average of **9.18%**.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the actual number should, in practice, come from the internal accounting
    system, not the external US **Energy Information Administration** (**EIA**) data
    that is used only for the purpose of electric power.
  prefs: []
  type: TYPE_NORMAL
- en: Based on the last 3 years of data, we find that the average cost of materials
    to sales stood at 31.15% (the average of iii from the table), which translates
    into $3.39 million/thousand cubic feet. The cost of the material of sales is at
    36.24% with the unit cost at $3.95 million/mcf in the upper range. The **mcf**
    is a standard unit cost of natural gas. It is equal to a thousand cubic feet.
    However, at the lower range, the cost of the material of sales is 26.07% with
    the unit cost at $2.84 million/mcf. The unit conversion details can be found on
    the EIA website.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data is extracted from the preceding sales figure table: *Operating Expenses/Operating
    Revenues = cost of materials to sales*.'
  prefs: []
  type: TYPE_NORMAL
- en: After we have established the procurement plan, we then need to understand where
    to source the natural gas from. In real life, we would consider how the model's
    insight gets executed; perhaps we also need to build a model to make the subsequent
    decision on how the model's insights get executed. This is exactly what we have
    mentioned in business understanding on how to execute the order in exchange markets.
  prefs: []
  type: TYPE_NORMAL
- en: To complete this story, we assume that we purchase the natural gas from the
    exchange markets using physical deliveries whenever the price hits the target
    range for the quantity we forecasted.
  prefs: []
  type: TYPE_NORMAL
- en: Data flow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following data flow outlines the steps we need to take in order to prepare
    and generate the code to build the commodity procurement model. The first box
    denotes a script run on the SQLite database; the other boxes denote steps run
    on Python:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/de546535-10d8-4539-af24-fe10f04bb9f7.png)'
  prefs: []
  type: TYPE_IMG
- en: It generally fits into the framework of CRISP-DM, with different areas of focus
    throughout this book—some may focus on understanding the business, while some
    may focus on evaluation. The steps in the preceding diagram are covered in detail
    in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Preprocessing the data (in the SQL database)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data preprocessing means converting the data into the desired data features.
    We run it outside of Python coding to reduce the layers involved (that is, we
    interact directly with SQLite rather than using Python to interact with SQLite).
    Here are the steps involved in performing database operations:'
  prefs: []
  type: TYPE_NORMAL
- en: Create the SQLite database.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Import the data as a staging table.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the required table(s)—a one-time operation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the staging table into the actual table with data type and format transformation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create the view that does the feature engineering.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Output the preprocessed view as CSV data.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Importing libraries and defining variables
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Import libraries and define variables to make sure that the relevant functions
    can be used. Import all of the relevant libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pandas`: This is for data storage before data is fed to the machine learning module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`keras`: This an easy-to-use machine learning framework that has another library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tensorflow`: This is used as the backend.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sklearn`: This is a very popular machine learning module that provides lots
    of data preprocessing toolkits along with some machine learning models that are
    easy to use. The models are not used in this example, as we wish to build up the
    foundation for the more extensive use of machine learning models afterward. In
    addition, `sklearn` also has metrics that appraise the performance of the models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`matplotlib`: This is the default data visualization tool.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following code block is the code importing all the listed libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Reading in data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is the code snippet to read in the data and take on the result
    generated from *step 1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Preprocessing the data (in Python)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we come to data preprocessing in Python. Some studies claim that data scientists
    spend 80% of their time on this step! It includes selecting features and target
    variables, checking/validating data types and handling missing values (this component
    is not included in this example to reduce complexity), and splitting data into
    a training set and a testing set. In some cases, when the ratios of the various
    classes of targets are not similar in quantity, we may need to do stratified sampling
    to ensure that balanced training samples are fed for machine learning. In this
    example, we set aside 20% for testing and 80% for training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Training and validating the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We train the neural network by feeding the training dataset to generate a model.
    The following code snippet defines the machine learning model in Keras and trains
    it. It builds the deep neural network model with 329 parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Testing the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will compare the data points set aside (20%) in *step 4* against the predicted
    outcome based on the models trained and the features data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing the test result
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This step allows us to cross-check the metrics that represent the performance
    of the model—the MSE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This will result in the following plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/676dc5bf-04f0-4c0e-97c3-745d6b7c9508.png)'
  prefs: []
  type: TYPE_IMG
- en: Generating the model for production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The model that was trained and tested in *steps 5* and *6* will be output as
    a file for the production system to run on unseen production data. We will output
    two files—one for scaling the input features and another one for the neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Congratulations! We have now delivered a model that can be used at the operational
    level to identify the quantity to order for this month''s demand, next month,
    and the month after. The following diagram shows the steps in the training versus
    the deployment of machine learning models:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f49bd5d6-8529-4a66-8fae-8c9f7fdc7cf8.png)'
  prefs: []
  type: TYPE_IMG
- en: However, we are not going to cover deployment right now. We will keep this in
    mind and address the topic as we progress in this book. We will explore wrapping
    the AI production solution as an API in [Chapter 8](064a80f9-0636-4b3f-aed3-e2fee86ed7af.xhtml),
    *Building Personal Wealth Advisers with Bank APIs*.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned about time series analysis, M2M communication,
    and the benefits of time series analysis for commercial banking. We also looked
    at two useful examples by defining the problem statement and deriving the solution
    step by step. We also learned about the basic concepts of time series analysis
    and a few techniques, such as ARIMA.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore reinforcement learning. Reinforcement learning
    is an area of machine learning involving algorithms. The application takes an
    appropriate action to maximize the effectiveness of the outcome in a particular
    situation. We will also look at how to automate decision-making in banking using
    reinforcement learning. Exciting, isn't it?
  prefs: []
  type: TYPE_NORMAL
