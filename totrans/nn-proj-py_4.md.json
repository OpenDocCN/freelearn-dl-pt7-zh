["```py\n$ git clone https://github.com/PacktPublishing/Neural-Network-Projects-with-Python.git\n```", "```py\n$ cd Neural-Network-Projects-with-Python\n```", "```py\n$ conda env create -f environment.yml\n```", "```py\n$ conda activate neural-network-projects-python\n```", "```py\n$ pip install piexif\n```", "```py\n$ cd Chapter04\n```", "```py\n$ python main_basic_cnn.py\n$ python main_vgg16.py\n```", "```py\nfrom matplotlib import pyplot as plt\nimport os\nimport random\n\n# Get list of file names\n_, _, cat_images = next(os.walk('Dataset/PetImages/Cat'))\n\n# Prepare a 3x3 plot (total of 9 images)\nfig, ax = plt.subplots(3,3, figsize=(20,10))\n\n# Randomly select and plot an image\nfor idx, img in enumerate(random.sample(cat_images, 9)):\n    img_read = plt.imread('Dataset/PetImages/Cat/'+img)\n    ax[int(idx/3), idx%3].imshow(img_read)\n    ax[int(idx/3), idx%3].axis('off')\n    ax[int(idx/3), idx%3].set_title('Cat/'+img)\nplt.show()\n```", "```py\n# Get list of file names\n_, _, dog_images = next(os.walk('Dataset/PetImages/Dog'))\n\n# Prepare a 3x3 plot (total of 9 images)\nfig, ax = plt.subplots(3,3, figsize=(20,10))\n\n# Randomly select and plot an image\nfor idx, img in enumerate(random.sample(dog_images, 9)):\n    img_read = plt.imread('Dataset/PetImages/Dog/'+img)\n    ax[int(idx/3), idx%3].imshow(img_read)\n    ax[int(idx/3), idx%3].axis('off')\n    ax[int(idx/3), idx%3].set_title('Dog/'+img)\nplt.show()\n```", "```py\nfrom utils import train_test_split\n\nsrc_folder = 'Dataset/PetImages/'\ntrain_test_split(src_folder)\n```", "```py\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimage_generator = ImageDataGenerator(rotation_range = 30,\n                                     width_shift_range = 0.2,\n                                     height_shift_range = 0.2,\n                                     zoom_range = 0.2,\n                                     horizontal_flip=True,\n                                     fill_mode='nearest')\nImageDataGenerator class. Each of the arguments control how much of a modification is done to the existing image. We should avoid extreme transformations, as those extremely distorted images do not represent images from the real world and may introduce noise into our model.\n```", "```py\nfig, ax = plt.subplots(2,3, figsize=(20,10))\nall_images = []\n\n_, _, dog_images = next(os.walk('Dataset/PetImages/Train/Dog/'))\nrandom_img = random.sample(dog_images, 1)[0]\nrandom_img = plt.imread('Dataset/PetImages/Train/Dog/'+random_img)\nall_images.append(random_img)\n\nrandom_img = random_img.reshape((1,) + random_img.shape)\nsample_augmented_images = image_generator.flow(random_img)\n\nfor _ in range(5):\n    augmented_imgs = sample_augmented_images.next()\n    for img in augmented_imgs:\n        all_images.append(img.astype('uint8'))\n\nfor idx, img in enumerate(all_images):\n    ax[int(idx/3), idx%3].imshow(img)\n    ax[int(idx/3), idx%3].axis('off')\n    if idx == 0:\n        ax[int(idx/3), idx%3].set_title('Original Image')\n    else:\n        ax[int(idx/3), idx%3].set_title('Augmented Image {}'.format(idx))\n\nplt.show()\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator\n\nmodel = Sequential()\n```", "```py\nFILTER_SIZE = 3\nNUM_FILTERS = 32\nINPUT_SIZE  = 32\nMAXPOOL_SIZE = 2\nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = 20000//BATCH_SIZE\nEPOCHS = 10\n```", "```py\nmodel.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n                 input_shape = (INPUT_SIZE, INPUT_SIZE, 3),\n                 activation = 'relu'))\n```", "```py\nmodel.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE)))\n```", "```py\nmodel.add(Conv2D(NUM_FILTERS, (FILTER_SIZE, FILTER_SIZE),\n                 input_shape = (INPUT_SIZE, INPUT_SIZE, 3),\n                 activation = 'relu'))\n\nmodel.add(MaxPooling2D(pool_size = (MAXPOOL_SIZE, MAXPOOL_SIZE)))\n```", "```py\nmodel.add(Flatten())\n```", "```py\nmodel.add(Dense(units = 128, activation = 'relu'))\n```", "```py\n# Set 50% of the weights to 0 \nmodel.add(Dropout(0.5))\n```", "```py\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\n```", "```py\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n```", "```py\ntraining_data_generator = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = training_data_generator. \\\n                   flow_from_directory('Dataset/PetImages/Train/',\n                                       target_size=(INPUT_SIZE,INPUT_SIZE), \n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode='binary')\n\nmodel.fit_generator(training_set, steps_per_epoch = STEPS_PER_EPOCH, \n                    epochs=EPOCHS, verbose=1)\n```", "```py\ntesting_data_generator = ImageDataGenerator(rescale = 1./255)\n\ntest_set = testing_data_generator. \\\n               flow_from_directory('Dataset/PetImages/Test/',\n                                   target_size=(INPUT_SIZE,INPUT_SIZE),\n                                   batch_size=BATCH_SIZE,\n                                   class_mode = 'binary')\n\nscore = model.evaluate_generator(test_set, steps=len(test_set))\nfor idx, metric in enumerate(model.metrics_names):\n    print(\"{}: {}\".format(metric, score[idx]))\n```", "```py\nfrom keras.applications.vgg16 import VGG16\n\nINPUT_SIZE = 128 # Change this to 48 if the code takes too long to run\nvgg16 = VGG16(include_top=False, weights='imagenet', \n              input_shape=(INPUT_SIZE,INPUT_SIZE,3))\n```", "```py\nfor layer in vgg16.layers:\n    layer.trainable = False\n```", "```py\nfrom keras.models import Model\n\ninput_ = vgg16.input\noutput_ = vgg16(input_)\nlast_layer = Flatten(name='flatten')(output_)\nlast_layer = Dense(1, activation='sigmoid')(last_layer)\nmodel = Model(input=input_, output=last_layer)\n```", "```py\n# Define hyperparameters\nBATCH_SIZE = 16\nSTEPS_PER_EPOCH = 200\nEPOCHS = 3\n\nmodel.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n              metrics = ['accuracy'])\n\ntraining_data_generator = ImageDataGenerator(rescale = 1./255)\ntesting_data_generator = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = training_data_generator. \\\n                   flow_from_directory('Dataset/PetImages/Train/',\n                                       target_size=(INPUT_SIZE,INPUT_SIZE),\n                                       batch_size = BATCH_SIZE,\n                                       class_mode = 'binary')\n\ntest_set = testing_data_generator. \\\n               flow_from_directory('Dataset/PetImages/Test/',\n                                   target_size=(INPUT_SIZE,INPUT_SIZE),\n                                   batch_size = BATCH_SIZE,\n                                   class_mode = 'binary')\n\nmodel.fit_generator(training_set, steps_per_epoch = STEPS_PER_EPOCH, \n                    epochs = EPOCHS, verbose=1)\n```", "```py\nscore = model.evaluate_generator(test_set, len(test_set))\n\nfor idx, metric in enumerate(model.metrics_names):\n    print(\"{}: {}\".format(metric, score[idx]))\n```", "```py\n# Generate test set for data visualization\ntest_set = testing_data_generator. \\\n               flow_from_directory('Dataset/PetImages/Test/',\n                                    target_size = (INPUT_SIZE,INPUT_SIZE),\n                                    batch_size = 1,\n                                    class_mode = 'binary')\n\nstrongly_wrong_idx = []\nstrongly_right_idx = []\nweakly_wrong_idx = []\n\nfor i in range(test_set.__len__()):\n    img = test_set.__getitem__(i)[0]\n    pred_prob = model.predict(img)[0][0]\n    pred_label = int(pred_prob > 0.5)\n    actual_label = int(test_set.__getitem__(i)[1][0])\n    if pred_label != actual_label and (pred_prob > 0.8 or \n        pred_prob < 0.2): strongly_wrong_idx.append(i)\n    elif pred_label != actual_label and (pred_prob > 0.4 and \n        pred_prob < 0.6): weakly_wrong_idx.append(i)\n    elif pred_label == actual_label and (pred_prob > 0.8 or\n        pred_prob < 0.2): strongly_right_idx.append(i)\n    # stop once we have enough images to plot\n    if (len(strongly_wrong_idx)>=9 and len(strongly_right_idx)>=9 \n        and len(weakly_wrong_idx)>=9): break\n```", "```py\nfrom matplotlib import pyplot as plt\nimport random\n\ndef plot_on_grid(test_set, idx_to_plot, img_size=INPUT_SIZE):\n    fig, ax = plt.subplots(3,3, figsize=(20,10))\n    for i, idx in enumerate(random.sample(idx_to_plot,9)):\n        img = test_set.__getitem__(idx)[0].reshape(img_size, img_size ,3)\n        ax[int(i/3), i%3].imshow(img)\n        ax[int(i/3), i%3].axis('off')\n```", "```py\nplot_on_grid(test_set, strongly_right_idx)\n```", "```py\nplot_on_grid(test_set, strongly_wrong_idx)\n```", "```py\nplot_on_grid(test_set, weakly_wrong_idx)\n```"]