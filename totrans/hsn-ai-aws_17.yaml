- en: What Is Next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the preceding chapters, as the title of this book suggests, we took a hands-on
    approach to help you become better AI practitioners. Through the hands-on projects
    in this book, you developed the skills to embed AWS AI capabilities into applications
    and create custom AI capabilities using AWS ML platforms. More importantly, you
    developed the intuition to create well-designed, intelligence-enabled solutions
    that can help solve real-world problems. These projects not only taught you about
    a variety of AI technologies, they also showed you the various problem domains
    and business contexts where AI can be applied. As AI practitioners, it is important
    to see AI through the lens of business capabilities rather than just technologies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part I
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part II
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part III
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part IV
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What's next?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part I
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Part I, we introduced you to a plethora of AI offerings from AWS and grouped
    them into two categories:'
  prefs: []
  type: TYPE_NORMAL
- en: AI services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ML platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our recommendation to you is to first leverage AWS-managed AI services, such
    as Rekogntion, Translate, and Comprehend, in your solution development. Only when
    there is a need for custom AI capabilities should you then build them with AWS
    ML platforms such as SageMaker. This approach will improve your speed to market
    and the return on investment for your intelligent-enabled applications. We also
    explained that the true power of developing intelligent-enabled solutions on AWS
    is to combine AWS AI offerings with the rest of the AWS cloud computing ecosystem,
    including S3, DynamoDB, and EMR.
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed architecture design for AI applications and how a well-designed
    architecture allows for rapid iteration and adaptability to market changes. We
    laid out an architecture design template for the hands-on projects in Part II
    and also showed you how the custom AI capabilities we built in Part III can easily
    integrate into this architecture. This architecture template can be adopted and
    modified for your next intelligent solution that's built on top of AWS AI services
    or your own custom AI capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part II
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In Part II, we focused on embedding AI capabilities into applications by doing
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We used many AWS-managed AI services to build several end-to-end intelligent-enabled
    solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We introduced to you the AWS SDK, boto3, to interact with cloud services and
    their infrastructure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used the AWS Chalice framework to develop and deploy serverless applications
    to the API Gateway and AWS Lambda.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We used HTML, CSS, and JavaScript to build user interfaces for these solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Along the way, we shared our tips and tricks for the development, testing, maintenance,
    and evolution of AI applications on AWS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 3](504c5915-cf10-4cd0-8f5c-3c75466f7dc6.xhtml), *Detecting and Translating
    Text with Amazon Rekognition and Translate*, we built a Pictorial Translator that
    not only detects text within an image but also translates it into any language
    (English, for our project). This application can be used by travelers to a foreign
    land or by the visually impaired who wish to interact with the real world.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](df16cdd8-9f43-4d5c-88d8-49b1f2a67748.xhtml), *Performing Speech-to-Text
    and Vice Versa with Amazon Transcribe and Polly*, we built a modestly named Universal
    Translator that can enable verbal communication between people who are speaking
    different languages. This application can be used by travelers, students, and
    so on.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 5](cffd245d-bee7-40bc-a64f-e108c039a8ec.xhtml), *Extracting Information
    from Text with Amazon Comprehend*, we built a Contact Organizer that helps automate
    the extraction of contact information from pictures of business cards. We introduced
    the human-in-the-loop concept to improve our end-to-end solution's accuracy. This
    type of application can help reduce manual works for many back-office tasks so
    that workers can focus on more creative tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 6](2e03dd94-bf8a-4583-9a77-e780a67e11d7.xhtml), *Building a Voice
    Chatbot with Amazon Lex,* we built an intelligent assistant, Contact Assistant,
    that can search for contact information through a conversational interface. This
    intelligent assistant not only understands us through natural language, it also
    remembers the context of the conversation to make the interface even more fluid.
    These types of intelligent assistant interface improve many of our daily tasks,
    such as information searches, communication, reminders, and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part III
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Part III, we focused on how SageMaker can be leveraged to train and deploy
    ML models, both built-in and custom, to solve business problems that cannot be
    readily solved using AWS AI services.
  prefs: []
  type: TYPE_NORMAL
- en: We started with [Chapter 7](ece77200-0c6c-44f8-986a-bc08531989b1.xhtml), *Working
    with Amazon SageMaker*, where we learned how to process large datasets, conduct
    training, and optimize hyperparameters in SageMaker.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we looked at how SageMaker makes it seamless to run multiple experiments
    and deploy the best performing model for inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We also illustrated how bringing your own model and container to SageMaker allows
    you to readily leverage capabilities such as model training, deployment, and inference
    at scale.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In [Chapter 8](16e50aca-401b-47b0-87c3-34cc0346e66e.xhtml), *Creating Machine
    Learning Inference Pipelines**,* we learned how to conduct data preprocessing
    via Glue, a serverless ETL AWS service. A machine learning pipeline was built
    to reuse data preprocessing logic for both training and inference. We also learned
    how to use the ML pipeline for both real-time and batch predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 9](0537c904-c763-496c-bfd2-f18042dcd0a2.xhtml), *Discovering Topics
    in Text Collection,* we reviewed various approaches—linear and non-linear – so
    that we could discover topics in text collection. Then, we delved into how topic
    modeling can be handled through the built-in NTM algorithm (variational autoencoder).
    The model training, deployment, and inference steps in SageMaker were explained
    through a sample dataset of *Enron Emails.*
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 10](504e6f30-cb03-44c3-843f-a7c67f478809.xhtml), *Sales Forecasting
    with Deep Learning and Auto Regression*, we looked at the difference between traditional
    time series forecasting methods, such as exponential smoothing and ARIMA, and
    more flexible and scalable methods, such as auto-regressive recurrent networks.
    We then looked at how the DeepAR algorithm in SageMaker can be used to model retail
    sales given a variety of factors, such as holidays, promotions, and unemployment.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 11](349450a8-2e51-4ea9-b533-dec8081cd71c.xhtml), *Classifying Images
    using Amazon SageMaker,* we reviewed convolutional neural networks and the purpose
    of residual networks. Then, we introduced the concept of incremental learning
    through transfer learning. We also explained how to classify bakery items through
    transfer learning, even with small image datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing the concepts we learned in Part IV
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In Part IV, that is, [Chapter 12](bc4728ee-263d-4713-8f3c-816336624043.xhtml),
    *Model Accuracy Degradation and Feedback Loops**,* we defined the concept of model
    performance deterioration through an ad-click conversion dataset. We walked through
    the idea of a feedback loop and why it becomes important in modeling dynamic ad-click
    behavior. Then, we demonstrated how model performance improves—through a feedback
    loop—in predicting whether an ad click results in app downloads.
  prefs: []
  type: TYPE_NORMAL
- en: What's next?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We've covered a lot of concepts and techniques in AI, but with this book we
    have only scratched the surface of this broad and deep field. Armed with the necessary
    AI skills and intuition, what's next for an AI practitioner? The following are
    some recommendations from us so that you can explore this growing field more comprehensively.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence in the physical world
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One way to grow as an AI practitioner is to broaden your experience with different
    applications of AI. One growing group of AI applications aims to combine AI capabilities
    with sensors and actuators in the physical world. Examples of such physical-world
    applications include home automation, smart factories, self-driving cars, and
    robots. The idea of building physical machinery, vehicles, and robots might be
    daunting to some AI practitioners. Luckily, AWS provides several products to make
    getting started with this group of AI applications easier.
  prefs: []
  type: TYPE_NORMAL
- en: AWS DeepLens
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS DeepLens is a physical device that has a video camera and compute, storage,
    and internet connectivity packaged into a small device. Along with other AWS AI
    services and tools, DeepLens becomes a powerful platform when you want to get
    hands-on experience with deep learning applications. Take a look at the following
    screenshot showing AWS DeepLens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff420db1-fd86-4fbc-b1d3-f429954c7881.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Let''s talk about some of the remarkable features of DeepLens:'
  prefs: []
  type: TYPE_NORMAL
- en: DeepLens can capture images and videos in **high definition** (**HD**), and
    has enough onboard power to process HD videos in real-time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI practitioners can quickly get started with projects on DeepLens with AWS
    AI services. For example, it integrates with Amazon Rekognition to analyze images
    and videos that have been taken by the camera.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepLens is fully programmable using AWS Lambda to invoke a broad set of functionalities
    and actuators connected to the internet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepLens also supports custom ML models that are trained with Amazon SageMaker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI practitioners can choose from a broad set of deep learning frameworks, including
    TensorFlow and Caffe, to train ML models and run them on DeepLens' onboard inference
    engine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These custom ML models can be deployed to DeepLens with just a few clicks or
    API calls.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By reading this book, you are already familiar with many of the tools that we
    just mentioned and have already developed many of the skills you need to get started
    with AWS DeepLens. With this powerful platform, AI practitioners can build a broad
    set of applications. A few example applications include home security, bird watching,
    traffic monitoring, delivery notification, home automation, and many more. Combined
    with other sensors and actuators, the possibilities are endless.
  prefs: []
  type: TYPE_NORMAL
- en: AWS DeepRacer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS DeepRacer is a 1/18^(th) scale race car with an integrated camera, accelerometer,
    and gyroscope; it also has compute, storage, and internet connectivity onboard.
    DeepRacer is designed to help AI practitioners get hands-on experience with reinforcement
    learning through autonomous car racing. Reinforcement learning is a branch of
    ML that aims to create intelligent agents that learn from optimizing reward functions
    rather than learning from examples (supervised learning) or the inherent structure
    of the data (unsupervised learning). This AI technique has been used to train
    intelligent agents to run, drive, and play games. For example, Google''s AlphaGo
    program that beat the top Go player in the world uses this ML technique. The following
    shows AWS DeepRacer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/990b4862-2ae0-4dc8-abb3-15f65bfed48d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'DeepRacer brings the following AI capabilities into the real world:'
  prefs: []
  type: TYPE_NORMAL
- en: By using the camera and other on-board sensors, an AI practitioner can develop
    reinforcement models to control DeepRacer's throttle and steer it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DeepRacer comes with a 3D racing simulator for easy development and testing
    of its AI racing capabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like DeepLens, DeepRacer also integrates with AWS AI services and the cloud
    infrastructure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use Amazon SageMaker to train reinforcement learning models and deploy
    them to your racer with ease.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is even a DeepRacer League to test out any AI racing capabilities you've
    developed for prizes and glory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The applications that are built on top of this platform don't have to be limited
    to racing either. With a camera on wheels, there are many options available, such
    as home surveillance, pet training, and item delivery. We are willing to bet that
    a DeepDrone has been proposed at AWS at some point.
  prefs: []
  type: TYPE_NORMAL
- en: Internet of Things and AWS IoT Greengrass
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For AI applications to function well in the physical world, there is a need
    for AI capabilities at the edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS IoT Greengrass lets connected devices seamlessly and securely interact
    with other devices and cloud applications. Greengrass brings many benefits to
    AI applications, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: It brings faster response times when you wish to act on local events and data
    without needing a trip to the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It improves the cost efficiency of running IoT by reducing the bandwidth requirements
    for data transport between the edge and the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It simplifies data security and privacy by processing and anonymizing sensitive
    information locally for applications in certain sectors such as healthcare.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AWS IoT Greengrass can also extend the power of AI capabilities to edge devices,
    thus creating an intelligent edge. The following architectural diagram shows how
    edge devices can run machine learning inferences locally and then connect to AWS
    IoT Core to send messages or inferences to the cloud for further analytics through
    Greengrass Core:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/053f360f-6867-4a31-b80c-4e6b7cf4e97d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In this architecture, we can see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Models that are trained in Amazon SageMaker are persisted in the S3 bucket.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data that's generated at the edge is then scored by these trained models via
    local lambda functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS Greengrass' core controls communication between the edge and the cloud,
    including security, messaging, and offline compute operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS IoT Core, on the other hand, orchestrates a connection with other AWS services,
    that is, durable storage or analytics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several business problems can be solved by leveraging the edge intelligent architecture.
    With autonomous vehicles, there's a need for an intelligent edge to steer the
    car around the local environment without latency from the network. If you manufacture
    plants, by running ML inferences on the edge, you can predict the end of life
    of machinery locally and take instant actions to improve safety. With health care
    applications, sensitive medical information can be used locally to perform intelligent
    diagnoses with low latency and without putting the patient's privacy at risk in
    the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial intelligence in your own field
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another way to grow as an AI practitioner is to delve more deeply into a particular
    field or business domain. A good approach is to apply AI to a field you have expertise
    in or have an interest in. You know better than anyone else which field to choose.
  prefs: []
  type: TYPE_NORMAL
- en: In that chosen field, you will find a particular set of business problems, and
    then develop the relevant AI skills that are needed to solve those problems. The
    problems in your field might require computer vision, natural language processing,
    speech recognition, knowledge reasoning, or a combination of these techniques.
    As an AI practitioner, you will then develop more specialized skills in those
    AI techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In that chosen field, you might know about some existing problems you wish to
    solve or you might need to discover new problems to solve. Finding and defining
    those problems is the key to gaining a competitive advantage over other AI generalists.
    To start on this path, however, we recommend that you just get started with small
    hands-on projects related to the field. Just like the recommendation from this
    book, you should develop your intuition by doing hands-on work, even if it's just
    replicating an existing solution from your field. Over time, you will gradually
    build up better insights into how to solve related problems.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we have covered various AI fundamentals in AWS, highlighting AI
    application development, pre-defined AI APIs, model building, training, deployment,
    management, and experimentation through ML pipelines. We have suggested two ways
    that you can continue your journey as an AI practitioner on AWS, that is, either
    going broad or going deep. We hope that you've enjoyed reading (and working through)
    this book and that you are all set to solve challenging business problems through
    AWS Artificial Intelligence-related services.
  prefs: []
  type: TYPE_NORMAL
