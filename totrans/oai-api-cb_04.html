<html><head></head><body>
<div id="_idContainer035" class="calibre2">
<h1 class="chapter-number" id="_idParaDest-72"><a id="_idTextAnchor074" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.1.1">4</span></h1>
<h1 id="_idParaDest-73" class="calibre5"><a id="_idTextAnchor075" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.2.1">Incorporating Additional Features from the OpenAI API</span></h1>
<p class="calibre3"><a id="_idTextAnchor076" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.3.1">The OpenAI API offers additional features beyond the standard endpoints and parameters that we learned about in the previous chapter. </span><span class="kobospan" id="kobo.3.2">These provide additional customizability to the existing model and enable far more use cases by linking the model to </span><span><span class="kobospan" id="kobo.4.1">other methods.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.5.1">In particular, the OpenAI API contains a robust embedding model, enabling users to vectorize text to perform typical NLP functions such as text clustering, text classification, text comparison, and more. </span><span class="kobospan" id="kobo.5.2">This is the same technology that search engines such as Google use, for example, to return relevant search results. </span><span class="kobospan" id="kobo.5.3">Now, with the OpenAI API, it is available at </span><span><span class="kobospan" id="kobo.6.1">your fingertips.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.7.1">The API also contains a method to </span><em class="italic"><span class="kobospan" id="kobo.8.1">fine-tune</span></em><span class="kobospan" id="kobo.9.1"> or customize a model for a particular use case. </span><span class="kobospan" id="kobo.9.2">Instead of the fine-tuning we did earlier, which required </span><em class="italic"><span class="kobospan" id="kobo.10.1">priming</span></em><span class="kobospan" id="kobo.11.1"> the model with several examples, this is a better and typically </span><span><span class="kobospan" id="kobo.12.1">cheaper alternative.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.13.1">Finally, the API also possesses the ability to </span><a id="_idIndexMarker156" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.14.1">create </span><strong class="bold"><span class="kobospan" id="kobo.15.1">function calls</span></strong><span class="kobospan" id="kobo.16.1">. </span><span class="kobospan" id="kobo.16.2">This enables you to provide the API with a set of functions and their descriptions, and the model in turn intelligently creates a JSON object containing arguments to call that function, enabling you to link the OpenAI API to any </span><span><span class="kobospan" id="kobo.17.1">user-defined functions.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.18.1">However, in order to use these features, we need to call the API through a programmatic language such as </span><em class="italic"><span class="kobospan" id="kobo.19.1">Python</span></em><span class="kobospan" id="kobo.20.1"> instead of through one-time HTTP requests such as Postman. </span><span class="kobospan" id="kobo.20.2">As a result, we will first cover how to use the OpenAI API with Python instead of Postman, and then learn about the benefits that this change in </span><span><span class="kobospan" id="kobo.21.1">methodology enables.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.22.1">By the end of this chapter, you will know how to use these features in your applications. </span><span class="kobospan" id="kobo.22.2">This is important because understanding these features will open up a plethora of other use cases that would otherwise not be possible to execute. </span><span class="kobospan" id="kobo.22.3">Additionally, we will cover applications of each feature beyond what is covered within </span><span><span class="kobospan" id="kobo.23.1">each recipe.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.24.1">In this chapter, we will cover the </span><span><span class="kobospan" id="kobo.25.1">following recipes:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><span class="kobospan" id="kobo.26.1">Using the Python library to call the </span><span><span class="kobospan" id="kobo.27.1">OpenAI API</span></span></li>
<li class="calibre15"><span class="kobospan" id="kobo.28.1">Using the embedding model for text comparison and other </span><span><span class="kobospan" id="kobo.29.1">use cases</span></span></li>
<li class="calibre15"><span class="kobospan" id="kobo.30.1">Fine-tuning a completion model and </span><span><span class="kobospan" id="kobo.31.1">relevant applications</span></span></li>
</ul>
<h1 id="_idParaDest-74" class="calibre5"><a id="_idTextAnchor077" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.32.1">Technical requirements</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.33.1">All the recipes in this chapter require you to have access to the OpenAI API (via a generated API key) and have an API client installed. </span><span class="kobospan" id="kobo.33.2">In case you don’t recall how to do this, you can refer to the </span><a href="B21007_01.xhtml#_idTextAnchor021" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.34.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.35.1"> recipe </span><em class="italic"><span class="kobospan" id="kobo.36.1">Making OpenAI API requests </span></em><span><em class="italic"><span class="kobospan" id="kobo.37.1">with Postman</span></em></span><span><span class="kobospan" id="kobo.38.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.39.1">In previous chapters, we have used Postman as our API client. </span><span class="kobospan" id="kobo.39.2">In this case, we will use the programmatic language Python instead. </span><span class="kobospan" id="kobo.39.3">Specifically, the recipes will use the OpenAI Python library to make calls to the </span><span><span class="kobospan" id="kobo.40.1">OpenAI API.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.41.1">We will run Python in a service called </span><strong class="bold"><span class="kobospan" id="kobo.42.1">Google Colab</span></strong><span class="kobospan" id="kobo.43.1">. </span><span class="kobospan" id="kobo.43.2">Colab is an online hosted </span><strong class="bold"><span class="kobospan" id="kobo.44.1">Jupyter Notebook</span></strong><span class="kobospan" id="kobo.45.1"> service by Google, that requires no setup to use and can run Python code within the browser. </span><span class="kobospan" id="kobo.45.2">The Jupyter Notebook is an open sourced web application that allows you to create and share documents and contains live code that can be run step by step. </span><span class="kobospan" id="kobo.45.3">This is the environment we will use to run our </span><span><span class="kobospan" id="kobo.46.1">Python code.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.47.1">To use Google Colab, you need to create and be signed in to a valid Google account, which is completely free. </span><span class="kobospan" id="kobo.47.2">Follow the steps to create a new Google account </span><span><span class="kobospan" id="kobo.48.1">at </span></span><a href="https://accounts.google.com/" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.49.1">https://accounts.google.com/</span></span></a><span><span class="kobospan" id="kobo.50.1">.</span></span></p>
<h1 id="_idParaDest-75" class="calibre5"><a id="_idTextAnchor078" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.51.1">Using the Python library to call the OpenAI API</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.52.1">Previously, we </span><a id="_idIndexMarker157" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.53.1">used HTTP requests and </span><a id="_idIndexMarker158" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.54.1">Postman to call the OpenAI API. </span><span class="kobospan" id="kobo.54.2">Now, we are transferring to another method of calling the API, through Python with the dedicated OpenAI Python library. </span><span class="kobospan" id="kobo.54.3">Why does this matter and why is </span><span><span class="kobospan" id="kobo.55.1">this important?</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.56.1">Utilizing the Python library for OpenAI API calls offers a significant advantage over manual HTTP requests in tools such as Postman, especially for developers looking to integrate ChatGPT functionality into their </span><span><span class="kobospan" id="kobo.57.1">applications seamlessly.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.58.1">Python’s library simplifies the intricacies involved in making direct HTTP requests by offering a more user-friendly and intuitive interface. </span><span class="kobospan" id="kobo.58.2">This facilitates quick prototyping, streamlined error management, and efficient parsing of responses. </span><span class="kobospan" id="kobo.58.3">The library wraps the fundamental </span><a id="_idIndexMarker159" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.59.1">details of the protocol, allowing developers to concentrate on their application’s essential functionality without being bogged down by the specifics of request headers, query strings, and </span><span><span class="kobospan" id="kobo.60.1">HTTP methods.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.61.1">Furthermore, Python’s </span><a id="_idIndexMarker160" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.62.1">extensive package ecosystem readily supports the integration of the OpenAI API with other services and systems, allowing for a scalable and maintainable </span><span><span class="kobospan" id="kobo.63.1">code base.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.64.1">Overall, if you are serious about building intelligent applications with the OpenAI API, you need to call the API with a programmatic language that enables complex logic and tie-ins to other systems. </span><span class="kobospan" id="kobo.64.2">Python, through the OpenAI library, is one way to </span><span><span class="kobospan" id="kobo.65.1">accomplish that.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.66.1">In this recipe, we will create some simple API calls using Python and the OpenAI library. </span><span class="kobospan" id="kobo.66.2">More information on the library can be found </span><span><span class="kobospan" id="kobo.67.1">here: </span></span><a href="https://github.com/openai/openai-python" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.68.1">https://github.com/openai/openai-python</span></span></a><span><span class="kobospan" id="kobo.69.1">.</span></span></p>
<h2 id="_idParaDest-76" class="calibre7"><a id="_idTextAnchor079" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.70.1">Getting ready</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.71.1">Ensure you have an OpenAI platform account with available usage credits. </span><span class="kobospan" id="kobo.71.2">If you don’t, please follow the </span><em class="italic"><span class="kobospan" id="kobo.72.1">Setting up your OpenAI Playground environment</span></em><span class="kobospan" id="kobo.73.1"> recipe in </span><a href="B21007_01.xhtml#_idTextAnchor021" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.74.1">Chapter 1</span></em></span></a><span><span class="kobospan" id="kobo.75.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.76.1">Furthermore, ensure you are logged in to a Google account and have access to a notebook. </span><span class="kobospan" id="kobo.76.2">You can verify this by going to </span><a href="https://colab.google/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.77.1">https://colab.google/</span></a><span class="kobospan" id="kobo.78.1"> and selecting </span><strong class="bold"><span class="kobospan" id="kobo.79.1">New Notebook</span></strong><span class="kobospan" id="kobo.80.1"> at the top right. </span><span class="kobospan" id="kobo.80.2">After that, you should have a blank screen with an empty </span><span><span class="kobospan" id="kobo.81.1">notebook open.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.82.1">All the recipes in this chapter have the </span><span><span class="kobospan" id="kobo.83.1">same requirements.</span></span></p>
<h2 id="_idParaDest-77" class="calibre7"><a id="_idTextAnchor080" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.84.1">How to do it…</span></h2>
<ol class="calibre14">
<li class="calibre15"><span class="kobospan" id="kobo.85.1">In your Google Colab notebook, click the first empty cell, and type in the following code to download and install the OpenAI Python library. </span><span class="kobospan" id="kobo.85.2">After you have typed the code in, press </span><em class="italic"><span class="kobospan" id="kobo.86.1">Shift</span></em><span class="kobospan" id="kobo.87.1"> + </span><em class="italic"><span class="kobospan" id="kobo.88.1">Enter</span></em><span class="kobospan" id="kobo.89.1"> to run the code inside the cell. </span><span class="kobospan" id="kobo.89.2">Alternatively, you can run the code inside the cell by clicking the </span><strong class="bold"><span class="kobospan" id="kobo.90.1">Play</span></strong><span class="kobospan" id="kobo.91.1"> button to the left of the cell. </span><span class="kobospan" id="kobo.91.2">This code will attempt to install the OpenAI Python library and all its dependencies. </span><span class="kobospan" id="kobo.91.3">You may see output such as </span><strong class="source-inline1"><span class="kobospan" id="kobo.92.1">Requirements already satisfied</span></strong><span class="kobospan" id="kobo.93.1"> or </span><strong class="source-inline1"><span class="kobospan" id="kobo.94.1">Installing httpcore</span></strong><span class="kobospan" id="kobo.95.1">. </span><span class="kobospan" id="kobo.95.2">This is Google attempting </span><a id="_idIndexMarker161" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.96.1">to install the libraries that OpenAI depends on to run its own library, and is </span><span><span class="kobospan" id="kobo.97.1">perfectly normal:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.98.1">
!pip install openai
from openai import OpenAI</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.99.1">Ensure</span><a id="_idIndexMarker162" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.100.1"> that the words </span><strong class="source-inline1"><span class="kobospan" id="kobo.101.1">Successfully installed openai-X.XX.X</span></strong><span class="kobospan" id="kobo.102.1"> are visible, as seen in </span><span><em class="italic"><span class="kobospan" id="kobo.103.1">Figure 4</span></em></span><span><em class="italic"><span class="kobospan" id="kobo.104.1">.1</span></em></span><span><span class="kobospan" id="kobo.105.1">.</span></span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer027">
<span class="kobospan" id="kobo.106.1"><img alt="Figure 4.1 – Output of Jupyter notebook after installing the OpenAI library" src="image/B21007_04_01.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.107.1">Figure 4.1 – Output of Jupyter notebook after installing the OpenAI library</span></p>
<ol class="calibre14">
<li value="3" class="calibre15"><span class="kobospan" id="kobo.108.1">Next, we need to perform authentication. </span><span class="kobospan" id="kobo.108.2">This is similar to the previous chapters where we had to authenticate our Postman requests by putting our API key in a </span><strong class="bold"><span class="kobospan" id="kobo.109.1">Header</span></strong><span class="kobospan" id="kobo.110.1"> parameter called </span><em class="italic"><span class="kobospan" id="kobo.111.1">Authorization</span></em><span class="kobospan" id="kobo.112.1">. </span><span class="kobospan" id="kobo.112.2">In Python, it’s much simpler. </span><span class="kobospan" id="kobo.112.3">In the cell below the one you used in </span><em class="italic"><span class="kobospan" id="kobo.113.1">step 1</span></em><span class="kobospan" id="kobo.114.1">, write the following code and press </span><em class="italic"><span class="kobospan" id="kobo.115.1">Shift</span></em><span class="kobospan" id="kobo.116.1"> + </span><em class="italic"><span class="kobospan" id="kobo.117.1">Enter</span></em><span class="kobospan" id="kobo.118.1">. </span><span class="kobospan" id="kobo.118.2">Note, replace </span><strong class="source-inline1"><span class="kobospan" id="kobo.119.1">&lt;api-key&gt;</span></strong><span class="kobospan" id="kobo.120.1"> with the API key that you generated in the last recipe in </span><a href="B21007_01.xhtml#_idTextAnchor021" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.121.1">Chapter 1</span></em></span></a><span><span class="kobospan" id="kobo.122.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.123.1">
api_key = "&lt;api-key&gt;"
client = OpenAI(api_key=api_key)</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.124.1">We will now make a chat completion request to the OpenAI API. </span><span class="kobospan" id="kobo.124.2">Similar to Postman, we</span><a id="_idIndexMarker163" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.125.1"> can use different endpoints and define a variety of different parameters within the request in Python. </span><span class="kobospan" id="kobo.125.2">Type</span><a id="_idIndexMarker164" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.126.1"> the following code into a new cell below and press </span><em class="italic"><span class="kobospan" id="kobo.127.1">Shift</span></em><span class="kobospan" id="kobo.128.1"> + </span><em class="italic"><span class="kobospan" id="kobo.129.1">Enter</span></em><span class="kobospan" id="kobo.130.1">, which runs the code and saves the output in a variable </span><span><span class="kobospan" id="kobo.131.1">called </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.132.1">completion</span></strong></span><span><span class="kobospan" id="kobo.133.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.134.1">
completion = client.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {'role': 'system', 'content': 'You are an assistant that creates a slogan based on company description'},
        {"role": "user", "content": "A company that sells ice cream"}
    ],
    n=1,
    temperature=1
)</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.135.1">Output the </span><strong class="source-inline1"><span class="kobospan" id="kobo.136.1">completion</span></strong><span class="kobospan" id="kobo.137.1"> variable, which is a </span><strong class="source-inline1"><span class="kobospan" id="kobo.138.1">ChatCompletion</span></strong><span class="kobospan" id="kobo.139.1"> object. </span><span class="kobospan" id="kobo.139.2">We can convert this into the more familiar JSON format (exactly as in Postman) by typing the following in the cell below and running the code by pressing </span><em class="italic"><span class="kobospan" id="kobo.140.1">Shift</span></em><span class="kobospan" id="kobo.141.1"> + </span><span><em class="italic"><span class="kobospan" id="kobo.142.1">Enter</span></em></span><span><span class="kobospan" id="kobo.143.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.144.1">
import json
completion_json = json.loads(completion.json())
print(completion_json)</span></pre><p class="calibre3"><span><em class="italic"><span class="kobospan" id="kobo.145.1">Figure 4</span></em></span><em class="italic"><span class="kobospan" id="kobo.146.1">.2</span></em><span class="kobospan" id="kobo.147.1"> shows the output that you will see after running </span><span><span class="kobospan" id="kobo.148.1">this code.</span></span></p></li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer028">
<span class="kobospan" id="kobo.149.1"><img alt="Figure 4.2 – JSON output of the Python OpenAI completion request" src="image/B21007_04_02.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.150.1">Figure 4.2 – JSON output of the Python OpenAI completion request</span></p>
<ol class="calibre14">
<li value="6" class="calibre15"><span class="kobospan" id="kobo.151.1">Using </span><a id="_idIndexMarker165" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.152.1">Python, we can parse through </span><a id="_idIndexMarker166" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.153.1">the JSON and only output the part of the JSON that contains the company slogan. </span><span class="kobospan" id="kobo.153.2">We can do this by typing the following code into the cell below and pressing </span><em class="italic"><span class="kobospan" id="kobo.154.1">Shift</span></em><span class="kobospan" id="kobo.155.1"> + </span><em class="italic"><span class="kobospan" id="kobo.156.1">Enter</span></em><span class="kobospan" id="kobo.157.1"> to run </span><span><span class="kobospan" id="kobo.158.1">the code:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.159.1">
print(completion_json['choices'][0]['message']['content'])</span></pre></li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer029">
<span class="kobospan" id="kobo.160.1"><img alt="Figure 4.3 – Input and output of step 6" src="image/B21007_04_03.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.161.1">Figure 4.3 – Input and output of step 6</span></p>
<ol class="calibre14">
<li value="7" class="calibre15"><span class="kobospan" id="kobo.162.1">You now have a working Python Jupyter notebook that calls the OpenAI API, makes a chat completion request, and outputs </span><span><span class="kobospan" id="kobo.163.1">the result.</span></span></li>
</ol>
<h2 id="_idParaDest-78" class="calibre7"><a id="_idTextAnchor081" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.164.1">How it works…</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.165.1">In this recipe, we performed the same actions as we have done in previous recipes, the difference being that we used the OpenAI Python library instead of invoking HTTP requests through Postman. </span><span class="kobospan" id="kobo.165.2">We authenticated using our API key, made a chat completion request, and adjusted several parameters (such as </span><em class="italic"><span class="kobospan" id="kobo.166.1">Model</span></em><span class="kobospan" id="kobo.167.1">, </span><em class="italic"><span class="kobospan" id="kobo.168.1">Messages</span></em><span class="kobospan" id="kobo.169.1">, </span><em class="italic"><span class="kobospan" id="kobo.170.1">N</span></em><span class="kobospan" id="kobo.171.1">, and </span><em class="italic"><span class="kobospan" id="kobo.172.1">Temperature</span></em><span class="kobospan" id="kobo.173.1">), and printed the </span><span><span class="kobospan" id="kobo.174.1">output result.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.175.1">Code walk-through</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.176.1">The code</span><a id="_idIndexMarker167" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.177.1"> that was run within the recipe can be explained in </span><span><span class="kobospan" id="kobo.178.1">four parts:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.179.1">Library installation</span></em><span class="kobospan" id="kobo.180.1">: The first line – </span><strong class="source-inline1"><span class="kobospan" id="kobo.181.1">!pip install openai; import openai</span></strong><span class="kobospan" id="kobo.182.1"> – is a command that installs the OpenAI library as a package in Python. </span><span class="kobospan" id="kobo.182.2">The second line imports it into the current Python namespace, enabling the use of the library’s functions </span><span><span class="kobospan" id="kobo.183.1">and classes.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.184.1">Authentication</span></em><span class="kobospan" id="kobo.185.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.186.1">openai.api_key = "sk-..."</span></strong><span class="kobospan" id="kobo.187.1"> line sets the API key for authenticating requests to the </span><span><span class="kobospan" id="kobo.188.1">OpenAI API.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.189.1">API call</span></em><span class="kobospan" id="kobo.190.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.191.1">openai.ChatCompletion.create()</span></strong><span class="kobospan" id="kobo.192.1"> line calls the API and makes a chat completion request. </span><span class="kobospan" id="kobo.192.2">As you can see, it contains the typical parameters that we have discussed in </span><span><span class="kobospan" id="kobo.193.1">previous chapters.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.194.1">Output</span></em><span class="kobospan" id="kobo.195.1">: The </span><strong class="source-inline1"><span class="kobospan" id="kobo.196.1">print(completion); print(completion['choices'][0]['message']['content'])</span></strong><span class="kobospan" id="kobo.197.1"> line prints out the raw response from the API call. </span><span class="kobospan" id="kobo.197.2">The response includes not only the content of the completion but also some metadata, similar to when we make HTTP requests with Postman. </span><span class="kobospan" id="kobo.197.3">This second line digs into the response object to extract and print only the content of </span><span><span class="kobospan" id="kobo.198.1">the message.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.199.1">Most API calls in Python follow these steps. </span><span class="kobospan" id="kobo.199.2">It should be noted that </span><em class="italic"><span class="kobospan" id="kobo.200.1">steps 1 and 2</span></em><span class="kobospan" id="kobo.201.1"> (i.e., library installation and authentication) only need to be performed once. </span><span class="kobospan" id="kobo.201.2">This is because once a library is installed, it becomes a part of your Python environment, ready to be used in any program without needing to be reinstalled each time. </span><span class="kobospan" id="kobo.201.3">Similarly, authentication, which is often a process of verifying credentials to gain access to the API, is typically required only once per session or configuration, as your credentials are then stored and reused for subsequent </span><span><span class="kobospan" id="kobo.202.1">API calls.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.203.1">Overall, we delved into using the OpenAI Python library for interacting with the OpenAI API, transitioning from the HTTP requests method in Postman. </span><span class="kobospan" id="kobo.203.2">We will continue following this process in </span><span><span class="kobospan" id="kobo.204.1">future recipes.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.205.1">Components of the Python library</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.206.1">The endpoints and parameters that we have discussed in previous chapters are all available </span><a id="_idIndexMarker168" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.207.1">within the OpenAI Python library. </span><span class="kobospan" id="kobo.207.2">The syntax is slightly different, as we are now using Python code rather than JSON (through Postman) to make API requests, but the fundamental idea is the same. </span><span class="kobospan" id="kobo.207.3">Here is a table that compares endpoint calls between Postman and </span><span><span class="kobospan" id="kobo.208.1">Python libraries.</span></span></p>
<table class="no-table-style" id="table001-4">
<colgroup class="calibre10">
<col class="calibre11"/>
<col class="calibre11"/>
<col class="calibre11"/>
</colgroup>
<thead class="calibre12">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.209.1">Endpoint</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.210.1">HTTP request in Postman through JSON (the </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.211.1">Body component)</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.212.1">Python </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.213.1">OpenAI Library</span></strong></span></p>
</td>
</tr>
</thead>
<tbody class="calibre13">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.214.1">Chat completions</span></strong></span></p>
</td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.215.1">
{</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.216.1">
    "model": "gpt-3.5-turbo",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.217.1">
    "messages": [</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.218.1">
      {</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.219.1">
        "role": "system",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.220.1">
        "content": "You are a helpful assistant."</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.221.1">
      },</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.222.1">
      {</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.223.1">
        "role": "user",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.224.1">
        "content": "Hello!"</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.225.1">
      }</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.226.1">
    ]</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.227.1">
  }</span></pre> </td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.228.1">
completion = client.chat.completions.create (</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.229.1">
  model="gpt-3.5-turbo",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.230.1">
  messages=[</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.231.1">
    {"role": "system", "content": "You are a helpful assistant."},</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.232.1">
    {"role": "user", "content": "Hello!"}</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.233.1">
  ]</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.234.1">
)</span></pre> </td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.235.1">Images</span></strong></span></p>
</td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.236.1">
{</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.237.1">
    "prompt": "A cute baby sea otter",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.238.1">
    "n": 2,</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.239.1">
    "size": "1024x1024"</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.240.1">
  }</span></pre> </td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.241.1">
client.images.generate(</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.242.1">
  prompt="A cute baby sea otter",</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.243.1">
  n=2,</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.244.1">
  size="1024x1024"</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.245.1">
)</span></pre> </td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.246.1">Audio</span></strong></span></p>
</td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.247.1">
-F file="@/path/to/file/audio.mp3" \</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.248.1">
  -F model="whisper-1"</span></pre> </td>
<td class="no-table-style2">
<pre class="source-code"><span class="kobospan1" id="kobo.249.1">
audio_file = open("audio.mp3", "rb")</span></pre> <pre class="source-code"><span class="kobospan1" id="kobo.250.1">
transcript = client.audio.transcriptions.create ("whisper-1", audio_file)</span></pre> </td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.251.1">Table 4.1 – Comparing endpoint calls between Postman and Python libraries</span></p>
<h2 id="_idParaDest-79" class="calibre7"><a id="_idTextAnchor082" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.252.1">Benefits and drawbacks of using the Python library</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.253.1">There are </span><a id="_idIndexMarker169" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.254.1">several benefits to doing this, aside from it just being a pre-requisite to future recipes. </span><span class="kobospan" id="kobo.254.2">It provides abstraction over the API request itself, leading to the </span><span><span class="kobospan" id="kobo.255.1">following benefits:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.256.1">Simplified authentication</span></em><span class="kobospan" id="kobo.257.1">: The library handles API key and token management, abstracting away the details of the authentication process from the user. </span><span class="kobospan" id="kobo.257.2">For example, in this case, we did not need to create a new parameter for </span><em class="italic"><span class="kobospan" id="kobo.258.1">Bearer</span></em><span class="kobospan" id="kobo.259.1">, unlike within HTTP. </span><span class="kobospan" id="kobo.259.2">Furthermore, unlike HTTP requests, we do not need to declare our API key for every </span><span><span class="kobospan" id="kobo.260.1">single request.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.261.1">Ease of use</span></em><span class="kobospan" id="kobo.262.1">: It provides a high-level interface with methods and classes that represent API endpoints, making it easier to understand and implement; the library takes care of constructing the correct HTTP requests, encoding parameters, and parsing </span><span><span class="kobospan" id="kobo.263.1">the responses.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.264.1">Do more</span></em><span class="kobospan" id="kobo.265.1">: The library often includes convenience features that are not available with simple HTTP requests, such as pagination helpers, streaming, session management, embeddings, function calls, and more (which is why we switched over to the Python library in this chapter – the subsequent recipes cover </span><span><span class="kobospan" id="kobo.266.1">these features).</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.267.1">Programmability</span></em><span class="kobospan" id="kobo.268.1">: The Python OpenAI library leverages the full programming capabilities of Python, enabling variables, logical conditioning, and functions (i.e., all the benefits of a programming language that you don’t get </span><span><span class="kobospan" id="kobo.269.1">with Postman).</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.270.1">There are, however, some specific</span><a id="_idIndexMarker170" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.271.1"> downsides to using the Python library </span><span><span class="kobospan" id="kobo.272.1">as well:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.273.1">Limited customization</span></em><span class="kobospan" id="kobo.274.1">: High-level abstraction may limit direct access to certain </span><span><span class="kobospan" id="kobo.275.1">API functionalities</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.276.1">Maintenance and compatibility</span></em><span class="kobospan" id="kobo.277.1">: There is a dependency on library updates and potential conflicts with different </span><span><span class="kobospan" id="kobo.278.1">Python versions</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.279.1">Performance overheads</span></em><span class="kobospan" id="kobo.280.1">: Additional abstraction layers can lead to slower performance in </span><span><span class="kobospan" id="kobo.281.1">resource-critical applications</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.282.1">Reduced control</span></em><span class="kobospan" id="kobo.283.1">: It </span><a id="_idIndexMarker171" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.284.1">offers less flexibility for users needing detailed control over </span><span><span class="kobospan" id="kobo.285.1">API interactions</span></span></li>
</ul>
<h1 id="_idParaDest-80" class="calibre5"><a id="_idTextAnchor083" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.286.1">Using the embedding model for text comparisons and other use cases</span></h1>
<p class="calibre3"><span class="kobospan" id="kobo.287.1">OpenAI has a model and endpoint that enables users to </span><a id="_idIndexMarker172" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.288.1">create </span><strong class="bold"><span class="kobospan" id="kobo.289.1">embeddings</span></strong><span class="kobospan" id="kobo.290.1">. </span><span class="kobospan" id="kobo.290.2">It’s a lesser-known feature of the API but has vast applications in enabling plenty of use cases (searching through text, text classification, and </span><span><span class="kobospan" id="kobo.291.1">much more).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.292.1">What are embeddings? </span><strong class="bold"><span class="kobospan" id="kobo.293.1">Text embedding</span></strong><span class="kobospan" id="kobo.294.1"> is a sophisticated technique employed in NLP that transforms</span><a id="_idIndexMarker173" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.295.1"> text into a numerical format that machines can </span><a id="_idIndexMarker174" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.296.1">understand. </span><span class="kobospan" id="kobo.296.2">Essentially, embeddings are high-dimensional vectors that capture the essence of words, sentences, or even entire documents, encapsulating not just their individual meanings but also the nuances and relationships </span><span><span class="kobospan" id="kobo.297.1">between them.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.298.1">Mathematically, a </span><a id="_idIndexMarker175" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.299.1">vector is a point in an n-dimensional vector space, but for our purposes, you can think of a vector as just a list of </span><a id="_idIndexMarker176" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.300.1">numbers. </span><span class="kobospan" id="kobo.300.2">However, the recipes discussed in this chapter do not require you to work with the process and science behind converting words to numbers. </span><span class="kobospan" id="kobo.300.3">For more information on the science behind embeddings, you can find a great introductory article </span><span><span class="kobospan" id="kobo.301.1">here: </span></span><a href="https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.302.1">https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/</span></span></a><span><span class="kobospan" id="kobo.303.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.304.1">In this recipe, we will use the OpenAI API to convert various texts into embeddings and use those embeddings for the use case of </span><span><span class="kobospan" id="kobo.305.1">text comparison.</span></span></p>
<h2 id="_idParaDest-81" class="calibre7"><a id="_idTextAnchor084" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.306.1">How to do it…</span></h2>
<ol class="calibre14">
<li class="calibre15"><span class="kobospan" id="kobo.307.1">Open up a new notebook by navigating to </span><a href="https://colab.google/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.308.1">https://colab.google/</span></a><span class="kobospan" id="kobo.309.1"> and selecting </span><strong class="bold"><span class="kobospan" id="kobo.310.1">New Notebook</span></strong><span class="kobospan" id="kobo.311.1"> at the </span><span><span class="kobospan" id="kobo.312.1">top right.</span></span></li>
<li class="calibre15"><span class="kobospan" id="kobo.313.1">In the first</span><a id="_idIndexMarker177" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.314.1"> cell, type in the following code and press </span><em class="italic"><span class="kobospan" id="kobo.315.1">Shift</span></em><span class="kobospan" id="kobo.316.1"> + </span><em class="italic"><span class="kobospan" id="kobo.317.1">Enter</span></em><span class="kobospan" id="kobo.318.1"> to run the code. </span><span class="kobospan" id="kobo.318.2">This will install the OpenAI library and import the required modules for </span><span><span class="kobospan" id="kobo.319.1">this recipe:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.320.1">
!pip install openai
from openai import OpenAI
from numpy import dot
from numpy.linalg import norm</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.321.1">Similar to the previous recipe, type the following code into the cell below, replacing </span><strong class="source-inline1"><span class="kobospan" id="kobo.322.1">&lt;api-key&gt;</span></strong><span class="kobospan" id="kobo.323.1"> with your OpenAI API Key. </span><span class="kobospan" id="kobo.323.2">Hit </span><em class="italic"><span class="kobospan" id="kobo.324.1">Shift</span></em><span class="kobospan" id="kobo.325.1"> + </span><em class="italic"><span class="kobospan" id="kobo.326.1">Enter</span></em><span class="kobospan" id="kobo.327.1"> to run </span><span><span class="kobospan" id="kobo.328.1">the code:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.329.1">
api_key = "&lt;Insert your API-key here&gt;"
client = OpenAI(api_key=api_key)</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.330.1">Next, we</span><a id="_idIndexMarker178" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.331.1"> will create two functions in Python. </span><span class="kobospan" id="kobo.331.2">The first function will create an embedding given a text string. </span><span class="kobospan" id="kobo.331.3">To do this, we will use the </span><strong class="bold"><span class="kobospan" id="kobo.332.1">Embeddings</span></strong><span class="kobospan" id="kobo.333.1"> endpoint from the OpenAI API. </span><span class="kobospan" id="kobo.333.2">The next function takes two embeddings and calculates the difference between them </span><a id="_idIndexMarker179" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.334.1">using </span><strong class="bold"><span class="kobospan" id="kobo.335.1">cosine similarity</span></strong><span class="kobospan" id="kobo.336.1">, a concept that we will discuss in the next section. </span><span class="kobospan" id="kobo.336.2">To do this, type the following code in the cell below and press </span><em class="italic"><span class="kobospan" id="kobo.337.1">Shift</span></em><span class="kobospan" id="kobo.338.1"> + </span><span><em class="italic"><span class="kobospan" id="kobo.339.1">Enter</span></em></span><span><span class="kobospan" id="kobo.340.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.341.1">
def create_embeddings(text):
  embedding = client.embeddings.create(input=text, model="text-embedding-ada-002").data[0].embedding
  return embedding
def compare_two_embeddings(a, b):
  cos_sim = dot(a, b)/(norm(a)*norm(b))
  return cos_sim</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.342.1">Now, we have everything we need to start comparing texts by creating embeddings and calculating the difference between them. </span><span class="kobospan" id="kobo.342.2">Let’s start with two pieces of text that are semantically very similar: </span><em class="italic"><span class="kobospan" id="kobo.343.1">I like apples</span></em><span class="kobospan" id="kobo.344.1"> and </span><em class="italic"><span class="kobospan" id="kobo.345.1">I like bananas</span></em><span class="kobospan" id="kobo.346.1">. </span><span class="kobospan" id="kobo.346.2">Type in the following code, hit </span><em class="italic"><span class="kobospan" id="kobo.347.1">Shift</span></em><span class="kobospan" id="kobo.348.1"> + </span><em class="italic"><span class="kobospan" id="kobo.349.1">Enter</span></em><span class="kobospan" id="kobo.350.1">, and note the </span><span><span class="kobospan" id="kobo.351.1">output result:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.352.1">
text_1 = "I like apples"
text_2 = "I like bananas"
round(compare_two_embeddings(create_embeddings(text_1), create_embeddings(text_</span><a id="_idTextAnchor085" class="calibre18 pcalibre1 pcalibre"/><span class="kobospan1" id="kobo.353.1">2)), 2)</span></pre></li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer030">
<span class="kobospan" id="kobo.354.1"><img alt="Figure 4.4 – Output of cosine similarity for similar texts" src="image/B21007_04_04.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.355.1">Figure 4.4 – Output of cosine similarity for similar texts</span></p>
<ol class="calibre14">
<li value="6" class="calibre15"><span class="kobospan" id="kobo.356.1">Next, let’s </span><a id="_idIndexMarker180" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.357.1">compare two pieces of</span><a id="_idIndexMarker181" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.358.1"> text that are not similar: </span><em class="italic"><span class="kobospan" id="kobo.359.1">I like apples</span></em><span class="kobospan" id="kobo.360.1"> and the first section of Article 1 of the US Constitution: </span><em class="italic"><span class="kobospan" id="kobo.361.1">All legislative Powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives</span></em><span class="kobospan" id="kobo.362.1"> (</span><a href="https://www.archives.gov/founding-docs/constitution-transcript" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.363.1">https://www.archives.gov/founding-docs/constitution-transcript</span></a><span class="kobospan" id="kobo.364.1">). </span><span class="kobospan" id="kobo.364.2">Type in the following code, hit </span><em class="italic"><span class="kobospan" id="kobo.365.1">Shift</span></em><span class="kobospan" id="kobo.366.1"> + </span><em class="italic"><span class="kobospan" id="kobo.367.1">Enter</span></em><span class="kobospan" id="kobo.368.1">, and note the </span><span><span class="kobospan" id="kobo.369.1">output result:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.370.1">
text_1 = "I like apples"
text_2 = "All legislative Powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House of Representatives."
</span><span class="kobospan1" id="kobo.370.2">round(compare_two_embeddings(create_embeddings(text_1), create_embeddings(text_2)), 2)</span></pre></li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer031">
<span class="kobospan" id="kobo.371.1"><img alt="Figure 4.5 – Output of cosine similarity for similar texts" src="image/B21007_04_05.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.372.1">Figure 4.5 – Output of cosine similarity for similar texts</span></p>
<ol class="calibre14">
<li value="7" class="calibre15"><span class="kobospan" id="kobo.373.1">Note the</span><a id="_idIndexMarker182" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.374.1"> similarity between the first set of texts (</span><strong class="source-inline1"><span class="kobospan" id="kobo.375.1">0.90</span></strong><span class="kobospan" id="kobo.376.1">) was higher than for the next set of texts (</span><strong class="source-inline1"><span class="kobospan" id="kobo.377.1">0.70</span></strong><span class="kobospan" id="kobo.378.1">). </span><span class="kobospan" id="kobo.378.2">This means that the first set of texts is more semantically similar than the next two texts, which makes sense given </span><span><span class="kobospan" id="kobo.379.1">the language.</span></span></li>
<li class="calibre15"><span class="kobospan" id="kobo.380.1">Let’s take </span><a id="_idIndexMarker183" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.381.1">this one step further. </span><span class="kobospan" id="kobo.381.2">Repeat </span><em class="italic"><span class="kobospan" id="kobo.382.1">steps 5-7</span></em><span class="kobospan" id="kobo.383.1"> with the following texts. </span><span class="kobospan" id="kobo.383.2">I’ve also noted the output similarities </span><span><span class="kobospan" id="kobo.384.1">I got:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.385.1">
text_1 = "Birds like to fly"
text_2 = "Airplanes can soar above the ground"
Output = 0.88
text_1 = "Birds like to fly"
text_2 = "A fly can irritate me"
Output = 0.84</span></pre></li> </ol>
<h2 id="_idParaDest-82" class="calibre7"><a id="_idTextAnchor086" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.386.1">How it works…</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.387.1">In this recipe, we converted texts into embeddings and then compared the embeddings. </span><span class="kobospan" id="kobo.387.2">The results showed us that, when comparing it to </span><em class="italic"><span class="kobospan" id="kobo.388.1">I like applies</span></em><span class="kobospan" id="kobo.389.1">, the text </span><em class="italic"><span class="kobospan" id="kobo.390.1">I like bananas</span></em><span class="kobospan" id="kobo.391.1"> is more semantically similar to the first section of the </span><span><span class="kobospan" id="kobo.392.1">US Constitution.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.393.1">Furthermore, it demonstrated that the text </span><em class="italic"><span class="kobospan" id="kobo.394.1">Birds like to fly</span></em><span class="kobospan" id="kobo.395.1"> is more semantically similar to </span><em class="italic"><span class="kobospan" id="kobo.396.1">Airplanes can soar above the ground</span></em><span class="kobospan" id="kobo.397.1"> than </span><em class="italic"><span class="kobospan" id="kobo.398.1">A fly can irritate me</span></em><span class="kobospan" id="kobo.399.1">. </span><span class="kobospan" id="kobo.399.2">This makes sense as in the first two pieces of text, the sentences were about </span><span><span class="kobospan" id="kobo.400.1">objects flying.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.401.1">Embedding 101</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.402.1">As </span><a id="_idIndexMarker184" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.403.1">mentioned before, the process of embedding turns text into a list of numbers. </span><span class="kobospan" id="kobo.403.2">This is imperative in NLP, as now machines can work with these lists of numbers instead </span><span><span class="kobospan" id="kobo.404.1">of text.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.405.1">The key feature of OpenAI’s embedding model is that it captures linguistic properties and semantic meaning. </span><span class="kobospan" id="kobo.405.2">This means that two pieces of text that are semantically similar will have similar vectors (i.e., a similar list of numbers). </span><strong class="bold"><span class="kobospan" id="kobo.406.1">Semantically similar</span></strong><span class="kobospan" id="kobo.407.1"> means that two pieces</span><a id="_idIndexMarker185" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.408.1"> of text convey the same or related meanings, concepts, or ideas, even if they use different words </span><span><span class="kobospan" id="kobo.409.1">or structures.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.410.1">Code structure</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.411.1">We used </span><a id="_idIndexMarker186" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.412.1">OpenAI’s embedding model to create these vectors, using the Embeddings endpoint. </span><span class="kobospan" id="kobo.412.2">The endpoint can be called with the </span><strong class="source-inline"><span class="kobospan" id="kobo.413.1">openai.Embedding.create()</span></strong><span class="kobospan" id="kobo.414.1"> function, and takes in </span><span><span class="kobospan" id="kobo.415.1">two arguments:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><strong class="source-inline1"><span class="kobospan" id="kobo.416.1">input</span></strong><span class="kobospan" id="kobo.417.1">: This argument represents the text that you want to create </span><span><span class="kobospan" id="kobo.418.1">embeddings for.</span></span></li>
<li class="calibre15"><strong class="source-inline1"><span class="kobospan" id="kobo.419.1">model</span></strong><span class="kobospan" id="kobo.420.1">: This is the ID of the model you want to use for the embeddings. </span><span class="kobospan" id="kobo.420.2">This is similar to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.421.1">model</span></strong><span class="kobospan" id="kobo.422.1"> parameter in other endpoints. </span><span class="kobospan" id="kobo.422.2">In this example, we used the</span><a id="_idIndexMarker187" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.423.1"> standard </span><strong class="bold"><span class="kobospan" id="kobo.424.1">ada</span></strong><span class="kobospan" id="kobo.425.1"> model, which was </span><strong class="source-inline1"><span class="kobospan" id="kobo.426.1">text-embedding-ada-002</span></strong><span class="kobospan" id="kobo.427.1">. </span><span class="kobospan" id="kobo.427.2">OpenAI recommends using this as the starting embedding model as it’s quite affordable and still has </span><span><span class="kobospan" id="kobo.428.1">excellent performance.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.429.1">The function call returns an embedding object in JSON format, which we then parse through to get the embedding itself (which again is a list of numbers in Python). </span><span class="kobospan" id="kobo.429.2">The parsing is done via the </span><strong class="source-inline"><span class="kobospan" id="kobo.430.1">["</span></strong><span><strong class="source-inline"><span class="kobospan" id="kobo.431.1">data"][0]["embedding"]</span></strong></span><span><span class="kobospan" id="kobo.432.1"> code.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.433.1">After we have the embeddings from two sets of text, we then need to compare them. </span><span class="kobospan" id="kobo.433.2">How do you compare two vectors (i.e., how do you compare two lists of numbers?)? </span><span class="kobospan" id="kobo.433.3">The most common method </span><a id="_idIndexMarker188" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.434.1">used is called </span><strong class="bold"><span class="kobospan" id="kobo.435.1">cosine similarity</span></strong><span class="kobospan" id="kobo.436.1">. </span><span class="kobospan" id="kobo.436.2">Cosine similarity measures the cosine of the angle between two vectors, resulting in a number between 0 </span><span><span class="kobospan" id="kobo.437.1">and 1.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.438.1">Cosine similarity</span><a id="_idIndexMarker189" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.439.1"> is often chosen over other similarity measuring techniques because it is particularly effective in high-dimensional spaces, such as text data, where it emphasizes the orientation rather than the magnitude of vectors. </span><span class="kobospan" id="kobo.439.2">This approach allows it to focus on the directional alignment of the vectors, making it more robust in assessing the semantic similarity between texts, even when they vary in length or </span><span><span class="kobospan" id="kobo.440.1">word frequency.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.441.1">The math does</span><a id="_idIndexMarker190" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.442.1"> not matter here – the implication is that the higher the cosine similarity, the more closely the two texts are </span><span><span class="kobospan" id="kobo.443.1">semantically related:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.444.1">Cosine similarity close to 1</span></em><span class="kobospan" id="kobo.445.1">: The texts are very similar or have similar context </span><span><span class="kobospan" id="kobo.446.1">or meaning</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.447.1">Cosine similarity close to 0</span></em><span class="kobospan" id="kobo.448.1">: The texts </span><span><span class="kobospan" id="kobo.449.1">are unrelated</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.450.1">Cosine similarity close to -1</span></em><span class="kobospan" id="kobo.451.1">: The texts are semantically opposite, which is rare in NLP because most text embeddings are designed to have </span><span><span class="kobospan" id="kobo.452.1">non-negative components</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.453.1">In Python, this is achieved through the following code, which takes the dot product of the two vectors and divides it by the product of the two vectors’ </span><span><span class="kobospan" id="kobo.454.1">Euclidean norm:</span></span></p>
<pre class="source-code"><span class="kobospan1" id="kobo.455.1">
def compare_two_embeddings(a, b):
  cos_sim = dot(a, b)/(norm(a)*norm(b))
  return cos_sim</span></pre> <p class="calibre3"><span class="kobospan" id="kobo.456.1">After we set up a function to return the embeddings for each text, and the function to compute the cosine similarity between two embeddings, we had all the tools we needed to compare two pieces </span><span><span class="kobospan" id="kobo.457.1">of text.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.458.1">The normalization in this formula (</span><strong class="source-inline"><span class="kobospan" id="kobo.459.1">norm</span></strong><span class="kobospan" id="kobo.460.1">) ensures that we’re comparing the direction, rather than the magnitude, of the two vectors. </span><span class="kobospan" id="kobo.460.2">This means we are focusing on how similar the two vectors are in terms of orientation, regardless of their length, which is essential for measuring similarity in many applications such as </span><span><span class="kobospan" id="kobo.461.1">comparing sentences.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.462.1">Applications in text comparison</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.463.1">Embeddings are an efficient way to compare two pieces of text, opening lots of different real-world </span><a id="_idIndexMarker191" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.464.1">applications. </span><span class="kobospan" id="kobo.464.2">Recall the similarity scores that were computed in the recipe, described in the table </span><span><span class="kobospan" id="kobo.465.1">that follows:</span></span></p>
<table class="no-table-style" id="table002-2">
<colgroup class="calibre10">
<col class="calibre11"/>
<col class="calibre11"/>
<col class="calibre11"/>
<col class="calibre11"/>
</colgroup>
<thead class="calibre12">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.466.1">Test</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.467.1">Base text</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.468.1">Comparison text</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.469.1">Cosine similarity </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.470.1">of embeddings</span></strong></span></p>
</td>
</tr>
</thead>
<tbody class="calibre13">
<tr class="no-table-style1">
<td class="no-table-style2" rowspan="2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.471.1">1</span></strong></p>
</td>
<td class="no-table-style2" rowspan="2">
<p class="calibre3"><span class="kobospan" id="kobo.472.1">I </span><span><span class="kobospan" id="kobo.473.1">like apples</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.474.1">I </span><span><span class="kobospan" id="kobo.475.1">like bananas</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.476.1">0.90</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.477.1">All legislative Powers herein granted shall be vested in a Congress of the United States, which shall consist of a Senate and House </span><span><span class="kobospan" id="kobo.478.1">of Representatives</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.479.1">0.71</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2" rowspan="2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.480.1">2</span></strong></p>
</td>
<td class="no-table-style2" rowspan="2">
<p class="calibre3"><span class="kobospan" id="kobo.481.1">Birds like </span><span><span class="kobospan" id="kobo.482.1">to </span></span><span><em class="italic"><span class="kobospan" id="kobo.483.1">fly</span></em></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.484.1">Airplanes can soar above </span><span><span class="kobospan" id="kobo.485.1">the ground</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.486.1">0.88</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.487.1">A </span><em class="italic"><span class="kobospan" id="kobo.488.1">fly</span></em><span class="kobospan" id="kobo.489.1"> can </span><span><span class="kobospan" id="kobo.490.1">irritate me</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.491.1">0.84</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.492.1">Table 4.2 – Cosine similarities between OpenAI embeddings for various sets of texts</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.493.1">The OpenAI API enables you to compute and rank the semantic similarity between different sets of text. </span><span class="kobospan" id="kobo.493.2">Note that semantic similarity understands the nuances of the meaning of the text. </span><span class="kobospan" id="kobo.493.3">In </span><em class="italic"><span class="kobospan" id="kobo.494.1">Test 2</span></em><span class="kobospan" id="kobo.495.1">, the semantic similarity to </span><em class="italic"><span class="kobospan" id="kobo.496.1">Airplanes can soar above the ground</span></em><span class="kobospan" id="kobo.497.1"> was greater than </span><em class="italic"><span class="kobospan" id="kobo.498.1">A fly can </span></em><span><em class="italic"><span class="kobospan" id="kobo.499.1">irritate me</span></em></span><span><span class="kobospan" id="kobo.500.1">.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.501.1">This is counterintuitive because you would assume that the text that shares the word </span><em class="italic"><span class="kobospan" id="kobo.502.1">fly</span></em><span class="kobospan" id="kobo.503.1"> would be more similar. </span><span class="kobospan" id="kobo.503.2">However, the embeddings recognize that the word </span><em class="italic"><span class="kobospan" id="kobo.504.1">fly</span></em><span class="kobospan" id="kobo.505.1"> is used in a different context in </span><em class="italic"><span class="kobospan" id="kobo.506.1">Birds like to fly</span></em><span class="kobospan" id="kobo.507.1"> versus </span><em class="italic"><span class="kobospan" id="kobo.508.1">A fly can irritate me</span></em><span class="kobospan" id="kobo.509.1">. </span><span class="kobospan" id="kobo.509.2">In this case, embeddings are powerful mechanisms to compare the meanings </span><span><span class="kobospan" id="kobo.510.1">of texts.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.511.1">There are other applications of embeddings that, thanks to OpenAI API, you can explore when building apps. </span><span class="kobospan" id="kobo.511.2">This is not an exhaustive list but should be a good start for you to get some idea about the </span><span><span class="kobospan" id="kobo.512.1">API’s potential:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.513.1">Information retrieval with search engines</span></em><span class="kobospan" id="kobo.514.1">: Enhancing search algorithms to return results that are semantically related to the query, not just </span><span><span class="kobospan" id="kobo.515.1">textually (</span></span><a href="https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.516.1">https://www.mage.ai/blog/building-semantic-search-engine-with-dual-space-word-embeddings</span></span></a><span><span class="kobospan" id="kobo.517.1">)</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.518.1">Document retrieval</span></em><span class="kobospan" id="kobo.519.1">: Finding documents that cover similar topics even if they don’t share the same </span><span><span class="kobospan" id="kobo.520.1">keywords (</span></span><a href="https://arxiv.org/pdf/1810.10176v2.pdf" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.521.1">https://arxiv.org/pdf/1810.10176v2.pdf</span></span></a><span><span class="kobospan" id="kobo.522.1">)</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.523.1">Content recommendation systems</span></em><span class="kobospan" id="kobo.524.1">: Recommending articles, products, or media to users based on semantic similarity to items they have liked </span><span><span class="kobospan" id="kobo.525.1">before (</span></span><a href="https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.526.1">https://towardsdatascience.com/introduction-to-embedding-based-recommender-systems-956faceb1919</span></span></a><span><span class="kobospan" id="kobo.527.1">)</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.528.1">Text classification</span></em><span class="kobospan" id="kobo.529.1">: Automatically classifying documents into predefined categories based on their semantic </span><span><span class="kobospan" id="kobo.530.1">content (</span></span><a href="https://realpython.com/python-keras-text-classification/" class="pcalibre1 calibre6 pcalibre"><span><span class="kobospan" id="kobo.531.1">https://realpython.com/python-keras-text-classification/</span></span></a><span><span class="kobospan" id="kobo.532.1">)</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.533.1">Overall, the</span><a id="_idIndexMarker192" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.534.1"> embeddings feature of the OpenAI API opens a plethora of other use cases, from text comparison to information retrieval. </span><span class="kobospan" id="kobo.534.2">Another key benefit is that these endpoints are far cheaper than the Completions or Images endpoint, making it a powerful and efficient tool in </span><span><span class="kobospan" id="kobo.535.1">your arsenal.</span></span></p>
<h1 id="_idParaDest-83" class="calibre5"><a id="_idTextAnchor087" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.536.1">Fine-tuning a completion model</span></h1>
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.537.1">Fine-tuning</span></strong><span class="kobospan" id="kobo.538.1"> is</span><a id="_idIndexMarker193" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.539.1"> the process of taking a pre-trained model and further adapting it to a specific task or dataset. </span><span class="kobospan" id="kobo.539.2">The goal is typically to take an original model that has been trained on a large, general dataset and apply it to a more specialized domain or to </span><a id="_idIndexMarker194" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.540.1">improve its performance on a specific type </span><span><span class="kobospan" id="kobo.541.1">of data.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.542.1">We </span><a id="_idIndexMarker195" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.543.1">previously saw a version of fine-tuning in the first recipe within </span><a href="B21007_01.xhtml#_idTextAnchor021" class="pcalibre1 calibre6 pcalibre"><span><em class="italic"><span class="kobospan" id="kobo.544.1">Chapter 1</span></em></span></a><span class="kobospan" id="kobo.545.1">, where we added examples of outputs in the </span><strong class="source-inline"><span class="kobospan" id="kobo.546.1">messages</span></strong><span class="kobospan" id="kobo.547.1"> parameter to </span><em class="italic"><span class="kobospan" id="kobo.548.1">fine-tune</span></em><span class="kobospan" id="kobo.549.1"> the output response. </span><span class="kobospan" id="kobo.549.2">In this case, the model had not technically been fine-tuned – we instead performed </span><strong class="bold"><span class="kobospan" id="kobo.550.1">few-shot learning</span></strong><span class="kobospan" id="kobo.551.1">, where</span><a id="_idIndexMarker196" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.552.1"> we gave examples of the output within the prompt itself to the Chat Completion model. </span><span class="kobospan" id="kobo.552.2">Fine-tuning, however, is a process where a whole new subset Chat Completion model is created with training data (inputs </span><span><span class="kobospan" id="kobo.553.1">and outputs).</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.554.1">In this recipe, we will explore how to fine-tune a model and execute that fine-tuned model. </span><span class="kobospan" id="kobo.554.2">Then, we will discuss the benefits and drawbacks of fine-tuning a model with the </span><span><span class="kobospan" id="kobo.555.1">OpenAI API.</span></span></p>
<h2 id="_idParaDest-84" class="calibre7"><a id="_idTextAnchor088" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.556.1">How to do it…</span></h2>
<ol class="calibre14">
<li class="calibre15"><span class="kobospan" id="kobo.557.1">Open up</span><a id="_idIndexMarker197" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.558.1"> a new notebook by navigating to </span><a href="https://colab.google/" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.559.1">https://colab.google/</span></a><span class="kobospan" id="kobo.560.1"> and selecting </span><strong class="bold"><span class="kobospan" id="kobo.561.1">New Notebook</span></strong><span class="kobospan" id="kobo.562.1"> at the </span><span><span class="kobospan" id="kobo.563.1">top right.</span></span></li>
<li class="calibre15"><span class="kobospan" id="kobo.564.1">In the first cell, type in the following code and press </span><em class="italic"><span class="kobospan" id="kobo.565.1">Shift</span></em><span class="kobospan" id="kobo.566.1"> + </span><em class="italic"><span class="kobospan" id="kobo.567.1">Enter</span></em><span class="kobospan" id="kobo.568.1"> to run the code. </span><span class="kobospan" id="kobo.568.2">This </span><a id="_idIndexMarker198" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.569.1">will install the OpenAI library and import the required modules for </span><span><span class="kobospan" id="kobo.570.1">this recipe:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.571.1">
!pip install openai
from openai import OpenAI
import os</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.572.1">Similar to the previous recipe, type the following code into the cell below, replacing </span><strong class="source-inline1"><span class="kobospan" id="kobo.573.1">&lt;api-key&gt;</span></strong><span class="kobospan" id="kobo.574.1"> with your OpenAI API key. </span><span class="kobospan" id="kobo.574.2">Hit </span><em class="italic"><span class="kobospan" id="kobo.575.1">Shift</span></em><span class="kobospan" id="kobo.576.1"> + </span><em class="italic"><span class="kobospan" id="kobo.577.1">Enter</span></em><span class="kobospan" id="kobo.578.1"> to run </span><span><span class="kobospan" id="kobo.579.1">the code:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.580.1">
api_key = "&lt;Insert your API-key here&gt;"
client = OpenAI(api_key=api_key)</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.581.1">Import the training data into Google Colab. </span><span class="kobospan" id="kobo.581.2">The training data file can be found here: </span><a href="https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing" class="pcalibre1 calibre6 pcalibre"><span class="kobospan" id="kobo.582.1">https://drive.google.com/file/d/1x0ciWtW3phjPHAosiCL90qsQY--ZoxsV/view?usp=sharing</span></a><span class="kobospan" id="kobo.583.1">. </span><span class="kobospan" id="kobo.583.2">To upload the file into Google Colab, select the </span><em class="italic"><span class="kobospan" id="kobo.584.1">Files</span></em><span class="kobospan" id="kobo.585.1"> icon on the left and select the </span><strong class="bold"><span class="kobospan" id="kobo.586.1">Upload File</span></strong><span class="kobospan" id="kobo.587.1"> button at the top of that menu. </span><span class="kobospan" id="kobo.587.2">Both these icons have been highlighted in </span><span><em class="italic"><span class="kobospan" id="kobo.588.1">Figure 4</span></em></span><em class="italic"><span class="kobospan" id="kobo.589.1">.6</span></em><span class="kobospan" id="kobo.590.1">. </span><span class="kobospan" id="kobo.590.2">Note that the training data includes several examples of where the prompt is a scenario (such as </span><em class="italic"><span class="kobospan" id="kobo.591.1">A student in a library</span></em><span class="kobospan" id="kobo.592.1">) and the completion is a one-liner joke followed by </span><em class="italic"><span class="kobospan" id="kobo.593.1">Haha</span></em><span class="kobospan" id="kobo.594.1"> (such as </span><em class="italic"><span class="kobospan" id="kobo.595.1">Why did the student bring a ladder to the library? </span><span class="kobospan" id="kobo.595.2">Because they heard the knowledge was on the top </span></em><span><em class="italic"><span class="kobospan" id="kobo.596.1">shelf! </span><span class="kobospan" id="kobo.596.2">Haha</span></em></span><span><span class="kobospan" id="kobo.597.1">).</span></span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer032">
<span class="kobospan" id="kobo.598.1"><img alt="Figure 4.6 – How to add a file to Google Colab" src="image/B21007_04_06.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.599.1">Figure 4.6 – How to add a file to Google Colab</span></p>
<ol class="calibre14">
<li value="5" class="calibre15"><span class="kobospan" id="kobo.600.1">Next, upload</span><a id="_idIndexMarker199" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.601.1"> the training dataset to the OpenAI API, by </span><a id="_idIndexMarker200" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.602.1">typing in the following code and hitting </span><em class="italic"><span class="kobospan" id="kobo.603.1">Shift</span></em><span class="kobospan" id="kobo.604.1"> + </span><em class="italic"><span class="kobospan" id="kobo.605.1">Enter</span></em><span class="kobospan" id="kobo.606.1">. </span><span class="kobospan" id="kobo.606.2">We will also retrieve </span><strong class="source-inline1"><span class="kobospan" id="kobo.607.1">file_id</span></strong><span class="kobospan" id="kobo.608.1"> from </span><span><span class="kobospan" id="kobo.609.1">the upload:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.610.1">
training_data = client.files.create(
  file=open("chapter4trainingdata.json", "rb"),
  purpose='fine-tune'
)
file_id = training_data.id</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.611.1">After that, we will begin fine-tuning the model, by typing in the following code and hitting </span><em class="italic"><span class="kobospan" id="kobo.612.1">Shift</span></em><span class="kobospan" id="kobo.613.1"> + </span><em class="italic"><span class="kobospan" id="kobo.614.1">Enter</span></em><span class="kobospan" id="kobo.615.1">. </span><span class="kobospan" id="kobo.615.2">This will begin the fine-tuning process, by instructing OpenAI to use the file that we had previously uploaded through the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.616.1">file_id</span></strong></span><span><span class="kobospan" id="kobo.617.1"> variable:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.618.1">
fine_tune_job = client.fine_tuning.jobs.create(training_file=file_id, model="gpt-3.5-turbo")</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.619.1">Fine-tuning</span><a id="_idIndexMarker201" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.620.1"> can take several minutes to finish. </span><span class="kobospan" id="kobo.620.2">We can check the status of the job by typing in the following code and hitting </span><em class="italic"><span class="kobospan" id="kobo.621.1">Shift</span></em><span class="kobospan" id="kobo.622.1"> + </span><em class="italic"><span class="kobospan" id="kobo.623.1">Enter</span></em><span class="kobospan" id="kobo.624.1">. </span><span class="kobospan" id="kobo.624.2">If the output is </span><em class="italic"><span class="kobospan" id="kobo.625.1">running</span></em><span class="kobospan" id="kobo.626.1">, that means the fine-tuning is still in process. </span><span class="kobospan" id="kobo.626.2">Wait until the following code </span><span><span class="kobospan" id="kobo.627.1">returns </span></span><span><strong class="source-inline1"><span class="kobospan" id="kobo.628.1">succeeded</span></strong></span><span><span class="kobospan" id="kobo.629.1">:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.630.1">
client.fine_tuning.jobs.retrieve(fine_tune_job.id).status</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.631.1">Now that </span><a id="_idIndexMarker202" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.632.1">the fine-tuning job has been completed, we need the name of the fine-tuned model, which we can get by typing in the following code and hitting </span><em class="italic"><span class="kobospan" id="kobo.633.1">Shift</span></em><span class="kobospan" id="kobo.634.1"> + </span><em class="italic"><span class="kobospan" id="kobo.635.1">Enter</span></em><span class="kobospan" id="kobo.636.1">. </span><span class="kobospan" id="kobo.636.2">We will save this to the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.637.1">fine_tuned_model</span></strong></span><span><span class="kobospan" id="kobo.638.1"> variable:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.639.1">
fine_tuned_model = client.fine_tuning.jobs.retrieve(fine_tune_job.id).fine_tuned_model</span></pre></li> <li class="calibre15"><span class="kobospan" id="kobo.640.1">Next, let’s use our fine-tuned model. </span><span class="kobospan" id="kobo.640.2">Let’s create a simple chat completion request, but we will modify the </span><strong class="source-inline1"><span class="kobospan" id="kobo.641.1">model</span></strong><span class="kobospan" id="kobo.642.1"> parameter to use the </span><strong class="source-inline1"><span class="kobospan" id="kobo.643.1">fine_tuned_model</span></strong><span class="kobospan" id="kobo.644.1"> object that we had </span><span><span class="kobospan" id="kobo.645.1">just created:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.646.1">
Completion = client.chat.completions.create(
  model=fine_tuned_model,
  messages=[
    {"role": "system", "content": "You are an assistant that creates funny one-line jokes based on a given scenario."},
     {"role": "user", "content": "A man walking across the road"}
  ]
)
print(completion.choices[0].message)</span></pre></li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer033">
<span class="kobospan" id="kobo.647.1"><img alt="Figure 4.7 – Chat completion request and output when using a fine-tuned model" src="image/B21007_04_07.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.648.1">Figure 4.7 – Chat completion request and output when using a fine-tuned model</span></p>
<ol class="calibre14">
<li value="10" class="calibre15"><span class="kobospan" id="kobo.649.1">Note that </span><a id="_idIndexMarker203" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.650.1">without providing any examples, the</span><a id="_idIndexMarker204" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.651.1"> completion output is a one-liner joke followed by the word </span><strong class="source-inline1"><span class="kobospan" id="kobo.652.1">Haha</span></strong><span class="kobospan" id="kobo.653.1">. </span><span class="kobospan" id="kobo.653.2">We successfully fine-tuned a model and then used the </span><span><span class="kobospan" id="kobo.654.1">fine-tuned model.</span></span></li>
</ol>
<h2 id="_idParaDest-85" class="calibre7"><a id="_idTextAnchor089" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.655.1">How it works…</span></h2>
<p class="calibre3"><span class="kobospan" id="kobo.656.1">In this recipe, we </span><a id="_idIndexMarker205" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.657.1">created a fine-tuned model by providing the OpenAI API with training data that taught the model how it should respond to prompts. </span><span class="kobospan" id="kobo.657.2">In this case, we trained it so that its output should be a one-liner joke followed by the word </span><strong class="source-inline"><span class="kobospan" id="kobo.658.1">Haha</span></strong><span class="kobospan" id="kobo.659.1">. </span><span class="kobospan" id="kobo.659.2">We then changed the </span><strong class="source-inline"><span class="kobospan" id="kobo.660.1">model</span></strong><span class="kobospan" id="kobo.661.1"> parameter to the ID of the model we just created, and made a </span><em class="italic"><span class="kobospan" id="kobo.662.1">chat completion</span></em><span class="kobospan" id="kobo.663.1"> request. </span><span class="kobospan" id="kobo.663.2">After that, we noted that the output we received on a prompt it had never seen before also resulted in a one-liner joke followed by the word </span><strong class="source-inline"><span class="kobospan" id="kobo.664.1">Haha</span></strong><span class="kobospan" id="kobo.665.1">. </span><span class="kobospan" id="kobo.665.2">In essence, we had successfully fine-tuned the </span><em class="italic"><span class="kobospan" id="kobo.666.1">gpt-3.5-turbo</span></em><span class="kobospan" id="kobo.667.1"> model to tell one-liner jokes given </span><span><span class="kobospan" id="kobo.668.1">any prompt.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.669.1">Fine-tuning steps</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.670.1">There are five steps that need</span><a id="_idIndexMarker206" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.671.1"> to be followed when fine-tuning a model and then using that </span><span><span class="kobospan" id="kobo.672.1">fine-tuned model:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.673.1">Prepare a training data file</span></em><span class="kobospan" id="kobo.674.1">: The training data consists of examples or prompts and desired completions. </span><span class="kobospan" id="kobo.674.2">You need at least 10 examples to successfully train a model. </span><span class="kobospan" id="kobo.674.3">Each example looks very similar (with purposeful intent) to the </span><strong class="source-inline1"><span class="kobospan" id="kobo.675.1">messages</span></strong><span class="kobospan" id="kobo.676.1"> parameter when making a chat completion request. </span><span class="kobospan" id="kobo.676.2">The difference, however, is that it also includes the completion (also known as the output from the assistant). </span><span class="kobospan" id="kobo.676.3">Here is </span><span><span class="kobospan" id="kobo.677.1">an example:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.678.1">
{"messages": [{"role": "system", "content": "You are an assistant that creates funny one-line jokes based on a given scenario."}, {"role": "user", "content": "A student in a library"}, {"role": "assistant", "content": "Why did the student bring a ladder to the library? </span><span class="kobospan1" id="kobo.678.2">Because they heard the knowledge was on the top shelf! </span><span class="kobospan1" id="kobo.678.3">Haha"}]}</span></pre><p class="calibre3"><span class="kobospan" id="kobo.679.1">These examples can be added to a JSON file, with each line representing </span><span><span class="kobospan" id="kobo.680.1">one example.</span></span></p></li> </ul>
<div class="calibre2">
<div class="img---figure" id="_idContainer034">
<span class="kobospan" id="kobo.681.1"><img alt="Figure 4.8 – Image of JSON file containing training data" src="image/B21007_04_08.jpg" class="calibre4"/></span>
</div>
</div>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.682.1">Figure 4.8 – Image of JSON file containing training data</span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.683.1">Import to OpenAI</span></em><span class="kobospan" id="kobo.684.1">: After the training file has been made, it needs to be uploaded to OpenAI’s servers, which is what we did with the </span><span><span class="kobospan" id="kobo.685.1">following code:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.686.1">
training_data = client.files.create(
  file=open("chapter4trainingdata.json", "rb"),
  purpose='fine-tune'
)</span></pre></li> <li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.687.1">Assign an ID</span></em><span class="kobospan" id="kobo.688.1">: After </span><a id="_idIndexMarker207" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.689.1">uploading the file, the API assigns it an ID. </span><span class="kobospan" id="kobo.689.2">This ID can be determined by looking at the response JSON from the preceding code, and parsing for the </span><span><strong class="source-inline1"><span class="kobospan" id="kobo.690.1">id</span></strong></span><span><span class="kobospan" id="kobo.691.1"> parameter:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.692.1">
file_id = training_data.id</span></pre></li> <li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.693.1">Fine-tune the model</span></em><span class="kobospan" id="kobo.694.1">: After that, we need to instruct the API to fine-tune the model using the uploaded training data. </span><span class="kobospan" id="kobo.694.2">We will put the response that we get from the API in </span><span><span class="kobospan" id="kobo.695.1">a variable:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.696.1">
fine_tune_job = client.fine_tuning.jobs.create(training_file=file_id, model="gpt-3.5-turbo")</span></pre><p class="calibre3"><span class="kobospan" id="kobo.697.1">Fine-tuning can take several minutes. </span><span class="kobospan" id="kobo.697.2">We can check the status of our fine-tuning job through another API call and then parse through the </span><span><span class="kobospan" id="kobo.698.1">response object:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.699.1">client.fine_tuning.jobs.retrieve(fine_tune_job.id).status</span></pre><p class="calibre3"><span class="kobospan" id="kobo.700.1">After the fine-tuning job is complete, the API will assign a </span><strong class="source-inline"><span class="kobospan" id="kobo.701.1">fine_tuned_model</span></strong><span class="kobospan" id="kobo.702.1"> parameter, giving the fine-tuned model a particular identifier, which we can store in </span><span><span class="kobospan" id="kobo.703.1">a variable:</span></span></p><pre class="source-code"><span class="kobospan1" id="kobo.704.1">fine_tuned_model = client.fine_tuning.jobs.retrieve(fine_tune_job.id).fine_tuned_model</span></pre></li> <li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.705.1">Use the fine-tuned model</span></em><span class="kobospan" id="kobo.706.1">: The last step is fairly easy – call the Chat Completions API as normal but modify the </span><strong class="source-inline1"><span class="kobospan" id="kobo.707.1">model</span></strong><span class="kobospan" id="kobo.708.1"> parameter to the newly fine-tuned model that </span><a id="_idIndexMarker208" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.709.1">was </span><span><span class="kobospan" id="kobo.710.1">just created:</span></span><pre class="source-code"><span class="kobospan1" id="kobo.711.1">
completion = client.chat.completions.create(
  model=fine_tuned_model,
  messages=[
    {"role": "system", "content": "You are an assistant that creates funny one-line jokes based on a given scenario."},
     {"role": "user", "content": "A man walking across the road"}
  ]
)
print(completion.choices[0].message.content)</span></pre></li> </ul>
<h3 class="calibre8"><span class="kobospan" id="kobo.712.1">Benefits of fine-tuning</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.713.1">Fine-tuning </span><a id="_idIndexMarker209" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.714.1">improves few-shot learning by allowing you to train on many more examples than what would fit in a typical prompt context window. </span><span class="kobospan" id="kobo.714.2">Once a model has been tuned, these examples are not needed every single time when making a completions request, thereby saving tokens (and costs) and resulting in lower latency (i.e., faster speed). </span><span class="kobospan" id="kobo.714.3">Recall that tokens are the smallest units of meaning in a piece of text (typically words, punctuation marks, or other elements) used in NLP and often form the basis of how OpenAI charges chat </span><span><span class="kobospan" id="kobo.715.1">completion requests.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.716.1">For example, let’s go through the number of tokens for two models (i) one that uses the </span><em class="italic"><span class="kobospan" id="kobo.717.1">gpt-3.5</span></em><span class="kobospan" id="kobo.718.1"> base model without any fine-tuning, but we need to include examples in the prompt every time, and (ii) a </span><span><span class="kobospan" id="kobo.719.1">fine-tuned model.</span></span></p>
<table class="no-table-style" id="table003-1">
<colgroup class="calibre10">
<col class="calibre11"/>
<col class="calibre11"/>
<col class="calibre11"/>
</colgroup>
<thead class="calibre12">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.720.1">Model</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.721.1">Gpt-3.5</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.722.1">Gpt-3.5 that has </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.723.1">been fine-tuned</span></strong></span></p>
</td>
</tr>
</thead>
<tbody class="calibre13">
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><span><strong class="bold"><span class="kobospan" id="kobo.724.1">Prompt</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.725.1">You are an assistant who creates funny one-line jokes based on a given scenario. </span><span class="kobospan" id="kobo.725.2">Here are </span><span><span class="kobospan" id="kobo.726.1">10 examples:</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.727.1">A knight getting ready for a battle </span><span lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.728.1"></span></span><span class="kobospan" id="kobo.729.1"> Why was the knight always calm before battle? </span><span class="kobospan" id="kobo.729.2">Because he was good at keeping his “armor” </span><span><span class="kobospan" id="kobo.730.1">cool! </span><span class="kobospan" id="kobo.730.2">Haha</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.731.1">… [9 more </span><span><span class="kobospan" id="kobo.732.1">examples] …</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.733.1">Scenario: A penguin in </span><span><span class="kobospan" id="kobo.734.1">the Arctic</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span class="kobospan" id="kobo.735.1">You are an assistant who creates funny one-line jokes based on a </span><span><span class="kobospan" id="kobo.736.1">given scenario.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.737.1">Scenario: A penguin in </span><span><span class="kobospan" id="kobo.738.1">the Arctic</span></span></p>
</td>
</tr>
<tr class="no-table-style1">
<td class="no-table-style2">
<p class="calibre3"><strong class="bold"><span class="kobospan" id="kobo.739.1">Number of tokens in </span></strong><span><strong class="bold"><span class="kobospan" id="kobo.740.1">prompt (estimated)</span></strong></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.741.1">400</span></span></p>
</td>
<td class="no-table-style2">
<p class="calibre3"><span><span class="kobospan" id="kobo.742.1">36</span></span></p>
</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US" xml:lang="en-US"><span class="kobospan" id="kobo.743.1">Table 4.3 – Comparison of prompt examples and number of tokens between a non-fine-tuned and a fine-tuned GPT-3.5 model</span></p>
<p class="calibre3"><span class="kobospan" id="kobo.744.1">A fine-tuned model </span><a id="_idIndexMarker210" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.745.1">uses about one-tenth of the number of tokens as the few-shot base model. </span><span class="kobospan" id="kobo.745.2">This means that using a fine-tuned model can result in 90% cost savings, which can be very high if you deploy these models to heavily </span><span><span class="kobospan" id="kobo.746.1">used applications.</span></span></p>
<p class="calibre3"><span class="kobospan" id="kobo.747.1">Other benefits of fine-tuning include higher-quality results by being able to train on thousands of examples, which is not possible using few-shot learning as there is a maximum length for </span><span><span class="kobospan" id="kobo.748.1">the prompt.</span></span></p>
<p class="callout-heading"><span class="kobospan" id="kobo.749.1">Note</span></p>
<p class="callout"><span class="kobospan" id="kobo.750.1">Fine-tuning a model to get better-quality results should only be done after sufficient attempts at prompt engineering and prompt chaining have been made. </span><span class="kobospan" id="kobo.750.2">Fine-tuning a model requires significant resources and effort, so it’s more efficient to first exhaust the potential of prompt engineering and prompt chaining, which can often achieve desired results without additional training. </span><strong class="bold"><span class="kobospan" id="kobo.751.1">Prompt engineering</span></strong><span class="kobospan" id="kobo.752.1"> refers to creating more detailed and structured prompts to yield better completions. </span><strong class="bold"><span class="kobospan" id="kobo.753.1">Prompt chaining</span></strong><span class="kobospan" id="kobo.754.1"> is the idea of breaking down more complex prompts into </span><span><span class="kobospan" id="kobo.755.1">simpler tasks.</span></span></p>
<h3 class="calibre8"><span class="kobospan" id="kobo.756.1">Applications of fine-tuning</span></h3>
<p class="calibre3"><span class="kobospan" id="kobo.757.1">When would</span><a id="_idIndexMarker211" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.758.1"> you resort to fine-tuning a model rather than (i) using the base </span><em class="italic"><span class="kobospan" id="kobo.759.1">gpt-3.5</span></em><span class="kobospan" id="kobo.760.1"> or </span><em class="italic"><span class="kobospan" id="kobo.761.1">gpt4</span></em><span class="kobospan" id="kobo.762.1"> model, or (ii) using few-shot learning to prime the model instead? </span><span class="kobospan" id="kobo.762.2">In general, here are some of the common use cases where you would need to fine-tune </span><span><span class="kobospan" id="kobo.763.1">the model:</span></span></p>
<ul class="calibre16">
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.764.1">Enhancement of desired outputs</span></em><span class="kobospan" id="kobo.765.1">: Fine-tuning is crucial when there’s a need for more reliability in generating specific types of responses. </span><span class="kobospan" id="kobo.765.2">By training the model on a specialized dataset, you can increase the chances that it will produce the desired output consistently. </span><span class="kobospan" id="kobo.765.3">This is common in content creation for a particular brand voice, creating educational resources that must follow a specific language, and </span><span><span class="kobospan" id="kobo.766.1">so on.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.767.1">Complex prompt compliance</span></em><span class="kobospan" id="kobo.768.1">: In instances where the model consistently fails to adhere to complex prompts or instructions, fine-tuning can help correct these shortcomings. </span><span class="kobospan" id="kobo.768.2">This ensures that the model better understands and follows detailed or multifaceted instructions. </span><span class="kobospan" id="kobo.768.3">This is very common when creating programming assistants, </span><span><span class="kobospan" id="kobo.769.1">for example.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.770.1">Specialized style and tone adjustments</span></em><span class="kobospan" id="kobo.771.1">: When a certain style, tone, or format is required – for example, legal language, a comedic tone, or a journalistic style – fine-tuning adjusts the model to capture these qualitative aspects more accurately. </span><span class="kobospan" id="kobo.771.2">This is common when developing </span><em class="italic"><span class="kobospan" id="kobo.772.1">customer service bots</span></em><span class="kobospan" id="kobo.773.1"> – where the bots need to maintain a kind but </span><span><span class="kobospan" id="kobo.774.1">firm tone.</span></span></li>
<li class="calibre15"><em class="italic"><span class="kobospan" id="kobo.775.1">Custom task performance</span></em><span class="kobospan" id="kobo.776.1">: For teaching the model a new skill or task that is difficult to convey through a prompt alone, fine-tuning allows the model to learn from examples. </span><span class="kobospan" id="kobo.776.2">This is particularly useful for niche applications or innovative tasks that the base model may not have been exposed to during its initial training, or more complex tasks such as </span><em class="italic"><span class="kobospan" id="kobo.777.1">dictating a </span></em><span><em class="italic"><span class="kobospan" id="kobo.778.1">medical diagnosis</span></em></span><span><span class="kobospan" id="kobo.779.1">.</span></span></li>
</ul>
<p class="calibre3"><span class="kobospan" id="kobo.780.1">Overall, fine-tuning a model is a great, cost-efficient way to get higher-quality, consistent results. </span><span class="kobospan" id="kobo.780.2">This</span><a id="_idIndexMarker212" class="pcalibre1 calibre6 pcalibre"/><span class="kobospan" id="kobo.781.1"> is especially useful if you intend to build applications where similar prompts and responses are expected, and where a particular tone and style </span><span><span class="kobospan" id="kobo.782.1">is required.</span></span></p>
</div>
</body></html>