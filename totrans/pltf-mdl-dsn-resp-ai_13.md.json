["```py\n    from sklearn.datasets import make_classification\n    from sklearn.calibration import CalibratedClassifierCV\n    from sklearn.calibration import calibration_curve\n    from sklearn.model_selection import train_test_split\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.metrics import roc_auc_score, brier_score_loss\n    import matplotlib.pyplot as plt\n    import pandas as pd\n    import numpy as np\n    import seaborn as sns\n    ```", "```py\n    X, y = make_classification(n_samples=10000, n_features=1000, n_redundant=10, random_state=37, weights=[0.5])\n    ```", "```py\nXs = pd.DataFrame(X)\nys = pd.DataFrame(y, columns=['label'])\n```", "```py\n    #plotting bar chart\n    ys.value_counts().plot(kind='bar')\n    ```", "```py\n    X_train_raw, X_test, y_train_raw, y_test = train_test_split(Xs, ys, test_size=0.20, shuffle=False)\n    X_train, X_val, y_train, y_val = train_test_split(X_train_raw, y_train_raw, test_size=0.20, shuffle=False)\n    ```", "```py\nclf = LogisticRegression()\nclf.fit(X_train, y_train.values.ravel())\ny_pred_uncal = clf.predict_proba(X_test)[:, 1]\n```", "```py\nroc_auc_score(y_test, y_pred_uncal)\n>>> 0\\. 9185432154389126\n```", "```py\nbrier_score_loss(y_test, y_pred_uncal)\n>>> 0.10919273032433353\n```", "```py\nCalibrated_clf = CalibratedClassifierCV(clf, method='sigmoid')\ncalibrated_clf.fit(X_val, y_val.values.ravel())\ny_pred_cal = calibrated_clf.predict_proba(X_test)[:, 1]\nprint(f'ROC Score {roc_auc_score(y_test, y_pred_cal):.2f} \\nBrier Score {brier_score_loss(y_test, y_pred_cal):.2f})\n>>> ROC Score 0.92\n>>> Brier Score 0.11\n```", "```py\nplt.rcParams.update({'font.size': 10})\nfrac_of_positives_uncal, pred_prob_uncal = calibration_curve(y_test, y_pred_uncal, n_bins=10)\nsns.lineplot(x=pred_prob_uncal, y=frac_of_positives_uncal)\nfrac_of_positives_cal, pred_prob_cal = calibration_curve(y_test, y_pred_cal, n_bins=10)\nsns.lineplot(x=pred_prob_cal, y=frac_of_positives_cal)\nplt.grid(linestyle='-', linewidth=0.2)\nplt.title(\"Reliability curve balanced data\")\nxlabel = plt.xlabel(\"Probability of positive\")\nylabel = plt.ylabel(\"Fraction of positives\")\nplt.legend(labels = ['Uncalibrated', 'Calibrated'])\nticks = [0, 0.2, 0.4, 0.6, 0.8, 1]\nxticks = plt.xticks(ticks)\nyticks = plt.yticks(ticks)\n```", "```py\nX, y = make_classification(n_samples=10000, n_features=1000, n_redundant=10, random_state=37, weights=[0.7])\nXs = pd.DataFrame(X)\nys = pd.DataFrame(y, columns=['label'])\n```", "```py\n#plotting bar chart\nys.value_counts().plot(kind='bar')\n```", "```py\nX_train_raw, X_test, y_train_raw, y_test = train_test_split(Xs, ys, test_size=0.20, shuffle=False)\nX_train, X_val, y_train, y_val = train_test_split(X_train_raw, y_train_raw, test_size=0.20, shuffle=False)\n```", "```py\nclf = LogisticRegression()\nclf.fit(X_train, y_train.values.ravel())\ny_pred_uncal = clf.predict_proba(X_test)[:, 1]\nprint(f'ROC Score {roc_auc_score(y_test, y_pred_uncal):.2f} \\nBrier Score {brier_score_loss(y_test, y_pred_uncal):.2f}')\n>>> ROC Score 0.88\n>>> Brier Score 0.04\n```", "```py\ncalibrated_clf = CalibratedClassifierCV(clf,cv=3, method='isotonic')\ncalibrated_clf.fit(X_val, y_val.values.ravel())\ny_pred_cal = calibrated_clf.predict_proba(X_test)[:, 1]\nprint(f'ROC Score {roc_auc_score(y_test, y_pred_uncal):.2f} \\nBrier Score {brier_score_loss(y_test, y_pred_uncal):.2f}')\n>>> ROC Score 0.88\n>>>Brier Score 0.04\n```"]