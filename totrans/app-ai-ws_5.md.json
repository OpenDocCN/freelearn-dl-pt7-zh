["```py\n    import numpy as np\n    data_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                            [8, 1], [8, 0], [8.5, 1], \\\n                            [6, 1], [1, 10], [1.5, 10], \\\n                            [1.5, 9.5], [10, 10], [1.5, 8.5]])\n    ```", "```py\n    import matplotlib.pyplot as plot\n    plot.scatter(data_points.transpose()[0], \\\n                 data_points.transpose()[1])\n    ```", "```py\n    from sklearn.cluster import KMeans\n    k_means_model = KMeans(n_clusters=3,random_state=8)\n    k_means_model.fit(data_points)\n    ```", "```py\n    KMeans(algorithm='auto', copy_x=True, init='k-means++', \n           max_iter=300, n_clusters=3, n_init=10, n_jobs=None,\n           precompute_distances='auto',\n           random_state=8, tol=0.0001, verbose=0)\n    ```", "```py\n    centers = k_means_model.cluster_centers_\n    centers\n    ```", "```py\n    array([[7.625     , 0.75      ],\n           [3.1       , 9.6       ],\n           [1.33333333, 1.5       ]])\n    ```", "```py\n    labels = k_means_model.labels_\n    labels\n    ```", "```py\n    array([2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n    ```", "```py\n    plot.scatter(centers[:,0], centers[:,1])\n    for i in range(len(data_points)):\n        plot.plot(data_points[i][0], data_points[i][1], \\\n                  ['k+','kx','k_'][k_means_model.labels_[i]])\n    plot.show()\n    ```", "```py\n    k_means_model = KMeans(n_clusters=2,random_state=8)\n    k_means_model.fit(data_points)\n    centers2 = k_means_model.cluster_centers_\n    labels2 = k_means_model.labels_\n    plot.scatter(centers2[:,0], centers2[:,1])\n    for i in range(len(data_points)):\n        plot.plot(data_points[i][0], data_points[i][1], \\\n                  ['k+','kx'][labels2[i]])\n    plot.show()\n    ```", "```py\n    predictions = k_means_model.predict([[5,5],[0,10]])\n    predictions\n    ```", "```py\n    array([0, 1], dtype=int32)\n    ```", "```py\n    import numpy as np\n    import matplotlib.pyplot as plot\n    from sklearn.cluster import KMeans\n    data_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                            [8, 1], [8, 0], [8.5, 1], \\\n                            [6, 1], [1, 10], [1.5, 10], \\\n                            [1.5, 9.5], [10, 10], [1.5, 8.5]])\n    k_means_model = KMeans(n_clusters=4,random_state=8)\n    k_means_model.fit(data_points)\n    centers = k_means_model.cluster_centers_\n    centers\n    ```", "```py\n    array([[ 7.625     ,  0.75      ],\n           [ 1.375     ,  9.5       ],\n           [ 1.33333333,  1.5       ],\n           [10\\.        , 10\\.        ]])\n    ```", "```py\n    labels = k_means_model.labels_\n    labels\n    ```", "```py\n    array([2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 3, 1], dtype=int32)\n    ```", "```py\n    import numpy as np\n    data_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                            [8, 1], [8, 0], [8.5, 1], \\\n                            [6, 1], [1, 10], [1.5, 10], \\\n                            [1.5, 9.5], [10, 10], [1.5, 8.5]])\n    import matplotlib.pyplot as plot\n    plot.scatter(data_points.transpose()[0], \\\n                 data_points.transpose()[1])\n    ```", "```py\n    P1 = [1, 1]\n    ```", "```py\n    from scipy.spatial import distance\n    r = 2\n    points1 = np.array([p0 for p0 in data_points if \\\n                        distance.euclidean(p0, P1) <= r])\n    points1\n    ```", "```py\n    array([[1\\. , 1\\. ],\n           [1\\. , 1.5],\n           [2\\. , 2\\. ]])\n    ```", "```py\n    P2 = [np.mean( points1.transpose()[0] ), \\\n          np.mean(points1.transpose()[1] )]\n    P2\n    ```", "```py\n    [1.3333333333333333, 1.5]\n    ```", "```py\n    points2 = np.array([p0 for p0 in data_points if \\\n                        distance.euclidean( p0, P2) <= r])\n    points2\n    ```", "```py\n    array([[1\\. , 1\\. ],\n           [1\\. , 1.5],\n           [2\\. , 2\\. ]])\n    ```", "```py\n    P3 = [8, 1]\n    points3 = np.array( [p0 for p0 in data_points if \\\n                         distance.euclidean(p0, P3) <= r])\n    points3\n    ```", "```py\n    array([[8\\. , 1\\. ],\n           [8\\. , 0\\. ],\n           [8.5, 1\\. ],\n           [6\\. , 1\\. ]])\n    ```", "```py\n    P4 = [np.mean(points3.transpose()[0]), \\\n          np.mean(points3.transpose()[1])]\n    P4\n    ```", "```py\n    [7.625, 0.75]\n    ```", "```py\n    P5 = [8, 0]\n    points4 = np.array([p0 for p0 in data_points if \\\n                       distance.euclidean(p0, P5) <= r])\n    points4\n    ```", "```py\n    array([[8\\. , 1\\. ],\n           [8\\. , 0\\. ],\n           [8.5, 1\\. ]])\n    ```", "```py\n    P6 = [np.mean(points4.transpose()[0]), \\\n          np.mean(points4.transpose()[1])]\n    P6\n    ```", "```py\n    [8.166666666666666, 0.6666666666666666]\n    ```", "```py\n    P7 = [8.5, 1]\n    points5 = np.array([p0 for p0 in data_points if \\\n                        distance.euclidean(p0, P7) <= r])\n    points5\n    ```", "```py\n    array([[8\\. , 1\\. ],\n           [8\\. , 0\\. ],\n           [8.5, 1\\. ]])\n    ```", "```py\n    P8 = [6, 1]\n    points6 = np.array([p0 for p0 in data_points if \\\n                        distance.euclidean(p0, P8) <= r])\n    points6\n    ```", "```py\n    array([[8., 1.],\n           [6., 1.]])\n    ```", "```py\n    P9 = [np.mean(points6.transpose()[0]), \\\n          np.mean(points6.transpose()[1]) ]\n    P9\n    ```", "```py\n    [7.0, 1.0]\n    ```", "```py\n    points7 = np.array([p0 for p0 in data_points if \\\n                        distance.euclidean(p0, P9) <= r])\n    points7\n    ```", "```py\n    array([[8\\. , 1\\. ],\n           [8\\. , 0\\. ],\n           [8.5, 1\\. ],\n           [6\\. , 1\\. ]])\n    ```", "```py\nimport numpy as np\ndata_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                        [8, 1], [8, 0], [8.5, 1], \\\n                        [6, 1], [1, 10], [1.5, 10], \\\n                        [1.5, 9.5], [10, 10], [1.5, 8.5]])\n```", "```py\nfrom sklearn.cluster import MeanShift\nmean_shift_model = MeanShift()\nmean_shift_model.fit(data_points)\n```", "```py\nmean_shift_model.cluster_centers_\n```", "```py\narray([[ 1.375     ,  9.5       ],\n       [ 8.16666667,  0.66666667],\n       [ 1.33333333,  1.5       ],\n       [10\\.        , 10\\.        ],\n       [ 6\\.        ,  1\\.        ]])\n```", "```py\nmean_shift_model.labels_\n```", "```py\narray([2, 2, 2, 1, 1, 1, 4, 0, 0, 0, 3, 0], dtype=int64)\n```", "```py\nimport matplotlib.pyplot as plot\nplot.scatter(mean_shift_model.cluster_centers_[:,0], \\\n             mean_shift_model.cluster_centers_[:,1])\nfor i in range(len(data_points)): \n    plot.plot(data_points[i][0], data_points[i][1], \\\n              ['k+','kx','kv', 'k_', 'k1']\\\n              [mean_shift_model.labels_[i]])\nplot.show()\n```", "```py\nimport numpy as np\ndata_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                        [8, 1], [8, 0], [8.5, 1], \\\n                        [6, 1], [1, 10], [1.5, 10], \\\n                        [1.5, 9.5], [10, 10], [1.5, 8.5]])\n```", "```py\nfrom scipy.cluster.hierarchy import dendrogram\nimport scipy.cluster.hierarchy as sch\n```", "```py\ndendrogram = sch.dendrogram(sch.linkage(data_points, \\\n                            method='ward'))\n```", "```py\nfrom sklearn.cluster import AgglomerativeClustering\nagglomerative_model = AgglomerativeClustering(n_clusters=4, \\\n                                              affinity='euclidean', \\\n                                              linkage='ward')\nagglomerative_model.fit(data_points)\n```", "```py\nAgglomerativeClustering(affinity='euclidean', \n                        compute_full_tree='auto',\n                        connectivity=None, \n                        distance_threshold=None,\n                        linkage='ward', memory=None,\n                        n_clusters=4, pooling_func='deprecated')\n```", "```py\nagglomerative_model.labels_\n```", "```py\narray([2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 3, 1], dtype=int64)\n```", "```py\nimport matplotlib.pyplot as plot\nfor i in range(len(data_points)): \n    plot.plot(data_points[i][0], data_points[i][1], \\\n              ['k+','kx','kv', 'k_'][agglomerative_model.labels_[i]])\nplot.show()\n```", "```py\nfrom sklearn import metrics\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plot\nfrom sklearn.cluster import KMeans\ndata_points = np.array([[1, 1], [1, 1.5], [2, 2], \\\n                        [8, 1], [8, 0], [8.5, 1], \\\n                        [6, 1], [1, 10], [1.5, 10], \\\n                        [1.5, 9.5], [10, 10], [1.5, 8.5]])\nk_means_model = KMeans(n_clusters=3,random_state = 8)\nk_means_model.fit(data_points)\nk_means_model.labels_\n```", "```py\narray([2, 2, 2, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n```", "```py\ndata_labels = np.array([0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 3, 1])\n```", "```py\nmetrics.adjusted_rand_score(data_labels, k_means_model.labels_)\n```", "```py\n0.8422939068100358\n```", "```py\nmetrics.adjusted_mutual_info_score(data_labels, \\\n                                   k_means_model.labels_)\n```", "```py\n0.8769185235006342\n```", "```py\nmetrics.homogeneity_score(data_labels, k_means_model.labels_)\nmetrics.completeness_score(data_labels, k_means_model.labels_)\nmetrics.v_measure_score(data_labels, k_means_model.labels_, \\\n                        beta=1)\n```", "```py\n0.8378758055108827\n```", "```py\n1.0\n```", "```py\n0.9117871871412709\n```", "```py\nmetrics.fowlkes_mallows_score(data_labels, k_means_model.labels_)\n```", "```py\n0.8885233166386386\n```", "```py\ndata_labels = np.array([0, 0, 0, 2, 2, 2, 2, 1, 1, 1, 3, 1])\n```", "```py\ndata_labels = np.array([2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 3, 0])\n```", "```py\nfrom sklearn.metrics.cluster import contingency_matrix\ncontingency_matrix(k_means_model.labels_,data_labels)\n```", "```py\narray([[0, 4, 0, 0],\n       [4, 0, 0, 1],\n       [0, 0, 3, 0]])\n```", "```py\nmetrics.silhouette_score(data_points, k_means_model.labels_)\n```", "```py\n0.6753568188872228\n```", "```py\nmetrics.calinski_harabasz_score(data_points, k_means_model.labels_)\n```", "```py\n19.52509172315154\n```", "```py\nmetrics.davies_bouldin_score(data_points, k_means_model.labels_)\n```", "```py\n0.404206621415983\n```"]