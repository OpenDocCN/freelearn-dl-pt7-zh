<html><head></head><body>
		<div id="_idContainer283">
			<h1 id="_idParaDest-262" class="chapter-nu ber"><a id="_idTextAnchor292"/>14</h1>
			<h1 id="_idParaDest-263"><a id="_idTextAnchor293"/>Industry-Wide Use Cases</h1>
			<p>This chapter presents different use cases of Responsible AI concerning retail, supply chain management, banking and finance, and healthcare. The primary aim of this chapter is to help you develop your skills through practical applications so that you can apply AI solutions to real-world use cases that can help create a more equitable and inclusive world. You will build your knowledge on the usefulness of AI ethics and compliance in a variety of contextual scenarios, enabling you to be more adept at identifying and solving future use cases involving the thoughtful application of AI in different industry verticals. Further, this chapter will allow you to test, measure, and quantify the business outcomes from respective industry domains by applying AI-based tools and algorithms to large-scale <span class="No-Break">distributed systems.</span></p>
			<p>By the end of this chapter, you will be able to create unbiased, fair AI-driven solutions concerning the retail, banking, and <span class="No-Break">healthcare sectors.</span></p>
			<p>In this chapter, these topics will <span class="No-Break">be covered:</span></p>
			<ul>
				<li>Building ethical AI solutions <span class="No-Break">across industries</span></li>
				<li>Use cases involving AI applications in retail and supply <span class="No-Break">chain management</span></li>
				<li>Use cases involving AI applications in banking <span class="No-Break">and finance</span></li>
				<li>Use cases involving AI applications <span class="No-Break">in healthcare</span></li>
			</ul>
			<h1 id="_idParaDest-264"><a id="_idTextAnchor294"/>Technical requirements</h1>
			<p>This chapter requires that you have Python 3.8 installed, along with the following Python packages using the <span class="No-Break">following commands:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="source-inline">tensorflow-2.7.0</strong></span></li>
				<li><strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install pycausalimpact</strong></span></li>
				<li><strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install causalml</strong></span></li>
				<li><strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install dice-ml</strong></span></li>
				<li><strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install causalnex</strong></span></li>
				<li><strong class="source-inline">pip </strong><span class="No-Break"><strong class="source-inline">install auton-survival</strong></span></li>
			</ul>
			<p>While installing these libraries, you may find that the depandant libraries conflict, so it is advised that you install and run the use cases for one library first before moving on to <span class="No-Break">the next.</span></p>
			<p>Let's begin by looking at how various industry domains suffer from biased solutions and how we can build ethical solutions to improve the <span class="No-Break">customer experience.</span></p>
			<h1 id="_idParaDest-265"><a id="_idTextAnchor295"/>Building ethical AI solutions across industries</h1>
			<p>Chatbots play<a id="_idIndexMarker1655"/> an important role in<a id="_idIndexMarker1656"/> the retail, finance, healthcare, travel, hospitality, and consumer sectors, as well as in other verticals. Hence, Responsible AI practices should be able to identify biased chatbots produced by AI/ML models and take proper action to ensure they are fair in <span class="No-Break">their predictions.</span></p>
			<h2 id="_idParaDest-266"><a id="_idTextAnchor296"/>Biased chatbots</h2>
			<p>Chatbots fails to understand a certain accent or dialect, which results in a negative customer experience. The customer is forced to contact your customer service department directly. Chatbots are widely used in the retail industry in the <span class="No-Break">following ways:</span></p>
			<ul>
				<li>Helping to retain customers by providing 24/7 assistance 365 days a year, providing quick turnaround times, and addressing <span class="No-Break">their problems</span></li>
				<li>Informing customers about the availability of new products and notifying customers about personalized products that fit the <span class="No-Break">buyer’s interests</span></li>
				<li>Helping customers to make orders and ensuring a smooth checkout process by taking customer details such as telephone numbers, payment options, and <span class="No-Break">so on</span></li>
			</ul>
			<p>Chatbots trained on data with insufficient diversity give biased answers to end users, forcing them to call customer service directly. Chatbots trained on data featuring the American-English accent might fail to pick up accents and dialects of minorities and underrepresented groups, such as African-American Vernacular English. Examples include the Blender chatbot trained by Facebook on Reddit data. It quickly learned abusive and vulgar language. </p>
			<p>A similar case was Microsoft’s AI chatbot, Tay, launched in 2016, which started issuing racist comments and was withdrawn within 24 hours of its launch. Tay was only trained with data from Twitter, demonstrating how predictions from biased datasets can be discriminatory toward different <span class="No-Break">population segments.</span></p>
			<p>Along with chatbots complying<a id="_idIndexMarker1657"/> with ethical standards, we also need to consider<a id="_idIndexMarker1658"/> the ethical aspects of <strong class="bold">Extended Reality</strong> (<strong class="bold">XR</strong>)/<strong class="bold">Augmented Reality</strong> (<strong class="bold">AR</strong>)/<strong class="bold">Virtual Reality</strong> (<strong class="bold">VR</strong>) environments as they are used across industry domains. Hence, let’s understand how VR, AR, and XR environments are used in the context of the retail industry and how important it is that they are designed while following <span class="No-Break">best practices.</span></p>
			<h2 id="_idParaDest-267"><a id="_idTextAnchor297"/>Ethics in XR/AR/VR</h2>
			<p>The retail industry<a id="_idIndexMarker1659"/> has come up with a variety of <strong class="bold">XR</strong> tools comprising <strong class="bold">AR, VR</strong>, and <strong class="bold">Mixed Reality</strong> (<strong class="bold">MR</strong>), where digital features are used to provide customers<a id="_idIndexMarker1660"/> with the ability to interact<a id="_idIndexMarker1661"/> with and experience<a id="_idIndexMarker1662"/> their chosen items<a id="_idIndexMarker1663"/> before buying them. Retailers<a id="_idIndexMarker1664"/> are now equipped with AR/VR facilities<a id="_idIndexMarker1665"/> to digitally project anything that customers may want to try on themselves, from different-sized and colored glasses to jewelry, clothes, shoes, and watches. Customers can also leverage their smartphone cameras to organize their planned furniture purchases in their homes, and even transfer themselves to a different location and enjoy the feeling of the dress or shoes they <span class="No-Break">are wearing.</span></p>
			<p>With the rising presence of brands on social media platforms, both brands and regulatory bodies should be aware of the best practices to promote the ethical use of AI on these platforms. As a result of targeting customers using demographic information and providing personalized shopping experiences, some brands have started to face accusations about their products, as many products have been found to carry racist branding. For example, major international consumer brands plan to remove labels such as “fair,” “white,” and “light” from their products, including the skin-lightening creams that are popular <span class="No-Break">in India.</span></p>
			<p><strong class="bold">Kantian duty ethics</strong> (which lays down universal moral principles applicable to all human beings, regardless of context or situation) explains that human<a id="_idIndexMarker1666"/> beings should treat each other with respect and honor in the same way they want themselves to be treated. This is also applicable to the context of AR/VR – if we treat virtual characters with disrespect or commit acts of violence or intolerance, knowingly or unknowingly, we may cause psychological harm to the people that those characters might represent. Thus, designers of AR/VR must scrutinize all possible actions taken by avatars and virtual agents to prohibit them from carrying out <span class="No-Break">immoral actions.</span></p>
			<p>In absence<a id="_idIndexMarker1667"/> of structured regulations<a id="_idIndexMarker1668"/> concerning data<a id="_idIndexMarker1669"/> privacy, copyright, and liability<a id="_idIndexMarker1670"/> in the field<a id="_idIndexMarker1671"/> of AR/VR/XR, we can use Kantian<a id="_idIndexMarker1672"/> duty ethics as a framework for thinking about the ethical implications of AI and the moral rules that should govern the development and use of AI systems. For example, Kant’s categorical imperative, which holds that we should act only in ways that we would be willing to see universalized, could be applied to the development of AI systems. It might be argued that we should only develop AI systems that are aligned with moral values and that we would be willing to see universalized, rather than developing systems that might be used for nefarious purposes or that could lead to <span class="No-Break">negative consequences.</span></p>
			<p>Further, ethical bodies and experienced researchers should evaluate the risk of exposure of vulnerable people to sensitive topics that could cause harm and impact the physical, psychological, and social well-being of users. For example, a customer could visit a fake virtual retail store and be prompted to make fake commercial transactions, where the personal data and bank details of the customer will <span class="No-Break">be stolen.</span></p>
			<p>Hence, developers of such AR/VR systems should consider the following parameters and may need to tune them based on the nature of the audience. For example, certain AR/VR systems could be dangerous for people with disabilities or young or elder sections of the population (<a href="https://www.frontiersin.org/articles/10.3389/frvir.2020.00001/full">https://www.frontiersin.org/articles/10.3389/frvir.2020.00001/full</a>). This includes <span class="No-Break">the following:</span></p>
			<ul>
				<li>The speed (or framerate) of the AR/VR media and the level of motion sickness people <span class="No-Break">may experience.</span></li>
				<li>Influencing changes in a person’s sensory, motor, and perceptual abilities, or their manual dexterity or ability to orientate <span class="No-Break">their body.</span></li>
				<li>The degree of information overload that could affect individuals through acts <span class="No-Break">of persuasion.</span></li>
				<li>The potential of the long-term and frequent use of XR leading to mistrust of physical world events and over-prioritization of virtual world events, such as customers failing to distinguish between real and virtual events <span class="No-Break">over time.</span></li>
				<li>The intensification of experiences in a VR environment to which the user needs time to adjust, or consideration of the need for psychological therapy to prevent them from having <span class="No-Break">adverse responses.</span></li>
				<li>Cognitive, emotional (for example, if a viewer’s avatar is insulted by a fictional virtual character), and behavioral (for example, certain actions accepted in XR are socially unethical, such as gender or racial discrimination, or false attribution toward a specific group) disturbances that people may carry with them after leaving the VR environment and re-entering the <span class="No-Break">physical world.</span></li>
				<li>Even realistic situations in a virtual world are dangerous in the real world. Such cases arise when customers see something in XR that has no corresponding counterpart in the real world, and they try to replicate it in the real world. An example of this is the chair problem, where customers try to sit on a virtual chair that does not have a <span class="No-Break">physical counterpart.</span></li>
			</ul>
			<p>To design<a id="_idIndexMarker1673"/> ethical<a id="_idIndexMarker1674"/> retail industry<a id="_idIndexMarker1675"/> solutions, we must<a id="_idIndexMarker1676"/> consider<a id="_idIndexMarker1677"/> privacy, fairness, <span class="No-Break">and</span><span class="No-Break"><a id="_idIndexMarker1678"/></span><span class="No-Break"> interpretability.</span></p>
			<h1 id="_idParaDest-268"><a id="_idTextAnchor298"/>Use cases in retail</h1>
			<p>Let’s consider some individual use cases that convey the importance of <span class="No-Break">these aspects.</span></p>
			<h2 id="_idParaDest-269"><a id="_idTextAnchor299"/>Privacy in the retail industry</h2>
			<p>Retailers should proactively protect<a id="_idIndexMarker1679"/> their customers’ sensitive<a id="_idIndexMarker1680"/> data by complying with legislation governing<a id="_idIndexMarker1681"/> data privacy and security, such as the European Union’s <strong class="bold">General Data Protection Regulation</strong> (<strong class="bold">GDPR</strong>). There are other legislations that retailers must comply with globally, to protect consumers. This includes the Electronic Commerce Regulations of 2002, Payment Card Industry Data Security Standards, and antispam laws, among the many other rules globally. To safeguard customers’ data, some of the best security practices involve installing firewall services, mandating two-factor authentication, and other security practices detailed in <a href="B18681_02.xhtml#_idTextAnchor040"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Emergence of Risk-Averse Methodologies </em><span class="No-Break"><em class="italic">and Frameworks</em></span><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-270"><a id="_idTextAnchor300"/>Fairness in the retail industry</h2>
			<p>In the retail industry, it has been observed<a id="_idIndexMarker1682"/> that AI-driven solutions<a id="_idIndexMarker1683"/> often lead to disparate outcomes for a wide range of people based on their socio-demographic (gender, race, or other attributes deemed sensitive) backgrounds. Hence, as AI designers, it is of utmost importance that we study the customer segment well to formulate our solutions. We know that in the retail world, the customer profile plays a dominant role in determining the lifetime value of the customer to a company. Consequently, the customer profile, along with their browsing history, leads to decisions where promotions, discounts, and coupons can be granted based on their clickstream sessions (series of events taking place in the user’s browsing sessions). However, even after considering those factors, it has been found that the act of incentivizing a purchase (Koehn et al., 2020, <em class="italic">Predicting online shopping behaviour from clickstream data using deep learning</em>, <strong class="source-inline">https://www.sciencedirect.com/science/article/abs/pii/S0957417420301676</strong>) may lead to a coupon distribution where consumers belonging to a certain social, demographical, or cultural background receive biased and unfair treatment over others, generating negative sentiments for those consumers who did not receive the discounts. An example to illustrate this is when discounts are unevenly distributed and primarily targeted at people from high-income households that have a higher likelihood of making a purchase, excluding people residing in low-income households <span class="No-Break">from discounts.</span></p>
			<p>Furthermore, clickstream sessions have uncovered recognized differences between female and male users, concluding with the fact that even gender acts as a proxy and gives rise to biased models. It has been found from statistical data that female users tend to have higher browsing frequency and spend a greater amount of time per session on a web page. With an increase in browsing time, the backend processing<a id="_idIndexMarker1684"/> engines of e-commerce platforms<a id="_idIndexMarker1685"/> always assume that female users demonstrate a greater likelihood of purchasing than their male counterparts. However, this may not be the same for all males and females for all age groups. Even age plays an important factor in yielding different distributions, where the mean age for a female is considerably higher than that for a male. To eliminate the use of unbiased data in our ML models, we need to apply the principle of equalized odds (as studied in <a href="B18681_05.xhtml#_idTextAnchor110"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Fair Data Collection</em>), <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Both male and female users, irrespective of their gender, should have the same probability of being considered eligible for <span class="No-Break">a coupon.</span></li>
				<li>Both male and female users, irrespective of their gender, should have the same probability of not being considered eligible for <span class="No-Break">a coupon.</span></li>
			</ul>
			<p>This would eliminate the bias that results in privileged users getting digital coupons, even after recording a lower rate of mouse clicks. If we implement the principle of equalized odds, then we can restrict gender biases present in real-world clickstream data, and thus prevent giving an advantage to certain groups via access to <span class="No-Break">more coupons.</span></p>
			<p>Another well-known discriminatory recommendation observed in the world of e-commerce is when AI has been used to personalize website interactions, and where such AI-based systems show remarkably fewer advertisements for new products or products sold by new entrants and small-scale players in <span class="No-Break">the market.</span></p>
			<p>Let’s understand the reasons<a id="_idIndexMarker1686"/> for discriminatory <span class="No-Break">recommendations here:</span></p>
			<ul>
				<li>The first reason for a discriminatory model outcome attributed to algorithmic behavior is where the algorithm learns a discriminatory action from actual customer behavior (for example, as more and more people are recommended products of big market players, they are more likely to click <span class="No-Break">those ads).</span></li>
				<li>The second possible reason is that the algorithm learned the behavior from other data sources (for example, other forms of gender discrimination, such as products and ads sponsored by market leaders based on demographic details of <span class="No-Break">the country).</span></li>
				<li>The third possibility concludes that it is not a result of learned bias but is rather propelled by the economics of the given region. Examples include ad delivery techniques driving<a id="_idIndexMarker1687"/> the observed differences (for example, a higher price premium for high-cost <span class="No-Break">ad keywords).</span></li>
			</ul>
			<p>To curb such discriminatory outcomes, eliminate bias, and ensure fairness in AI solutions, as studied in <a href="B18681_05.xhtml#_idTextAnchor110"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Fairness in Data Collection</em>, techniques such as the omission of sensitive attributes may not be sufficient alone. This is because other attributes may act as proxies and would result in inherent bias in the predicted outcomes. One such example can be seen in e-commerce, where AI considers a user’s browsing history to predict the most successful advertising content to show. One major drawback of this approach is that information on browsing history is often used as a proxy for gender (for example, <strong class="source-inline">github.com</strong> as a proxy for men and <strong class="source-inline">pinterest.com</strong> as a proxy for women). Further, in <a href="B18681_08.xhtml#_idTextAnchor176"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Fairness in Model Training and Optimization</em>, we learned about the importance of constraints in algorithmic optimizers that can <span class="No-Break">control bias.</span></p>
			<p>In the world of retail, prices change<a id="_idIndexMarker1688"/> often and govern sales and revenue, so<a id="_idIndexMarker1689"/> it is important to justify the causes of price change. So, let’s consider the importance of ethics in pricing items in <span class="No-Break">retail stores.</span></p>
			<h3>Ethical price selection</h3>
			<p>To promote<a id="_idIndexMarker1690"/> social good, ethical price selection<a id="_idIndexMarker1691"/> is an important factor when e-commerce apps and platforms employ smart dynamic pricing engines. The design methodology of dynamic pricing engines should address the root cause of price changes to reduce potential harm to customers, the organization, and the wider society. If a business avoids resolving the negative impacts of dynamic pricing, it may result in media coverage, lawsuits, and legislative investigations. Legal and regulatory changes can hurt a brand’s image and reputation and raise customer distrust in <span class="No-Break">the company.</span></p>
			<p>Some of the notable factors in ethical price selection (referenced from <a href="https://hbr.org/2021/03/how-ai-can-help-companies-set-prices-more-ethically">https://hbr.org/2021/03/how-ai-can-help-companies-set-prices-more-ethically</a>) are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The level of hindrance caused by changes in prices of essential services and products – at worst, blocking<a id="_idIndexMarker1692"/> access to essential services such as food, shelter, medicine, transportation, and the internet. We observed<a id="_idIndexMarker1693"/> this during the pandemic when high prices reduced access to personal protective equipment such as N95 masks and hand sanitizer, and people who lost access to them became exposed to the virus. </li>
				<li>In the retail world, before the pandemic, small third-party sellers alleged that big retail players such as Amazon had leveraged their data to compete with these small-scale sellers by buying the same products in large quantities from suppliers at lower costs and selling them at lower prices. High price increases proposed by the AI-powered algorithms of pharma companies have historically blocked access to drugs for chronically ill patients, jeopardizing <span class="No-Break">their lives.</span></li>
				<li>The degree to which price changes affect vulnerable sectors of the population. For example, when products or services are sold to customers demonstrating chronic/serious medical conditions or on limited incomes, the vulnerability caused by social discrimination becomes more prominent. In addition, in the realm of insurance, guidelines on prospective interest rates that take into account policyholders’ profession, age, and so on have culminated in widespread societal harm, where underprivileged policyholders end up paying higher insurance rates than those in <span class="No-Break">elite professions.</span></li>
				<li>The ways that pricing engines alter prices cause them to take advantage of customers. This issue often leads us to design interpretable models that provide better-informed decisions on buying. This would also help us to state that customers benefitting from pricing engines are empowered to make better-informed decisions. If price changes always put the business first by taking advantage of customers (such as ride-hailing apps using exponential fare increases in times of need), then such a model needs auditing and approval from <span class="No-Break">regulatory bodies.</span></li>
			</ul>
			<p>Therefore, we can see the negative consequences of dynamic pricing engines in e-commerce, retail, and insurance. As dynamic pricing algorithm experts, we should double-check that the issue gets the required attention from businesses and makes the pricing decisions fair for all <span class="No-Break">customer segments.</span></p>
			<p>Now that we understand<a id="_idIndexMarker1694"/> the concept of fairness in retail, let’s dig into how the concept of interpretability fits into the <span class="No-Break">retail industry.</span></p>
			<h2 id="_idParaDest-271"><a id="_idTextAnchor301"/>Interpretability – the role of counterfactuals (CFs)</h2>
			<p>Understanding customer pain<a id="_idIndexMarker1695"/> points and preferences<a id="_idIndexMarker1696"/> is a key prerequisite for campaigns<a id="_idIndexMarker1697"/> and promotions on e-commerce platforms. Once customer needs have been identified, retailers can provide promotional offers and discounts and bring back churned customers. For example, for retailers such as Tesco, Carrefour, or Walmart, it is important to be able to identify regular as well as big-fish customers per store, the latter of which contribute significantly toward the overall monthly purchases of that store. Once retailers have understood the primary customer genomes and their preferences, they can not only make real-time recommendations but also drive business decisions through short-term and long-term programs <span class="No-Break">and campaigns.</span></p>
			<p>Customer dissatisfaction can be driven by causal inferencing, which translates intangible variables such as customer satisfaction or customer reward points into key business metrics. One such example of a promotional offer provided to Uber drivers is Uber Pro, which ran as a pilot in eight US cities, to reward the contribution of the most dedicated driver partners. The drivers were rewarded with things such as higher earnings, reduced car maintenance charges, access to faster airport pickups, and free <span class="No-Break">dent repair.</span></p>
			<p>Often, e-commerce platforms make the mistake of giving greater importance to social media advertising as it might lead to, say, increased sales of garments during winter, and when the advertising budget was cut short in other time of the year, the sales were reduced. However, they fail to notice that the months of winter coincide with Christmas, Thanksgiving, New Year, and other festivals where people generally exchange gifts. Hence, social media marketers on e-commerce platforms need to consider the CFs by studying the impact on sales had there been no marketing campaign. This means directly determining the increase in revenue attributable to marketing, as opposed to low prices of items or ongoing festivals that drive people’s purchases. We can carry out a detailed experiment via A/B testing and splitting our customers into two different groups: the control group and the target group. With the control group, we do not perform the marketing activity, while we do with the target group. Then, we compare the uplift in revenue between the target and control groups. Determining the impact of CFs with higher confidence provides insights into the effectiveness of different interventions by measuring the difference between those who are targeted and those who are not. It also helps us evaluate the impact of marketing campaigns, new product launches, promotions, and offers<a id="_idIndexMarker1698"/> launched in certain regions<a id="_idIndexMarker1699"/> and targeted at selected consumer<a id="_idIndexMarker1700"/> segments. We’ll understand the marketing campaigns for CFs in <span class="No-Break">detail next.</span></p>
			<h3>Evaluating impacts in marketing campaigns with CFs</h3>
			<p>With causal inferencing, we can answer<a id="_idIndexMarker1701"/> causal questions that, in certain<a id="_idIndexMarker1702"/> cases, cannot be answered through A/B testing alone. We often encounter another difficulty when we have a randomized, controlled A/B test but the treatment (actions taken by individuals) is different for different individuals in the group. Say, for example, someone in the group does not open the email or fails to apply the reward points. We will see an example of how causal inferencing can help resolve <span class="No-Break">this shortly.</span></p>
			<p>First, let’s study how causal inferencing helps us determine the impact of marketing campaigns or promotions on sales by providing us insights into <span class="No-Break">the following:</span></p>
			<ul>
				<li>How price changes impact a selected campaign metric (positively <span class="No-Break">or negatively)</span></li>
				<li>How a promotional campaign between selected dates <span class="No-Break">impacts sales</span></li>
			</ul>
			<p>In the following example, we will demonstrate how a retailer can examine the effect of new product recommendations on their websites to conclude whether the impact is positive or negative. We can take any fixed/specific date, such as Christmas. The observed traffic change before and after the specified date will allow us to determine any improvement or degradation achieved through the recommendation framework. The growth or decline of sales can be evaluated using causal impact modeling, showing the effect of an action before and after a specified date. We will demonstrate this in this example. By doing this, it becomes easier to determine and explain whether there’s an increase in the number of organic searches because of the newly designed recommendation framework. In addition, we can also predict<a id="_idIndexMarker1703"/> what could be expected<a id="_idIndexMarker1704"/> in the absence of <span class="No-Break">any campaign:</span></p>
			<ol>
				<li>First, let’s do the necessary imports and load <span class="No-Break">the dataset:</span><pre class="console">
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_probability as tfp
import matplotlib.pyplot as plt
from causalimpact import CausalImpact
df = pd.read_csv('https://raw.githubusercontent.com/flyandlure/datasets/master/causal_impact_dataset.csv')</pre></li>
				<li>Now, let’s set the pre- and post-periods for <span class="No-Break">our study:</span><pre class="console">
pre_period = ['2021-07-04', '2021-07-17']
post_period = ['2021-07-18', '2021-07-31']</pre></li>
			</ol>
			<p>Next, we want to examine the number of clicks on the retailer’s website during the <strong class="source-inline">pre_period</strong> and <strong class="source-inline">post_period</strong> date ranges present in the preceding list:</p>
			<pre class="console">
model = CausalImpact(df['clicks'], pre_period, post_period)</pre>
			<ol>
				<li value="3">Finally, we must analyze the model output by studying the impact <span class="No-Break">of interventions:</span><pre class="console">
print(model.summary(output='report'))</pre></li>
			</ol>
			<p>Here is the output for it:</p>
			<div>
				<div id="_idContainer269" class="IMG---Figure">
					<img src="image/Figure_14.1_B18681.jpg" alt="Figure 14.1 – Output obtained from model.summary()"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – Output obtained from model.summary()</p>
			<p>The model summary yields<a id="_idIndexMarker1705"/> a predicted average of 243 clicks in the post-intervention period<a id="_idIndexMarker1706"/> among those who did not have any intervention. Through intervention, we determine an association between two variables, <em class="italic">X</em> and <em class="italic">Y</em>, such that one variable, <em class="italic">X</em>, is a direct cause of another variable, <em class="italic">Y</em>, when all other variables are held fixed at some value.</p>
			<p>However, the actual number of clicks observed was 344. So, the <em class="italic">difference</em> between the prediction and the actual number is 101 clicks. These 101 click impressions demonstrate the causal effect of the intervention on the model. The introduction of the product recommendation framework on the e-commerce site, along with other changes, if any, has therefore contributed positively by increasing site traffic by 42%.</p>
			<ol>
				<li value="4">We can also plot the data using <strong class="source-inline">model.plot()</strong> to study the difference between the predictions and the <span class="No-Break">actual data:</span></li>
			</ol>
			<div>
				<div id="_idContainer270" class="IMG---Figure">
					<img src="image/Figure_14.2_B18681.jpg" alt="Figure 14.2 – Causal effect obtained through predicted versus the actual number of clicks in the post-intervention period"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Causal effect obtained through predicted versus the actual number of clicks in the post-intervention period</p>
			<p>This is how we study the causal<a id="_idIndexMarker1707"/> effect before and after the <span class="No-Break">post-intervention</span><span class="No-Break"><a id="_idIndexMarker1708"/></span><span class="No-Break"> period.</span></p>
			<p>We will now study different scenarios that can drive customer conversion through necessary and <span class="No-Break">sufficient causation.</span></p>
			<h3>Understanding conversion rates – necessary and sufficient causation</h3>
			<p>Let’s illustrate the causal effect of a voucher<a id="_idIndexMarker1709"/> on customer conversion rates by studying three different types <span class="No-Break">of causation:</span></p>
			<ul>
				<li><strong class="bold">Necessary</strong>: A mandatory condition without which the customer<a id="_idIndexMarker1710"/> does not convert, that is, in the absence of <span class="No-Break">a voucher.</span></li>
				<li><strong class="bold">Sufficient</strong>: An existing condition, where<a id="_idIndexMarker1711"/> the voucher helps to convert <span class="No-Break">a customer.</span></li>
				<li><strong class="bold">Necessary and sufficient</strong>: The voucher plays a primary role<a id="_idIndexMarker1712"/> in customer conversion as the customer will not convert in any case without <span class="No-Break">a voucher.</span></li>
			</ul>
			<p>If we need to study these three types of interventions, we can assimilate experimental and observational data to determine the bounds of the probability of each of the preceding types of causation occurring. Once the bounds are available, we can safely infer the most effective way to use voucher-based promotions without wasting money. The following code illustrates the step-by-step method to <span class="No-Break">achieve this:</span></p>
			<ol>
				<li>First, let’s do the necessary <span class="No-Break">library imports:</span><pre class="console">
import numpy as np
import pandas as pd
from causalml.optimize import get_pns_bounds</pre></li>
			</ol>
			<p>Here, we try to observe the outcomes for individuals who choose the promotion (say, people who get a drug or receive a voucher) versus those who don’t. Based on Tian and Pearl’s hypothesis (<a href="https://ftp.cs.ucla.edu/pub/stat_ser/R290-A.pdf">https://ftp.cs.ucla.edu/pub/stat_ser/R290-A.pdf</a>) on identifying conditions for causal effects, the two datasets shown here can be combined to obtain information that is not visible by looking at either of the datasets independently. This will help us identify<a id="_idIndexMarker1713"/> the probabilities or the boundaries of <strong class="bold">necessary and sufficient causation</strong>, by combining two data sources, where we have the deaths and survivals in treatment and control groups.</p>
			<p>The dataset used for the experiment is shown here:</p>
			<table id="table001-8" class="T---Table _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="T---Table">
						<td class="T---Table T---Header">
							<p class="T-regular"><span class="No-Break"><strong class="bold">Dataset name</strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p class="T-regular"><span class="No-Break"><strong class="bold">Group</strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p class="T-regular"><span class="No-Break"><strong class="bold">Treatment</strong></span></p>
						</td>
						<td class="T---Table T---Header">
							<p class="T-regular"><span class="No-Break"><strong class="bold">Control</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Dataset 1</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Non-conversions</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">16</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">14</span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Dataset 2</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Conversions</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">894</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">986</span></p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Dataset 3</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Non-conversions</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">28</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular">2</p>
						</td>
					</tr>
					<tr class="T---Table">
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Dataset 4</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">Conversions</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">998</span></p>
						</td>
						<td class="T---Table T---Body">
							<p class="T-regular"><span class="No-Break">972</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Figure"><span lang="en-US" xml:lang="en-US">Table 14.1 – Experimental simulated datasets</span></p>
			<p>Here is the code:</p>
			<pre class="console">
num_samples = 5000
half = int(num_samples / 2)
treatment = np.tile([0, 1], half)
recovery = np.zeros(num_samples)
df_expt = pd.DataFrame({'treatment': treatment, 'death': recovery})
df_obsv = pd.DataFrame({'treatment': treatment, 'death': recovery})</pre>
			<ol>
				<li value="2">Now, for experimental purposes<a id="_idIndexMarker1714"/> and to analyze the impact, let’s set the label to 1 for 16 treatments and 14 control observations in the experimental dataset, and set the label to 1 for 2 treatments and 28 control observations in the <span class="No-Break">observational dataset:</span><pre class="console">
df_expt.loc[df_expt.loc[df_expt['treatment'] == 1].sample(n=16).index, 'death'] = 1
df_expt.loc[df_expt.loc[df_expt['treatment'] == 0].sample(n=14).index, 'death'] = 1
df_obsv.loc[df_obsv.loc[df_obsv['treatment'] == 1].sample(n=2).index, 'death'] = 1
df_obsv.loc[df_obsv.loc[df_obsv['treatment'] == 0].sample(n=2).index, 'death'] = 1 df_obsv.loc[df_obs.loc[df_obsv['treatment'] == 0].sample(n=28).index, 'death'] = 1</pre></li>
				<li>Next, we will use the <strong class="source-inline">get_pns_bounds()</strong> function to evaluate the relevant probability bounds, which are mainly of <span class="No-Break">three types:</span><pre class="console">
pns_lb, pns_ub = get_pns_bounds(df_expt, df_obsv, 'treatment', 'death', type='PNS')
pn_lb, pn_ub = get_pns_bounds(df_expt, df_obsv, 'treatment','death', type='PN')
ps_lb, ps_ub = get_pns_bounds(df_expt, df_obsv, 'treatment', 'death', type='PS')</pre></li>
				<li>This yields the following <span class="No-Break">probability bounds:</span></li>
			</ol>
			<div>
				<div id="_idContainer271" class="IMG---Figure">
					<img src="image/Figure_14.4_B18681.jpg" alt=" Figure 14.﻿3 – Probability bounds for necessary and sufficient causation"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"> Figure 14.3 – Probability bounds for necessary and sufficient causation</p>
			<p>This demonstrates that participants<a id="_idIndexMarker1715"/> who did not convert and were given the voucher had a higher chance of converting compared to those who did not receive the voucher. Those who got converted and were not provided the voucher would have had a risk of between 0.1% and 1.2% of not converting if they had been given the voucher. Further, we can see that the probability scores range between 0.1% and 0.6% for individuals of being converted, as well as getting <span class="No-Break">the voucher.</span></p>
			<p>Now, let’s understand different types of causal inferencing techniques and how they can be applied to <span class="No-Break">various contexts.</span></p>
			<h3>Different modes of causal inferencing techniques</h3>
			<p>The following figure<a id="_idIndexMarker1716"/> depicts different ways by which we can carry on causal analysis in a non-mutually exclusive manner, wherein we can apply multiple methods to the <span class="No-Break">same problem:</span></p>
			<div>
				<div id="_idContainer272" class="IMG---Figure">
					<img src="image/Figure_14.5_B18681.jpg" alt="Figure 14.﻿4 – Different causal inferencing methods"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Different causal inferencing methods</p>
			<p>The methods described in the preceding figure can be used to eliminate selection bias. Examples of selection bias occur in a rewards campaign when we try to estimate an <span class="No-Break">email’s impact:</span></p>
			<ul>
				<li>Not everyone in the treatment group who got the reward <span class="No-Break">opened it.</span></li>
				<li>People who opened the reward in the treatment group are compared with those in the control group that didn’t get <span class="No-Break">a reward.</span></li>
				<li>People who chose to open the email or apply the reward may be different from those who didn’t choose to open the email or apply <span class="No-Break">the reward.</span></li>
			</ul>
			<p>To avoid selection bias, we could compare the entire treatment (or test) group, irrespective of whether they opened the email or used the rewards program. But this does not prevent the dilution effect where individuals in treatment groups (more suitable in the context<a id="_idIndexMarker1717"/> of multiple treatment groups) are treated differently. To address and evaluate the impact of actually receiving the treatment, we can use the <strong class="bold">Compiler Average Causal Effect</strong> (<strong class="bold">CACE</strong>), where CACE adjusts the <strong class="bold">Intention-to-Treat</strong> (<strong class="bold">ITT</strong>) effect (that is, the effect of being assigned<a id="_idIndexMarker1718"/> treatment, which means being subjected to the test conditions under consideration) with the compliance rate. This is because the ITT parameter underestimates the efficacy of an intervention. After all, certain individuals may deviate from their assigned treatment <span class="No-Break">in trials.</span></p>
			<p>This adjustment helps to estimate the treatment effect for the subpopulation that is being treated or being considered for the experimentation. Treatment here refers to the experimental group that experiences the test conditions. The CACE framework relies on the assumption that customers open the email and use the rewards program, and the effect of receiving the actual treatment (customer group receiving the reward program) drives<a id="_idIndexMarker1719"/> the outcome variable. To summarize, CACE operates through <strong class="bold">Instrumental V</strong><strong class="bold">ariables</strong> (<strong class="bold">IVs</strong>), which determine the causal relationships when controlled experiments are not feasible. </p>
			<p>This occurs in randomized experiments, where treatment (in this context, the rewards program) cannot be carried out and, as a result, the impact of such treatment cannot be delivered to every unit. Here, the CACE framework and its IVs can be used. An IV is a kind of third variable that helps us study<a id="_idIndexMarker1720"/> the effect of a candidate’s cause on <span class="No-Break">an outcome.</span></p>
			<h4>When the treatment effect varies across segments</h4>
			<p>Retail giants<a id="_idIndexMarker1721"/> and transportation-as-a-service firms (as in the case of Uber) have very varied customer bases<a id="_idIndexMarker1722"/> to the point that a treatment practiced on one segment of customers does not work on other segments. The <strong class="bold">Heterogeneous Treatment Estimation</strong> (<strong class="bold">HTE</strong>) method of causal inference is recommended to identify customized experiences that can be optimally applied for the benefit of everyone. In this method, the <strong class="bold">Conditional Average Treatment Effect</strong> (<strong class="bold">CATE</strong>) is deployed successfully to compute the treatment<a id="_idIndexMarker1723"/> effect and operates conditionally on observed covariates. The main objective of this method is to evaluate which subgroup of a given population will benefit the most when subjected to treatment. The evaluation is carried out with the help of A/B testing, where experimental data is used to train the model. The metric represents an upliftment success and is evaluated by computing the largest delta (or difference) between the target (to whom the treatment is applied) and the control group. Uber applies HTE by using its uplift modeling. Quantile regression (which estimates the conditional median of the response variable) is <span class="No-Break">also popular.</span></p>
			<p><strong class="bold">Mediation modeling</strong> is another well-known method of causal inferencing<a id="_idIndexMarker1724"/> that is designed to unveil the black box between a treatment and an outcome variable. In other words, it explains why something happened to allow us to conclude whether the findings support a <em class="italic">causal</em> hypothesis. This mechanism operates by decomposing the total treatment effect into the following <span class="No-Break">two parts:</span></p>
			<ul>
				<li>The hypothesis of a particular mechanism representing the average causal <span class="No-Break">mediation effect</span></li>
				<li>Other mechanisms present that demonstrate the average <span class="No-Break">direct effect</span></li>
			</ul>
			<p>Further, this method brings out the relative importance of multiple underlying mechanisms, where intangible variables have an impact on elements of the business, including revenue and customer satisfaction, and helps formulate both long-term and short-term steps to address customer pain points. For example, when we observe that customers experience the late home delivery of orders by retailers, we often assume that this is due to increased customer engagement, where a customer is frequently changing the ordered items. However, the delay can also be attributed to the presence of a large number of orders, which invariably drive the group toward <span class="No-Break">higher engagement:</span></p>
			<div>
				<div id="_idContainer273" class="IMG---Figure">
					<img src="image/Figure_14.6_B18681.jpg" alt="Figure 14.﻿5 – A causal graph with data generation capabilities to demonstrate the influence of an instrument/factor on the candidate’s causal variable"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – A causal graph with data generation capabilities to demonstrate the influence of an instrument/factor on the candidate’s causal variable</p>
			<p>In the preceding figure, we can see a confounding relationship between a factor and the outcome. A user’s number of Amazon Fresh orders represents the existence of a back-door path (a kind of dependency) between the treatment variable and the outcome of interest. Causal inferencing supports observational analysis, where we attempt to block back-door paths. This can be done by limiting the number of orders to, say, three or four. Determining which variables should and should not be controlled involves collaboration between domain experts and data scientists. Additionally, a biased estimation resulting from the back-door path between delayed deliveries and customer engagement can be tackled if we can identify a third variable that impacts the outcome of delayed delivery on <span class="No-Break">customer experience.</span></p>
			<p>Another known approach is the <strong class="bold">front-door approach</strong>, where we try to estimate the effect of a variable by evaluating<a id="_idIndexMarker1725"/> the relationship between that variable and the outcome of interest. This approach relies on the mediation principle, which requires the introduction of an intervening variable (mostly used in clinical research) other than the treatment (that is, the outcome) and is popularly known as <strong class="bold">Causal Mediation Analysis</strong> (<strong class="bold">CMA</strong>). It plays an important role in dissecting<a id="_idIndexMarker1726"/> the total effect a treatment has into direct and <span class="No-Break">indirect effects.</span></p>
			<p>The first step in causal modeling<a id="_idIndexMarker1727"/> is to identify variables that should be included. We apply the causal modeling technique to the identified variables to compare the treated and non-treated individuals possessing the same values for the relevant covariates side by side. The comparison metric relies on the representation of the variables through a predicted probability score. This probability helps us measure the effectiveness of the treatment procedure and is called the <span class="No-Break">propensity score.</span></p>
			<p>The other popular causal inference technique is called the <strong class="bold">regression discontinuity</strong> method. This method helps us study and evaluate<a id="_idIndexMarker1728"/> the discontinuities present in the regression lines. The absence of continuity at the point where the intervention takes place demonstrates the impact due to an intervention. This has been highly useful in determining how different levels of <strong class="bold">dynamic pricing</strong> influence customers’ decisions to buy an item from a retail store or book a trip on the Uber platform. </p>
			<p>Taking Uber as an example, as we study the causal effect, we must be aware that, in its absence, trip request rates should be the same on both sides of a sharp cut-off point, such as the introduction of surge pricing. This holds good under the assumption that riders who are very close to the cut-off point resemble each other with respect to relevant confounding variables (a third variable that influences both the independent and dependent variables). Further, observing any noticeable discontinuity in trip request rates at the point of introduction of surge pricing is an indication that raising prices beyond this point has a causal impact on <span class="No-Break">request rates.</span></p>
			<p>Another similar approach is to analyze the outcome<a id="_idIndexMarker1729"/> of time series data before and after a candidate causal event. This method, known as <strong class="bold">interrupted time series design</strong>, aims to predict any change in the time series at the instant the event occurred. The most popular methods used for time series analysis for causal inferencing are synthetic control and Bayesian<a id="_idIndexMarker1730"/> structural time series. One of the popular libraries for Bayesian structural time series analysis is provided by Google in the form of the Causal <span class="No-Break">Impact package.</span></p>
			<p>Now, let’s examine how causal modeling plays a role in solving problems related to the <span class="No-Break">supply chain.</span></p>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor302"/>Supply chain use cases</h1>
			<p>Another important<a id="_idIndexMarker1731"/> aspect of retail where fairness plays a vital role is in the supply chain. In scenarios where retailers see both shortages and surpluses of stock, it is imperative that, as data science and ML experts, we oversee stock optimization policies. In doing so, we are likely to evaluate fairness allocation based on realized demands and currently available stock capacity. Some of the factors that have a direct impact on fair stock fulfillment (without stock underflow and overflow, by appropriately matching supply and demand) for multiple retailers are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Fair inventory allocation by retailers (for example, equal profit, same fill rate, or an equal share of supply while handling demand mismatch). This is governed by a proportional allocation policy (best in times of inventory underflow) or stock scarcity and an equal split of excess inventory (used in times of <span class="No-Break">stock overflow).</span></li>
				<li>How we can satisfy fairness perceptions in the industry, including elements such as fair pricing and <span class="No-Break">fair wages.</span></li>
			</ul>
			<p>To elaborate further on fairness in the context of integrated supply chain networks that serve multiple retailers, let’s consider a common pool of inventory where the total inventory is allocated at the retailer level, and the total cost is distributed among multiple retailer locations. Stock replenishment and fulfillment orders come to the warehouse, where fairness constraints<a id="_idIndexMarker1732"/> are incorporated in the <span class="No-Break">following</span><span class="No-Break"><a id="_idIndexMarker1733"/></span><span class="No-Break"> scenarios:</span></p>
			<ul>
				<li>The total demand from the combined set of retailers exceeds the <span class="No-Break">available supply.</span></li>
				<li>The total supply from multiple suppliers exceeds <span class="No-Break">the demand.</span></li>
				<li>Multiple retailers receive stock from the <span class="No-Break">same suppliers.</span></li>
				<li>A fair inventory split between multiple retailers (subject to other conditions such as the number of items ordered by each retailer) based on market demand to ensure fair <span class="No-Break">profit distribution.</span></li>
			</ul>
			<p>Apart from introducing fairness in stock optimization, from the standpoint of ethics, both accuracy and interpretability become important. This is because optimized stock allocation at different levels of the supply chain cycle can minimize as well as predict shipping delays from the supplier. In addition, we can attribute causes for the delay and suggest <span class="No-Break">remedial actions.</span></p>
			<p>While studying model explainability and interpretability in <a href="B18681_10.xhtml#_idTextAnchor218"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, we saw that understanding the root cause behind a model’s prediction can help a business take remedial actions. Million-dollar losses from delays in a complex supply chain pipeline can be avoided once the stage and source of vulnerabilities have been identified. For example, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.6</em>, a delay in supply chain pipelines occurred during the pandemic, which can be attributed to a variety <span class="No-Break">of causes:</span></p>
			<div>
				<div id="_idContainer274" class="IMG---Figure">
					<img src="image/Figure_14.7_B18681.jpg" alt="Figure 14.﻿6 – Causal relationships demonstrating direct and spurious correlations"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 – Causal relationships demonstrating direct and spurious correlations</p>
			<p>The primary delay factors were lockdowns and a reduced number of suppliers in operation. However, these primary delay factors can lead to other delay factors caused by factory shutdowns, staff absenteeism, or the need for travel passes to <span class="No-Break">transport goods.</span></p>
			<p>To explain the cause and effect, what we need is an evaluation procedure that not only helps in determining correlation but also aids in the causal discovery process through graphs, as we’ve demonstrated here. Once we have a graphical representation of the causal structure, it becomes<a id="_idIndexMarker1734"/> easier to suggest remedial actions or allocate resources at each step of <span class="No-Break">the problem.</span></p>
			<p>In the next section, we’ll learn how causal structures can help us with supply <span class="No-Break">chain delivery.</span></p>
			<p>Causal discovery for supply <span class="No-Break">chain management</span></p>
			<p>Causal graphs can capture<a id="_idIndexMarker1735"/> the causal relationships between the different<a id="_idIndexMarker1736"/> variables in a given problem, highlighting the key players in the system, the role they play in the system, and in what direction. The key system players in a typical supply chain are <span class="No-Break">the following:</span></p>
			<ul>
				<li>Number of orders and the quantity of <span class="No-Break">each order</span></li>
				<li>Supply of raw materials at manufacturing plants and the availability <span class="No-Break">of suppliers</span></li>
				<li>The operational mode of the factory and the number of <span class="No-Break">workers present</span></li>
				<li>Successful <strong class="bold">Purchase Order</strong> (<span class="No-Break"><strong class="bold">PO</strong></span><span class="No-Break">) creation</span></li>
				<li>An efficient delivery system that confirms <span class="No-Break">delivery data</span></li>
			</ul>
			<p>These principal elements<a id="_idIndexMarker1737"/> act together in a causal graph, describe<a id="_idIndexMarker1738"/> their inter-relationships, and state how demand for an item is reaching the destination at an earlier/delayed schedule, along with the impact of the delay on other upstream delivery channels. Hence, any delay and uncertainty of a delivery pipeline can be better explained, which can further speed up the graph discovery process. The relative influence of different variables on an overall delay at two different stages of a supply chain pipeline (PO creation and the order delivery service) is best explained by the <span class="No-Break">following figure:</span></p>
			<div>
				<div id="_idContainer275" class="IMG---Figure">
					<img src="image/Figure_14.8_B18681.jpg" alt="Figure 14.﻿7 – Causal graphs to explain delivery delays at different stages of the supply chain life cycle"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7 – Causal graphs to explain delivery delays at different stages of the supply chain life cycle</p>
			<p>We can go<a id="_idIndexMarker1739"/> one step further<a id="_idIndexMarker1740"/> and extract a <strong class="bold">Structural Causal Model</strong> (<strong class="bold">SCM</strong>) from the causal graph<a id="_idIndexMarker1741"/> to explain the interactions of variables, as demonstrated in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer276" class="IMG---Figure">
					<img src="image/Figure_14.9_B18681.jpg" alt="Figure 14.﻿8 – Causal graphs to explain ﻿CF recourse for certain orders at different stages of the supply chain life cycle"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8 – Causal graphs to explain CF recourse for certain orders at different stages of the supply chain life cycle</p>
			<p>On the left of the figure, we see that by increasing the number of suppliers by 15% and following an optimal stock fulfillment policy, we can mitigate PO creation delays. On the right-hand side, we see that by using CF explanations, we can discover the best delivery partners and routes, along with alternate sources of transport (for example, using air travel to avoid a delay at a seaport) within the causal graph. Such discoveries are made possible when we have real-time monitoring in the system to trigger CF recourse actions to drive through the best possible routes to reach the destination as quickly <span class="No-Break">as possible.</span></p>
			<p>As well as reducing<a id="_idIndexMarker1742"/> cost and providing revenue uplift<a id="_idIndexMarker1743"/> to businesses, these CF<a id="_idIndexMarker1744"/> recourses, made possible with the help of causal graphs, also allow us to understand the appropriate <strong class="bold">Key Performance Indicators</strong> (<strong class="bold">KPIs</strong>) to be used to reduce cost and <span class="No-Break">boost revenue.</span></p>
			<h3>Fairness in multi-stakeholder platforms</h3>
			<p>Large-scale multi-sided retail platforms<a id="_idIndexMarker1745"/> such as Amazon, Alibaba, and Airbnb provide personalized recommendations to buyers to connect them to relevant sellers. The recommendation services offered should be designed to promote fairness in terms of the number of items recommended by each seller. This will ensure that items from small-scale sellers also get a fair chance of being recommended to buyers. The principal objective of fair recommendations is to maximize recommendation utility (so that they lead to conversions in the real world) with minimal <span class="No-Break">logistical costs.</span></p>
			<p>A fair policy remains far from being achieved in circumstances where biases creep in and buyers receive low-utility recommendations to satisfy the coverage demands of global sellers. In a fair and ideal system, we can incorporate<a id="_idIndexMarker1746"/> constraints to satisfy sellers’ coverage criteria alongside buyers’ objectives, yielding high-utility recommendations for <span class="No-Break">each buyer.</span></p>
			<p>Now, let’s walk through how Responsible AI has an important role to play in the <strong class="bold">Banking, Financial Services, and Insurance </strong>(<span class="No-Break"><strong class="bold">BFSI</strong></span><span class="No-Break">) industries.</span></p>
			<h2 id="_idParaDest-273"><a id="_idTextAnchor303"/>Use cases in BFSI</h2>
			<p>One important element<a id="_idIndexMarker1747"/> of ethical AI is interpretability, as we discussed in <a href="B18681_09.xhtml#_idTextAnchor198"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>. Along with model explanations, if we can provide a sort of interaction (to tweak model hyperparameters and features) to model designers, decision-makers, and key stakeholders, then they can tune model hyperparameters and simulate different scenarios for numerical features, allowing them to evaluate and minimize financial loss from high-risk financial models. In the context of BFSI, this would provide a higher level of detail to explanations of high-risk decisions, thereby reducing the risk of critical decisions to life, such<a id="_idIndexMarker1748"/> as the denial of a mortgage or car loan. Here, CF explanations have a definite role to play where a consistent interpretable explanation could help to <em class="italic">interrogate</em> a model to find the required changes that can invert a <span class="No-Break">model’s decision.</span></p>
			<p>The following are some prominent use cases for CFs <span class="No-Break">in BFSI:</span></p>
			<ul>
				<li><strong class="bold">Trading</strong>: CFs are used to analyze the potential consequences<a id="_idIndexMarker1749"/> of different trades and the potential risks and rewards of different investment strategies. For example, an AI system might be used to analyze historical data and identify patterns that might indicate opportunities for profitable trades. CF analysis can then be used to understand what might have happened if different trades had been made, and to optimize trading strategies<a id="_idIndexMarker1750"/> based on <span class="No-Break">this analysis.</span></li>
				<li><strong class="bold">Portfolio optimization</strong>: Optimizing the composition of a financial portfolio by analyzing<a id="_idIndexMarker1751"/> the potential consequences of different asset allocations. For example, an AI uses historical data to identify patterns that might indicate the relative performance of different assets. CF analysis can then be used to understand what might have happened if different assets had been included in the portfolio, and to optimize the portfolio based on <span class="No-Break">this analysis.</span></li>
				<li><strong class="bold">Risk management</strong>: Understanding and mitigating risk<a id="_idIndexMarker1752"/> in financial systems that involve market risks, credit risks, or operational risks. CF analysis can then be used to understand what might have happened if different risk management strategies had been employed, and to optimize risk management based on <span class="No-Break">this analysis.</span></li>
			</ul>
			<p>Now, let’s see how CF explanation libraries can <span class="No-Break">be used.</span></p>
			<h3>The functionality of CF explanation libraries</h3>
			<p>Having explored a few use cases<a id="_idIndexMarker1753"/> of CFs in the BFSI sector, let’s see a working example of a CF explanation used in the context of granting<a id="_idIndexMarker1754"/> a loan application. Our example will use the <strong class="bold">Diverse Counterfactual Explanations</strong> (<span class="No-Break"><strong class="bold">DiCE</strong></span><span class="No-Break">) library.</span></p>
			<p>DiCE is a Python library that helps us convey the necessary explanations by presenting feature-perturbed versions of the same input feature that yield a different outcome. In the context of applications such as loan rejections from financial institutions, DiCE is equipped to demonstrate a diverse set of feature perturbations on one loan candidate using a given ML model. </p>
			<p>This can boost customers’ confidence by showing that rejection is not the be-all and end-all, giving them directions for how they could increase their chances of getting the loan. For example, if a DiCE CF were to state “<em class="italic">had the income been $10K more, then the customer would have received the loan</em>,” it would help decision-makers to evaluate the trustworthiness of the loan application and at the same time guide them with the necessary conditions (such as existing loans or income) that are driving the outcome, such as a loan denial CF explanations over multiple inputs, help them to evaluate fairness criteria, and <span class="No-Break">reduce errors.</span></p>
			<p>However, DiCE comes with two major challenges in generating CF explanations that are diverse<a id="_idIndexMarker1755"/> and feasible. Hence, an extension of DiCE was created, known as <strong class="bold">DiCE4EL</strong> (short for <strong class="bold">DiCE for Event Logs</strong> – see more at <a href="https://icpmconference.org/2021/wp-content/uploads/sites/5/2021/09/DiCE4EL_-Interpreting-Process-Predictions-using-a-Milestone-Aware-Counterfactual-Approach.pdf">https://icpmconference.org/2021/wp-content/uploads/sites/5/2021/09/DiCE4EL_-Interpreting-Process-Predictions-using-a-Milestone-Aware-Counterfactual-Approach.pdf</a>), which assists with CF explanations for process prediction by capturing and explaining logs (such as those regarding loan applications made to a financial institution) and events at the intermediate stages. DiCE was designed using a generic neural network architecture that predicts the next event by considering both static and dynamic features. We can use this to resolve scenarios where we have long traces of process execution logs that are less understandable. Furthermore, the difficulties encountered in optimizing the CF search with categorical variables are addressed by the introduction of a search for valid CFs in the training set and leveraging that information in the <span class="No-Break">loss function.</span></p>
			<p>Now, let’s see an example<a id="_idIndexMarker1756"/> of using DiCE to evaluate different feature perturbations of a customer’s application for a loan. The model-agnostic techniques used here apply a black-box classifier. The loss function optimization relies on sampling other points near a given point in terms of proximity (as well as sparsity, diversity, <span class="No-Break">and feasibility):</span></p>
			<ol>
				<li>First, we must import the necessary libraries for CF analysis and load the adult <span class="No-Break">income dataset:</span><pre class="console">
import dice_ml
from dice_ml.utils import helpers
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
dataset = helpers.load_adult_income_dataset()
d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')</pre></li>
				<li>After we’ve performed feature transformations with standard scaling and one-hot encoding, we must train the model <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">RandomForestClassifier</strong></span><span class="No-Break">:</span><pre class="console">
clf = Pipeline(steps=[('preprocessor', transformations),('classifier', RandomForestClassifier())])
model = clf.fit(x_train, y_train)</pre></li>
				<li>Next, we must provide<a id="_idIndexMarker1757"/> the trained ML model to DiCE’s model object to generate <span class="No-Break">diverse CFs:</span><pre class="console">
backend = 'sklearn'
m = dice_ml.Model(model=model, backend=backend)
exp_random = dice_ml.Dice(d, m, method="random")
dice_exp_random = exp_random.generate_counterfactuals(query_instances, total_CFs=2, desired_class="opposite", verbose=False)</pre></li>
			</ol>
			<p>This is the output:</p>
			<div>
				<div id="_idContainer277" class="IMG---Figure">
					<img src="image/Figure_14.10_B18681.jpg" alt="Figure ﻿14.9 – Generated CFs with random sampling"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.9 – Generated CFs with random sampling</p>
			<p>Using random sampling, we can generate less sparse CFs in contrast to DiCE’s current implementation. However, it is also true that increasing <strong class="source-inline">total_CFs</strong> increases the sparsity of CFs.</p>
			<ol>
				<li value="4">Now, we must select feature ranges to demonstrate how we can precisely control the range of continuous features as an input parameter (<strong class="source-inline">permitted_range</strong>) during the process of CF generation. We could use the <strong class="source-inline">features_to_vary</strong> parameter to set features such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">['age','workclass','education','occupation','hours_per_week']</strong></span><span class="No-Break">:</span><pre class="console">
dice_exp_random = exp_random.generate_counterfactuals(
query_instances, total_CFs=4, desired_class="opposite",permitted_range={'age': [22, 50], 'hours_per_week': [40, 60]})</pre></li>
			</ol>
			<p>This is how it appears:</p>
			<div>
				<div id="_idContainer278" class="IMG---Figure">
					<img src="image/Figure_14.11_B18681.jpg" alt="Figure 14.1﻿0 – Generated CFs with feature ranges (permitted_range)"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.10 – Generated CFs with feature ranges (permitted_range)</p>
			<p>To obtain a trade-off between proximity<a id="_idIndexMarker1758"/> and diversity goals, we try to generate only those CF explanations that are feasible for a user. Here, proximity and diversity help us to understand how close the data is to the original input in contrast to how data that has been significantly modified affects the CF explanations. We also try to set enough diversity for the model to select between multiple possible options. Here, with DiCE, we have set <strong class="source-inline">proximity_weight</strong> (the default is <strong class="source-inline">0.5</strong>) and <strong class="source-inline">diversity_weight</strong> (the default is <strong class="source-inline">1.0</strong>) to tweak the proximity and diversity, respectively. However, we can change them further as we study how the <span class="No-Break">CFs change:</span></p>
			<pre class="console">
query_instance = pd.DataFrame({'age': 25, 'workclass': 'Private', 'education': 'HS-grad', 'marital_status': 'Single','occupation': 'Service', 'race': 'White', 'gender': 'Female',
'hours_per_week': 45}, index=[0])
r_exp = dice_ml.Dice(d, m)
dice_exp = r_exp.generate_counterfactuals(query_instance, total_CFs=4, desired_class="opposite", proximity_weight=1.5, diversity_weight=1.0)
dice_exp.visualize_as_dataframe(show_only_changes=True)</pre>
			<p>This is how<a id="_idIndexMarker1759"/> <span class="No-Break">it appears:</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div id="_idContainer279" class="IMG---Figure">
					<img src="image/Figure_14.12_B18681.jpg" alt="Figure 14.1﻿1 – Generated CFs with proximity and diversity parameters"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.11 – Generated CFs with proximity and diversity parameters</p>
			<p>The preceding output<a id="_idIndexMarker1760"/> shows a diverse set of CFs that were generated from the original data, where the <strong class="bold">income</strong> value gets flipped, <strong class="bold">education</strong> changes from <strong class="bold">HS-grad</strong> to <strong class="bold">Prof-school</strong>, <strong class="bold">marital_status</strong> changes to <strong class="bold">Married</strong> from <strong class="bold">Single</strong>, and <strong class="bold">occupation</strong> changes from <strong class="bold">Service</strong> to either <strong class="bold">White-Collar</strong> or <strong class="bold">Professional</strong>. Such alternatives or diversity help a bank official explain to the individual applying for the loan what could have changed the model’s outcome. In other words, they explain what conditions would have approved the loan instead of it being denied. </p>
			<p>In this example, we learned about techniques to generate different types of CFs from the input query by inverting the target income column. We are now familiar with how models provide recommendations for decisions and how we can interact with them. With this foundation, let’s learn how ML models that have been misused can create threats for customers<a id="_idIndexMarker1761"/> in the BFSI industry. One such powerful threat that we’ll look at next <span class="No-Break">is deepfakes.</span></p>
			<h2 id="_idParaDest-274"><a id="_idTextAnchor304"/>Deepfakes</h2>
			<p>Whether in retail, banking, or finance, one application<a id="_idIndexMarker1762"/> of AI for which responsible<a id="_idIndexMarker1763"/> use is required is that of deepfakes. Deepfakes are realistic fake videos, audio recordings, or photos of humans generated using deep learning methods. The generated synthetic videos, audio, and photos of humans are obtained by training models on large volumes of data, where the modeled versions represent modified actions or utterances of words or sentences that the actual person had nothing to do with. As the original actions are modified, there is an unprecedented threat of deepfakes being used to impersonate individuals, resulting in fraudulent phone calls or video conferences. An example of this is using synthetic voice audio of a CEO to instruct staff to transfer assets or funds. Even higher levels of security breaches are possible, where synthetic impersonation of clients via audio or video conferencing could result in the transfer of sensitive information regarding a project <span class="No-Break">or organization.</span></p>
			<p>Now, let’s take a look at the potential threats to the banking and financial sector that result <span class="No-Break">from deepfakes:</span></p>
			<ul>
				<li>Creation of fraudulent accounts as part of money-laundering schemes. Here, the criminal might fake identities at scale to attack multiple accounts and bring down financial services globally, leading to losses of $3.4 billion <span class="No-Break">globally (</span><a href="https://www.finextra.com/blogposting/23223/why-deepfake-fraud-losses-should-scare-financial-institutions"><span class="No-Break">https://www.finextra.com/blogposting/23223/why-deepfake-fraud-losses-should-scare-financial-institutions</span></a><span class="No-Break">).</span></li>
				<li>Use of ghost fraud techniques, where criminals leverage the personal data of a deceased person to gain control of their online accounts and services, including credit cards, savings accounts, mortgages, and <span class="No-Break">car loans.</span></li>
				<li>Synthetic identity fraud, where criminals can assimilate fake, real, and stolen information to create false identities of individuals who do not exist in reality. Synthetic identity fraud is the fastest-growing type of <span class="No-Break">financial crime.</span></li>
			</ul>
			<p>However, despite these abuses of deepfake technology, we also see several advantages in the world of retail, e-commerce, and fashion. The Facebook Shops and Google Shopping platforms use deepfakes to reach out to small- and medium-sized retailers to promote their sales through e-commerce<a id="_idIndexMarker1764"/> platforms. For example, Cadbury used AI based ML models  to recreate a popular actor's face and voice, bearing very close resemblance to the actor's voice, uttering the local store or brand’s name. Retailers are exploring realistic digital models and the power of <strong class="bold">Generative Adversarial Networks</strong> (<strong class="bold">GANs</strong>) to create a better experience for customers. Deepfake models demonstrate outfits with different skin tones, heights, and weights, appealing to a wider range of customers. Small and medium-sized retailers are thus able to save costs and fully leverage the capabilities of immersive photorealistic platforms (such as Unreal Engine) to generate live models <span class="No-Break">and backgrounds.</span></p>
			<p>In the interests of security and privacy, organizations need to keep the following guidelines in mind to prevent the threats that arise <span class="No-Break">from deepfakes:</span></p>
			<ul>
				<li>Enterprise security teams should employ efficient cybersecurity strategies using cybersecurity and social media monitoring tools to monitor payments <span class="No-Break">and transfers.</span></li>
				<li>Organizations should educate employees on deepfake technologies. All staff in the organization should be knowledgeable of how to detect deepfakes, such as inconsistencies or the unnatural movements of the people <span class="No-Break">in them.</span></li>
				<li>Apply biometric and online face verification techniques to verify and authenticate existing and <span class="No-Break">new users.</span></li>
			</ul>
			<p>Now that you<a id="_idIndexMarker1765"/> understand<a id="_idIndexMarker1766"/> the role of AI in BFSI, let’s look at different use cases in the <span class="No-Break">healthcare industry.</span></p>
			<h1 id="_idParaDest-275"><a id="_idTextAnchor305"/>Use cases in healthcare</h1>
			<p>As we delve into the ethical use of AI in the healthcare<a id="_idIndexMarker1767"/> industry, we should know how the early detection and treatment of diseases relate to ethical AI. Here are a <span class="No-Break">few examples:</span></p>
			<ul>
				<li>AI can support diagnosis using X-rays, CT scans, and MRI <span class="No-Break">imaging techniques.</span></li>
				<li>Detecting cancers, tumors, and other malignant cells in the early stages <span class="No-Break">of development.</span></li>
				<li>Experimenting with and determining whether a treatment <span class="No-Break">is working.</span></li>
				<li>Monitoring patients to identify the reoccurrence or remission of <span class="No-Break">a disease.</span></li>
			</ul>
			<p>The following figure illustrates how AI-based deep learning algorithms can help identify the presence of an IDH1 gene mutation in a brain tumor after being trained on images that radiologists and doctors have labeled as suspected <span class="No-Break">cancer (</span><a href="https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging"><span class="No-Break">https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging</span></a><span class="No-Break">):</span></p>
			<div>
				<div id="_idContainer280" class="IMG---Figure">
					<img src="image/Figure_14.13_B18681.jpg" alt="Figure 14.1﻿2 – MRI scans predicting the presence of an IDH1 gene mutation in brain tumors"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.12 – MRI scans predicting the presence of an IDH1 gene mutation in brain tumors</p>
			<p>When predicting the presence<a id="_idIndexMarker1768"/> of high-risk diseases, we should design systems that are compliant with healthcare standards. Let’s study a reference architecture using Google Cloud, which is compliant with <span class="No-Break">these standards.</span></p>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor306"/>Healthcare system architecture using Google Cloud</h2>
			<p>Now, let’s study the different cloud<a id="_idIndexMarker1769"/> components needed to design<a id="_idIndexMarker1770"/> a compliant, large-scale, distributed healthcare system for storing medical data and <span class="No-Break">disease diagnoses:</span></p>
			<ul>
				<li>DICOM imaging data obtained from radiological tests can be ingested via the Cloud Healthcare DICOM API for easy search and retrieval. This API also provides metadata extraction and data assimilation (stored in BigQuery) functionalities to infer advanced insights into disease prediction and <span class="No-Break">clinical investigations.</span></li>
				<li>Compliance with industry-wide <span class="No-Break">healthcare standards:</span><ul><li><strong class="bold">FHIR</strong>: An emerging healthcare data <span class="No-Break">interchange standard</span></li><li><strong class="bold">HL7v2</strong>: The most popular method for healthcare <span class="No-Break">systems integration</span></li><li><strong class="bold">DICOM</strong>: The dominant standard for the radiology and <span class="No-Break">imaging domain</span></li></ul></li>
			</ul>
			<p>Further, it also supports data format conversion using the Cloud Healthcare API and Cloud Dataflow from HL7v2 to FHIR format. In addition, it offers compliance with HIPAA in the US, the PIPEDA in Canada, and other global privacy standards.</p>
			<ul>
				<li>A unit equipped to detect <a id="_idIndexMarker1771"/>the arrival of new data <a id="_idIndexMarker1772"/>and send notifications via Cloud Pub/Sub to applications. This allows seamless integration with the HL7v2 <span class="No-Break">message-parsing stack.</span></li>
				<li>A data de-identification (via redaction or transformation) service to protect sensitive data elements that can be used for analysis, ML models, and other <span class="No-Break">use cases.</span></li>
				<li>Integration with Cloud Datalab and Cloud ML to explore large-scale datasets and train on DICOM radiological and natural-light images stored in Cloud Healthcare <span class="No-Break">API datasets:</span></li>
			</ul>
			<div>
				<div id="_idContainer281" class="IMG---Figure">
					<img src="image/Figure_14.14_B18681.jpg" alt="Figure 14.1﻿3 – Healthcare system architecture using Google Cloud"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.13 – Healthcare system architecture using Google Cloud</p>
			<p>Now, let’s learn how to build Responsible AI systems before a disease goes into remission, before a patient or group of patients progresses toward death (for example, during COVID-19), or to evaluate<a id="_idIndexMarker1773"/> different treatments within<a id="_idIndexMarker1774"/> a clinical trial. In such cases, we need to develop AI models using <span class="No-Break">survival analysis.</span></p>
			<h2 id="_idParaDest-277"><a id="_idTextAnchor307"/>Survival analysis for Responsible AI healthcare applications</h2>
			<p>Responsible AI applications<a id="_idIndexMarker1775"/> in the field of healthcare<a id="_idIndexMarker1776"/> require accurate predictions on the occurrence or likelihood of adverse events such as disease, hospitalization, and mortality. To solve such problems, we often use survival analysis, a statistical measure that can predict the time to failure and time to occurrence of events. In addition, survival analysis is capable of handling censoring (a kind of missing data problem) when expected events do not happen during the study, either because subjects of interest have not participated in the study or have left the study before the study ended. In such situations, a researcher might have partial information available on the survival times for the patients during the pandemic – for example, where patients were found to die due to diseases other than the virus. An example of this is when researchers wanted to study the average time it took for patients to start showing signs of infection of the virus but were missing data of individuals on account of not having proper data collection processes in place to authentically collect data over the period when a virus infects a <span class="No-Break">patient’s body.</span></p>
			<p>The following are the key capabilities that we need to have to build a responsible survival <span class="No-Break">analysis model:</span></p>
			<ul>
				<li>Survival regression with adjustments in scenarios of <span class="No-Break">domain shift</span></li>
				<li>Analysis of censored data and study of the impacts of different <span class="No-Break">censoring theories</span></li>
				<li>CF and treatment impact estimation <span class="No-Break">and evaluation</span></li>
				<li>Subgroup discovery and phenotyping to identify and stratify risk factors to <span class="No-Break">different groups</span></li>
				<li>The presence of multiple time-dependent and time-varying covariate observations per individual to help uncover temporal dependencies while estimating <span class="No-Break">time-to-event predictions</span></li>
				<li>Virtual twins survival regression (virtual twins enable visualization, modeling, and simulation of the entire environment with an enhanced experience) to understand individual behavior and responses to heterogeneous treatment effects of <span class="No-Break">an intervention</span></li>
			</ul>
			<p>Now, let’s look at an example<a id="_idIndexMarker1777"/> that uses the Cox proportional-hazards<a id="_idIndexMarker1778"/> deep neural network with the open source <strong class="source-inline">auton-survival</strong> package. This package helps evaluate the interactions in the model (through the proportional-hazard ratios) between a patient’s covariates and the treatment’s effectiveness and serves as a mechanism for suggesting personalized treatment recommendations. Let’s <span class="No-Break">get started:</span></p>
			<ol>
				<li>Let’s begin with the required library imports. Note that for this example, we are using the <strong class="source-inline">SUPPORT</strong> dataset, which comes with the <span class="No-Break"><strong class="source-inline">auton-survival</strong></span><span class="No-Break"> package:</span><pre class="console">
from auton_survival.estimators import SurvivalModel
from auton_survival.metrics import survival_regression_metric
from sklearn.model_selection import ParameterGrid
from estimators_demo_utils import plot_performance_metrics</pre></li>
				<li>Next, we will create the <strong class="source-inline">SurvivalModel</strong> object and use the <strong class="source-inline">fit</strong> function to train the model. The <strong class="source-inline">times</strong> variable we’ve set here is used to tune the model hyperparameters over<a id="_idIndexMarker1779"/> a certain period. We have<a id="_idIndexMarker1780"/> also provided the code for training, along with the output for a selected parameter, from the <strong class="source-inline">param_grid</strong> parameter <span class="No-Break">defined here:</span><pre class="console">
param_grid = {'bs': [100, 200],
              'learning_rate': [ 1e-4, 1e-3],
              'layers': [ [100], [100, 100]]
     }
params = ParameterGrid(param_grid)
times = np.quantile(y_tr['time'][y_tr['event']==1], np.linspace(0.1, 1, 10)).tolist()
model = SurvivalModel('dcph', random_seed=0, bs=param['bs'], learning_rate=param['learning_rate'], layers=param['layers'])
model.fit(x_tr, y_tr)</pre></li>
				<li>We must also compute the survival<a id="_idIndexMarker1781"/> probabilities for the validation set, along with the <strong class="bold">Integrated Brier </strong><span class="No-Break"><strong class="bold">Score</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">IBS</strong></span><span class="No-Break">):</span><pre class="console">
predictions_val = model.predict_survival(x_val, times)
metric_val = survival_regression_metric('ibs', y_val, predictions_val, times, y_tr)</pre></li>
				<li>Following this, we must obtain the survival probabilities on the test set. Further, we must also get the predicted outcome of a particular model over a selected hyperparameter. The <strong class="source-inline">times</strong> variable helps us fetch the model hyperparameters used at a <span class="No-Break">certain time:</span><pre class="console">
predictions_te = model.predict_survival(x_te, times)</pre></li>
				<li>Finally, we must evaluate the IBS and time-dependent concordance index for the test set. This determines the <span class="No-Break">model’s performance:</span><pre class="console">
results = dict()
results['Brier Score'] = survival_regression_metric('brs', outcomes=y_te, predictions=predictions_te, times=times, outcomes_train=y_tr)
results['Concordance Index'] = survival_regression_metric('ctd', outcomes=y_te, predictions=predictions_te, times=times, outcomes_train=y_tr)
plot_performance_metrics(results, times)</pre></li>
			</ol>
			<p>The final model<a id="_idIndexMarker1782"/> performance<a id="_idIndexMarker1783"/> statistics over the set of model hyperparameters are shown in the following plots:</p>
			<div>
				<div id="_idContainer282" class="IMG---Figure">
					<img src="image/Figure_14.15_B18681.jpg" alt="Figure 14.1﻿4 – Model performance overtuning with hyperparameters"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.14 – Model performance overtuning with hyperparameters</p>
			<p>In the preceding example, we learned how to use DeepSurv (a feed-forward deep neural network parameterized by the weights of the network) to evaluate an individual’s risk of failure (non-reactive to treatment, sometimes leading to death) by leveraging the impacts a patient’s covariates had on their hazard rate. In the healthcare industry, this serves in offering personalized treatment plans/recommendations by allowing us to study how effectively an individual reacted to the evaluated hazard rate based on the hazard-specific treatment. Furthermore, we can also undertake A/B testing by creating a target group (which receives the treatment recommendations) and a control group (which does not). We can run a log-rank test on the two groups’ outcomes to validate whether<a id="_idIndexMarker1784"/> the difference between the two subsets is significant, representing how effective <a id="_idIndexMarker1785"/>the treatment <span class="No-Break">recommendation was.</span></p>
			<p>Now that we understand the role survival analysis models have in terms of Responsible AI, let’s summarize what we have learned in <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-278"><a id="_idTextAnchor308"/>Summary</h1>
			<p>In this chapter, we examined a variety of AI use cases concerning the retail, supply chain, BFSI, and healthcare sectors. We saw the regulations and standards that retailers must follow to comply with privacy laws, and we understood, as advocates of Responsible AI, both the positive and negative consequences of dynamic pricing and how fair pricing can be achieved. Next, we delved into understanding CFs and their indispensable applications in the retail, supply chain, BFSI, and healthcare industries. Via examples, we learned how CFs help us in evaluating marketing campaigns, calculating conversion rates in the retail industry, understanding the impacts of delays, and mitigating them in supply chain pipelines. We also worked on a practical use case to dig into a loan application process and generate diverse CFs to see how they would impact the approval/rejection of a <span class="No-Break">loan application.</span></p>
			<p>We also understood the necessity of audits and Responsible AI regulations to regulate deepfakes, chatbots, and AR/VR/XR media. These innovations can endanger people’s lives through discriminatory and unethical misuse. Next, we studied how to build a scalable, compliant, and distributed healthcare system architecture. Finally, we gained insight into survival regression modeling and how it can help us evaluate and suggest effective patient <span class="No-Break">treatment methodologies.</span></p>
			<p>With this, we have covered the concepts surrounding platform and model design. We hope you are encouraged to further the knowledge you've acquired from this book and <span class="No-Break">keep learning!</span></p>
			<p>We hope you have enjoyed reading the book. With ChatGPT coming up and although Responsible AI being a significant aspect of it at this moment, we could not cover AI ethics related to the design of Large Language Models (LLMs), Metaverse, and Blockchain. Hopefully, we can in the <span class="No-Break">future versions.</span></p>
			<h1 id="_idParaDest-279"><a id="_idTextAnchor309"/>Further reading</h1>
			<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
			<ul>
				<li><em class="italic">The Cost of Fairness in AI: Evidence from E-Commerce – Moritz von Zahn, Stefan Feuerriegel, and Niklas </em><span class="No-Break"><em class="italic">Kuehl</em></span><span class="No-Break">: </span><a href="https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1681&amp;context=bise"><span class="No-Break">https://aisel.aisnet.org/cgi/viewcontent.cgi?article=1681&amp;context=bise</span></a></li>
				<li><em class="italic">Using Causal Inference to Improve the Uber User </em><span class="No-Break"><em class="italic">Experience</em></span><span class="No-Break">:</span><span class="No-Break"><em class="italic"> </em></span><a href="https://www.uber.com/blog/causal-inference-at-uber/"><span class="No-Break">https://www.uber.com/blog/causal-inference-at-uber/</span></a></li>
				<li><em class="italic">How AI Can Help Companies Set Prices More </em><span class="No-Break"><em class="italic">Ethically</em></span><span class="No-Break">: </span><a href="https://hbr.org/2021/03/how-ai-can-help-companies-set-prices-more-ethically"><span class="No-Break">https://hbr.org/2021/03/how-ai-can-help-companies-set-prices-more-ethically</span></a></li>
				<li><em class="italic">Supply Chain Root Cause Analysis with Causal </em><span class="No-Break"><em class="italic">AI</em></span><span class="No-Break">: </span><a href="https://medium.com/causalens/supply-chain-root-cause-analysis-with-causal-ai-be73c78441f2"><span class="No-Break">https://medium.com/causalens/supply-chain-root-cause-analysis-with-causal-ai-be73c78441f2</span></a></li>
				<li><em class="italic">DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural </em><span class="No-Break"><em class="italic">network</em></span><span class="No-Break">:</span><span class="No-Break"><em class="italic"> </em></span><a href="https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0482-1"><span class="No-Break">https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0482-1</span></a></li>
				<li><em class="italic">Can Artificial Intelligence Help See Cancer in New, and Better, </em><span class="No-Break"><em class="italic">Ways?</em></span><span class="No-Break">:</span><span class="No-Break"><em class="italic"> </em></span><a href="https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging"><span class="No-Break">https://www.cancer.gov/news-events/cancer-currents-blog/2022/artificial-intelligence-cancer-imaging</span></a></li>
				<li><em class="italic">auton-survival: an Open-Source Package for Regression, Counterfactual Estimation, Evaluation and Phenotyping with Censored Time-to-Event </em><span class="No-Break"><em class="italic">Data</em></span><span class="No-Break">: </span><a href="https://www.cs.cmu.edu/~chiragn/papers/auton_survival.pdf"><span class="No-Break">https://www.cs.cmu.edu/~chiragn/papers/auton_survival.pdf</span></a></li>
				<li><em class="italic">The Cost of Fairness in AI: Evidence from </em><span class="No-Break"><em class="italic">E-Commerce</em></span><span class="No-Break">: </span><a href="https://link.springer.com/article/10.1007/s12599-021-00716-w"><span class="No-Break">https://link.springer.com/article/10.1007/s12599-021-00716-w</span></a></li>
				<li><em class="italic">Fairness ideals in inventory </em><span class="No-Break"><em class="italic">allocation</em></span><span class="No-Break">: </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/deci.12540"><span class="No-Break">https://onlinelibrary.wiley.com/doi/full/10.1111/deci.12540</span></a></li>
				<li><em class="italic">India Debates Skin-Tone Bias as Beauty Companies Alter </em><span class="No-Break"><em class="italic">Ads</em></span><span class="No-Break">: </span><a href="https://www.nytimes.com/2020/06/28/world/asia/india-skin-color-unilever.html"><span class="No-Break">https://www.nytimes.com/2020/06/28/world/asia/india-skin-color-unilever.html</span></a></li>
				<li><em class="italic">The Ethics of Realism in Virtual and Augmented </em><span class="No-Break"><em class="italic">Reality</em></span><span class="No-Break">: </span><a href="https://www.frontiersin.org/articles/10.3389/frvir.2020.00001/full"><span class="No-Break">https://www.frontiersin.org/articles/10.3389/frvir.2020.00001/full</span></a></li>
				<li><em class="italic">What are the risks of virtual reality and augmented reality, and what good practices does ANSES </em><span class="No-Break"><em class="italic">recommend?</em></span><span class="No-Break">: </span><a href="https://www.anses.fr/en/content/what-are-risks-virtual-reality-and-augmented-reality-and-what-good-practices-does-anses"><span class="No-Break">https://www.anses.fr/en/content/what-are-risks-virtual-reality-and-augmented-reality-and-what-good-practices-does-anses</span></a></li>
				<li><em class="italic">Google Cloud Platform: Healthcare Solutions </em><span class="No-Break"><em class="italic">Playbook</em></span><span class="No-Break">:</span><span class="No-Break"><em class="italic"> </em></span><a href="https://cloud.nih.gov/resources/guides/science-at-cloud-providers/science-on-gcp/GCPHealthcareSolutionsPlaybook.pdf"><span class="No-Break">https://cloud.nih.gov/resources/guides/science-at-cloud-providers/science-on-gcp/GCPHealthcareSolutionsPlaybook.pdf</span></a></li>
			</ul>
		</div>
	</body></html>