["```py\n    import joblib\n    from verta import Client\n    from verta.dataset import Path\n    from sklearn import ensemble\n    ```", "```py\n    modeldb_client = Client(\"http://localhost:3000\")\n    proj = modeldb_client.set_project(\"Model Classification\")\n    expt = modeldb_client.set_experiment(\"ModelDB Experiment\")\n    run = modeldb_client.set_experiment_run(\"First Run\")\n    dataset = modeldb_client.set_dataset(name = \"Diabetes Data\")\n    save_path = '/tmp/modeldb_model_artifacts/'\n    dataset_version = dataset.create_version(Path(save_path))\n    run.log_dataset_version(\"v1\", dataset_version)\n    diabetes = datasets.load_diabetes()\n    X, y = diabetes.data, diabetes.target\n    ```", "```py\n    reg_model = ensemble.GradientBoostingRegressor()\n    cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=3, random_state=1)\n    grid_search = GridSearchCV(estimator=reg_model, param_grid=params, n_jobs=-1, cv=cv, scoring='r2',error_score=0)\n    grid_result = grid_search.fit(X, y)\n    ```", "```py\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    run.log_metric(\"r2\", grid_result.best_score_)\n    means = grid_result.cv_results_['mean_test_score']\n    stds = grid_result.cv_results_['std_test_score']\n    params = grid_result.cv_results_['params']\n    i = 0\n    for mean, stdev, param in zip(means, stds, params):\n        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n        run.log_observation(\"mean\", mean)\n        run.log_observation(\"stdev\", stdev)\n        param_dict = dict(param)\n        param_dict['iter'] = str(i)\n        i = i +1\n        run.log_observation(\"lr\", param_dict['learning_rate'])\n        run.log_observation(\"loss\", param_dict['loss'])\n        run.log_observation(\"maxdepth\", param_dict['max_depth'])\n        run.log_observation(\"minsamplesplit\", param_dict['min_samples_split'])\n        run.log_observation(\"nestimator\", param_dict['n_estimators'])\n        run.log_observation(\"iter\", param_dict['iter'])\n    grid_result.fit(X_train, y_train)\n    y_pred = grid_result.predict(X_test)\n    train_score = grid_result.score(X_train, y_train)\n    test_score = grid_result.score(X_test, y_test)\n    run.log_metric(\"Accuracy_train\", train_score)\n    run.log_metric(\"Accuracy_test\", test_score)\n    ```", "```py\n    run.log_metric(\"mse\", mse)\n    run.log_hyperparameters(grid_result.best_params_)\n    filename_2 = \"simple_model_gbr_2.joblib\"\n    joblib.dump(grid_result, filename_2)\n    run.log_model(save_path, filename_2)\n    test_score = np.zeros((grid_result.best_params_[\"n_estimators\"],), dtype=np.float64)\n    best_model = grid_result.best_estimator_\n    print(\"test score shape\", test_score.shape)\n    for i, y_pred in enumerate(best_model.staged_predict(X_test)):\n        test_score[i] = best_model.loss_(y_test, y_pred)\n        run.log_observation(\"testscore\", test_score[i])\n    ```", "```py\n    fig = plt.figure(figsize=(6, 6))\n    plt.subplot(1, 1, 1)\n    plt.title(\"Deviance\")\n    plt.plot(np.arange(grid_result.best_params_[\"n_estimators\"]) + 1,\n        best_model.train_score_,\n        \"b-\",\n        label=\"Training Set Deviance\",\n    )\n    plt.plot(np.arange(grid_result.best_params_[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n    )\n    plt.legend(loc=\"upper right\")\n    plt.xlabel(\"Boosting Iterations\")\n    plt.ylabel(\"Deviance\")\n    fig.tight_layout()\n    plt.savefig(save_path + 'perf_gbr.png')\n    run.log_artifact(\"perf_gbr\", save_path + 'perf_gbr.png')\n    ```", "```py\n    import wandb\n    wandb.login(key='') #please specify our own login key\n    ```", "```py\n    for _ in range(5):\n    wandb.init(\n    project=\"pytorch-intro\",\n    config={\n    \"epochs\": 20,\n    \"batch_size\": 64,\n    \"lr\": 1e-3,\n    \"dropout\": random.uniform(0.02, 0.90),\n    })\n    config = wandb.config\n    ```", "```py\n    model = get_model(config.dropout)\n    loss_func = nn.CrossEntropyLoss()\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)example_ct = 0\n    step_ct = 0\n    for epoch in range(config.epochs):\n    model.train()\n    for step, (images, labels) in enumerate(train_dl):\n    images, labels = images.to(device), labels.to(device)\n    outputs = model(images)\n    train_loss = loss_func(outputs, labels)\n    optimizer.zero_grad()\n    train_loss.backward()\n    optimizer.step()\n    example_ct += len(images)\n    metrics = {\"train/train_loss\": train_loss,\n    \"train/epoch\": (step + 1 + (n_steps_per_epoch * epoch)) / n_steps_per_epoch,\n    \"train/example_ct\": example_ct}\n    if step + 1 < n_steps_per_epoch:\n    wandb.log(metrics)\n    step_ct += 1\n    val_loss, accuracy = validate_model(model, valid_dl, loss_func, log_images=(epoch==(config.epochs-1)))\n    ```", "```py\n    val_metrics = {\"val/val_loss\": val_loss,\n    \"val/val_accuracy\": accuracy}\n    wandb.log({**metrics, **val_metrics})\n    print(f\"Train Loss: {train_loss:.3f}, Valid Loss: {val_loss:3f}, Accuracy: {accuracy:.2f}\")\n    wandb.summary['test_accuracy'] = 0.8\n    wandb.finish()\n    ```", "```py\n    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(10)])\n    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n    table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n    wandb.log({\"predictions_table\":table}, commit=False)\n    ```", "```py\ncurl -v -H 'Accept: application/json, text/plain, */*' -H 'Content-Type: application/json;charset=UTF-8' -u admin:admin -d @lineage.json\n```", "```py\n    http://localhost:21000/api/atlas/entities\n    ```", "```py\n    curl -X DELETE -u admin:admin -H 'Content-Type: application/json; charset=UTF-8' 127.0.0.1:21000/api/atlas/entities?guid=febdc024-a3f8-4a66-be88-1e719c23db35\n    ```", "```py\n    import feast\n    from joblib import dump\n    import pandas as pd\n    from sklearn.linear_model import LinearRegression\n    orders = pd.read_csv(\"/content/feast-driver-ranking-tutorial/driver_orders.csv\", sep=\"\\t\")\n    orders[\"event_timestamp\"] = pd.to_datetime(orders[\"event_timestamp\"])\n    ```", "```py\n    fs = feast.FeatureStore(repo_path=\"/content/feast-driver-ranking-tutorial/driver_ranking\")\n    training_df = fs.get_historical_features(\n    entity_df=orders,\n    feature_refs=[\n    \"driver_hourly_stats:conv_rate\",\n    \"driver_hourly_stats:acc_rate\",\n    \"driver_hourly_stats:avg_daily_trips\",\n    ],\n    ).to_df()\n    print(\"----- Feature schema -----\\n\")\n    print(training_df.info)\n    ```", "```py\n    target = \"trip_completed\"\n    reg = LinearRegression()\n    train_X = training_df[training_df.columns.drop(target).drop(\"event_timestamp\")]\n    train_Y = training_df.loc[:, target]\n    reg.fit(train_X[sorted(train_X)], train_Y)\n    dump(reg, \"driver_model.bin\")\n    ```", "```py\n    !cd /content/feast-driver-ranking-tutorial/driver_ranking/ && feast materialize-incremental 2022-01-01T00:00:00\n    ```", "```py\n    self.fs = feast.FeatureStore(repo_path=\"/content/feast-driver-ranking-tutorial/driver_ranking/\")\n    # Read features from Feast\n    driver_features = self.fs.get_online_features(\n    entity_rows=[{\"driver_id\": driver_id} for driver_id in driver_ids],\n    features=[\n    \"driver_hourly_stats:conv_rate\",\n    \"driver_hourly_stats:acc_rate\",\n    \"driver_hourly_stats:avg_daily_trips\",\n    ],\n    )\n    df = pd.DataFrame.from_dict(driver_features.to_dict())\n    df[\"prediction\"] = reg.predict(df[sorted(df)])\n     best_driver_id = df[\"driver_id\"].iloc[df[\"prediction\"].argmax()]\n    ```"]